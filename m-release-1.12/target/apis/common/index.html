<!--
Licensed to the Apache Software Foundation (ASF) under one
or more contributor license agreements.  See the NOTICE file
distributed with this work for additional information
regarding copyright ownership.  The ASF licenses this file
to you under the Apache License, Version 2.0 (the
"License"); you may not use this file except in compliance
with the License.  You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing,
software distributed under the License is distributed on an
"AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
KIND, either express or implied.  See the License for the
specific language governing permissions and limitations
under the License.
-->
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->
    <title>Apache Flink 1.1-SNAPSHOT Documentation: Basic API Concepts</title>
    <link rel="shortcut icon" href="/page/favicon.ico" type="image/x-icon">
    <link rel="icon" href="/page/favicon.ico" type="image/x-icon">

    <!-- Bootstrap -->
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.4/css/bootstrap.min.css">
    <link rel="stylesheet" href="/page/css/flink.css">
    <link rel="stylesheet" href="/page/css/syntax.css">
    <link rel="stylesheet" href="/page/css/codetabs.css">
    
    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
      <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->
  </head>
  <body>
    
    





    <!-- Top navbar. -->
    <nav class="navbar navbar-default navbar-fixed-top">
      <div class="container">
        <!-- The logo. -->
        <div class="navbar-header">
          <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1">
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </button>
          <div class="navbar-logo">
            <a href="http://flink.apache.org"><img alt="Apache Flink" src="/page/img/navbar-brand-logo.jpg"></a>
          </div>
        </div><!-- /.navbar-header -->

        <!-- The navigation links. -->
        <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
          <ul class="nav navbar-nav">
            <li class="hidden-sm "><a href="/">Docs v1.1</a></li>

            <li class=""><a href="/concepts/concepts.html">Concepts</a></li>

            <!-- Setup -->
            <li class="dropdown">
              <a href="/setup" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">Setup <span class="caret"></span></a>
              <ul class="dropdown-menu" role="menu">
                
                
                <li class=""><a href="/setup/building.html">Build Flink from Source</a></li>
                
                <li class=""><a href="/setup/config.html">Configuration</a></li>
                

                <li class="divider"></li>
                <li role="presentation" class="dropdown-header"><strong>Quickstart</strong></li>

                <!-- Quickstart -->
                
                
                <li class=""><a href="/quickstart/setup_quickstart.html">Setup & Run Example</a></li>
                
                <li class=""><a href="/quickstart/java_api_quickstart.html">Java API</a></li>
                
                <li class=""><a href="/quickstart/scala_api_quickstart.html">Scala API</a></li>
                

                <li class="divider"></li>
                <li role="presentation" class="dropdown-header"><strong>Deployment</strong></li>
                
                
                <li class=""><a href="/setup/local_setup.html">Local</a></li>
                
                <li class=""><a href="/setup/cluster_setup.html">Cluster (Standalone)</a></li>
                
                <li class=""><a href="/setup/yarn_setup.html">YARN</a></li>
                
                <li class=""><a href="/setup/gce_setup.html">Google Compute Engine</a></li>
                
                <li class=""><a href="/setup/aws.html">AWS</a></li>
                
                <li class=""><a href="/setup/jobmanager_high_availability.html">High Availability</a></li>
                
              </ul>
            </li>

            <!-- Programming Guides -->
            <li class="dropdown active">
              <a href="/apis" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">Programming Guides <span class="caret"></span></a>
              <ul class="dropdown-menu" role="menu">
                
                
                <li class="active"><a href="/apis/common/index.html"><strong>Basic API Concepts</strong></a></li>
                
                <li class=""><a href="/apis/streaming/index.html"><strong>Streaming Guide</strong> (DataStream API)</a></li>
                
                <li class=""><a href="/apis/batch/index.html"><strong>Batch Guide</strong> (DataSet API)</a></li>
                
                <li class=""><a href="/apis/best_practices.html">Best Practices</a></li>
                
                <li class=""><a href="/apis/table.html">Table API and SQL</a></li>
                
                <li class=""><a href="/apis/cli.html">Command-Line Interface</a></li>
                
                <li class=""><a href="/apis/local_execution.html">Local Execution</a></li>
                
                <li class=""><a href="/apis/cluster_execution.html">Cluster Execution</a></li>
                
                <li class=""><a href="/apis/scala_shell.html">Scala Shell</a></li>
                
                <li class=""><a href="/apis/scala_api_extensions.html">Scala API Extensions</a></li>
                
                <li class=""><a href="/apis/java8.html">Java 8</a></li>
                
              </ul>
            </li>

            <!-- Libraries -->
            <li class="dropdown">
              <a href="/libs" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">Libraries <span class="caret"></span></a>
                <ul class="dropdown-menu" role="menu">
                  
                  
                  <li class=""><a href="/apis/batch/libs/gelly.html">Graphs: Gelly</a></li>
                  
                  <li class=""><a href="/apis/streaming/libs/cep.html">CEP</a></li>
                  
                  <li class=""><a href="/apis/batch/libs/ml/index.html">Machine Learning</a></li>
                  
              </ul>
            </li>

            <!-- Internals -->
            <li class="dropdown">
              <a href="/internals" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">Internals <span class="caret"></span></a>
              <ul class="dropdown-menu" role="menu">
                <li role="presentation" class="dropdown-header"><strong>Contribute</strong></li>
                <li><a href="http://flink.apache.org/how-to-contribute.html"><small><span class="glyphicon glyphicon-new-window"></span></small> How to Contribute</a></li>
                <li><a href="http://flink.apache.org/contribute-code.html#coding-guidelines"><small><span class="glyphicon glyphicon-new-window"></span></small> Coding Guidelines</a></li>
                
                
                <li class=""><a href="/internals/ide_setup.html">IDE Setup</a></li>
                
                <li class=""><a href="/internals/logging.html">Logging</a></li>
                
                <li class=""><a href="/internals/general_arch.html">Architecture and Process Model</a></li>
                
                <li class=""><a href="/internals/stream_checkpointing.html">Fault Tolerance for Data Streaming</a></li>
                
                <li class=""><a href="/internals/types_serialization.html">Type Extraction and Serialization</a></li>
                
                <li class=""><a href="/internals/monitoring_rest_api.html">Monitoring REST API</a></li>
                
                <li class=""><a href="/internals/job_scheduling.html">Jobs and Scheduling</a></li>
                
                <li class=""><a href="/internals/add_operator.html">How-To: Add an Operator</a></li>
                
                <li class=""><a href="/internals/back_pressure_monitoring.html">Back Pressure Monitoring</a></li>
                
              </ul>
            </li>
          </ul>
          <form class="navbar-form navbar-right hidden-sm hidden-md" role="search" action="/search-results.html">
            <div class="form-group">
              <input type="text" class="form-control" size="16px" name="q" placeholder="Search all pages">
            </div>
            <button type="submit" class="btn btn-default">Search</button>
          </form>
        </div><!-- /.navbar-collapse -->
      </div><!-- /.container -->
    </nav>


    

    <!-- Main content. -->
    <div class="container">
      
      
<div class="row">

  
  <div class="col-md-8 col-md-offset-2 text">
    <!-- Artifact name change warning. Remove for the 1.0 release. -->
    <div class="panel panel-default">
      <div class="panel-body"><strong>Important</strong>: Maven artifacts which depend on Scala are now suffixed with the Scala major version, e.g. "2.10" or "2.11". Please consult the <a href="https://cwiki.apache.org/confluence/display/FLINK/Maven+artifact+names+suffixed+with+Scala+version">migration guide on the project Wiki</a>.</div>
    </div>

    <h1>Basic API Concepts</h1>


<p>Flink programs are regular programs that implement transformations on distributed collections
(e.g., filtering, mapping, updating state, joining, grouping, defining windows, aggregating).
Collections are initially created from sources (e.g., by reading files, kafka, or from local
collections). Results are returned via sinks, which may for example write the data to
(distributed) files, or to standard output (for example the command line terminal).
Flink programs run in a variety of contexts, standalone, or embedded in other programs.
The execution can happen in a local JVM, or on clusters of many machines.</p>

<p>Depending on the type of data sources, i.e. bounded or unbounded sources you would either
write a batch program or a streaming program where the DataSet API is used for the former
and the DataStream API is used for the latter. This guide will introduce the basic concepts
that are common to both APIs but please see our
<a href="/apis/streaming/index.html">Streaming Guide</a> and
<a href="/apis/batch/index.html">Batch Guide</a> for concrete information about
writing programs with each API.</p>

<p><strong>NOTE:</strong> When showing actual examples of how the APIs can be used  we will use
<code>StreamingExecutionEnvironment</code> and the <code>DataStream</code> API. The concepts are exactly the same
in the <code>DataSet</code> API, just replace by <code>ExecutionEnvironment</code> and <code>DataSet</code>.</p>

<ul id="markdown-toc">
  <li><a href="#linking-with-flink" id="markdown-toc-linking-with-flink">Linking with Flink</a></li>
  <li><a href="#dataset-and-datastream" id="markdown-toc-dataset-and-datastream">DataSet and DataStream</a></li>
  <li><a href="#anatomy-of-a-flink-program" id="markdown-toc-anatomy-of-a-flink-program">Anatomy of a Flink Program</a></li>
  <li><a href="#lazy-evaluation" id="markdown-toc-lazy-evaluation">Lazy Evaluation</a></li>
  <li><a href="#specifying-keys" id="markdown-toc-specifying-keys">Specifying Keys</a></li>
  <li><a href="#specifying-transformation-functions" id="markdown-toc-specifying-transformation-functions">Specifying Transformation Functions</a></li>
  <li><a href="#supported-data-types" id="markdown-toc-supported-data-types">Supported Data Types</a></li>
  <li><a href="#execution-configuration" id="markdown-toc-execution-configuration">Execution Configuration</a></li>
  <li><a href="#program-packaging-and-distributed-execution" id="markdown-toc-program-packaging-and-distributed-execution">Program Packaging and Distributed Execution</a></li>
  <li><a href="#accumulators--counters" id="markdown-toc-accumulators--counters">Accumulators &amp; Counters</a></li>
  <li><a href="#parallel-execution" id="markdown-toc-parallel-execution">Parallel Execution</a>    <ul>
      <li><a href="#operator-level" id="markdown-toc-operator-level">Operator Level</a></li>
      <li><a href="#execution-environment-level" id="markdown-toc-execution-environment-level">Execution Environment Level</a></li>
      <li><a href="#client-level" id="markdown-toc-client-level">Client Level</a></li>
      <li><a href="#system-level" id="markdown-toc-system-level">System Level</a></li>
    </ul>
  </li>
  <li><a href="#execution-plans" id="markdown-toc-execution-plans">Execution Plans</a></li>
</ul>

<h2 id="linking-with-flink">Linking with Flink</h2>

<p>To write programs with Flink, you need to include the Flink library corresponding to
your programming language in your project.</p>

<p>The simplest way to do this is to use one of the quickstart scripts: either for
<a href="/quickstart/java_api_quickstart.html">Java</a> or for <a href="/quickstart/scala_api_quickstart.html">Scala</a>. They
create a blank project from a template (a Maven Archetype), which sets up everything for you. To
manually create the project, you can use the archetype and create a project by calling:</p>

<div class="codetabs">
  <div data-lang="java">

    <div class="highlight"><pre><code class="language-bash" data-lang="bash">mvn archetype:generate <span class="se">\</span>
    -DarchetypeGroupId<span class="o">=</span>org.apache.flink <span class="se">\</span>
    -DarchetypeArtifactId<span class="o">=</span>flink-quickstart-java <span class="se">\</span>
    -DarchetypeVersion<span class="o">=</span>1.1-SNAPSHOT</code></pre></div>

  </div>
  <div data-lang="scala">

    <div class="highlight"><pre><code class="language-bash" data-lang="bash">mvn archetype:generate <span class="se">\</span>
    -DarchetypeGroupId<span class="o">=</span>org.apache.flink <span class="se">\</span>
    -DarchetypeArtifactId<span class="o">=</span>flink-quickstart-scala <span class="se">\</span>
    -DarchetypeVersion<span class="o">=</span>1.1-SNAPSHOT</code></pre></div>

  </div>
</div>

<p>The archetypes are working for stable releases and preview versions (<code>-SNAPSHOT</code>).</p>

<p>If you want to add Flink to an existing Maven project, add the following entry to your
<em>dependencies</em> section in the <em>pom.xml</em> file of your project:</p>

<div class="codetabs">
  <div data-lang="java">

    <div class="highlight"><pre><code class="language-xml" data-lang="xml"><span class="c">&lt;!-- Use this dependency if you are using the DataStream API --&gt;</span>
<span class="nt">&lt;dependency&gt;</span>
  <span class="nt">&lt;groupId&gt;</span>org.apache.flink<span class="nt">&lt;/groupId&gt;</span>
  <span class="nt">&lt;artifactId&gt;</span>flink-streaming-java_2.10<span class="nt">&lt;/artifactId&gt;</span>
  <span class="nt">&lt;version&gt;</span>1.1-SNAPSHOT<span class="nt">&lt;/version&gt;</span>
<span class="nt">&lt;/dependency&gt;</span>
<span class="c">&lt;!-- Use this dependency if you are using the DataSet API --&gt;</span>
<span class="nt">&lt;dependency&gt;</span>
  <span class="nt">&lt;groupId&gt;</span>org.apache.flink<span class="nt">&lt;/groupId&gt;</span>
  <span class="nt">&lt;artifactId&gt;</span>flink-java<span class="nt">&lt;/artifactId&gt;</span>
  <span class="nt">&lt;version&gt;</span>1.1-SNAPSHOT<span class="nt">&lt;/version&gt;</span>
<span class="nt">&lt;/dependency&gt;</span>
<span class="nt">&lt;dependency&gt;</span>
  <span class="nt">&lt;groupId&gt;</span>org.apache.flink<span class="nt">&lt;/groupId&gt;</span>
  <span class="nt">&lt;artifactId&gt;</span>flink-clients_2.10<span class="nt">&lt;/artifactId&gt;</span>
  <span class="nt">&lt;version&gt;</span>1.1-SNAPSHOT<span class="nt">&lt;/version&gt;</span>
<span class="nt">&lt;/dependency&gt;</span></code></pre></div>

  </div>
  <div data-lang="scala">

    <div class="highlight"><pre><code class="language-xml" data-lang="xml"><span class="c">&lt;!-- Use this dependency if you are using the DataStream API --&gt;</span>
<span class="nt">&lt;dependency&gt;</span>
  <span class="nt">&lt;groupId&gt;</span>org.apache.flink<span class="nt">&lt;/groupId&gt;</span>
  <span class="nt">&lt;artifactId&gt;</span>flink-streaming-scala_2.10<span class="nt">&lt;/artifactId&gt;</span>
  <span class="nt">&lt;version&gt;</span>1.1-SNAPSHOT<span class="nt">&lt;/version&gt;</span>
<span class="nt">&lt;/dependency&gt;</span>
<span class="c">&lt;!-- Use this dependency if you are using the DataSet API --&gt;</span>
<span class="nt">&lt;dependency&gt;</span>
  <span class="nt">&lt;groupId&gt;</span>org.apache.flink<span class="nt">&lt;/groupId&gt;</span>
  <span class="nt">&lt;artifactId&gt;</span>flink-scala_2.10<span class="nt">&lt;/artifactId&gt;</span>
  <span class="nt">&lt;version&gt;</span>1.1-SNAPSHOT<span class="nt">&lt;/version&gt;</span>
<span class="nt">&lt;/dependency&gt;</span>
<span class="nt">&lt;dependency&gt;</span>
  <span class="nt">&lt;groupId&gt;</span>org.apache.flink<span class="nt">&lt;/groupId&gt;</span>
  <span class="nt">&lt;artifactId&gt;</span>flink-clients_2.10<span class="nt">&lt;/artifactId&gt;</span>
  <span class="nt">&lt;version&gt;</span>1.1-SNAPSHOT<span class="nt">&lt;/version&gt;</span>
<span class="nt">&lt;/dependency&gt;</span></code></pre></div>

    <p><strong>Important:</strong> When working with the Scala API you must have one of these two imports:</p>

    <div class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">import</span> <span class="nn">org.apache.flink.api.scala._</span></code></pre></div>

    <p>or</p>

    <div class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">import</span> <span class="nn">org.apache.flink.api.scala.createTypeInformation</span></code></pre></div>

    <p>The reason is that Flink analyzes the types that are used in a program and generates serializers
and comparaters for them. By having either of those imports you enable an implicit conversion
that creates the type information for Flink operations.</p>
  </div>
</div>

<h4 id="scala-dependency-versions">Scala Dependency Versions</h4>

<p>Because Scala 2.10 binary is not compatible with Scala 2.11 binary, we provide multiple artifacts
to support both Scala versions.</p>

<p>Starting from the 0.10 line, we cross-build all Flink modules for both 2.10 and 2.11. If you want
to run your program on Flink with Scala 2.11, you need to add a <code>_2.11</code> suffix to the <code>artifactId</code>
values of the Flink modules in your dependencies section.</p>

<p>If you are looking for building Flink with Scala 2.11, please check
<a href="/setup/building.html#scala-versions">build guide</a>.</p>

<h4 id="hadoop-dependency-versions">Hadoop Dependency Versions</h4>

<p>If you are using Flink together with Hadoop, the version of the dependency may vary depending on the
version of Hadoop (or more specifically, HDFS) that you want to use Flink with. Please refer to the
<a href="http://flink.apache.org/downloads.html">downloads page</a> for a list of available versions, and instructions
on how to link with custom versions of Hadoop.</p>

<p>In order to link against the latest SNAPSHOT versions of the code, please follow
<a href="http://flink.apache.org/how-to-contribute.html#snapshots-nightly-builds">this guide</a>.</p>

<p>The <em>flink-clients</em> dependency is only necessary to invoke the Flink program locally (for example to
run it standalone for testing and debugging).  If you intend to only export the program as a JAR
file and <a href="/apis/cluster_execution.html">run it on a cluster</a>, you can skip that dependency.</p>

<p><a href="#top" class="top pull-right"><span class="glyphicon glyphicon-chevron-up"></span> Back to top</a></p>

<h2 id="dataset-and-datastream">DataSet and DataStream</h2>

<p>Flink has the special classes <code>DataSet</code> and <code>DataStream</code> to represent data in a program. You
can think of them as immutable collections of data that can contain duplicates. In the case
of <code>DataSet</code> the data is finite while for a <code>DataStream</code> the number of elements can be unbounded.</p>

<p>These collections differ from regular Java collections in some key ways. First, they
are immutable, meaning that once they are created you cannot add or remove elements. You can also
not simply inspect the elements inside.</p>

<p>A collection is initially created by adding a source in a Flink program and new collections are
derived from these by transforming them using API methods such as <code>map</code>, <code>filter</code> and so on.</p>

<h2 id="anatomy-of-a-flink-program">Anatomy of a Flink Program</h2>

<p>Flink program programs look like regular programs that transform collections of data.
Each program consists of the same basic parts:</p>

<ol>
  <li>Obtain an <code>execution environment</code>,</li>
  <li>Load/create the initial data,</li>
  <li>Specify transformations on this data,</li>
  <li>Specify where to put the results of your computations,</li>
  <li>Trigger the program execution</li>
</ol>

<div class="codetabs">
  <div data-lang="java">

    <p>We will now give an overview of each of those steps, please refer to the respective sections for
more details. Note that all core classes of the Java DataSet API are found in the package
<a href="https://github.com/apache/flink/blob/master//flink-java/src/main/java/org/apache/flink/api/java">org.apache.flink.api.java</a>
while the classes of the Java DataStream API can be found in
<a href="https://github.com/apache/flink/blob/master//flink-streaming-java/src/main/java/org/apache/flink/streaming/api">org.apache.flink.streaming.api</a>.</p>

    <p>The <code>StreamExecutionEnvironment</code> is the basis for all Flink programs. You can
obtain one using these static methods on <code>StreamExecutionEnvironment</code>:</p>

    <div class="highlight"><pre><code class="language-java" data-lang="java"><span class="n">getExecutionEnvironment</span><span class="o">()</span>

<span class="n">createLocalEnvironment</span><span class="o">()</span>

<span class="n">createRemoteEnvironment</span><span class="o">(</span><span class="n">String</span> <span class="n">host</span><span class="o">,</span> <span class="kt">int</span> <span class="n">port</span><span class="o">,</span> <span class="n">String</span><span class="o">...</span> <span class="n">jarFiles</span><span class="o">)</span></code></pre></div>

    <p>Typically, you only need to use <code>getExecutionEnvironment()</code>, since this
will do the right thing depending on the context: if you are executing
your program inside an IDE or as a regular Java program it will create
a local environment that will execute your program on your local machine. If
you created a JAR file from your program, and invoke it through the
<a href="/apis/cli.html">command line</a>, the Flink cluster manager
will execute your main method and <code>getExecutionEnvironment()</code> will return
an execution environment for executing your program on a cluster.</p>

    <p>For specifying data sources the execution environment has several methods
to read from files using various methods: you can just read them line by line,
as CSV files, or using completely custom data input formats. To just read
a text file as a sequence of lines, you can use:</p>

    <div class="highlight"><pre><code class="language-java" data-lang="java"><span class="kd">final</span> <span class="n">StreamExecutionEnvironment</span> <span class="n">env</span> <span class="o">=</span> <span class="n">StreamExecutionEnvironment</span><span class="o">.</span><span class="na">getExecutionEnvironment</span><span class="o">();</span>

<span class="n">DataStream</span><span class="o">&lt;</span><span class="n">String</span><span class="o">&gt;</span> <span class="n">text</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="na">readTextFile</span><span class="o">(</span><span class="s">&quot;file:///path/to/file&quot;</span><span class="o">);</span></code></pre></div>

    <p>This will give you a DataStream on which you can then apply transformations to create new
derived DataStreams.</p>

    <p>You apply transformations by calling methods on DataStream with a transformation
functions. For example, a map transformation looks like this:</p>

    <div class="highlight"><pre><code class="language-java" data-lang="java"><span class="n">DataStream</span><span class="o">&lt;</span><span class="n">String</span><span class="o">&gt;</span> <span class="n">input</span> <span class="o">=</span> <span class="o">...;</span>

<span class="n">DataStream</span><span class="o">&lt;</span><span class="n">Integer</span><span class="o">&gt;</span> <span class="n">parsed</span> <span class="o">=</span> <span class="n">input</span><span class="o">.</span><span class="na">map</span><span class="o">(</span><span class="k">new</span> <span class="n">MapFunction</span><span class="o">&lt;</span><span class="n">String</span><span class="o">,</span> <span class="n">Integer</span><span class="o">&gt;()</span> <span class="o">{</span>
    <span class="nd">@Override</span>
    <span class="kd">public</span> <span class="n">Integer</span> <span class="nf">map</span><span class="o">(</span><span class="n">String</span> <span class="n">value</span><span class="o">)</span> <span class="o">{</span>
        <span class="k">return</span> <span class="n">Integer</span><span class="o">.</span><span class="na">parseInt</span><span class="o">(</span><span class="n">value</span><span class="o">);</span>
    <span class="o">}</span>
<span class="o">});</span></code></pre></div>

    <p>This will create a new DataStream by converting every String in the original
collection to an Integer.</p>

    <p>Once you have a DataStream containing your final results, you can write it to an outside system
by creating a sink. These are just some example methods for creating a sink:</p>

    <div class="highlight"><pre><code class="language-java" data-lang="java"><span class="n">writeAsText</span><span class="o">(</span><span class="n">String</span> <span class="n">path</span><span class="o">)</span>

<span class="n">print</span><span class="o">()</span></code></pre></div>

  </div>
  <div data-lang="scala">

    <p>We will now give an overview of each of those steps, please refer to the respective sections for
more details. Note that all core classes of the Scala DataSet API are found in the package
<a href="https://github.com/apache/flink/blob/master//flink-scala/src/main/scala/org/apache/flink/api/scala">org.apache.flink.api.scala</a>
while the classes of the Scala DataStream API can be found in
<a href="https://github.com/apache/flink/blob/master//flink-streaming-scala/src/main/java/org/apache/flink/streaming/api/scala">org.apache.flink.streaming.api.scala</a>.</p>

    <p>The <code>StreamExecutionEnvironment</code> is the basis for all Flink programs. You can
obtain one using these static methods on <code>StreamExecutionEnvironment</code>:</p>

    <div class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="n">getExecutionEnvironment</span><span class="o">()</span>

<span class="n">createLocalEnvironment</span><span class="o">()</span>

<span class="n">createRemoteEnvironment</span><span class="o">(</span><span class="n">host</span><span class="k">:</span> <span class="kt">String</span><span class="o">,</span> <span class="n">port</span><span class="k">:</span> <span class="kt">Int</span><span class="o">,</span> <span class="n">jarFiles</span><span class="k">:</span> <span class="kt">String*</span><span class="o">)</span></code></pre></div>

    <p>Typically, you only need to use <code>getExecutionEnvironment()</code>, since this
will do the right thing depending on the context: if you are executing
your program inside an IDE or as a regular Java program it will create
a local environment that will execute your program on your local machine. If
you created a JAR file from your program, and invoke it through the
<a href="/apis/cli.html">command line</a>, the Flink cluster manager
will execute your main method and <code>getExecutionEnvironment()</code> will return
an execution environment for executing your program on a cluster.</p>

    <p>For specifying data sources the execution environment has several methods
to read from files using various methods: you can just read them line by line,
as CSV files, or using completely custom data input formats. To just read
a text file as a sequence of lines, you can use:</p>

    <div class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">env</span> <span class="k">=</span> <span class="nc">StreamExecutionEnvironment</span><span class="o">.</span><span class="n">getExecutionEnvironment</span><span class="o">()</span>

<span class="k">val</span> <span class="n">text</span><span class="k">:</span> <span class="kt">DataStream</span><span class="o">[</span><span class="kt">String</span><span class="o">]</span> <span class="k">=</span> <span class="n">env</span><span class="o">.</span><span class="n">readTextFile</span><span class="o">(</span><span class="s">&quot;file:///path/to/file&quot;</span><span class="o">)</span></code></pre></div>

    <p>This will give you a DataStream on which you can then apply transformations to create new
derived DataStreams.</p>

    <p>You apply transformations by calling methods on DataSet with a transformation
functions. For example, a map transformation looks like this:</p>

    <div class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">input</span><span class="k">:</span> <span class="kt">DataSet</span><span class="o">[</span><span class="kt">String</span><span class="o">]</span> <span class="k">=</span> <span class="o">...</span>

<span class="k">val</span> <span class="n">mapped</span> <span class="k">=</span> <span class="n">input</span><span class="o">.</span><span class="n">map</span> <span class="o">{</span> <span class="n">x</span> <span class="k">=&gt;</span> <span class="n">x</span><span class="o">.</span><span class="n">toInt</span> <span class="o">}</span></code></pre></div>

    <p>This will create a new DataStream by converting every String in the original
collection to an Integer.</p>

    <p>Once you have a DataStream containing your final results, you can write it to an outside system
by creating a sink. These are just some example methods for creating a sink:</p>

    <div class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="n">writeAsText</span><span class="o">(</span><span class="n">path</span><span class="k">:</span> <span class="kt">String</span><span class="o">)</span>

<span class="n">print</span><span class="o">()</span></code></pre></div>

  </div>
</div>

<p>Once you specified the complete program you need to <strong>trigger the program execution</strong> by calling
<code>execute()</code> on the <code>StreamExecutionEnvironment</code>.
Depending on the type of the <code>ExecutionEnvironment</code> the execution will be triggered on your local
machine or submit your program for execution on a cluster.</p>

<p>The <code>execute()</code> method is returning a <code>JobExecutionResult</code>, this contains execution
times and accumulator results.</p>

<p>Please see the <a href="/apis/streaming/index.html">Streaming Guide</a>
for information about streaming data sources and sink and for more in-depths information
about the supported transformations on DataStream.</p>

<p>Check out the <a href="/apis/batch/index.html">Batch Guide</a>
for information about batch data sources and sink and for more in-depths information
about the supported transformations on DataSet.</p>

<p><a href="#top" class="top pull-right"><span class="glyphicon glyphicon-chevron-up"></span> Back to top</a></p>

<h2 id="lazy-evaluation">Lazy Evaluation</h2>

<p>All Flink programs are executed lazily: When the program’s main method is executed, the data loading
and transformations do not happen directly. Rather, each operation is created and added to the
program’s plan. The operations are actually executed when the execution is explicitly triggered by
an <code>execute()</code> call on the execution environment. Whether the program is executed locally
or on a cluster depends on the type of execution environment</p>

<p>The lazy evaluation lets you construct sophisticated programs that Flink executes as one
holistically planned unit.</p>

<p><a href="#top" class="top pull-right"><span class="glyphicon glyphicon-chevron-up"></span> Back to top</a></p>

<h2 id="specifying-keys">Specifying Keys</h2>

<p>Some transformations (join, coGroup, keyBy, groupBy) require that a key be defined on
a collection of elements. Other transformations (Reduce, GroupReduce,
Aggregate, Windows) allow data being grouped on a key before they are
applied.</p>

<p>A DataSet is grouped as</p>

<div class="highlight"><pre><code class="language-java" data-lang="java"><span class="n">DataSet</span><span class="o">&lt;...&gt;</span> <span class="n">input</span> <span class="o">=</span> <span class="c1">// [...]</span>
<span class="n">DataSet</span><span class="o">&lt;...&gt;</span> <span class="n">reduced</span> <span class="o">=</span> <span class="n">input</span>
  <span class="o">.</span><span class="na">groupBy</span><span class="o">(</span><span class="cm">/*define key here*/</span><span class="o">)</span>
  <span class="o">.</span><span class="na">reduceGroup</span><span class="o">(</span><span class="cm">/*do something*/</span><span class="o">);</span></code></pre></div>

<p>while a key can be specified on a DataStream using</p>

<div class="highlight"><pre><code class="language-java" data-lang="java"><span class="n">DataStream</span><span class="o">&lt;...&gt;</span> <span class="n">input</span> <span class="o">=</span> <span class="c1">// [...]</span>
<span class="n">DataStream</span><span class="o">&lt;...&gt;</span> <span class="n">windowed</span> <span class="o">=</span> <span class="n">input</span>
  <span class="o">.</span><span class="na">key</span><span class="o">(</span><span class="cm">/*define key here*/</span><span class="o">)</span>
  <span class="o">.</span><span class="na">window</span><span class="o">(</span><span class="cm">/*window specification*/</span><span class="o">);</span></code></pre></div>

<p>The data model of Flink is not based on key-value pairs. Therefore,
you do not need to physically pack the data set types into keys and
values. Keys are “virtual”: they are defined as functions over the
actual data to guide the grouping operator.</p>

<p><strong>NOTE:</strong> In the following discussion we will use the <code>DataStream</code> API and <code>keyBy</code>.
For the DataSet API you just have to replace by <code>DataSet</code> and <code>groupBy</code>.</p>

<h3 class="no_toc" id="define-keys-for-tuples">Define keys for Tuples</h3>

<p>The simplest case is grouping Tuples on one or more
fields of the Tuple:</p>

<div class="codetabs">
  <div data-lang="java">

    <div class="highlight"><pre><code class="language-java" data-lang="java"><span class="n">DataStream</span><span class="o">&lt;</span><span class="n">Tuple3</span><span class="o">&lt;</span><span class="n">Integer</span><span class="o">,</span><span class="n">String</span><span class="o">,</span><span class="n">Long</span><span class="o">&gt;&gt;</span> <span class="n">input</span> <span class="o">=</span> <span class="c1">// [...]</span>
<span class="n">KeyedStream</span><span class="o">&lt;</span><span class="n">Tuple3</span><span class="o">&lt;</span><span class="n">Integer</span><span class="o">,</span><span class="n">String</span><span class="o">,</span><span class="n">Long</span><span class="o">&gt;</span> <span class="n">keyed</span> <span class="o">=</span> <span class="n">input</span><span class="o">.</span><span class="na">keyBy</span><span class="o">(</span><span class="mi">0</span><span class="o">)</span></code></pre></div>

  </div>
  <div data-lang="scala">

    <div class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">input</span><span class="k">:</span> <span class="kt">DataStream</span><span class="o">[(</span><span class="kt">Int</span>, <span class="kt">String</span>, <span class="kt">Long</span><span class="o">)]</span> <span class="k">=</span> <span class="c1">// [...]</span>
<span class="k">val</span> <span class="n">keyed</span> <span class="k">=</span> <span class="n">input</span><span class="o">.</span><span class="n">keyBy</span><span class="o">(</span><span class="mi">0</span><span class="o">)</span></code></pre></div>

  </div>
</div>

<p>The tuples is grouped on the first field (the one of
Integer type).</p>

<div class="codetabs">
  <div data-lang="java">

    <div class="highlight"><pre><code class="language-java" data-lang="java"><span class="n">DataStream</span><span class="o">&lt;</span><span class="n">Tuple3</span><span class="o">&lt;</span><span class="n">Integer</span><span class="o">,</span><span class="n">String</span><span class="o">,</span><span class="n">Long</span><span class="o">&gt;&gt;</span> <span class="n">input</span> <span class="o">=</span> <span class="c1">// [...]</span>
<span class="n">KeyedStream</span><span class="o">&lt;</span><span class="n">Tuple3</span><span class="o">&lt;</span><span class="n">Integer</span><span class="o">,</span><span class="n">String</span><span class="o">,</span><span class="n">Long</span><span class="o">&gt;</span> <span class="n">keyed</span> <span class="o">=</span> <span class="n">input</span><span class="o">.</span><span class="na">keyBy</span><span class="o">(</span><span class="mi">0</span><span class="o">,</span><span class="mi">1</span><span class="o">)</span></code></pre></div>

  </div>
  <div data-lang="scala">

    <div class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">input</span><span class="k">:</span> <span class="kt">DataSet</span><span class="o">[(</span><span class="kt">Int</span>, <span class="kt">String</span>, <span class="kt">Long</span><span class="o">)]</span> <span class="k">=</span> <span class="c1">// [...]</span>
<span class="k">val</span> <span class="n">grouped</span> <span class="k">=</span> <span class="n">input</span><span class="o">.</span><span class="n">groupBy</span><span class="o">(</span><span class="mi">0</span><span class="o">,</span><span class="mi">1</span><span class="o">)</span></code></pre></div>

  </div>
</div>

<p>Here, we group the tuples on a composite key consisting of the first and the
second field.</p>

<p>A note on nested Tuples: If you have a DataStream with a nested tuple, such as:</p>

<div class="highlight"><pre><code class="language-java" data-lang="java"><span class="n">DataStream</span><span class="o">&lt;</span><span class="n">Tuple3</span><span class="o">&lt;</span><span class="n">Tuple2</span><span class="o">&lt;</span><span class="n">Integer</span><span class="o">,</span> <span class="n">Float</span><span class="o">&gt;,</span><span class="n">String</span><span class="o">,</span><span class="n">Long</span><span class="o">&gt;&gt;</span> <span class="n">ds</span><span class="o">;</span></code></pre></div>

<p>Specifying <code>keyBy(0)</code> will cause the system to use the full <code>Tuple2</code> as a key (with the Integer and Float being the key). If you want to “navigate” into the nested <code>Tuple2</code>, you have to use field expression keys which are explained below.</p>

<h3 class="no_toc" id="define-keys-using-field-expressions">Define keys using Field Expressions</h3>

<p>You can use String-based field expressions to reference nested fields and define keys for grouping, sorting, joining, or coGrouping.</p>

<p>Field expressions make it very easy to select fields in (nested) composite types such as <a href="#tuples-and-case-classes">Tuple</a> and <a href="#pojos">POJO</a> types.</p>

<div class="codetabs">
  <div data-lang="java">

    <p>In the example below, we have a <code>WC</code> POJO with two fields “word” and “count”. To group by the field <code>word</code>, we just pass its name to the <code>groupBy()</code> function.</p>

    <div class="highlight"><pre><code class="language-java" data-lang="java"><span class="c1">// some ordinary POJO (Plain old Java Object)</span>
<span class="kd">public</span> <span class="kd">class</span> <span class="nc">WC</span> <span class="o">{</span>
  <span class="kd">public</span> <span class="n">String</span> <span class="n">word</span><span class="o">;</span>
  <span class="kd">public</span> <span class="kt">int</span> <span class="n">count</span><span class="o">;</span>
<span class="o">}</span>
<span class="n">DataStream</span><span class="o">&lt;</span><span class="n">WC</span><span class="o">&gt;</span> <span class="n">words</span> <span class="o">=</span> <span class="c1">// [...]</span>
<span class="n">DataStream</span><span class="o">&lt;</span><span class="n">WC</span><span class="o">&gt;</span> <span class="n">wordCounts</span> <span class="o">=</span> <span class="n">words</span><span class="o">.</span><span class="na">keyBy</span><span class="o">(</span><span class="s">&quot;word&quot;</span><span class="o">).</span><span class="na">window</span><span class="o">(</span><span class="cm">/*window specification*/</span><span class="o">);</span></code></pre></div>

    <p><strong>Field Expression Syntax</strong>:</p>

    <ul>
      <li>
        <p>Select POJO fields by their field name. For example <code>"user"</code> refers to the “user” field of a POJO type.</p>
      </li>
      <li>
        <p>Select Tuple fields by their field name or 0-offset field index. For example <code>"f0"</code> and <code>"5"</code> refer to the first and sixth field of a Java Tuple type, respectively.</p>
      </li>
      <li>
        <p>You can select nested fields in POJOs and Tuples. For example <code>"user.zip"</code> refers to the “zip” field of a POJO which is stored in the “user” field of a POJO type. Arbitrary nesting and mixing of POJOs and Tuples is supported such as <code>"f1.user.zip"</code> or <code>"user.f3.1.zip"</code>.</p>
      </li>
      <li>
        <p>You can select the full type using the <code>"*"</code> wildcard expressions. This does also work for types which are not Tuple or POJO types.</p>
      </li>
    </ul>

    <p><strong>Field Expression Example</strong>:</p>

    <div class="highlight"><pre><code class="language-java" data-lang="java"><span class="kd">public</span> <span class="kd">static</span> <span class="kd">class</span> <span class="nc">WC</span> <span class="o">{</span>
  <span class="kd">public</span> <span class="n">ComplexNestedClass</span> <span class="n">complex</span><span class="o">;</span> <span class="c1">//nested POJO</span>
  <span class="kd">private</span> <span class="kt">int</span> <span class="n">count</span><span class="o">;</span>
  <span class="c1">// getter / setter for private field (count)</span>
  <span class="kd">public</span> <span class="kt">int</span> <span class="nf">getCount</span><span class="o">()</span> <span class="o">{</span>
    <span class="k">return</span> <span class="n">count</span><span class="o">;</span>
  <span class="o">}</span>
  <span class="kd">public</span> <span class="kt">void</span> <span class="nf">setCount</span><span class="o">(</span><span class="kt">int</span> <span class="n">c</span><span class="o">)</span> <span class="o">{</span>
    <span class="k">this</span><span class="o">.</span><span class="na">count</span> <span class="o">=</span> <span class="n">c</span><span class="o">;</span>
  <span class="o">}</span>
<span class="o">}</span>
<span class="kd">public</span> <span class="kd">static</span> <span class="kd">class</span> <span class="nc">ComplexNestedClass</span> <span class="o">{</span>
  <span class="kd">public</span> <span class="n">Integer</span> <span class="n">someNumber</span><span class="o">;</span>
  <span class="kd">public</span> <span class="kt">float</span> <span class="n">someFloat</span><span class="o">;</span>
  <span class="kd">public</span> <span class="n">Tuple3</span><span class="o">&lt;</span><span class="n">Long</span><span class="o">,</span> <span class="n">Long</span><span class="o">,</span> <span class="n">String</span><span class="o">&gt;</span> <span class="n">word</span><span class="o">;</span>
  <span class="kd">public</span> <span class="n">IntWritable</span> <span class="n">hadoopCitizen</span><span class="o">;</span>
<span class="o">}</span></code></pre></div>

    <p>These are valid field expressions for the example code above:</p>

    <ul>
      <li>
        <p><code>"count"</code>: The count field in the <code>WC</code> class.</p>
      </li>
      <li>
        <p><code>"complex"</code>: Recursively selects all fields of the field complex of POJO type <code>ComplexNestedClass</code>.</p>
      </li>
      <li>
        <p><code>"complex.word.f2"</code>: Selects the last field of the nested <code>Tuple3</code>.</p>
      </li>
      <li>
        <p><code>"complex.hadoopCitizen"</code>: Selects the Hadoop <code>IntWritable</code> type.</p>
      </li>
    </ul>

  </div>
  <div data-lang="scala">

    <p>In the example below, we have a <code>WC</code> POJO with two fields “word” and “count”. To group by the field <code>word</code>, we just pass its name to the <code>groupBy()</code> function.</p>

    <div class="highlight"><pre><code class="language-java" data-lang="java"><span class="c1">// some ordinary POJO (Plain old Java Object)</span>
<span class="kd">class</span> <span class="nf">WC</span><span class="o">(</span><span class="n">var</span> <span class="nl">word:</span> <span class="n">String</span><span class="o">,</span> <span class="n">var</span> <span class="nl">count:</span> <span class="n">Int</span><span class="o">)</span> <span class="o">{</span>
  <span class="n">def</span> <span class="nf">this</span><span class="o">()</span> <span class="o">{</span> <span class="k">this</span><span class="o">(</span><span class="s">&quot;&quot;</span><span class="o">,</span> <span class="mi">0L</span><span class="o">)</span> <span class="o">}</span>
<span class="o">}</span>
<span class="n">val</span> <span class="nl">words:</span> <span class="n">DataStream</span><span class="o">[</span><span class="n">WC</span><span class="o">]</span> <span class="o">=</span> <span class="c1">// [...]</span>
<span class="n">val</span> <span class="n">wordCounts</span> <span class="o">=</span> <span class="n">words</span><span class="o">.</span><span class="na">keyBy</span><span class="o">(</span><span class="s">&quot;word&quot;</span><span class="o">).</span><span class="na">window</span><span class="o">(</span><span class="cm">/*window specification*/</span><span class="o">)</span>

<span class="c1">// or, as a case class, which is less typing</span>
<span class="k">case</span> <span class="kd">class</span> <span class="nf">WC</span><span class="o">(</span><span class="nl">word:</span> <span class="n">String</span><span class="o">,</span> <span class="nl">count:</span> <span class="n">Int</span><span class="o">)</span>
<span class="n">val</span> <span class="nl">words:</span> <span class="n">DataStream</span><span class="o">[</span><span class="n">WC</span><span class="o">]</span> <span class="o">=</span> <span class="c1">// [...]</span>
<span class="n">val</span> <span class="n">wordCounts</span> <span class="o">=</span> <span class="n">words</span><span class="o">.</span><span class="na">keyBy</span><span class="o">(</span><span class="s">&quot;word&quot;</span><span class="o">).</span><span class="na">reduce</span><span class="o">(</span><span class="cm">/*window specification*/</span><span class="o">)</span></code></pre></div>

    <p><strong>Field Expression Syntax</strong>:</p>

    <ul>
      <li>
        <p>Select POJO fields by their field name. For example <code>"user"</code> refers to the “user” field of a POJO type.</p>
      </li>
      <li>
        <p>Select Tuple fields by their 1-offset field name or 0-offset field index. For example <code>"_1"</code> and <code>"5"</code> refer to the first and sixth field of a Scala Tuple type, respectively.</p>
      </li>
      <li>
        <p>You can select nested fields in POJOs and Tuples. For example <code>"user.zip"</code> refers to the “zip” field of a POJO which is stored in the “user” field of a POJO type. Arbitrary nesting and mixing of POJOs and Tuples is supported such as <code>"_2.user.zip"</code> or <code>"user._4.1.zip"</code>.</p>
      </li>
      <li>
        <p>You can select the full type using the <code>"_"</code> wildcard expressions. This does also work for types which are not Tuple or POJO types.</p>
      </li>
    </ul>

    <p><strong>Field Expression Example</strong>:</p>

    <div class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">class</span> <span class="nc">WC</span><span class="o">(</span><span class="k">var</span> <span class="n">complex</span><span class="k">:</span> <span class="kt">ComplexNestedClass</span><span class="o">,</span> <span class="k">var</span> <span class="n">count</span><span class="k">:</span> <span class="kt">Int</span><span class="o">)</span> <span class="o">{</span>
  <span class="k">def</span> <span class="k">this</span><span class="o">()</span> <span class="o">{</span> <span class="k">this</span><span class="o">(</span><span class="kc">null</span><span class="o">,</span> <span class="mi">0</span><span class="o">)</span> <span class="o">}</span>
<span class="o">}</span>

<span class="k">class</span> <span class="nc">ComplexNestedClass</span><span class="o">(</span>
    <span class="k">var</span> <span class="n">someNumber</span><span class="k">:</span> <span class="kt">Int</span><span class="o">,</span>
    <span class="n">someFloat</span><span class="k">:</span> <span class="kt">Float</span><span class="o">,</span>
    <span class="n">word</span><span class="k">:</span> <span class="o">(</span><span class="kt">Long</span><span class="o">,</span> <span class="kt">Long</span><span class="o">,</span> <span class="nc">String</span><span class="o">),</span>
    <span class="n">hadoopCitizen</span><span class="k">:</span> <span class="kt">IntWritable</span><span class="o">)</span> <span class="o">{</span>
  <span class="k">def</span> <span class="k">this</span><span class="o">()</span> <span class="o">{</span> <span class="k">this</span><span class="o">(</span><span class="mi">0</span><span class="o">,</span> <span class="mi">0</span><span class="o">,</span> <span class="o">(</span><span class="mi">0</span><span class="o">,</span> <span class="mi">0</span><span class="o">,</span> <span class="s">&quot;&quot;</span><span class="o">),</span> <span class="k">new</span> <span class="nc">IntWritable</span><span class="o">(</span><span class="mi">0</span><span class="o">))</span> <span class="o">}</span>
<span class="o">}</span></code></pre></div>

    <p>These are valid field expressions for the example code above:</p>

    <ul>
      <li>
        <p><code>"count"</code>: The count field in the <code>WC</code> class.</p>
      </li>
      <li>
        <p><code>"complex"</code>: Recursively selects all fields of the field complex of POJO type <code>ComplexNestedClass</code>.</p>
      </li>
      <li>
        <p><code>"complex.word._3"</code>: Selects the last field of the nested <code>Tuple3</code>.</p>
      </li>
      <li>
        <p><code>"complex.hadoopCitizen"</code>: Selects the Hadoop <code>IntWritable</code> type.</p>
      </li>
    </ul>

  </div>
</div>

<h3 class="no_toc" id="define-keys-using-key-selector-functions">Define keys using Key Selector Functions</h3>

<p>An additional way to define keys are “key selector” functions. A key selector function
takes a single element as input and returns the key for the element. The key can be of any type and be derived from arbitrary computations.</p>

<p>The following example shows a key selector function that simply returns the field of an object:</p>

<div class="codetabs">
  <div data-lang="java">

    <div class="highlight"><pre><code class="language-java" data-lang="java"><span class="c1">// some ordinary POJO</span>
<span class="kd">public</span> <span class="kd">class</span> <span class="nc">WC</span> <span class="o">{</span><span class="kd">public</span> <span class="n">String</span> <span class="n">word</span><span class="o">;</span> <span class="kd">public</span> <span class="kt">int</span> <span class="n">count</span><span class="o">;}</span>
<span class="n">DataStream</span><span class="o">&lt;</span><span class="n">WC</span><span class="o">&gt;</span> <span class="n">words</span> <span class="o">=</span> <span class="c1">// [...]</span>
<span class="n">KeyedStream</span><span class="o">&lt;</span><span class="n">WC</span><span class="o">&gt;</span> <span class="n">kyed</span> <span class="o">=</span> <span class="n">words</span>
  <span class="o">.</span><span class="na">keyBy</span><span class="o">(</span><span class="k">new</span> <span class="n">KeySelector</span><span class="o">&lt;</span><span class="n">WC</span><span class="o">,</span> <span class="n">String</span><span class="o">&gt;()</span> <span class="o">{</span>
     <span class="kd">public</span> <span class="n">String</span> <span class="nf">getKey</span><span class="o">(</span><span class="n">WC</span> <span class="n">wc</span><span class="o">)</span> <span class="o">{</span> <span class="k">return</span> <span class="n">wc</span><span class="o">.</span><span class="na">word</span><span class="o">;</span> <span class="o">}</span>
   <span class="o">});</span></code></pre></div>

  </div>
  <div data-lang="scala">

    <div class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="c1">// some ordinary case class</span>
<span class="k">case</span> <span class="k">class</span> <span class="nc">WC</span><span class="o">(</span><span class="n">word</span><span class="k">:</span> <span class="kt">String</span><span class="o">,</span> <span class="n">count</span><span class="k">:</span> <span class="kt">Int</span><span class="o">)</span>
<span class="k">val</span> <span class="n">words</span><span class="k">:</span> <span class="kt">DataStream</span><span class="o">[</span><span class="kt">WC</span><span class="o">]</span> <span class="k">=</span> <span class="c1">// [...]</span>
<span class="k">val</span> <span class="n">keyed</span> <span class="k">=</span> <span class="n">words</span><span class="o">.</span><span class="n">keyBy</span><span class="o">(</span> <span class="k">_</span><span class="o">.</span><span class="n">word</span> <span class="o">)</span></code></pre></div>

  </div>
</div>

<p><a href="#top" class="top pull-right"><span class="glyphicon glyphicon-chevron-up"></span> Back to top</a></p>

<h2 id="specifying-transformation-functions">Specifying Transformation Functions</h2>

<p>Most transformations require user-defined functions. This section lists different ways
of how they can be specified</p>

<div class="codetabs">
  <div data-lang="java">

    <h4 id="implementing-an-interface">Implementing an interface</h4>

    <p>The most basic way is to implement one of the provided interfaces:</p>

    <div class="highlight"><pre><code class="language-java" data-lang="java"><span class="kd">class</span> <span class="nc">MyMapFunction</span> <span class="kd">implements</span> <span class="n">MapFunction</span><span class="o">&lt;</span><span class="n">String</span><span class="o">,</span> <span class="n">Integer</span><span class="o">&gt;</span> <span class="o">{</span>
  <span class="kd">public</span> <span class="n">Integer</span> <span class="nf">map</span><span class="o">(</span><span class="n">String</span> <span class="n">value</span><span class="o">)</span> <span class="o">{</span> <span class="k">return</span> <span class="n">Integer</span><span class="o">.</span><span class="na">parseInt</span><span class="o">(</span><span class="n">value</span><span class="o">);</span> <span class="o">}</span>
<span class="o">});</span>
<span class="n">data</span><span class="o">.</span><span class="na">map</span><span class="o">(</span><span class="k">new</span> <span class="nf">MyMapFunction</span><span class="o">());</span></code></pre></div>

    <h4 id="anonymous-classes">Anonymous classes</h4>

    <p>You can pass a function as an anonymous class:</p>

    <div class="highlight"><pre><code class="language-java" data-lang="java"><span class="n">data</span><span class="o">.</span><span class="na">map</span><span class="o">(</span><span class="k">new</span> <span class="n">MapFunction</span><span class="o">&lt;</span><span class="n">String</span><span class="o">,</span> <span class="n">Integer</span><span class="o">&gt;</span> <span class="o">()</span> <span class="o">{</span>
  <span class="kd">public</span> <span class="n">Integer</span> <span class="nf">map</span><span class="o">(</span><span class="n">String</span> <span class="n">value</span><span class="o">)</span> <span class="o">{</span> <span class="k">return</span> <span class="n">Integer</span><span class="o">.</span><span class="na">parseInt</span><span class="o">(</span><span class="n">value</span><span class="o">);</span> <span class="o">}</span>
<span class="o">});</span></code></pre></div>

    <h4 id="java-8-lambdas">Java 8 Lambdas</h4>

    <p>Flink also supports Java 8 Lambdas in the Java API. Please see the full <a href="/apis/java8.html">Java 8 Guide</a>.</p>

    <div class="highlight"><pre><code class="language-java" data-lang="java"><span class="n">data</span><span class="o">.</span><span class="na">filter</span><span class="o">(</span><span class="n">s</span> <span class="o">-&gt;</span> <span class="n">s</span><span class="o">.</span><span class="na">startsWith</span><span class="o">(</span><span class="s">&quot;http://&quot;</span><span class="o">));</span></code></pre></div>

    <div class="highlight"><pre><code class="language-java" data-lang="java"><span class="n">data</span><span class="o">.</span><span class="na">reduce</span><span class="o">((</span><span class="n">i1</span><span class="o">,</span><span class="n">i2</span><span class="o">)</span> <span class="o">-&gt;</span> <span class="n">i1</span> <span class="o">+</span> <span class="n">i2</span><span class="o">);</span></code></pre></div>

    <h4 id="rich-functions">Rich functions</h4>

    <p>All transformations that require a user-defined function can
instead take as argument a <em>rich</em> function. For example, instead of</p>

    <div class="highlight"><pre><code class="language-java" data-lang="java"><span class="kd">class</span> <span class="nc">MyMapFunction</span> <span class="kd">implements</span> <span class="n">MapFunction</span><span class="o">&lt;</span><span class="n">String</span><span class="o">,</span> <span class="n">Integer</span><span class="o">&gt;</span> <span class="o">{</span>
  <span class="kd">public</span> <span class="n">Integer</span> <span class="nf">map</span><span class="o">(</span><span class="n">String</span> <span class="n">value</span><span class="o">)</span> <span class="o">{</span> <span class="k">return</span> <span class="n">Integer</span><span class="o">.</span><span class="na">parseInt</span><span class="o">(</span><span class="n">value</span><span class="o">);</span> <span class="o">}</span>
<span class="o">});</span></code></pre></div>

    <p>you can write</p>

    <div class="highlight"><pre><code class="language-java" data-lang="java"><span class="kd">class</span> <span class="nc">MyMapFunction</span> <span class="kd">extends</span> <span class="n">RichMapFunction</span><span class="o">&lt;</span><span class="n">String</span><span class="o">,</span> <span class="n">Integer</span><span class="o">&gt;</span> <span class="o">{</span>
  <span class="kd">public</span> <span class="n">Integer</span> <span class="nf">map</span><span class="o">(</span><span class="n">String</span> <span class="n">value</span><span class="o">)</span> <span class="o">{</span> <span class="k">return</span> <span class="n">Integer</span><span class="o">.</span><span class="na">parseInt</span><span class="o">(</span><span class="n">value</span><span class="o">);</span> <span class="o">}</span>
<span class="o">});</span></code></pre></div>

    <p>and pass the function as usual to a <code>map</code> transformation:</p>

    <div class="highlight"><pre><code class="language-java" data-lang="java"><span class="n">data</span><span class="o">.</span><span class="na">map</span><span class="o">(</span><span class="k">new</span> <span class="nf">MyMapFunction</span><span class="o">());</span></code></pre></div>

    <p>Rich functions can also be defined as an anonymous class:</p>

    <div class="highlight"><pre><code class="language-java" data-lang="java"><span class="n">data</span><span class="o">.</span><span class="na">map</span> <span class="o">(</span><span class="k">new</span> <span class="n">RichMapFunction</span><span class="o">&lt;</span><span class="n">String</span><span class="o">,</span> <span class="n">Integer</span><span class="o">&gt;()</span> <span class="o">{</span>
  <span class="kd">public</span> <span class="n">Integer</span> <span class="nf">map</span><span class="o">(</span><span class="n">String</span> <span class="n">value</span><span class="o">)</span> <span class="o">{</span> <span class="k">return</span> <span class="n">Integer</span><span class="o">.</span><span class="na">parseInt</span><span class="o">(</span><span class="n">value</span><span class="o">);</span> <span class="o">}</span>
<span class="o">});</span></code></pre></div>

  </div>
  <div data-lang="scala">

    <h4 id="lambda-functions">Lambda Functions</h4>

    <p>As already seen in previous examples all operations accept lambda functions for describing
the operation:</p>

    <div class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">data</span><span class="k">:</span> <span class="kt">DataSet</span><span class="o">[</span><span class="kt">String</span><span class="o">]</span> <span class="k">=</span> <span class="c1">// [...]</span>
<span class="n">data</span><span class="o">.</span><span class="n">filter</span> <span class="o">{</span> <span class="k">_</span><span class="o">.</span><span class="n">startsWith</span><span class="o">(</span><span class="s">&quot;http://&quot;</span><span class="o">)</span> <span class="o">}</span></code></pre></div>

    <div class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">data</span><span class="k">:</span> <span class="kt">DataSet</span><span class="o">[</span><span class="kt">Int</span><span class="o">]</span> <span class="k">=</span> <span class="c1">// [...]</span>
<span class="n">data</span><span class="o">.</span><span class="n">reduce</span> <span class="o">{</span> <span class="o">(</span><span class="n">i1</span><span class="o">,</span><span class="n">i2</span><span class="o">)</span> <span class="k">=&gt;</span> <span class="n">i1</span> <span class="o">+</span> <span class="n">i2</span> <span class="o">}</span>
<span class="c1">// or</span>
<span class="n">data</span><span class="o">.</span><span class="n">reduce</span> <span class="o">{</span> <span class="k">_</span> <span class="o">+</span> <span class="k">_</span> <span class="o">}</span></code></pre></div>

    <h4 id="rich-functions-1">Rich functions</h4>

    <p>All transformations that take as argument a lambda function can
instead take as argument a <em>rich</em> function. For example, instead of</p>

    <div class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="n">data</span><span class="o">.</span><span class="n">map</span> <span class="o">{</span> <span class="n">x</span> <span class="k">=&gt;</span> <span class="n">x</span><span class="o">.</span><span class="n">toInt</span> <span class="o">}</span></code></pre></div>

    <p>you can write</p>

    <div class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">class</span> <span class="nc">MyMapFunction</span> <span class="k">extends</span> <span class="nc">RichMapFunction</span><span class="o">[</span><span class="kt">String</span>, <span class="kt">Int</span><span class="o">]</span> <span class="o">{</span>
  <span class="k">def</span> <span class="n">map</span><span class="o">(</span><span class="n">in</span><span class="k">:</span> <span class="kt">String</span><span class="o">)</span><span class="k">:</span><span class="kt">Int</span> <span class="o">=</span> <span class="o">{</span> <span class="n">in</span><span class="o">.</span><span class="n">toInt</span> <span class="o">}</span>
<span class="o">})</span></code></pre></div>

    <p>and pass the function to a <code>map</code> transformation:</p>

    <div class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="n">data</span><span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="k">new</span> <span class="nc">MyMapFunction</span><span class="o">())</span></code></pre></div>

    <p>Rich functions can also be defined as an anonymous class:</p>

    <div class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="n">data</span><span class="o">.</span><span class="n">map</span> <span class="o">(</span><span class="k">new</span> <span class="nc">RichMapFunction</span><span class="o">[</span><span class="kt">String</span>, <span class="kt">Int</span><span class="o">]</span> <span class="o">{</span>
  <span class="k">def</span> <span class="n">map</span><span class="o">(</span><span class="n">in</span><span class="k">:</span> <span class="kt">String</span><span class="o">)</span><span class="k">:</span><span class="kt">Int</span> <span class="o">=</span> <span class="o">{</span> <span class="n">in</span><span class="o">.</span><span class="n">toInt</span> <span class="o">}</span>
<span class="o">})</span></code></pre></div>

  </div>

</div>

<p>Rich functions provide, in addition to the user-defined function (map,
reduce, etc), four methods: <code>open</code>, <code>close</code>, <code>getRuntimeContext</code>, and
<code>setRuntimeContext</code>. These are useful for parameterizing the function
(see <a href="/apis/batch/index.html#passing-parameters-to-functions">Passing Parameters to Functions</a>),
creating and finalizing local state, accessing broadcast variables (see
<a href="/apis/batch/index.html#broadcast-variables">Broadcast Variables</a>, and for accessing runtime
information such as accumulators and counters (see
<a href="#accumulators--counters">Accumulators and Counters</a>, and information
on iterations (see <a href="/apis/batch/index.htmliterations.html">Iterations</a>).</p>

<p><a href="#top" class="top pull-right"><span class="glyphicon glyphicon-chevron-up"></span> Back to top</a></p>

<h2 id="supported-data-types">Supported Data Types</h2>

<p>Flink places some restrictions on the type of elements that can be in a DataSet or DataStream.
The reason for this is that the system analyzes the types to determine
efficient execution strategies.</p>

<p>There are six different categories of data types:</p>

<ol>
  <li><strong>Java Tuples</strong> and <strong>Scala Case Classes</strong></li>
  <li><strong>Java POJOs</strong></li>
  <li><strong>Primitive Types</strong></li>
  <li><strong>Regular Classes</strong></li>
  <li><strong>Values</strong></li>
  <li><strong>Hadoop Writables</strong></li>
  <li><strong>Special Types</strong></li>
</ol>

<h4 id="tuples-and-case-classes">Tuples and Case Classes</h4>

<div class="codetabs">
  <div data-lang="java">

    <p>Tuples are composite types that contain a fixed number of fields with various types.
The Java API provides classes from <code>Tuple1</code> up to <code>Tuple25</code>. Every field of a tuple
can be an arbitrary Flink type including further tuples, resulting in nested tuples. Fields of a
tuple can be accessed directly using the field’s name as <code>tuple.f4</code>, or using the generic getter method
<code>tuple.getField(int position)</code>. The field indices start at 0. Note that this stands in contrast
to the Scala tuples, but it is more consistent with Java’s general indexing.</p>

    <div class="highlight"><pre><code class="language-java" data-lang="java"><span class="n">DataStream</span><span class="o">&lt;</span><span class="n">Tuple2</span><span class="o">&lt;</span><span class="n">String</span><span class="o">,</span> <span class="n">Integer</span><span class="o">&gt;&gt;</span> <span class="n">wordCounts</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="na">fromElements</span><span class="o">(</span>
    <span class="k">new</span> <span class="n">Tuple2</span><span class="o">&lt;</span><span class="n">String</span><span class="o">,</span> <span class="n">Integer</span><span class="o">&gt;(</span><span class="s">&quot;hello&quot;</span><span class="o">,</span> <span class="mi">1</span><span class="o">),</span>
    <span class="k">new</span> <span class="n">Tuple2</span><span class="o">&lt;</span><span class="n">String</span><span class="o">,</span> <span class="n">Integer</span><span class="o">&gt;(</span><span class="s">&quot;world&quot;</span><span class="o">,</span> <span class="mi">2</span><span class="o">));</span>

<span class="n">wordCounts</span><span class="o">.</span><span class="na">map</span><span class="o">(</span><span class="k">new</span> <span class="n">MapFunction</span><span class="o">&lt;</span><span class="n">Tuple2</span><span class="o">&lt;</span><span class="n">String</span><span class="o">,</span> <span class="n">Integer</span><span class="o">&gt;,</span> <span class="n">Integer</span><span class="o">&gt;()</span> <span class="o">{</span>
    <span class="nd">@Override</span>
    <span class="kd">public</span> <span class="n">String</span> <span class="nf">map</span><span class="o">(</span><span class="n">Tuple2</span><span class="o">&lt;</span><span class="n">String</span><span class="o">,</span> <span class="n">Integer</span><span class="o">&gt;</span> <span class="n">value</span><span class="o">)</span> <span class="kd">throws</span> <span class="n">Exception</span> <span class="o">{</span>
        <span class="k">return</span> <span class="n">value</span><span class="o">.</span><span class="na">f1</span><span class="o">;</span>
    <span class="o">}</span>
<span class="o">});</span>

<span class="n">wordCounts</span><span class="o">.</span><span class="na">keyBy</span><span class="o">(</span><span class="mi">0</span><span class="o">);</span> <span class="c1">// also valid .keyBy(&quot;f0&quot;)</span></code></pre></div>

  </div>
  <div data-lang="scala">

    <p>Scala case classes (and Scala tuples which are a special case of case classes), are composite types that contain a fixed number of fields with various types. Tuple fields are addressed by their 1-offset names such as <code>_1</code> for the first field. Case class fields are accessed by their name.</p>

    <div class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">case</span> <span class="k">class</span> <span class="nc">WordCount</span><span class="o">(</span><span class="n">word</span><span class="k">:</span> <span class="kt">String</span><span class="o">,</span> <span class="n">count</span><span class="k">:</span> <span class="kt">Int</span><span class="o">)</span>
<span class="k">val</span> <span class="n">input</span> <span class="k">=</span> <span class="n">env</span><span class="o">.</span><span class="n">fromElements</span><span class="o">(</span>
    <span class="nc">WordCount</span><span class="o">(</span><span class="s">&quot;hello&quot;</span><span class="o">,</span> <span class="mi">1</span><span class="o">),</span>
    <span class="nc">WordCount</span><span class="o">(</span><span class="s">&quot;world&quot;</span><span class="o">,</span> <span class="mi">2</span><span class="o">))</span> <span class="c1">// Case Class Data Set</span>

<span class="n">input</span><span class="o">.</span><span class="n">keyBy</span><span class="o">(</span><span class="s">&quot;word&quot;</span><span class="o">)</span><span class="c1">// key by field expression &quot;word&quot;</span>

<span class="k">val</span> <span class="n">input2</span> <span class="k">=</span> <span class="n">env</span><span class="o">.</span><span class="n">fromElements</span><span class="o">((</span><span class="s">&quot;hello&quot;</span><span class="o">,</span> <span class="mi">1</span><span class="o">),</span> <span class="o">(</span><span class="s">&quot;world&quot;</span><span class="o">,</span> <span class="mi">2</span><span class="o">))</span> <span class="c1">// Tuple2 Data Set</span>

<span class="n">input2</span><span class="o">.</span><span class="n">keyBy</span><span class="o">(</span><span class="mi">0</span><span class="o">,</span> <span class="mi">1</span><span class="o">)</span> <span class="c1">// key by field positions 0 and 1</span></code></pre></div>

  </div>
</div>

<h4 id="pojos">POJOs</h4>

<p>Java and Scala classes are treated by Flink as a special POJO data type if they fulfill the following requirements:</p>

<ul>
  <li>
    <p>The class must be public.</p>
  </li>
  <li>
    <p>It must have a public constructor without arguments (default constructor).</p>
  </li>
  <li>
    <p>All fields are either public or must be accessible through getter and setter functions. For a field called <code>foo</code> the getter and setter methods must be named <code>getFoo()</code> and <code>setFoo()</code>.</p>
  </li>
  <li>
    <p>The type of a field must be supported by Flink. At the moment, Flink uses <a href="http://avro.apache.org">Avro</a> to serialize arbitrary objects (such as <code>Date</code>).</p>
  </li>
</ul>

<p>Flink analyzes the structure of POJO types, i.e., it learns about the fields of a POJO. As a result POJO types are easier to use than general types. Moreover, Flink can process POJOs more efficiently than general types.</p>

<p>The following example shows a simple POJO with two public fields.</p>

<div class="codetabs">
  <div data-lang="java">

    <div class="highlight"><pre><code class="language-java" data-lang="java"><span class="kd">public</span> <span class="kd">class</span> <span class="nc">WordWithCount</span> <span class="o">{</span>

    <span class="kd">public</span> <span class="n">String</span> <span class="n">word</span><span class="o">;</span>
    <span class="kd">public</span> <span class="kt">int</span> <span class="n">count</span><span class="o">;</span>

    <span class="kd">public</span> <span class="nf">WordWithCount</span><span class="o">()</span> <span class="o">{}</span>

    <span class="kd">public</span> <span class="nf">WordWithCount</span><span class="o">(</span><span class="n">String</span> <span class="n">word</span><span class="o">,</span> <span class="kt">int</span> <span class="n">count</span><span class="o">)</span> <span class="o">{</span>
        <span class="k">this</span><span class="o">.</span><span class="na">word</span> <span class="o">=</span> <span class="n">word</span><span class="o">;</span>
        <span class="k">this</span><span class="o">.</span><span class="na">count</span> <span class="o">=</span> <span class="n">count</span><span class="o">;</span>
    <span class="o">}</span>
<span class="o">}</span>

<span class="n">DataStream</span><span class="o">&lt;</span><span class="n">Tuple2</span><span class="o">&lt;</span><span class="n">String</span><span class="o">,</span> <span class="n">Integer</span><span class="o">&gt;&gt;</span> <span class="n">wordCounts</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="na">fromElements</span><span class="o">(</span>
    <span class="k">new</span> <span class="nf">WordWithCount</span><span class="o">(</span><span class="s">&quot;hello&quot;</span><span class="o">,</span> <span class="mi">1</span><span class="o">),</span>
    <span class="k">new</span> <span class="nf">WordWithCount</span><span class="o">(</span><span class="s">&quot;world&quot;</span><span class="o">,</span> <span class="mi">2</span><span class="o">));</span>

<span class="n">wordCounts</span><span class="o">.</span><span class="na">keyBy</span><span class="o">(</span><span class="s">&quot;word&quot;</span><span class="o">);</span> <span class="c1">// key by field expression &quot;word&quot;</span></code></pre></div>

  </div>
  <div data-lang="scala">

    <div class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">class</span> <span class="nc">WordWithCount</span><span class="o">(</span><span class="k">var</span> <span class="n">word</span><span class="k">:</span> <span class="kt">String</span><span class="o">,</span> <span class="k">var</span> <span class="n">count</span><span class="k">:</span> <span class="kt">Int</span><span class="o">)</span> <span class="o">{</span>
    <span class="k">def</span> <span class="k">this</span><span class="o">()</span> <span class="o">{</span>
      <span class="k">this</span><span class="o">(</span><span class="kc">null</span><span class="o">,</span> <span class="o">-</span><span class="mi">1</span><span class="o">)</span>
    <span class="o">}</span>
<span class="o">}</span>

<span class="k">val</span> <span class="n">input</span> <span class="k">=</span> <span class="n">env</span><span class="o">.</span><span class="n">fromElements</span><span class="o">(</span>
    <span class="k">new</span> <span class="nc">WordWithCount</span><span class="o">(</span><span class="s">&quot;hello&quot;</span><span class="o">,</span> <span class="mi">1</span><span class="o">),</span>
    <span class="k">new</span> <span class="nc">WordWithCount</span><span class="o">(</span><span class="s">&quot;world&quot;</span><span class="o">,</span> <span class="mi">2</span><span class="o">))</span> <span class="c1">// Case Class Data Set</span>

<span class="n">input</span><span class="o">.</span><span class="n">keyBy</span><span class="o">(</span><span class="s">&quot;word&quot;</span><span class="o">)</span><span class="c1">// key by field expression &quot;word&quot;</span></code></pre></div>

  </div>
</div>

<h4 id="primitive-types">Primitive Types</h4>

<p>Flink supports all Java and Scala primitive types such as <code>Integer</code>, <code>String</code>, and <code>Double</code>.</p>

<h4 id="general-class-types">General Class Types</h4>

<p>Flink supports most Java and Scala classes (API and custom).
Restrictions apply to classes containing fields that cannot be serialized, like file pointers, I/O streams, or other native
resources. Classes that follow the Java Beans conventions work well in general.</p>

<p>All classes that are not identified as POJO types (see POJO requirements above) are handled by Flink as general class types.
Flink treats these data types as black boxes and is not able to access their their content (i.e., for efficient sorting). General types are de/serialized using the serialization framework <a href="https://github.com/EsotericSoftware/kryo">Kryo</a>.</p>

<h4 id="values">Values</h4>

<p><em>Value</em> types describe their serialization and deserialization manually. Instead of going through a
general purpose serialization framework, they provide custom code for those operations by means of
implementing the <code>org.apache.flinktypes.Value</code> interface with the methods <code>read</code> and <code>write</code>. Using
a Value type is reasonable when general purpose serialization would be highly inefficient. An
example would be a data type that implements a sparse vector of elements as an array. Knowing that
the array is mostly zero, one can use a special encoding for the non-zero elements, while the
general purpose serialization would simply write all array elements.</p>

<p>The <code>org.apache.flinktypes.CopyableValue</code> interface supports manual internal cloning logic in a
similar way.</p>

<p>Flink comes with pre-defined Value types that correspond to basic data types. (<code>ByteValue</code>,
<code>ShortValue</code>, <code>IntValue</code>, <code>LongValue</code>, <code>FloatValue</code>, <code>DoubleValue</code>, <code>StringValue</code>, <code>CharValue</code>,
<code>BooleanValue</code>). These Value types act as mutable variants of the basic data types: Their value can
be altered, allowing programmers to reuse objects and take pressure off the garbage collector.</p>

<h4 id="hadoop-writables">Hadoop Writables</h4>

<p>You can use types that implement the <code>org.apache.hadoop.Writable</code> interface. The serialization logic
defined in the <code>write()</code>and <code>readFields()</code> methods will be used for serialization.</p>

<h4 id="special-types">Special Types</h4>

<p>You can use special types, including Scala’s <code>Either</code>, <code>Option</code>, and <code>Try</code>.
The Java API has its own custom implementation of <code>Either</code>.
Similarly to Scala’s <code>Either</code>, it represents a value of one two possible types, <em>Left</em> or <em>Right</em>.
<code>Either</code> can be useful for error handling or operators that need to output two different types of records.</p>

<h4 id="type-erasure--type-inference">Type Erasure &amp; Type Inference</h4>

<p><em>Note: This Section is only relevant for Java.</em></p>

<p>The Java compiler throws away much of the generic type information after compilation. This is
known as <em>type erasure</em> in Java. It means that at runtime, an instance of an object does not know
its generic type any more. For example, instances of <code>DataStream&lt;String&gt;</code> and <code>DataStream&lt;Long&gt;</code> look the
same to the JVM.</p>

<p>Flink requires type information at the time when it prepares the program for execution (when the
main method of the program is called). The Flink Java API tries to reconstruct the type information
that was thrown away in various ways and store it explicitly in the data sets and operators. You can
retrieve the type via <code>DataStream.getType()</code>. The method returns an instance of <code>TypeInformation</code>,
which is Flink’s internal way of representing types.</p>

<p>The type inference has its limits and needs the “cooperation” of the programmer in some cases.
Examples for that are methods that create data sets from collections, such as
<code>ExecutionEnvironment.fromCollection(),</code> where you can pass an argument that describes the type. But
also generic functions like <code>MapFunction&lt;I, O&gt;</code> may need extra type information.</p>

<p>The
<a href="https://github.com/apache/flink/blob/master//flink-java/src/main/java/org/apache/flink/api/java/typeutils/ResultTypeQueryable.java">ResultTypeQueryable</a>
interface can be implemented by input formats and functions to tell the API
explicitly about their return type. The <em>input types</em> that the functions are invoked with can
usually be inferred by the result types of the previous operations.</p>

<h2 id="execution-configuration">Execution Configuration</h2>

<p>The <code>StreamExecutionEnvironment</code> also contains the <code>ExecutionConfig</code> which allows to set job specific configuration values for the runtime.</p>

<div class="codetabs">
  <div data-lang="java">

    <div class="highlight"><pre><code class="language-java" data-lang="java"><span class="n">StreamExecutionEnvironment</span> <span class="n">env</span> <span class="o">=</span> <span class="n">StreamExecutionEnvironment</span><span class="o">.</span><span class="na">getExecutionEnvironment</span><span class="o">();</span>
<span class="n">ExecutionConfig</span> <span class="n">executionConfig</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="na">getConfig</span><span class="o">();</span></code></pre></div>

  </div>
  <div data-lang="scala">

    <div class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">env</span> <span class="k">=</span> <span class="nc">StreamExecutionEnvironment</span><span class="o">.</span><span class="n">getExecutionEnvironment</span>
<span class="k">var</span> <span class="n">executionConfig</span> <span class="k">=</span> <span class="n">env</span><span class="o">.</span><span class="n">getConfig</span></code></pre></div>

  </div>
</div>

<p>The following configuration options are available: (the default is bold)</p>

<ul>
  <li>
    <p><strong><code>enableClosureCleaner()</code></strong> / <code>disableClosureCleaner()</code>. The closure cleaner is enabled by default. The closure cleaner removes unneeded references to the surrounding class of anonymous functions inside Flink programs.
With the closure cleaner disabled, it might happen that an anonymous user function is referencing the surrounding class, which is usually not Serializable. This will lead to exceptions by the serializer.</p>
  </li>
  <li>
    <p><code>getParallelism()</code> / <code>setParallelism(int parallelism)</code> Set the default parallelism for the job.</p>
  </li>
  <li>
    <p><code>getNumberOfExecutionRetries()</code> / <code>setNumberOfExecutionRetries(int numberOfExecutionRetries)</code> Sets the number of times that failed tasks are re-executed. A value of zero effectively disables fault tolerance. A value of <code>-1</code> indicates that the system default value (as defined in the configuration) should be used.</p>
  </li>
  <li>
    <p><code>getExecutionRetryDelay()</code> / <code>setExecutionRetryDelay(long executionRetryDelay)</code> Sets the delay in milliseconds that the system waits after a job has failed, before re-executing it. The delay starts after all tasks have been successfully been stopped on the TaskManagers, and once the delay is past, the tasks are re-started. This parameter is useful to delay re-execution in order to let certain time-out related failures surface fully (like broken connections that have not fully timed out), before attempting a re-execution and immediately failing again due to the same problem. This parameter only has an effect if the number of execution re-tries is one or more.</p>
  </li>
  <li>
    <p><code>getExecutionMode()</code> / <code>setExecutionMode()</code>. The default execution mode is PIPELINED. Sets the execution mode to execute the program. The execution mode defines whether data exchanges are performed in a batch or on a pipelined manner.</p>
  </li>
  <li>
    <p><code>enableForceKryo()</code> / <strong><code>disableForceKryo</code></strong>. Kryo is not forced by default. Forces the GenericTypeInformation to use the Kryo serializer for POJOS even though we could analyze them as a POJO. In some cases this might be preferable. For example, when Flink’s internal serializers fail to handle a POJO properly.</p>
  </li>
  <li>
    <p><code>enableForceAvro()</code> / <strong><code>disableForceAvro()</code></strong>. Avro is not forced by default. Forces the Flink AvroTypeInformation to use the Avro serializer instead of Kryo for serializing Avro POJOs.</p>
  </li>
  <li>
    <p><code>enableObjectReuse()</code> / <strong><code>disableObjectReuse()</code></strong> By default, objects are not reused in Flink. Enabling the object reuse mode will instruct the runtime to reuse user objects for better performance. Keep in mind that this can lead to bugs when the user-code function of an operation is not aware of this behavior.</p>
  </li>
  <li>
    <p><strong><code>enableSysoutLogging()</code></strong> / <code>disableSysoutLogging()</code> JobManager status updates are printed to <code>System.out</code> by default. This setting allows to disable this behavior.</p>
  </li>
  <li>
    <p><code>getGlobalJobParameters()</code> / <code>setGlobalJobParameters()</code> This method allows users to set custom objects as a global configuration for the job. Since the <code>ExecutionConfig</code> is accessible in all user defined functions, this is an easy method for making configuration globally available in a job.</p>
  </li>
  <li>
    <p><code>addDefaultKryoSerializer(Class&lt;?&gt; type, Serializer&lt;?&gt; serializer)</code> Register a Kryo serializer instance for the given <code>type</code>.</p>
  </li>
  <li>
    <p><code>addDefaultKryoSerializer(Class&lt;?&gt; type, Class&lt;? extends Serializer&lt;?&gt;&gt; serializerClass)</code> Register a Kryo serializer class for the given <code>type</code>.</p>
  </li>
  <li>
    <p><code>registerTypeWithKryoSerializer(Class&lt;?&gt; type, Serializer&lt;?&gt; serializer)</code> Register the given type with Kryo and specify a serializer for it. By registering a type with Kryo, the serialization of the type will be much more efficient.</p>
  </li>
  <li>
    <p><code>registerKryoType(Class&lt;?&gt; type)</code> If the type ends up being serialized with Kryo, then it will be registered at Kryo to make sure that only tags (integer IDs) are written. If a type is not registered with Kryo, its entire class-name will be serialized with every instance, leading to much higher I/O costs.</p>
  </li>
  <li>
    <p><code>registerPojoType(Class&lt;?&gt; type)</code> Registers the given type with the serialization stack. If the type is eventually serialized as a POJO, then the type is registered with the POJO serializer. If the type ends up being serialized with Kryo, then it will be registered at Kryo to make sure that only tags are written. If a type is not registered with Kryo, its entire class-name will be serialized with every instance, leading to much higher I/O costs.</p>
  </li>
</ul>

<p>Note that types registered with <code>registerKryoType()</code> are not available to Flink’s Kryo serializer instance.</p>

<ul>
  <li>
    <p><code>disableAutoTypeRegistration()</code> Automatic type registration is enabled by default. The automatic type registration is registering all types (including sub-types) used by usercode with Kryo and the POJO serializer.</p>
  </li>
  <li>
    <p><code>setTaskCancellationInterval(long interval)</code> Sets the the interval (in milliseconds) to wait between consecutive attempts to cancel a running task. When a task is canceled a new thread is created which periodically calls <code>interrupt()</code> on the task thread, if the task thread does not terminate within a certain time. This parameter refers to the time between consecutive calls to <code>interrupt()</code> and is set by default to <strong>30000</strong> milliseconds, or <strong>30 seconds</strong>.</p>
  </li>
</ul>

<p>The <code>RuntimeContext</code> which is accessible in <code>Rich*</code> functions through the <code>getRuntimeContext()</code> method also allows to access the <code>ExecutionConfig</code> in all user defined functions.</p>

<p><a href="#top" class="top pull-right"><span class="glyphicon glyphicon-chevron-up"></span> Back to top</a></p>

<h2 id="program-packaging-and-distributed-execution">Program Packaging and Distributed Execution</h2>

<p>As described earlier, Flink programs can be executed on
clusters by using a <code>remote environment</code>. Alternatively, programs can be packaged into JAR Files
(Java Archives) for execution. Packaging the program is a prerequisite to executing them through the
<a href="/apis/cli.html">command line interface</a>.</p>

<h4 id="packaging-programs">Packaging Programs</h4>

<p>To support execution from a packaged JAR file via the command line or web interface, a program must
use the environment obtained by <code>StreamExecutionEnvironment.getExecutionEnvironment()</code>. This environment
will act as the cluster’s environment when the JAR is submitted to the command line or web
interface. If the Flink program is invoked differently than through these interfaces, the
environment will act like a local environment.</p>

<p>To package the program, simply export all involved classes as a JAR file. The JAR file’s manifest
must point to the class that contains the program’s <em>entry point</em> (the class with the public
<code>main</code> method). The simplest way to do this is by putting the <em>main-class</em> entry into the
manifest (such as <code>main-class: org.apache.flinkexample.MyProgram</code>). The <em>main-class</em> attribute is
the same one that is used by the Java Virtual Machine to find the main method when executing a JAR
files through the command <code>java -jar pathToTheJarFile</code>. Most IDEs offer to include that attribute
automatically when exporting JAR files.</p>

<h4 id="packaging-programs-through-plans">Packaging Programs through Plans</h4>

<p>Additionally, we support packaging programs as <em>Plans</em>. Instead of defining a progam in the main
method and calling
<code>execute()</code> on the environment, plan packaging returns the <em>Program Plan</em>, which is a description of
the program’s data flow. To do that, the program must implement the
<code>org.apache.flink.api.common.Program</code> interface, defining the <code>getPlan(String...)</code> method. The
strings passed to that method are the command line arguments. The program’s plan can be created from
the environment via the <code>ExecutionEnvironment#createProgramPlan()</code> method. When packaging the
program’s plan, the JAR manifest must point to the class implementing the
<code>org.apache.flinkapi.common.Program</code> interface, instead of the class with the main method.</p>

<h4 id="summary">Summary</h4>

<p>The overall procedure to invoke a packaged program is as follows:</p>

<ol>
  <li>
    <p>The JAR’s manifest is searched for a <em>main-class</em> or <em>program-class</em> attribute. If both
attributes are found, the <em>program-class</em> attribute takes precedence over the <em>main-class</em>
attribute. Both the command line and the web interface support a parameter to pass the entry point
class name manually for cases where the JAR manifest contains neither attribute.</p>
  </li>
  <li>
    <p>If the entry point class implements the <code>org.apache.flinkapi.common.Program</code>, then the system
calls the <code>getPlan(String...)</code> method to obtain the program plan to execute.</p>
  </li>
  <li>
    <p>If the entry point class does not implement the <code>org.apache.flinkapi.common.Program</code> interface,
the system will invoke the main method of the class.</p>
  </li>
</ol>

<p><a href="#top" class="top pull-right"><span class="glyphicon glyphicon-chevron-up"></span> Back to top</a></p>

<h2 id="accumulators--counters">Accumulators &amp; Counters</h2>

<p>Accumulators are simple constructs with an <strong>add operation</strong> and a <strong>final accumulated result</strong>,
which is available after the job ended.</p>

<p>The most straightforward accumulator is a <strong>counter</strong>: You can increment it using the
<code>Accumulator.add(V value)</code> method. At the end of the job Flink will sum up (merge) all partial
results and send the result to the client. Accumulators are useful during debugging or if you
quickly want to find out more about your data.</p>

<p>Flink currently has the following <strong>built-in accumulators</strong>. Each of them implements the
<a href="https://github.com/apache/flink/blob/master//flink-core/src/main/java/org/apache/flink/api/common/accumulators/Accumulator.java">Accumulator</a>
interface.</p>

<ul>
  <li><a href="https://github.com/apache/flink/blob/master//flink-core/src/main/java/org/apache/flink/api/common/accumulators/IntCounter.java"><strong>IntCounter</strong></a>,
<a href="https://github.com/apache/flink/blob/master//flink-core/src/main/java/org/apache/flink/api/common/accumulators/LongCounter.java"><strong>LongCounter</strong></a>
and <a href="https://github.com/apache/flink/blob/master//flink-core/src/main/java/org/apache/flink/api/common/accumulators/DoubleCounter.java"><strong>DoubleCounter</strong></a>:
See below for an example using a counter.</li>
  <li><a href="https://github.com/apache/flink/blob/master//flink-core/src/main/java/org/apache/flink/api/common/accumulators/Histogram.java"><strong>Histogram</strong></a>:
A histogram implementation for a discrete number of bins. Internally it is just a map from Integer
to Integer. You can use this to compute distributions of values, e.g. the distribution of
words-per-line for a word count program.</li>
</ul>

<p><strong>How to use accumulators:</strong></p>

<p>First you have to create an accumulator object (here a counter) in the user-defined transformation
function where you want to use it.</p>

<div class="highlight"><pre><code class="language-java" data-lang="java"><span class="kd">private</span> <span class="n">IntCounter</span> <span class="n">numLines</span> <span class="o">=</span> <span class="k">new</span> <span class="nf">IntCounter</span><span class="o">();</span></code></pre></div>

<p>Second you have to register the accumulator object, typically in the <code>open()</code> method of the
<em>rich</em> function. Here you also define the name.</p>

<div class="highlight"><pre><code class="language-java" data-lang="java"><span class="n">getRuntimeContext</span><span class="o">().</span><span class="na">addAccumulator</span><span class="o">(</span><span class="s">&quot;num-lines&quot;</span><span class="o">,</span> <span class="k">this</span><span class="o">.</span><span class="na">numLines</span><span class="o">);</span></code></pre></div>

<p>You can now use the accumulator anywhere in the operator function, including in the <code>open()</code> and
<code>close()</code> methods.</p>

<div class="highlight"><pre><code class="language-java" data-lang="java"><span class="k">this</span><span class="o">.</span><span class="na">numLines</span><span class="o">.</span><span class="na">add</span><span class="o">(</span><span class="mi">1</span><span class="o">);</span></code></pre></div>

<p>The overall result will be stored in the <code>JobExecutionResult</code> object which is
returned from the <code>execute()</code> method of the execution environment
(currently this only works if the execution waits for the
completion of the job).</p>

<div class="highlight"><pre><code class="language-java" data-lang="java"><span class="n">myJobExecutionResult</span><span class="o">.</span><span class="na">getAccumulatorResult</span><span class="o">(</span><span class="s">&quot;num-lines&quot;</span><span class="o">)</span></code></pre></div>

<p>All accumulators share a single namespace per job. Thus you can use the same accumulator in
different operator functions of your job. Flink will internally merge all accumulators with the same
name.</p>

<p>A note on accumulators and iterations: Currently the result of accumulators is only available after
the overall job ended. We plan to also make the result of the previous iteration available in the
next iteration. You can use
<a href="https://github.com/apache/flink/blob/master//flink-java/src/main/java/org/apache/flink/api/java/operators/IterativeDataSet.java#L98">Aggregators</a>
to compute per-iteration statistics and base the termination of iterations on such statistics.</p>

<p><strong>Custom accumulators:</strong></p>

<p>To implement your own accumulator you simply have to write your implementation of the Accumulator
interface. Feel free to create a pull request if you think your custom accumulator should be shipped
with Flink.</p>

<p>You have the choice to implement either
<a href="https://github.com/apache/flink/blob/master//flink-core/src/main/java/org/apache/flink/api/common/accumulators/Accumulator.java">Accumulator</a>
or <a href="https://github.com/apache/flink/blob/master//flink-core/src/main/java/org/apache/flink/api/common/accumulators/SimpleAccumulator.java">SimpleAccumulator</a>.</p>

<p><code>Accumulator&lt;V,R&gt;</code> is most flexible: It defines a type <code>V</code> for the value to add, and a
result type <code>R</code> for the final result. E.g. for a histogram, <code>V</code> is a number and <code>R</code> is
 a histogram. <code>SimpleAccumulator</code> is for the cases where both types are the same, e.g. for counters.</p>

<p><a href="#top" class="top pull-right"><span class="glyphicon glyphicon-chevron-up"></span> Back to top</a></p>

<h2 id="parallel-execution">Parallel Execution</h2>

<p>This section describes how the parallel execution of programs can be configured in Flink. A Flink
program consists of multiple tasks (transformations/operators, data sources, and sinks). A task is split into
several parallel instances for execution and each parallel instance processes a subset of the task’s
input data. The number of parallel instances of a task is called its <em>parallelism</em>.</p>

<p>The parallelism of a task can be specified in Flink on different levels.</p>

<h3 id="operator-level">Operator Level</h3>

<p>The parallelism of an individual operator, data source, or data sink can be defined by calling its
<code>setParallelism()</code> method.  For example, like this:</p>

<div class="codetabs">
  <div data-lang="java">

    <div class="highlight"><pre><code class="language-java" data-lang="java"><span class="kd">final</span> <span class="n">StreamExecutionEnvironment</span> <span class="n">env</span> <span class="o">=</span> <span class="n">StreamExecutionEnvironment</span><span class="o">.</span><span class="na">getExecutionEnvironment</span><span class="o">();</span>

<span class="n">DataStream</span><span class="o">&lt;</span><span class="n">String</span><span class="o">&gt;</span> <span class="n">text</span> <span class="o">=</span> <span class="o">[...]</span>
<span class="n">DataStream</span><span class="o">&lt;</span><span class="n">Tuple2</span><span class="o">&lt;</span><span class="n">String</span><span class="o">,</span> <span class="n">Integer</span><span class="o">&gt;&gt;</span> <span class="n">wordCounts</span> <span class="o">=</span> <span class="n">text</span>
    <span class="o">.</span><span class="na">flatMap</span><span class="o">(</span><span class="k">new</span> <span class="nf">LineSplitter</span><span class="o">())</span>
    <span class="o">.</span><span class="na">keyBy</span><span class="o">(</span><span class="mi">0</span><span class="o">)</span>
    <span class="o">.</span><span class="na">timeWindow</span><span class="o">(</span><span class="n">Time</span><span class="o">.</span><span class="na">seconds</span><span class="o">(</span><span class="mi">5</span><span class="o">))</span>
    <span class="o">.</span><span class="na">sum</span><span class="o">(</span><span class="mi">1</span><span class="o">).</span><span class="na">setParallelism</span><span class="o">(</span><span class="mi">5</span><span class="o">);</span>

<span class="n">wordCounts</span><span class="o">.</span><span class="na">print</span><span class="o">();</span>

<span class="n">env</span><span class="o">.</span><span class="na">execute</span><span class="o">(</span><span class="s">&quot;Word Count Example&quot;</span><span class="o">);</span></code></pre></div>

  </div>
  <div data-lang="scala">

    <div class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">env</span> <span class="k">=</span> <span class="nc">StreamExecutionEnvironment</span><span class="o">.</span><span class="n">getExecutionEnvironment</span>

<span class="k">val</span> <span class="n">text</span> <span class="k">=</span> <span class="o">[</span><span class="kt">...</span><span class="o">]</span>
<span class="k">val</span> <span class="n">wordCounts</span> <span class="k">=</span> <span class="n">text</span>
    <span class="o">.</span><span class="n">flatMap</span><span class="o">{</span> <span class="k">_</span><span class="o">.</span><span class="n">split</span><span class="o">(</span><span class="s">&quot; &quot;</span><span class="o">)</span> <span class="n">map</span> <span class="o">{</span> <span class="o">(</span><span class="k">_</span><span class="o">,</span> <span class="mi">1</span><span class="o">)</span> <span class="o">}</span> <span class="o">}</span>
    <span class="o">.</span><span class="n">keyBy</span><span class="o">(</span><span class="mi">0</span><span class="o">)</span>
    <span class="o">.</span><span class="n">timeWindow</span><span class="o">(</span><span class="nc">Time</span><span class="o">.</span><span class="n">seconds</span><span class="o">(</span><span class="mi">5</span><span class="o">))</span>
    <span class="o">.</span><span class="n">sum</span><span class="o">(</span><span class="mi">1</span><span class="o">).</span><span class="n">setParallelism</span><span class="o">(</span><span class="mi">5</span><span class="o">)</span>
<span class="n">wordCounts</span><span class="o">.</span><span class="n">print</span><span class="o">()</span>

<span class="n">env</span><span class="o">.</span><span class="n">execute</span><span class="o">(</span><span class="s">&quot;Word Count Example&quot;</span><span class="o">)</span></code></pre></div>

  </div>
</div>

<h3 id="execution-environment-level">Execution Environment Level</h3>

<p>As mentioned <a href="#anatomy-of-a-flink-program">here</a> Flink programs are executed in the context
of an execution environment. An
execution environment defines a default parallelism for all operators, data sources, and data sinks
it executes. Execution environment parallelism can be overwritten by explicitly configuring the
parallelism of an operator.</p>

<p>The default parallelism of an execution environment can be specified by calling the
<code>setParallelism()</code> method. To execute all operators, data sources, and data sinks with a parallelism
of <code>3</code>, set the default parallelism of the execution environment as follows:</p>

<div class="codetabs">
  <div data-lang="java">

    <div class="highlight"><pre><code class="language-java" data-lang="java"><span class="kd">final</span> <span class="n">StreamExecutionEnvironment</span> <span class="n">env</span> <span class="o">=</span> <span class="n">StreamExecutionEnvironment</span><span class="o">.</span><span class="na">getExecutionEnvironment</span><span class="o">();</span>
<span class="n">env</span><span class="o">.</span><span class="na">setParallelism</span><span class="o">(</span><span class="mi">3</span><span class="o">);</span>

<span class="n">DataStream</span><span class="o">&lt;</span><span class="n">String</span><span class="o">&gt;</span> <span class="n">text</span> <span class="o">=</span> <span class="o">[...]</span>
<span class="n">DataStream</span><span class="o">&lt;</span><span class="n">Tuple2</span><span class="o">&lt;</span><span class="n">String</span><span class="o">,</span> <span class="n">Integer</span><span class="o">&gt;&gt;</span> <span class="n">wordCounts</span> <span class="o">=</span> <span class="o">[...]</span>
<span class="n">wordCounts</span><span class="o">.</span><span class="na">print</span><span class="o">();</span>

<span class="n">env</span><span class="o">.</span><span class="na">execute</span><span class="o">(</span><span class="s">&quot;Word Count Example&quot;</span><span class="o">);</span></code></pre></div>

  </div>
  <div data-lang="scala">

    <div class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">env</span> <span class="k">=</span> <span class="nc">StreamExecutionEnvironment</span><span class="o">.</span><span class="n">getExecutionEnvironment</span>
<span class="n">env</span><span class="o">.</span><span class="n">setParallelism</span><span class="o">(</span><span class="mi">3</span><span class="o">)</span>

<span class="k">val</span> <span class="n">text</span> <span class="k">=</span> <span class="o">[</span><span class="kt">...</span><span class="o">]</span>
<span class="k">val</span> <span class="n">wordCounts</span> <span class="k">=</span> <span class="n">text</span>
    <span class="o">.</span><span class="n">flatMap</span><span class="o">{</span> <span class="k">_</span><span class="o">.</span><span class="n">split</span><span class="o">(</span><span class="s">&quot; &quot;</span><span class="o">)</span> <span class="n">map</span> <span class="o">{</span> <span class="o">(</span><span class="k">_</span><span class="o">,</span> <span class="mi">1</span><span class="o">)</span> <span class="o">}</span> <span class="o">}</span>
    <span class="o">.</span><span class="n">keyBy</span><span class="o">(</span><span class="mi">0</span><span class="o">)</span>
    <span class="o">.</span><span class="n">timeWindow</span><span class="o">(</span><span class="nc">Time</span><span class="o">.</span><span class="n">seconds</span><span class="o">(</span><span class="mi">5</span><span class="o">))</span>
    <span class="o">.</span><span class="n">sum</span><span class="o">(</span><span class="mi">1</span><span class="o">)</span>
<span class="n">wordCounts</span><span class="o">.</span><span class="n">print</span><span class="o">()</span>

<span class="n">env</span><span class="o">.</span><span class="n">execute</span><span class="o">(</span><span class="s">&quot;Word Count Example&quot;</span><span class="o">)</span></code></pre></div>

  </div>
</div>

<h3 id="client-level">Client Level</h3>

<p>The parallelism can be set at the Client when submitting jobs to Flink. The
Client can either be a Java or a Scala program. One example of such a Client is
Flink’s Command-line Interface (CLI).</p>

<p>For the CLI client, the parallelism parameter can be specified with <code>-p</code>. For
example:</p>

<div class="highlight"><pre><code>./bin/flink run -p 10 ../examples/*WordCount-java*.jar
</code></pre></div>

<p>In a Java/Scala program, the parallelism is set as follows:</p>

<div class="codetabs">
  <div data-lang="java">

    <div class="highlight"><pre><code class="language-java" data-lang="java"><span class="k">try</span> <span class="o">{</span>
    <span class="n">PackagedProgram</span> <span class="n">program</span> <span class="o">=</span> <span class="k">new</span> <span class="nf">PackagedProgram</span><span class="o">(</span><span class="n">file</span><span class="o">,</span> <span class="n">args</span><span class="o">);</span>
    <span class="n">InetSocketAddress</span> <span class="n">jobManagerAddress</span> <span class="o">=</span> <span class="n">RemoteExecutor</span><span class="o">.</span><span class="na">getInetFromHostport</span><span class="o">(</span><span class="s">&quot;localhost:6123&quot;</span><span class="o">);</span>
    <span class="n">Configuration</span> <span class="n">config</span> <span class="o">=</span> <span class="k">new</span> <span class="nf">Configuration</span><span class="o">();</span>

    <span class="n">Client</span> <span class="n">client</span> <span class="o">=</span> <span class="k">new</span> <span class="nf">Client</span><span class="o">(</span><span class="n">jobManagerAddress</span><span class="o">,</span> <span class="n">config</span><span class="o">,</span> <span class="n">program</span><span class="o">.</span><span class="na">getUserCodeClassLoader</span><span class="o">());</span>

    <span class="c1">// set the parallelism to 10 here</span>
    <span class="n">client</span><span class="o">.</span><span class="na">run</span><span class="o">(</span><span class="n">program</span><span class="o">,</span> <span class="mi">10</span><span class="o">,</span> <span class="kc">true</span><span class="o">);</span>

<span class="o">}</span> <span class="k">catch</span> <span class="o">(</span><span class="n">ProgramInvocationException</span> <span class="n">e</span><span class="o">)</span> <span class="o">{</span>
    <span class="n">e</span><span class="o">.</span><span class="na">printStackTrace</span><span class="o">();</span>
<span class="o">}</span></code></pre></div>

  </div>
  <div data-lang="scala">

    <div class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">try</span> <span class="o">{</span>
    <span class="nc">PackagedProgram</span> <span class="n">program</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">PackagedProgram</span><span class="o">(</span><span class="n">file</span><span class="o">,</span> <span class="n">args</span><span class="o">)</span>
    <span class="nc">InetSocketAddress</span> <span class="n">jobManagerAddress</span> <span class="k">=</span> <span class="nc">RemoteExecutor</span><span class="o">.</span><span class="n">getInetFromHostport</span><span class="o">(</span><span class="s">&quot;localhost:6123&quot;</span><span class="o">)</span>
    <span class="nc">Configuration</span> <span class="n">config</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Configuration</span><span class="o">()</span>

    <span class="nc">Client</span> <span class="n">client</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Client</span><span class="o">(</span><span class="n">jobManagerAddress</span><span class="o">,</span> <span class="k">new</span> <span class="nc">Configuration</span><span class="o">(),</span> <span class="n">program</span><span class="o">.</span><span class="n">getUserCodeClassLoader</span><span class="o">())</span>

    <span class="c1">// set the parallelism to 10 here</span>
    <span class="n">client</span><span class="o">.</span><span class="n">run</span><span class="o">(</span><span class="n">program</span><span class="o">,</span> <span class="mi">10</span><span class="o">,</span> <span class="kc">true</span><span class="o">)</span>

<span class="o">}</span> <span class="k">catch</span> <span class="o">{</span>
    <span class="k">case</span> <span class="n">e</span><span class="k">:</span> <span class="kt">Exception</span> <span class="o">=&gt;</span> <span class="n">e</span><span class="o">.</span><span class="n">printStackTrace</span>
<span class="o">}</span></code></pre></div>

  </div>
</div>

<h3 id="system-level">System Level</h3>

<p>A system-wide default parallelism for all execution environments can be defined by setting the
<code>parallelism.default</code> property in <code>./conf/flink-conf.yaml</code>. See the
<a href="/setup/config.html">Configuration</a> documentation for details.</p>

<p><a href="#top" class="top pull-right"><span class="glyphicon glyphicon-chevron-up"></span> Back to top</a></p>

<h2 id="execution-plans">Execution Plans</h2>

<p>Depending on various parameters such as data size or number of machines in the cluster, Flink’s
optimizer automatically chooses an execution strategy for your program. In many cases, it can be
useful to know how exactly Flink will execute your program.</p>

<p><strong>Plan Visualization Tool</strong></p>

<p>Flink comes packaged with a visualization tool for execution plans. The HTML document containing
the visualizer is located under <code>tools/planVisualizer.html</code>. It takes a JSON representation of
the job execution plan and visualizes it as a graph with complete annotations of execution
strategies.</p>

<p>The following code shows how to print the execution plan JSON from your program:</p>

<div class="codetabs">
  <div data-lang="java">

    <div class="highlight"><pre><code class="language-java" data-lang="java"><span class="kd">final</span> <span class="n">ExecutionEnvironment</span> <span class="n">env</span> <span class="o">=</span> <span class="n">ExecutionEnvironment</span><span class="o">.</span><span class="na">getExecutionEnvironment</span><span class="o">();</span>

<span class="o">...</span>

<span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="n">env</span><span class="o">.</span><span class="na">getExecutionPlan</span><span class="o">());</span></code></pre></div>

  </div>
  <div data-lang="scala">

    <div class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">env</span> <span class="k">=</span> <span class="nc">ExecutionEnvironment</span><span class="o">.</span><span class="n">getExecutionEnvironment</span>

<span class="o">...</span>

<span class="n">println</span><span class="o">(</span><span class="n">env</span><span class="o">.</span><span class="n">getExecutionPlan</span><span class="o">())</span></code></pre></div>

  </div>
</div>

<p>To visualize the execution plan, do the following:</p>

<ol>
  <li><strong>Open</strong> <code>planVisualizer.html</code> with your web browser,</li>
  <li><strong>Paste</strong> the JSON string into the text field, and</li>
  <li><strong>Press</strong> the draw button.</li>
</ol>

<p>After these steps, a detailed execution plan will be visualized.</p>

<p><img alt="A flink job execution graph." src="fig/plan_visualizer.png" width="80%" /></p>

<p><strong>Web Interface</strong></p>

<p>Flink offers a web interface for submitting and executing jobs. The interface is part of the JobManager’s
web interface for monitoring, per default running on port 8081. Job submission via this interfaces requires
that you have set <code>jobmanager.web.submit.enable: true</code> in <code>flink-conf.yaml</code>.</p>

<p>You may specify program arguments before the job is executed. The plan visualization enables you to show
the execution plan before executing the Flink job.</p>

<p><a href="#top" class="top pull-right"><span class="glyphicon glyphicon-chevron-up"></span> Back to top</a></p>


  </div>

  
</div>

    </div><!-- /.container -->

    <!-- jQuery (necessary for Bootstrap's JavaScript plugins) -->
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.2/jquery.min.js"></script>
    <!-- Include all compiled plugins (below), or include individual files as needed -->
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.4/js/bootstrap.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/anchor-js/3.1.0/anchor.min.js"></script>
    <script src="/page/js/flink.js"></script>

    <!-- Google Analytics -->
    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-52545728-1', 'auto');
      ga('send', 'pageview');
    </script>

    <!-- Disqus -->
    
  </body>
</html>
