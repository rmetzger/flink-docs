<!--
Licensed to the Apache Software Foundation (ASF) under one
or more contributor license agreements.  See the NOTICE file
distributed with this work for additional information
regarding copyright ownership.  The ASF licenses this file
to you under the Apache License, Version 2.0 (the
"License"); you may not use this file except in compliance
with the License.  You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing,
software distributed under the License is distributed on an
"AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
KIND, either express or implied.  See the License for the
specific language governing permissions and limitations
under the License.
-->
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->
    <title>Apache Flink 1.1-SNAPSHOT Documentation: Apache Kafka Connector</title>
    <link rel="shortcut icon" href="/page/favicon.ico" type="image/x-icon">
    <link rel="icon" href="/page/favicon.ico" type="image/x-icon">

    <!-- Bootstrap -->
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.4/css/bootstrap.min.css">
    <link rel="stylesheet" href="/page/css/flink.css">
    <link rel="stylesheet" href="/page/css/syntax.css">
    <link rel="stylesheet" href="/page/css/codetabs.css">
    
    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
      <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->
  </head>
  <body>
    
    





    <!-- Top navbar. -->
    <nav class="navbar navbar-default navbar-fixed-top">
      <div class="container">
        <!-- The logo. -->
        <div class="navbar-header">
          <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1">
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </button>
          <div class="navbar-logo">
            <a href="http://flink.apache.org"><img alt="Apache Flink" src="/page/img/navbar-brand-logo.jpg"></a>
          </div>
        </div><!-- /.navbar-header -->

        <!-- The navigation links. -->
        <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
          <ul class="nav navbar-nav">
            <li class="hidden-sm "><a href="/">Docs v1.1</a></li>

            <li class=""><a href="/concepts/concepts.html">Concepts</a></li>

            <!-- Setup -->
            <li class="dropdown">
              <a href="/setup" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">Setup <span class="caret"></span></a>
              <ul class="dropdown-menu" role="menu">
                
                
                <li class=""><a href="/setup/building.html">Build Flink from Source</a></li>
                
                <li class=""><a href="/setup/config.html">Configuration</a></li>
                

                <li class="divider"></li>
                <li role="presentation" class="dropdown-header"><strong>Quickstart</strong></li>

                <!-- Quickstart -->
                
                
                <li class=""><a href="/quickstart/setup_quickstart.html">Setup & Run Example</a></li>
                
                <li class=""><a href="/quickstart/java_api_quickstart.html">Java API</a></li>
                
                <li class=""><a href="/quickstart/scala_api_quickstart.html">Scala API</a></li>
                

                <li class="divider"></li>
                <li role="presentation" class="dropdown-header"><strong>Deployment</strong></li>
                
                
                <li class=""><a href="/setup/local_setup.html">Local</a></li>
                
                <li class=""><a href="/setup/cluster_setup.html">Cluster (Standalone)</a></li>
                
                <li class=""><a href="/setup/yarn_setup.html">YARN</a></li>
                
                <li class=""><a href="/setup/gce_setup.html">Google Compute Engine</a></li>
                
                <li class=""><a href="/setup/aws.html">AWS</a></li>
                
                <li class=""><a href="/setup/jobmanager_high_availability.html">High Availability</a></li>
                
              </ul>
            </li>

            <!-- Programming Guides -->
            <li class="dropdown active">
              <a href="/apis" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">Programming Guides <span class="caret"></span></a>
              <ul class="dropdown-menu" role="menu">
                
                
                <li class=""><a href="/apis/common/index.html"><strong>Basic API Concepts</strong></a></li>
                
                <li class=""><a href="/apis/streaming/index.html"><strong>Streaming Guide</strong> (DataStream API)</a></li>
                
                <li class=""><a href="/apis/batch/index.html"><strong>Batch Guide</strong> (DataSet API)</a></li>
                
                <li class=""><a href="/apis/best_practices.html">Best Practices</a></li>
                
                <li class=""><a href="/apis/table.html">Table API and SQL</a></li>
                
                <li class=""><a href="/apis/cli.html">Command-Line Interface</a></li>
                
                <li class=""><a href="/apis/local_execution.html">Local Execution</a></li>
                
                <li class=""><a href="/apis/cluster_execution.html">Cluster Execution</a></li>
                
                <li class=""><a href="/apis/scala_shell.html">Scala Shell</a></li>
                
                <li class=""><a href="/apis/scala_api_extensions.html">Scala API Extensions</a></li>
                
                <li class=""><a href="/apis/java8.html">Java 8</a></li>
                
              </ul>
            </li>

            <!-- Libraries -->
            <li class="dropdown">
              <a href="/libs" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">Libraries <span class="caret"></span></a>
                <ul class="dropdown-menu" role="menu">
                  
                  
                  <li class=""><a href="/apis/batch/libs/gelly.html">Graphs: Gelly</a></li>
                  
                  <li class=""><a href="/apis/streaming/libs/cep.html">CEP</a></li>
                  
                  <li class=""><a href="/apis/batch/libs/ml/index.html">Machine Learning</a></li>
                  
              </ul>
            </li>

            <!-- Internals -->
            <li class="dropdown">
              <a href="/internals" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">Internals <span class="caret"></span></a>
              <ul class="dropdown-menu" role="menu">
                <li role="presentation" class="dropdown-header"><strong>Contribute</strong></li>
                <li><a href="http://flink.apache.org/how-to-contribute.html"><small><span class="glyphicon glyphicon-new-window"></span></small> How to Contribute</a></li>
                <li><a href="http://flink.apache.org/contribute-code.html#coding-guidelines"><small><span class="glyphicon glyphicon-new-window"></span></small> Coding Guidelines</a></li>
                
                
                <li class=""><a href="/internals/ide_setup.html">IDE Setup</a></li>
                
                <li class=""><a href="/internals/logging.html">Logging</a></li>
                
                <li class=""><a href="/internals/general_arch.html">Architecture and Process Model</a></li>
                
                <li class=""><a href="/internals/stream_checkpointing.html">Fault Tolerance for Data Streaming</a></li>
                
                <li class=""><a href="/internals/types_serialization.html">Type Extraction and Serialization</a></li>
                
                <li class=""><a href="/internals/monitoring_rest_api.html">Monitoring REST API</a></li>
                
                <li class=""><a href="/internals/job_scheduling.html">Jobs and Scheduling</a></li>
                
                <li class=""><a href="/internals/add_operator.html">How-To: Add an Operator</a></li>
                
                <li class=""><a href="/internals/back_pressure_monitoring.html">Back Pressure Monitoring</a></li>
                
              </ul>
            </li>
          </ul>
          <form class="navbar-form navbar-right hidden-sm hidden-md" role="search" action="/search-results.html">
            <div class="form-group">
              <input type="text" class="form-control" size="16px" name="q" placeholder="Search all pages">
            </div>
            <button type="submit" class="btn btn-default">Search</button>
          </form>
        </div><!-- /.navbar-collapse -->
      </div><!-- /.container -->
    </nav>


    

    <!-- Main content. -->
    <div class="container">
      
      
<div class="row">


  <!-- Sub Navigation -->
  <div class="col-sm-3">
    <ul id="sub-nav">
      
      
      
        
        
        
        <li><a href="/apis/streaming/index.html" class="">DataStream API</a>
          
        </li>
      
        
        
        
        <li><a href="/quickstart/run_example_quickstart.html" class="">Example: Wikipedia Edits</a>
          
        </li>
      
        
        
        
        <li><a href="/apis/streaming/event_time.html" class="">Event Time</a>
          
          <ul>
            
              <li><a href="/apis/streaming/event_timestamp_extractors.html" class="">Pre-defined Timestamp Extractors / Watermark Emitters</a></li>
            
              <li><a href="/apis/streaming/event_timestamps_watermarks.html" class="">Generating Timestamps / Watermarks</a></li>
            
          </ul>
          
        </li>
      
        
        
        
        <li><a href="/apis/streaming/windows.html" class="">Windows</a>
          
        </li>
      
        
        
        
        <li><a href="/apis/streaming/fault_tolerance.html" class="">Fault Tolerance</a>
          
          <ul>
            
              <li><a href="/apis/streaming/state.html" class="">Working with State</a></li>
            
              <li><a href="/apis/streaming/state_backends.html" class="">State Backends</a></li>
            
          </ul>
          
        </li>
      
        
        
        
        <li><a href="/apis/streaming/connectors/index.html" class="">Connectors</a>
          
          <ul>
            
              <li><a href="/apis/streaming/connectors/kafka.html" class="active">Kafka</a></li>
            
              <li><a href="/apis/streaming/connectors/elasticsearch.html" class="">Elasticsearch</a></li>
            
              <li><a href="/apis/streaming/connectors/elasticsearch2.html" class="">Elasticsearch 2.x</a></li>
            
              <li><a href="/apis/streaming/connectors/filesystem_sink.html" class="">Filesystem Sink</a></li>
            
              <li><a href="/apis/streaming/connectors/rabbitmq.html" class="">RabbitMQ</a></li>
            
              <li><a href="/apis/streaming/connectors/kinesis.html" class="">Amazon Kinesis Streams</a></li>
            
              <li><a href="/apis/streaming/connectors/twitter.html" class="">Twitter</a></li>
            
          </ul>
          
        </li>
      
        
        
        
        <li><a href="/apis/streaming/savepoints.html" class="">Savepoints</a>
          
        </li>
      
        
        
        
        <li><a href="/apis/streaming/libs/index.html" class="">Libraries</a>
          
          <ul>
            
              <li><a href="/apis/streaming/libs/cep.html" class="">Event Processing (CEP)</a></li>
            
          </ul>
          
        </li>
      
        
        
        
        <li><a href="/apis/streaming/storm_compatibility.html" class="">Storm Compatibility</a>
          
        </li>
      
    </ul>
  </div>
  <!-- Main -->
  <div class="col-sm-9">
    <!-- Top anchor -->
    <a href="#top"></a>

    <!-- Artifact name change warning. Remove for the 1.0 release. -->
    <div class="panel panel-default">
      <div class="panel-body"><strong>Important</strong>: Maven artifacts which depend on Scala are now suffixed with the Scala major version, e.g. "2.10" or "2.11". Please consult the <a href="https://cwiki.apache.org/confluence/display/FLINK/Maven+artifact+names+suffixed+with+Scala+version">migration guide on the project Wiki</a>.</div>
    </div>

    <!-- Breadcrumbs above the main heading -->
    <ol class="breadcrumb">
      
      
      <li><a href="/apis/streaming/index.html">Streaming Guide</a></li>
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      

      
      
      

      

      <li><a href="/apis/streaming/connectors/index.html">Connectors</a></li>
      
      
      <li class="active">Kafka</li>
    </ol>

    <div class="text">
      <!-- Main heading -->
      <h1>Apache Kafka Connector</h1>

      <!-- Content -->
      

<p>This connector provides access to event streams served by <a href="https://kafka.apache.org/">Apache Kafka</a>.</p>

<p>Flink provides special Kafka Connectors for reading and writing data from/to Kafka topics.
The Flink Kafka Consumer integrates with Flink’s checkpointing mechanism to provide
exactly-once processing semantics. To achieve that, Flink does not purely rely on Kafka’s consumer group
offset tracking, but tracks and checkpoints these offsets internally as well.</p>

<p>Please pick a package (maven artifact id) and class name for your use-case and environment.
For most users, the <code>FlinkKafkaConsumer08</code> (part of <code>flink-connector-kafka</code>) is appropriate.</p>

<table class="table table-bordered">
  <thead>
    <tr>
      <th class="text-left">Maven Dependency</th>
      <th class="text-left">Supported since</th>
      <th class="text-left">Consumer and <br />
      Producer Class name</th>
      <th class="text-left">Kafka version</th>
      <th class="text-left">Notes</th>
    </tr>
  </thead>
  <tbody>
    <tr>
        <td>flink-connector-kafka</td>
        <td>0.9.1, 0.10</td>
        <td>FlinkKafkaConsumer082<br />
        FlinkKafkaProducer</td>
        <td>0.8.x</td>
        <td>Uses the <a href="https://cwiki.apache.org/confluence/display/KAFKA/0.8.0+SimpleConsumer+Example">SimpleConsumer</a> API of Kafka internally. Offsets are committed to ZK by Flink.</td>
    </tr>
     <tr>
        <td>flink-connector-kafka-0.8_2.10</td>
        <td>1.0.0</td>
        <td>FlinkKafkaConsumer08<br />
        FlinkKafkaProducer08</td>
        <td>0.8.x</td>
        <td>Uses the <a href="https://cwiki.apache.org/confluence/display/KAFKA/0.8.0+SimpleConsumer+Example">SimpleConsumer</a> API of Kafka internally. Offsets are committed to ZK by Flink.</td>
    </tr>
     <tr>
        <td>flink-connector-kafka-0.9_2.10</td>
        <td>1.0.0</td>
        <td>FlinkKafkaConsumer09<br />
        FlinkKafkaProducer09</td>
        <td>0.9.x</td>
        <td>Uses the new <a href="http://kafka.apache.org/documentation.html#newconsumerapi">Consumer API</a> Kafka.</td>
    </tr>
  </tbody>
</table>

<p>Then, import the connector in your maven project:</p>

<div class="highlight"><pre><code class="language-xml" data-lang="xml"><span class="nt">&lt;dependency&gt;</span>
  <span class="nt">&lt;groupId&gt;</span>org.apache.flink<span class="nt">&lt;/groupId&gt;</span>
  <span class="nt">&lt;artifactId&gt;</span>flink-connector-kafka-0.8_2.10<span class="nt">&lt;/artifactId&gt;</span>
  <span class="nt">&lt;version&gt;</span>1.1-SNAPSHOT<span class="nt">&lt;/version&gt;</span>
<span class="nt">&lt;/dependency&gt;</span></code></pre></div>

<p>Note that the streaming connectors are currently not part of the binary distribution. See how to link with them for cluster execution <a href="/apis/cluster_execution.html#linking-with-modules-not-contained-in-the-binary-distribution">here</a>.</p>

<h3 id="installing-apache-kafka">Installing Apache Kafka</h3>

<ul>
  <li>Follow the instructions from <a href="https://kafka.apache.org/documentation.html#quickstart">Kafka’s quickstart</a> to download the code and launch a server (launching a Zookeeper and a Kafka server is required every time before starting the application).</li>
  <li>On 32 bit computers <a href="http://stackoverflow.com/questions/22325364/unrecognized-vm-option-usecompressedoops-when-running-kafka-from-my-ubuntu-in">this</a> problem may occur.</li>
  <li>If the Kafka and Zookeeper servers are running on a remote machine, then the <code>advertised.host.name</code> setting in the <code>config/server.properties</code> file must be set to the machine’s IP address.</li>
</ul>

<h3 id="kafka-consumer">Kafka Consumer</h3>

<p>Flink’s Kafka consumer is called <code>FlinkKafkaConsumer08</code> (or <code>09</code> for Kafka 0.9.0.x versions). It provides access to one or more Kafka topics.</p>

<p>The constructor accepts the following arguments:</p>

<ol>
  <li>The topic name / list of topic names</li>
  <li>A DeserializationSchema / KeyedDeserializationSchema for deserializing the data from Kafka</li>
  <li>Properties for the Kafka consumer.
  The following properties are required:
    <ul>
      <li>“bootstrap.servers” (comma separated list of Kafka brokers)</li>
      <li>“zookeeper.connect” (comma separated list of Zookeeper servers) (<strong>only required for Kafka 0.8</strong>)</li>
      <li>“group.id” the id of the consumer group</li>
    </ul>
  </li>
</ol>

<p>Example:</p>

<div class="codetabs">
  <div data-lang="java">

    <div class="highlight"><pre><code class="language-java" data-lang="java"><span class="n">Properties</span> <span class="n">properties</span> <span class="o">=</span> <span class="k">new</span> <span class="nf">Properties</span><span class="o">();</span>
<span class="n">properties</span><span class="o">.</span><span class="na">setProperty</span><span class="o">(</span><span class="s">&quot;bootstrap.servers&quot;</span><span class="o">,</span> <span class="s">&quot;localhost:9092&quot;</span><span class="o">);</span>
<span class="c1">// only required for Kafka 0.8</span>
<span class="n">properties</span><span class="o">.</span><span class="na">setProperty</span><span class="o">(</span><span class="s">&quot;zookeeper.connect&quot;</span><span class="o">,</span> <span class="s">&quot;localhost:2181&quot;</span><span class="o">);</span>
<span class="n">properties</span><span class="o">.</span><span class="na">setProperty</span><span class="o">(</span><span class="s">&quot;group.id&quot;</span><span class="o">,</span> <span class="s">&quot;test&quot;</span><span class="o">);</span>
<span class="n">DataStream</span><span class="o">&lt;</span><span class="n">String</span><span class="o">&gt;</span> <span class="n">stream</span> <span class="o">=</span> <span class="n">env</span>
	<span class="o">.</span><span class="na">addSource</span><span class="o">(</span><span class="k">new</span> <span class="n">FlinkKafkaConsumer08</span><span class="o">&lt;&gt;(</span><span class="s">&quot;topic&quot;</span><span class="o">,</span> <span class="k">new</span> <span class="nf">SimpleStringSchema</span><span class="o">(),</span> <span class="n">properties</span><span class="o">))</span>
	<span class="o">.</span><span class="na">print</span><span class="o">();</span></code></pre></div>

  </div>
  <div data-lang="scala">

    <div class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">properties</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Properties</span><span class="o">();</span>
<span class="n">properties</span><span class="o">.</span><span class="n">setProperty</span><span class="o">(</span><span class="s">&quot;bootstrap.servers&quot;</span><span class="o">,</span> <span class="s">&quot;localhost:9092&quot;</span><span class="o">);</span>
<span class="c1">// only required for Kafka 0.8</span>
<span class="n">properties</span><span class="o">.</span><span class="n">setProperty</span><span class="o">(</span><span class="s">&quot;zookeeper.connect&quot;</span><span class="o">,</span> <span class="s">&quot;localhost:2181&quot;</span><span class="o">);</span>
<span class="n">properties</span><span class="o">.</span><span class="n">setProperty</span><span class="o">(</span><span class="s">&quot;group.id&quot;</span><span class="o">,</span> <span class="s">&quot;test&quot;</span><span class="o">);</span>
<span class="n">stream</span> <span class="k">=</span> <span class="n">env</span>
    <span class="o">.</span><span class="n">addSource</span><span class="o">(</span><span class="k">new</span> <span class="nc">FlinkKafkaConsumer08</span><span class="o">[</span><span class="kt">String</span><span class="o">](</span><span class="s">&quot;topic&quot;</span><span class="o">,</span> <span class="k">new</span> <span class="nc">SimpleStringSchema</span><span class="o">(),</span> <span class="n">properties</span><span class="o">))</span>
    <span class="o">.</span><span class="n">print</span></code></pre></div>

  </div>
</div>

<p>The current FlinkKafkaConsumer implementation will establish a connection from the client (when calling the constructor)
for querying the list of topics and partitions.</p>

<p>For this to work, the consumer needs to be able to access the consumers from the machine submitting the job to the Flink cluster.
If you experience any issues with the Kafka consumer on the client side, the client log might contain information about failed requests, etc.</p>

<h4 id="the-deserializationschema">The <code>DeserializationSchema</code></h4>

<p>The Flink Kafka Consumer needs to know how to turn the binary data in Kafka into Java/Scala objects. The 
<code>DeserializationSchema</code> allows users to specify such a schema. The <code>T deserialize(byte[] message)</code>
method gets called for each Kafka message, passing the value from Kafka.</p>

<p>It is usually helpful to start from the <code>AbstractDeserializationSchema</code>, which takes care of describing the
produced Java/Scala type to Flink’s type system. Users that implement a vanilla <code>DeserializationSchema</code> need
to implement the <code>getProducedType(...)</code> method themselves.</p>

<p>For accessing both the key and value of the Kafka message, the <code>KeyedDeserializationSchema</code> has
the following deserialize method ` T deserialize(byte[] messageKey, byte[] message, String topic, int partition, long offset)`.</p>

<p>For convenience, Flink provides the following schemas:</p>

<ol>
  <li>
    <p><code>TypeInformationSerializationSchema</code> (and <code>TypeInformationKeyValueSerializationSchema</code>) which creates 
 a schema based on a Flink’s <code>TypeInformation</code>. This is useful if the data is both written and read by Flink.
 This schema is a performant Flink-specific alternative to other generic serialization approaches.</p>
  </li>
  <li>
    <p><code>JsonDeserializationSchema</code> (and <code>JSONKeyValueDeserializationSchema</code>) which turns the serialized JSON 
 into an ObjectNode object, from which fields can be accessed using objectNode.get(“field”).as(Int/String/…)(). 
 The KeyValue objectNode contains a “key” and “value” field which contain all fields, as well as 
 an optional “metadata” field that exposes the offset/partition/topic for this message.</p>
  </li>
</ol>

<h4 id="kafka-consumers-and-fault-tolerance">Kafka Consumers and Fault Tolerance</h4>

<p>With Flink’s checkpointing enabled, the Flink Kafka Consumer will consume records from a topic and periodically checkpoint all
its Kafka offsets, together with the state of other operations, in a consistent manner. In case of a job failure, Flink will restore
the streaming program to the state of the latest checkpoint and re-consume the records from Kafka, starting from the offsets that where
stored in the checkpoint.</p>

<p>The interval of drawing checkpoints therefore defines how much the program may have to go back at most, in case of a failure.</p>

<p>To use fault tolerant Kafka Consumers, checkpointing of the topology needs to be enabled at the execution environment:</p>

<div class="codetabs">
  <div data-lang="java">

    <div class="highlight"><pre><code class="language-java" data-lang="java"><span class="kd">final</span> <span class="n">StreamExecutionEnvironment</span> <span class="n">env</span> <span class="o">=</span> <span class="n">StreamExecutionEnvironment</span><span class="o">.</span><span class="na">getExecutionEnvironment</span><span class="o">();</span>
<span class="n">env</span><span class="o">.</span><span class="na">enableCheckpointing</span><span class="o">(</span><span class="mi">5000</span><span class="o">);</span> <span class="c1">// checkpoint every 5000 msecs</span></code></pre></div>

  </div>
  <div data-lang="scala">

    <div class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">env</span> <span class="k">=</span> <span class="nc">StreamExecutionEnvironment</span><span class="o">.</span><span class="n">getExecutionEnvironment</span><span class="o">()</span>
<span class="n">env</span><span class="o">.</span><span class="n">enableCheckpointing</span><span class="o">(</span><span class="mi">5000</span><span class="o">)</span> <span class="c1">// checkpoint every 5000 msecs</span></code></pre></div>

  </div>
</div>

<p>Also note that Flink can only restart the topology if enough processing slots are available to restart the topology.
So if the topology fails due to loss of a TaskManager, there must still be enough slots available afterwards.
Flink on YARN supports automatic restart of lost YARN containers.</p>

<p>If checkpointing is not enabled, the Kafka consumer will periodically commit the offsets to Zookeeper.</p>

<h3 id="kafka-producer">Kafka Producer</h3>

<p>The <code>FlinkKafkaProducer08</code> writes data to a Kafka topic. The producer can specify a custom partitioner that assigns
records to partitions.</p>

<p>Example:</p>

<div class="codetabs">
  <div data-lang="java">

    <div class="highlight"><pre><code class="language-java" data-lang="java"><span class="n">stream</span><span class="o">.</span><span class="na">addSink</span><span class="o">(</span><span class="k">new</span> <span class="n">FlinkKafkaProducer08</span><span class="o">&lt;</span><span class="n">String</span><span class="o">&gt;(</span><span class="s">&quot;localhost:9092&quot;</span><span class="o">,</span> <span class="s">&quot;my-topic&quot;</span><span class="o">,</span> <span class="k">new</span> <span class="nf">SimpleStringSchema</span><span class="o">()));</span></code></pre></div>

  </div>
  <div data-lang="scala">

    <div class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="n">stream</span><span class="o">.</span><span class="n">addSink</span><span class="o">(</span><span class="k">new</span> <span class="nc">FlinkKafkaProducer08</span><span class="o">[</span><span class="kt">String</span><span class="o">](</span><span class="s">&quot;localhost:9092&quot;</span><span class="o">,</span> <span class="s">&quot;my-topic&quot;</span><span class="o">,</span> <span class="k">new</span> <span class="nc">SimpleStringSchema</span><span class="o">()))</span></code></pre></div>

  </div>
</div>

<p>You can also define a custom Kafka producer configuration for the KafkaSink with the constructor. Please refer to
the <a href="https://kafka.apache.org/documentation.html">Apache Kafka documentation</a> for details on how to configure
Kafka Producers.</p>

<p>Similar to the consumer, the producer also allows using an advanced serialization schema which allows
serializing the key and value separately. It also allows to override the target topic id, so that
one producer instance can send data to multiple topics.</p>

<p>The interface of the serialization schema is called <code>KeyedSerializationSchema</code>.</p>

<p><strong>Note</strong>: By default, the number of retries is set to “0”. This means that the producer fails immediately on errors,
including leader changes. The value is set to “0” by default to avoid duplicate messages in the target topic.
For most production environments with frequent broker changes, we recommend setting the number of retries to a 
higher value.</p>

<p>There is currently no transactional producer for Kafka, so Flink can not guarantee exactly-once delivery
into a Kafka topic.</p>


    </div>
  </div>

  
</div>

    </div><!-- /.container -->

    <!-- jQuery (necessary for Bootstrap's JavaScript plugins) -->
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.2/jquery.min.js"></script>
    <!-- Include all compiled plugins (below), or include individual files as needed -->
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.4/js/bootstrap.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/anchor-js/3.1.0/anchor.min.js"></script>
    <script src="/page/js/flink.js"></script>

    <!-- Google Analytics -->
    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-52545728-1', 'auto');
      ga('send', 'pageview');
    </script>

    <!-- Disqus -->
    
  </body>
</html>
