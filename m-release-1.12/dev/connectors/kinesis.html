<!--
Licensed to the Apache Software Foundation (ASF) under one
or more contributor license agreements.  See the NOTICE file
distributed with this work for additional information
regarding copyright ownership.  The ASF licenses this file
to you under the Apache License, Version 2.0 (the
"License"); you may not use this file except in compliance
with the License.  You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing,
software distributed under the License is distributed on an
"AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
KIND, either express or implied.  See the License for the
specific language governing permissions and limitations
under the License.
-->
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->
    <title>Apache Flink 1.12 Documentation: Amazon Kinesis Data Streams Connector</title>
    <link rel="shortcut icon" href="//ci.apache.org/projects/flink/flink-docs-release-1.12/page/favicon.ico" type="image/x-icon">
    <link rel="icon" href="//ci.apache.org/projects/flink/flink-docs-release-1.12/page/favicon.ico" type="image/x-icon">
    <link rel="canonical" href="//ci.apache.org/projects/flink/flink-docs-stable/dev/connectors/kinesis.html">

    <!-- Bootstrap -->
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.4/css/bootstrap.min.css">
    <link rel="stylesheet" href="//ci.apache.org/projects/flink/flink-docs-release-1.12/page/css/flink.css">
    <link rel="stylesheet" href="//ci.apache.org/projects/flink/flink-docs-release-1.12/page/css/syntax.css">
    <link rel="stylesheet" href="//ci.apache.org/projects/flink/flink-docs-release-1.12/page/css/codetabs.css">
    <link rel="stylesheet" href="//ci.apache.org/projects/flink/flink-docs-release-1.12/page/font-awesome/css/font-awesome.min.css">
    
    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
      <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->
  </head>
  <body>
    

    <!-- Main content. -->
    <div class="container">
      
      <div class="row">
        <div class="col-lg-3" id="sidenavcol">
          <div class="sidenav-logo">
  <p><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/"><img class="bottom" alt="Apache Flink" src="//ci.apache.org/projects/flink/flink-docs-release-1.12/page/img/navbar-brand-logo.jpg"></a> v1.12</p>
</div>
<ul id="sidenav">
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/"><i class="fa fa-home title" aria-hidden="true"></i> Home</a></li><hr class="section-break"></hr>
<li><a href="#collapse-2" data-toggle="collapse"><i class="fa fa-rocket title appetizer" aria-hidden="true"></i> Try Flink<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-2"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/try-flink/local_installation.html">Local Installation</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/try-flink/datastream_api.html">Fraud Detection with the DataStream API</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/try-flink/table_api.html">Real Time Reporting with the Table API</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/try-flink/flink-operations-playground.html">Flink Operations Playground</a></li>
</ul></div></li>
<li><a href="#collapse-8" data-toggle="collapse"><i class="fa fa-hand-paper-o title appetizer" aria-hidden="true"></i> Learn Flink<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-8"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/learn-flink/">Overview</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/learn-flink/datastream_api.html">Intro to the DataStream API</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/learn-flink/etl.html">Data Pipelines & ETL</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/learn-flink/streaming_analytics.html">Streaming Analytics</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/learn-flink/event_driven.html">Event-driven Applications</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/learn-flink/fault_tolerance.html">Fault Tolerance</a></li>
</ul></div></li>
<li><a href="#collapse-15" data-toggle="collapse"><i class="fa fa-map-o title appetizer" aria-hidden="true"></i> Concepts<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-15"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/concepts/index.html">Overview</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/concepts/stateful-stream-processing.html">Stateful Stream Processing</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/concepts/timely-stream-processing.html">Timely Stream Processing</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/concepts/flink-architecture.html">Flink Architecture</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/concepts/glossary.html">Glossary</a></li>
</ul></div></li><hr class="section-break"></hr>
<li><a href="#collapse-21" data-toggle="collapse"><i class="fa fa-code title maindish" aria-hidden="true"></i> Application Development<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-21"><ul>
<li><a href="#collapse-22" data-toggle="collapse">DataStream API<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-22"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/datastream_api.html">Overview</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/datastream_execution_mode.html">Execution Mode (Batch/Streaming)</a></li>
<li><a href="#collapse-24" data-toggle="collapse">Event Time<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-24"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/event_time.html">Overview</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/event_timestamps_watermarks.html">Generating Watermarks</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/event_timestamp_extractors.html">Builtin Watermark Generators</a></li>
</ul></div></li>
<li><a href="#collapse-28" data-toggle="collapse">State & Fault Tolerance<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-28"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/stream/state/">Overview</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/stream/state/state.html">Working with State</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/stream/state/broadcast_state.html">The Broadcast State Pattern</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/stream/state/checkpointing.html">Checkpointing</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/stream/state/queryable_state.html">Queryable State</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/stream/state/state_backends.html">State Backends</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/stream/state/schema_evolution.html">State Schema Evolution</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/stream/state/custom_serialization.html">Custom State Serialization</a></li>
</ul></div></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/user_defined_functions.html">User-Defined Functions</a></li>
<li><a href="#collapse-38" data-toggle="collapse">Operators<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-38"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/stream/operators/">Overview</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/stream/operators/windows.html">Windows</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/stream/operators/joining.html">Joining</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/stream/operators/process_function.html">Process Function</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/stream/operators/asyncio.html">Async I/O</a></li>
</ul></div></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/stream/sources.html">Data Sources</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/stream/side_output.html">Side Outputs</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/application_parameters.html">Handling Application Parameters</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/stream/testing.html">Testing</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/stream/experimental.html">Experimental Features</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/scala_api_extensions.html">Scala API Extensions</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/java_lambdas.html">Java Lambda Expressions</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/project-configuration.html">Project Configuration</a></li>
</ul></div></li>
<li><a href="#collapse-53" data-toggle="collapse">DataSet API<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-53"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/batch/">Overview</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/batch/dataset_transformations.html">Transformations</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/batch/iterations.html">Iterations</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/batch/zip_elements_guide.html">Zipping Elements</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/batch/hadoop_compatibility.html">Hadoop Compatibility</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/local_execution.html">Local Execution</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/cluster_execution.html">Cluster Execution</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/batch/examples.html">Batch Examples</a></li>
</ul></div></li>
<li><a href="#collapse-62" data-toggle="collapse">Table API & SQL<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-62"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/">Overview</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/common.html">Concepts & Common API</a></li>
<li><a href="#collapse-64" data-toggle="collapse">Streaming Concepts<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-64"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/streaming/">Overview</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/streaming/dynamic_tables.html">Dynamic Tables</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/streaming/time_attributes.html">Time Attributes</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/streaming/joins.html">Joins in Continuous Queries</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/streaming/temporal_tables.html">Temporal Tables</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/streaming/match_recognize.html">Detecting Patterns</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/streaming/query_configuration.html">Query Configuration</a></li>
</ul></div></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/types.html">Data Types</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/tableApi.html">Table API</a></li>
<li><a href="#collapse-74" data-toggle="collapse">SQL<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-74"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/sql/">Overview</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/sql/queries.html">Queries</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/sql/create.html">CREATE Statements</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/sql/drop.html">DROP Statements</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/sql/alter.html">ALTER Statements</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/sql/insert.html">INSERT Statement</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/sql/hints.html">SQL Hints</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/sql/describe.html">DESCRIBE Statements</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/sql/explain.html">EXPLAIN Statements</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/sql/use.html">USE Statements</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/sql/show.html">SHOW Statements</a></li>
</ul></div></li>
<li><a href="#collapse-86" data-toggle="collapse">Functions<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-86"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/functions/">Overview</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/functions/systemFunctions.html">System (Built-in) Functions</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/functions/udfs.html">User-defined Functions</a></li>
</ul></div></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/modules.html">Modules</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/catalogs.html">Catalogs</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/sqlClient.html">SQL Client</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/config.html">Configuration</a></li>
<li><a href="#collapse-94" data-toggle="collapse">Performance Tuning<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-94"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/tuning/streaming_aggregation_optimization.html">Streaming Aggregation</a></li>
</ul></div></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/sourceSinks.html">User-defined Sources & Sinks</a></li>
</ul></div></li>
<li><a href="#collapse-99" data-toggle="collapse">Python API<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-99"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/python/">Overview</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/python/installation.html">Installation</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/python/table_api_tutorial.html">Table API Tutorial</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/python/datastream_tutorial.html">DataStream API Tutorial</a></li>
<li><a href="#collapse-103" data-toggle="collapse">Table API User's Guide<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-103"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/python/table-api-users-guide/intro_to_table_api.html">Intro to the Python Table API</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/python/table-api-users-guide/table_environment.html">TableEnvironment</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/python/table-api-users-guide/operations.html">Operations</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/python/table-api-users-guide/python_types.html">Data Types</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/python/table-api-users-guide/built_in_functions.html">System (Built-in) Functions</a></li>
<li><a href="#collapse-109" data-toggle="collapse">User Defined Functions<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-109"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/python/table-api-users-guide/udfs/python_udfs.html">General User-defined Functions</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/python/table-api-users-guide/udfs/vectorized_python_udfs.html">Vectorized User-defined Functions</a></li>
</ul></div></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/python/table-api-users-guide/conversion_of_pandas.html">Conversions between PyFlink Table and Pandas DataFrame</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/python/table-api-users-guide/dependency_management.html">Dependency Management</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/python/table-api-users-guide/sql.html">SQL</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/python/table-api-users-guide/catalogs.html">Catalogs</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/python/table-api-users-guide/metrics.html">Metrics</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/python/table-api-users-guide/python_table_api_connectors.html">Connectors</a></li>
</ul></div></li>
<li><a href="#collapse-120" data-toggle="collapse">DataStream API User's Guide<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-120"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/python/datastream-api-users-guide/data_types.html">Data Types</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/python/datastream-api-users-guide/operators.html">Operators</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/python/datastream-api-users-guide/dependency_management.html">Dependency Management</a></li>
</ul></div></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/python/python_config.html">Configuration</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/python/environment_variables.html">Environment Variables</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/python/faq.html">FAQ</a></li>
</ul></div></li>
<li><a href="#collapse-129" data-toggle="collapse">Data Types & Serialization<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-129"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/types_serialization.html">Overview</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/custom_serializers.html">Custom Serializers</a></li>
</ul></div></li>
<li><a href="#collapse-132" data-toggle="collapse">Managing Execution<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-132"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/execution_configuration.html">Execution Configuration</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/packaging.html">Program Packaging</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/parallel.html">Parallel Execution</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/execution_plans.html">Execution Plans</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/task_failure_recovery.html">Task Failure Recovery</a></li>
</ul></div></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/migration.html">API Migration Guides</a></li>
</ul></div></li>
<li><a href="#collapse-141" data-toggle="collapse"><i class="fa fa-book title maindish" aria-hidden="true"></i> Libraries<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-141"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/libs/cep.html">Event Processing (CEP)</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/libs/state_processor_api.html">State Processor API</a></li>
<li><a href="#collapse-144" data-toggle="collapse">Graphs: Gelly<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-144"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/libs/gelly/">Overview</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/libs/gelly/graph_api.html">Graph API</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/libs/gelly/iterative_graph_processing.html">Iterative Graph Processing</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/libs/gelly/library_methods.html">Library Methods</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/libs/gelly/graph_algorithms.html">Graph Algorithms</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/libs/gelly/graph_generators.html">Graph Generators</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/libs/gelly/bipartite_graph.html">Bipartite Graph</a></li>
</ul></div></li>
</ul></div></li>
<li><a href="#collapse-153" data-toggle="collapse"class="active"><i class="fa fa-random title maindish" aria-hidden="true"></i> Connectors</a><div class="collapse in" id="collapse-153"><ul>
<li><a href="#collapse-154" data-toggle="collapse"class="active">DataStream Connectors</a><div class="collapse in" id="collapse-154"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/connectors/">Overview</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/connectors/guarantees.html">Fault Tolerance Guarantees</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/connectors/kafka.html">Kafka</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/connectors/cassandra.html">Cassandra</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/connectors/kinesis.html" class="active">Kinesis</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/connectors/elasticsearch.html">Elasticsearch</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/connectors/file_sink.html">File Sink</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/connectors/streamfile_sink.html">Streaming File Sink</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/connectors/rabbitmq.html">RabbitMQ</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/connectors/nifi.html">NiFi</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/connectors/pubsub.html">Google Cloud PubSub</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/connectors/twitter.html">Twitter</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/connectors/jdbc.html">JDBC</a></li>
</ul></div></li>
<li><a href="#collapse-168" data-toggle="collapse">Table & SQL Connectors<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-168"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/connectors/">Overview</a></li>
<li><a href="#collapse-169" data-toggle="collapse">Formats<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-169"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/connectors/formats/">Overview</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/connectors/formats/csv.html">CSV</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/connectors/formats/json.html">JSON</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/connectors/formats/avro-confluent.html">Confluent Avro</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/connectors/formats/avro.html">Avro</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/connectors/formats/debezium.html">Debezium</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/connectors/formats/canal.html">Canal</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/connectors/formats/maxwell.html">Maxwell</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/connectors/formats/parquet.html">Parquet</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/connectors/formats/orc.html">Orc</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/connectors/formats/raw.html">Raw</a></li>
</ul></div></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/connectors/kafka.html">Kafka</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/connectors/upsert-kafka.html">Upsert Kafka</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/connectors/kinesis.html">Kinesis</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/connectors/jdbc.html">JDBC</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/connectors/elasticsearch.html">Elasticsearch</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/connectors/filesystem.html">FileSystem</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/connectors/hbase.html">HBase</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/connectors/datagen.html">DataGen</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/connectors/print.html">Print</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/connectors/blackhole.html">BlackHole</a></li>
<li><a href="#collapse-191" data-toggle="collapse">Hive<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-191"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/connectors/hive/">Overview</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/connectors/hive/hive_catalog.html">Hive Catalog</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/connectors/hive/hive_dialect.html">Hive Dialect</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/connectors/hive/hive_read_write.html">Hive Read & Write</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/connectors/hive/hive_functions.html">Hive Functions</a></li>
</ul></div></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/connectors/downloads.html">Download</a></li>
</ul></div></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/batch/connectors.html">DataSet Connectors</a></li>
</ul></div></li>
<li><a href="#collapse-201" data-toggle="collapse"><i class="fa fa-sliders title maindish" aria-hidden="true"></i> Deployment<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-201"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/deployment/">Overview</a></li>
<li><a href="#collapse-202" data-toggle="collapse">Resource Providers<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-202"><ul>
<li><a href="#collapse-203" data-toggle="collapse">Standalone<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-203"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/deployment/resource-providers/standalone/">Overview</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/deployment/resource-providers/standalone/local.html">Local Cluster</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/deployment/resource-providers/standalone/docker.html">Docker</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/deployment/resource-providers/standalone/kubernetes.html">Kubernetes</a></li>
</ul></div></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/deployment/resource-providers/native_kubernetes.html">Native Kubernetes</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/deployment/resource-providers/yarn.html">YARN</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/deployment/resource-providers/mesos.html">Mesos</a></li>
</ul></div></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/deployment/config.html">Configuration</a></li>
<li><a href="#collapse-213" data-toggle="collapse">Memory Configuration<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-213"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/deployment/memory/mem_setup.html">Set up Flink's Process Memory</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/deployment/memory/mem_setup_tm.html">Set up TaskManager Memory</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/deployment/memory/mem_setup_jobmanager.html">Set up JobManager Memory</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/deployment/memory/mem_tuning.html">Memory tuning guide</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/deployment/memory/mem_trouble.html">Troubleshooting</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/deployment/memory/mem_migration.html">Migration Guide</a></li>
</ul></div></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/deployment/cli.html">Command-Line Interface</a></li>
<li><a href="#collapse-222" data-toggle="collapse">File Systems<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-222"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/deployment/filesystems/">Overview</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/deployment/filesystems/common.html">Common Configurations</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/deployment/filesystems/s3.html">Amazon S3</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/deployment/filesystems/oss.html">Aliyun OSS</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/deployment/filesystems/azure.html">Azure Blob Storage</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/deployment/filesystems/plugins.html">Plugins</a></li>
</ul></div></li>
<li><a href="#collapse-229" data-toggle="collapse">High Availability (HA)<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-229"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/deployment/ha/">Overview</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/deployment/ha/zookeeper_ha.html">ZooKeeper HA Services</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/deployment/ha/kubernetes_ha.html">Kubernetes HA Services</a></li>
</ul></div></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/deployment/metric_reporters.html">Metric Reporters</a></li>
<li><a href="#collapse-234" data-toggle="collapse">Security<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-234"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/deployment/security/security-ssl.html">SSL Setup</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/deployment/security/security-kerberos.html">Kerberos</a></li>
</ul></div></li>
<li><a href="#collapse-238" data-toggle="collapse">REPLs<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-238"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/deployment/repls/python_shell.html">Python REPL</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/deployment/repls/scala_shell.html">Scala REPL</a></li>
</ul></div></li>
<li><a href="#collapse-242" data-toggle="collapse">Advanced<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-242"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/deployment/advanced/external_resources.html">External Resources</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/deployment/advanced/historyserver.html">History Server</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/deployment/advanced/logging.html">Logging</a></li>
</ul></div></li>
</ul></div></li>
<li><a href="#collapse-248" data-toggle="collapse"><i class="fa fa-cogs title maindish" aria-hidden="true"></i> Operations<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-248"><ul>
<li><a href="#collapse-249" data-toggle="collapse">State & Fault Tolerance<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-249"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/ops/state/checkpoints.html">Checkpoints</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/ops/state/savepoints.html">Savepoints</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/ops/state/state_backends.html">State Backends</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/ops/state/large_state_tuning.html">Tuning Checkpoints and Large State</a></li>
</ul></div></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/ops/metrics.html">Metrics</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/ops/rest_api.html">REST API</a></li>
<li><a href="#collapse-257" data-toggle="collapse">Debugging<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-257"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/ops/debugging/debugging_event_time.html">Debugging Windows & Event Time</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/ops/debugging/debugging_classloading.html">Debugging Classloading</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/ops/debugging/application_profiling.html">Application Profiling & Debugging</a></li>
</ul></div></li>
<li><a href="#collapse-262" data-toggle="collapse">Monitoring<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-262"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/ops/monitoring/checkpoint_monitoring.html">Monitoring Checkpointing</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/ops/monitoring/back_pressure.html">Monitoring Back Pressure</a></li>
</ul></div></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/ops/upgrading.html">Upgrading Applications and Flink Versions</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/ops/production_ready.html">Production Readiness Checklist</a></li>
</ul></div></li><hr class="section-break"></hr>
<li><a href="#collapse-269" data-toggle="collapse"><i class="fa fa-cogs title dessert" aria-hidden="true"></i> Flink Development<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-269"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/flinkDev/ide_setup.html">Importing Flink into an IDE</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/flinkDev/building.html">Building Flink from Source</a></li>
</ul></div></li>
<li><a href="#collapse-273" data-toggle="collapse"><i class="fa fa-book title dessert" aria-hidden="true"></i> Internals<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-273"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/internals/job_scheduling.html">Jobs and Scheduling</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/internals/task_lifecycle.html">Task Lifecycle</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/internals/filesystems.html">File Systems</a></li>
</ul></div></li>
  <li class="divider"></li>
  <li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/api/java"><i class="fa fa-external-link title" aria-hidden="true"></i> Javadocs</a></li>
  <li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/api/scala/index.html#org.apache.flink.api.scala.package"><i class="fa fa-external-link title" aria-hidden="true"></i> Scaladocs</a></li>
  <li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/api/python"><i class="fa fa-external-link title" aria-hidden="true"></i> Pythondocs</a></li>
  <li><a href="http://flink.apache.org"><i class="fa fa-external-link title" aria-hidden="true"></i> Project Page</a></li>
</ul>

<div class="sidenav-search-box">
  <form class="navbar-form" role="search" action="//ci.apache.org/projects/flink/flink-docs-release-1.12/search-results.html">
    <div class="form-group">
      <input type="text" class="form-control" size="16px" name="q" placeholder="Search">
    </div>
    <button type="submit" class="btn btn-default">Go</button>
  </form>
</div>

<div class="sidenav-versions">
  <div class="dropdown">
    <button class="btn btn-default dropdown-toggle" type="button" data-toggle="dropdown">Pick Docs Version<span class="caret"></span></button>
    <ul class="dropdown-menu">
      <li><a href="http://ci.apache.org/projects/flink/flink-docs-release-1.11">v1.11</a></li>
      <li><a href="http://ci.apache.org/projects/flink/flink-docs-release-1.10">v1.10</a></li>
      <li><a href="http://ci.apache.org/projects/flink/flink-docs-release-1.9">v1.9</a></li>
      <li><a href="http://ci.apache.org/projects/flink/flink-docs-release-1.8">v1.8</a></li>
      <li><a href="http://ci.apache.org/projects/flink/flink-docs-release-1.7">v1.7</a></li>
      <li><a href="http://ci.apache.org/projects/flink/flink-docs-release-1.6">v1.6</a></li>
      <li><a href="http://ci.apache.org/projects/flink/flink-docs-release-1.5">v1.5</a></li>
      <li><a href="http://ci.apache.org/projects/flink/flink-docs-release-1.4">v1.4</a></li>
      <li><a href="http://ci.apache.org/projects/flink/flink-docs-release-1.3">v1.3</a></li>
      <li><a href="http://ci.apache.org/projects/flink/flink-docs-release-1.2">v1.2</a></li>
      <li><a href="http://ci.apache.org/projects/flink/flink-docs-release-1.1">v1.1</a></li>
      <li><a href="http://ci.apache.org/projects/flink/flink-docs-release-1.0">v1.0</a></li>
    </ul>
  </div>
</div>

<div class="sidenav-languages"><!-- link to the Chinese home page when current is blog page -->
    <a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/connectors/kinesis.html">
      <button type="submit" class="btn btn-default">中文版</button>
    </a>
</div>

        </div>
        <div class="col-lg-9 content" id="contentcol">

          

<ol class="breadcrumb">
  
    <li><i class="fa fa-random title maindish" aria-hidden="true"></i> Connectors</li>
  
    <li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/connectors/">DataStream Connectors</a></li>
  
    <li class="active">Kinesis</li>
</ol>

<h1>Amazon Kinesis Data Streams Connector</h1>




<ul id="markdown-toc">
  <li><a href="#using-the-amazon-kinesis-streams-service" id="markdown-toc-using-the-amazon-kinesis-streams-service">Using the Amazon Kinesis Streams Service</a></li>
  <li><a href="#configuring-access-to-kinesis-with-iam" id="markdown-toc-configuring-access-to-kinesis-with-iam">Configuring Access to Kinesis with IAM</a></li>
  <li><a href="#kinesis-consumer" id="markdown-toc-kinesis-consumer">Kinesis Consumer</a>    <ul>
      <li><a href="#configuring-starting-position" id="markdown-toc-configuring-starting-position">Configuring Starting Position</a></li>
      <li><a href="#fault-tolerance-for-exactly-once-user-defined-state-update-semantics" id="markdown-toc-fault-tolerance-for-exactly-once-user-defined-state-update-semantics">Fault Tolerance for Exactly-Once User-Defined State Update Semantics</a></li>
      <li><a href="#using-enhanced-fan-out" id="markdown-toc-using-enhanced-fan-out">Using Enhanced Fan-Out</a></li>
      <li><a href="#event-time-for-consumed-records" id="markdown-toc-event-time-for-consumed-records">Event Time for Consumed Records</a></li>
      <li><a href="#event-time-alignment-for-shard-consumers" id="markdown-toc-event-time-alignment-for-shard-consumers">Event Time Alignment for Shard Consumers</a></li>
      <li><a href="#threading-model" id="markdown-toc-threading-model">Threading Model</a></li>
      <li><a href="#internally-used-kinesis-apis" id="markdown-toc-internally-used-kinesis-apis">Internally Used Kinesis APIs</a></li>
    </ul>
  </li>
  <li><a href="#kinesis-producer" id="markdown-toc-kinesis-producer">Kinesis Producer</a>    <ul>
      <li><a href="#threading-model-1" id="markdown-toc-threading-model-1">Threading Model</a></li>
      <li><a href="#backpressure" id="markdown-toc-backpressure">Backpressure</a></li>
    </ul>
  </li>
  <li><a href="#using-custom-kinesis-endpoints" id="markdown-toc-using-custom-kinesis-endpoints">Using Custom Kinesis Endpoints</a></li>
</ul>

<p>The Kinesis connector provides access to <a href="http://aws.amazon.com/kinesis/streams/">Amazon AWS Kinesis Streams</a>.</p>

<p>To use the connector, add the following Maven dependency to your project:</p>

<figure class="highlight"><pre><code class="language-xml" data-lang="xml"><span class="nt">&lt;dependency&gt;</span>
  <span class="nt">&lt;groupId&gt;</span>org.apache.flink<span class="nt">&lt;/groupId&gt;</span>
  <span class="nt">&lt;artifactId&gt;</span>flink-connector-kinesis_2.11<span class="nt">&lt;/artifactId&gt;</span>
  <span class="nt">&lt;version&gt;</span>1.12.0<span class="nt">&lt;/version&gt;</span>
<span class="nt">&lt;/dependency&gt;</span></code></pre></figure>

<p><span class="label label-danger">Attention</span> Prior to Flink version 1.10.0 the <code class="highlighter-rouge">flink-connector-kinesis_2.11</code> has a dependency on code licensed under the <a href="https://aws.amazon.com/asl/">Amazon Software License</a>.
Linking to the prior versions of flink-connector-kinesis will include this code into your application.</p>

<p>Due to the licensing issue, the <code class="highlighter-rouge">flink-connector-kinesis_2.11</code> artifact is not deployed to Maven central for the prior versions. Please see the version specific documentation for further information.</p>

<h2 id="using-the-amazon-kinesis-streams-service">Using the Amazon Kinesis Streams Service</h2>
<p>Follow the instructions from the <a href="https://docs.aws.amazon.com/streams/latest/dev/learning-kinesis-module-one-create-stream.html">Amazon Kinesis Streams Developer Guide</a>
to setup Kinesis streams.</p>

<h2 id="configuring-access-to-kinesis-with-iam">Configuring Access to Kinesis with IAM</h2>
<p>Make sure to create the appropriate IAM policy to allow reading / writing to / from the Kinesis streams. See examples <a href="https://docs.aws.amazon.com/streams/latest/dev/controlling-access.html">here</a>.</p>

<p>Depending on your deployment you would choose a different Credentials Provider to allow access to Kinesis.
By default, the <code class="highlighter-rouge">AUTO</code> Credentials Provider is used.
If the access key ID and secret key are set in the configuration, the <code class="highlighter-rouge">BASIC</code> provider is used.</p>

<p>A specific Credentials Provider can <strong>optionally</strong> be set by using the <code class="highlighter-rouge">AWSConfigConstants.AWS_CREDENTIALS_PROVIDER</code> setting.</p>

<p>Supported Credential Providers are:</p>
<ul>
  <li><code class="highlighter-rouge">AUTO</code> - Using the default AWS Credentials Provider chain that searches for credentials in the following order: <code class="highlighter-rouge">ENV_VARS</code>, <code class="highlighter-rouge">SYS_PROPS</code>, <code class="highlighter-rouge">WEB_IDENTITY_TOKEN</code>, <code class="highlighter-rouge">PROFILE</code> and EC2/ECS credentials provider.</li>
  <li><code class="highlighter-rouge">BASIC</code> - Using access key ID and secret key supplied as configuration.</li>
  <li><code class="highlighter-rouge">ENV_VAR</code> - Using <code class="highlighter-rouge">AWS_ACCESS_KEY_ID</code> &amp; <code class="highlighter-rouge">AWS_SECRET_ACCESS_KEY</code> environment variables.</li>
  <li><code class="highlighter-rouge">SYS_PROP</code> - Using Java system properties aws.accessKeyId and aws.secretKey.</li>
  <li><code class="highlighter-rouge">PROFILE</code> - Use AWS credentials profile file to create the AWS credentials.</li>
  <li><code class="highlighter-rouge">ASSUME_ROLE</code> - Create AWS credentials by assuming a role. The credentials for assuming the role must be supplied.</li>
  <li><code class="highlighter-rouge">WEB_IDENTITY_TOKEN</code> - Create AWS credentials by assuming a role using Web Identity Token.</li>
</ul>

<h2 id="kinesis-consumer">Kinesis Consumer</h2>

<p>The <code class="highlighter-rouge">FlinkKinesisConsumer</code> is an exactly-once parallel streaming data source that subscribes to multiple AWS Kinesis
streams within the same AWS service region, and can transparently handle resharding of streams while the job is running. Each subtask of the consumer is
responsible for fetching data records from multiple Kinesis shards. The number of shards fetched by each subtask will
change as shards are closed and created by Kinesis.</p>

<p>Before consuming data from Kinesis streams, make sure that all streams are created with the status “ACTIVE” in the AWS dashboard.</p>

<div class="codetabs">
  <div data-lang="java">

    <figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="nc">Properties</span> <span class="n">consumerConfig</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">Properties</span><span class="o">();</span>
<span class="n">consumerConfig</span><span class="o">.</span><span class="na">put</span><span class="o">(</span><span class="nc">AWSConfigConstants</span><span class="o">.</span><span class="na">AWS_REGION</span><span class="o">,</span> <span class="s">"us-east-1"</span><span class="o">);</span>
<span class="n">consumerConfig</span><span class="o">.</span><span class="na">put</span><span class="o">(</span><span class="nc">AWSConfigConstants</span><span class="o">.</span><span class="na">AWS_ACCESS_KEY_ID</span><span class="o">,</span> <span class="s">"aws_access_key_id"</span><span class="o">);</span>
<span class="n">consumerConfig</span><span class="o">.</span><span class="na">put</span><span class="o">(</span><span class="nc">AWSConfigConstants</span><span class="o">.</span><span class="na">AWS_SECRET_ACCESS_KEY</span><span class="o">,</span> <span class="s">"aws_secret_access_key"</span><span class="o">);</span>
<span class="n">consumerConfig</span><span class="o">.</span><span class="na">put</span><span class="o">(</span><span class="nc">ConsumerConfigConstants</span><span class="o">.</span><span class="na">STREAM_INITIAL_POSITION</span><span class="o">,</span> <span class="s">"LATEST"</span><span class="o">);</span>

<span class="nc">StreamExecutionEnvironment</span> <span class="n">env</span> <span class="o">=</span> <span class="nc">StreamExecutionEnvironment</span><span class="o">.</span><span class="na">getExecutionEnvironment</span><span class="o">();</span>

<span class="nc">DataStream</span><span class="o">&lt;</span><span class="nc">String</span><span class="o">&gt;</span> <span class="n">kinesis</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="na">addSource</span><span class="o">(</span><span class="k">new</span> <span class="nc">FlinkKinesisConsumer</span><span class="o">&lt;&gt;(</span>
    <span class="s">"kinesis_stream_name"</span><span class="o">,</span> <span class="k">new</span> <span class="nc">SimpleStringSchema</span><span class="o">(),</span> <span class="n">consumerConfig</span><span class="o">));</span></code></pre></figure>

  </div>
  <div data-lang="scala">

    <figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="nv">consumerConfig</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Properties</span><span class="o">()</span>
<span class="nv">consumerConfig</span><span class="o">.</span><span class="py">put</span><span class="o">(</span><span class="nv">AWSConfigConstants</span><span class="o">.</span><span class="py">AWS_REGION</span><span class="o">,</span> <span class="s">"us-east-1"</span><span class="o">)</span>
<span class="nv">consumerConfig</span><span class="o">.</span><span class="py">put</span><span class="o">(</span><span class="nv">AWSConfigConstants</span><span class="o">.</span><span class="py">AWS_ACCESS_KEY_ID</span><span class="o">,</span> <span class="s">"aws_access_key_id"</span><span class="o">)</span>
<span class="nv">consumerConfig</span><span class="o">.</span><span class="py">put</span><span class="o">(</span><span class="nv">AWSConfigConstants</span><span class="o">.</span><span class="py">AWS_SECRET_ACCESS_KEY</span><span class="o">,</span> <span class="s">"aws_secret_access_key"</span><span class="o">)</span>
<span class="nv">consumerConfig</span><span class="o">.</span><span class="py">put</span><span class="o">(</span><span class="nv">ConsumerConfigConstants</span><span class="o">.</span><span class="py">STREAM_INITIAL_POSITION</span><span class="o">,</span> <span class="s">"LATEST"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">env</span> <span class="k">=</span> <span class="nv">StreamExecutionEnvironment</span><span class="o">.</span><span class="py">getExecutionEnvironment</span><span class="o">()</span>

<span class="k">val</span> <span class="nv">kinesis</span> <span class="k">=</span> <span class="nv">env</span><span class="o">.</span><span class="py">addSource</span><span class="o">(</span><span class="k">new</span> <span class="nc">FlinkKinesisConsumer</span><span class="o">[</span><span class="kt">String</span><span class="o">](</span>
    <span class="s">"kinesis_stream_name"</span><span class="o">,</span> <span class="k">new</span> <span class="nc">SimpleStringSchema</span><span class="o">,</span> <span class="n">consumerConfig</span><span class="o">))</span></code></pre></figure>

  </div>
</div>

<p>The above is a simple example of using the consumer. Configuration for the consumer is supplied with a <code class="highlighter-rouge">java.util.Properties</code>
instance, the configuration keys for which can be found in <code class="highlighter-rouge">AWSConfigConstants</code> (AWS-specific parameters) and 
<code class="highlighter-rouge">ConsumerConfigConstants</code> (Kinesis consumer parameters). The example
demonstrates consuming a single Kinesis stream in the AWS region “us-east-1”. The AWS credentials are supplied using the basic method in which
the AWS access key ID and secret access key are directly supplied in the configuration. Also, data is being consumed
from the newest position in the Kinesis stream (the other option will be setting <code class="highlighter-rouge">ConsumerConfigConstants.STREAM_INITIAL_POSITION</code>
to <code class="highlighter-rouge">TRIM_HORIZON</code>, which lets the consumer start reading the Kinesis stream from the earliest record possible).</p>

<p>Other optional configuration keys for the consumer can be found in <code class="highlighter-rouge">ConsumerConfigConstants</code>.</p>

<p>Note that the configured parallelism of the Flink Kinesis Consumer source
can be completely independent of the total number of shards in the Kinesis streams.
When the number of shards is larger than the parallelism of the consumer,
then each consumer subtask can subscribe to multiple shards; otherwise
if the number of shards is smaller than the parallelism of the consumer,
then some consumer subtasks will simply be idle and wait until it gets assigned
new shards (i.e., when the streams are resharded to increase the
number of shards for higher provisioned Kinesis service throughput).</p>

<p>Also note that the assignment of shards to subtasks may not be optimal when
shard IDs are not consecutive (as result of dynamic re-sharding in Kinesis).
For cases where skew in the assignment leads to significant imbalanced consumption,
a custom implementation of <code class="highlighter-rouge">KinesisShardAssigner</code> can be set on the consumer.</p>

<h3 id="configuring-starting-position">Configuring Starting Position</h3>

<p>The Flink Kinesis Consumer currently provides the following options to configure where to start reading Kinesis streams, simply by setting <code class="highlighter-rouge">ConsumerConfigConstants.STREAM_INITIAL_POSITION</code> to
one of the following values in the provided configuration properties (the naming of the options identically follows <a href="http://docs.aws.amazon.com/kinesis/latest/APIReference/API_GetShardIterator.html#API_GetShardIterator_RequestSyntax">the namings used by the AWS Kinesis Streams service</a>):</p>

<ul>
  <li><code class="highlighter-rouge">LATEST</code>: read all shards of all streams starting from the latest record.</li>
  <li><code class="highlighter-rouge">TRIM_HORIZON</code>: read all shards of all streams starting from the earliest record possible (data may be trimmed by Kinesis depending on the retention settings).</li>
  <li><code class="highlighter-rouge">AT_TIMESTAMP</code>: read all shards of all streams starting from a specified timestamp. The timestamp must also be specified in the configuration
properties by providing a value for <code class="highlighter-rouge">ConsumerConfigConstants.STREAM_INITIAL_TIMESTAMP</code>, in one of the following date pattern :
    <ul>
      <li>a non-negative double value representing the number of seconds that has elapsed since the Unix epoch (for example, <code class="highlighter-rouge">1459799926.480</code>).</li>
      <li>a user defined pattern, which is a valid pattern for <code class="highlighter-rouge">SimpleDateFormat</code> provided by <code class="highlighter-rouge">ConsumerConfigConstants.STREAM_TIMESTAMP_DATE_FORMAT</code>.
  If <code class="highlighter-rouge">ConsumerConfigConstants.STREAM_TIMESTAMP_DATE_FORMAT</code> is not defined then the default pattern will be <code class="highlighter-rouge">yyyy-MM-dd'T'HH:mm:ss.SSSXXX</code>
  (for example, timestamp value is <code class="highlighter-rouge">2016-04-04</code> and pattern is <code class="highlighter-rouge">yyyy-MM-dd</code> given by user or timestamp value is <code class="highlighter-rouge">2016-04-04T19:58:46.480-00:00</code> without given a pattern).</li>
    </ul>
  </li>
</ul>

<h3 id="fault-tolerance-for-exactly-once-user-defined-state-update-semantics">Fault Tolerance for Exactly-Once User-Defined State Update Semantics</h3>

<p>With Flink’s checkpointing enabled, the Flink Kinesis Consumer will consume records from shards in Kinesis streams and
periodically checkpoint each shard’s progress. In case of a job failure, Flink will restore the streaming program to the
state of the latest complete checkpoint and re-consume the records from Kinesis shards, starting from the progress that
was stored in the checkpoint.</p>

<p>The interval of drawing checkpoints therefore defines how much the program may have to go back at most, in case of a failure.</p>

<p>To use fault tolerant Kinesis Consumers, checkpointing of the topology needs to be enabled at the execution environment:</p>

<div class="codetabs">
  <div data-lang="java">

    <figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="kd">final</span> <span class="nc">StreamExecutionEnvironment</span> <span class="n">env</span> <span class="o">=</span> <span class="nc">StreamExecutionEnvironment</span><span class="o">.</span><span class="na">getExecutionEnvironment</span><span class="o">();</span>
<span class="n">env</span><span class="o">.</span><span class="na">enableCheckpointing</span><span class="o">(</span><span class="mi">5000</span><span class="o">);</span> <span class="c1">// checkpoint every 5000 msecs</span></code></pre></figure>

  </div>
  <div data-lang="scala">

    <figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="nv">env</span> <span class="k">=</span> <span class="nv">StreamExecutionEnvironment</span><span class="o">.</span><span class="py">getExecutionEnvironment</span><span class="o">()</span>
<span class="nv">env</span><span class="o">.</span><span class="py">enableCheckpointing</span><span class="o">(</span><span class="mi">5000</span><span class="o">)</span> <span class="c1">// checkpoint every 5000 msecs</span></code></pre></figure>

  </div>
</div>

<p>Also note that Flink can only restart the topology if enough processing slots are available to restart the topology.
Therefore, if the topology fails due to loss of a TaskManager, there must still be enough slots available afterwards.
Flink on YARN supports automatic restart of lost YARN containers.</p>

<h3 id="using-enhanced-fan-out">Using Enhanced Fan-Out</h3>

<p><a href="https://aws.amazon.com/blogs/aws/kds-enhanced-fanout/">Enhanced Fan-Out (EFO)</a> increases the maximum 
number of concurrent consumers per Kinesis stream.
Without EFO, all concurrent consumers share a single read quota per shard. 
Using EFO, each consumer gets a distinct dedicated read quota per shard, allowing read throughput to scale with the number of consumers. 
Using EFO will <a href="https://aws.amazon.com/kinesis/data-streams/pricing/">incur additional cost</a>.</p>

<p>In order to enable EFO two additional configuration parameters are required:</p>

<ul>
  <li><code class="highlighter-rouge">RECORD_PUBLISHER_TYPE</code>: Determines whether to use <code class="highlighter-rouge">EFO</code> or <code class="highlighter-rouge">POLLING</code>. The default <code class="highlighter-rouge">RecordPublisher</code> is <code class="highlighter-rouge">POLLING</code>.</li>
  <li><code class="highlighter-rouge">EFO_CONSUMER_NAME</code>: A name to identify the consumer. 
For a given Kinesis data stream, each consumer must have a unique name. 
However, consumer names do not have to be unique across data streams. 
Reusing a consumer name will result in existing subscriptions being terminated.</li>
</ul>

<p>The code snippet below shows a simple example configurating an EFO consumer.</p>

<div class="codetabs">
  <div data-lang="java">

    <figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="nc">Properties</span> <span class="n">consumerConfig</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">Properties</span><span class="o">();</span>
<span class="n">consumerConfig</span><span class="o">.</span><span class="na">put</span><span class="o">(</span><span class="nc">AWSConfigConstants</span><span class="o">.</span><span class="na">AWS_REGION</span><span class="o">,</span> <span class="s">"us-east-1"</span><span class="o">);</span>
<span class="n">consumerConfig</span><span class="o">.</span><span class="na">put</span><span class="o">(</span><span class="nc">ConsumerConfigConstants</span><span class="o">.</span><span class="na">STREAM_INITIAL_POSITION</span><span class="o">,</span> <span class="s">"LATEST"</span><span class="o">);</span>

<span class="n">consumerConfig</span><span class="o">.</span><span class="na">put</span><span class="o">(</span><span class="nc">ConsumerConfigConstants</span><span class="o">.</span><span class="na">RECORD_PUBLISHER_TYPE</span><span class="o">,</span> 
    <span class="nc">ConsumerConfigConstants</span><span class="o">.</span><span class="na">RecordPublisherType</span><span class="o">.</span><span class="na">EFO</span><span class="o">.</span><span class="na">name</span><span class="o">());</span>
<span class="n">consumerConfig</span><span class="o">.</span><span class="na">put</span><span class="o">(</span><span class="nc">ConsumerConfigConstants</span><span class="o">.</span><span class="na">EFO_CONSUMER_NAME</span><span class="o">,</span> <span class="s">"my-flink-efo-consumer"</span><span class="o">);</span>

<span class="nc">StreamExecutionEnvironment</span> <span class="n">env</span> <span class="o">=</span> <span class="nc">StreamExecutionEnvironment</span><span class="o">.</span><span class="na">getExecutionEnvironment</span><span class="o">();</span>

<span class="nc">DataStream</span><span class="o">&lt;</span><span class="nc">String</span><span class="o">&gt;</span> <span class="n">kinesis</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="na">addSource</span><span class="o">(</span><span class="k">new</span> <span class="nc">FlinkKinesisConsumer</span><span class="o">&lt;&gt;(</span>
    <span class="s">"kinesis_stream_name"</span><span class="o">,</span> <span class="k">new</span> <span class="nc">SimpleStringSchema</span><span class="o">(),</span> <span class="n">consumerConfig</span><span class="o">));</span></code></pre></figure>

  </div>
  <div data-lang="scala">

    <figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="nv">consumerConfig</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Properties</span><span class="o">()</span>
<span class="nv">consumerConfig</span><span class="o">.</span><span class="py">put</span><span class="o">(</span><span class="nv">AWSConfigConstants</span><span class="o">.</span><span class="py">AWS_REGION</span><span class="o">,</span> <span class="s">"us-east-1"</span><span class="o">)</span>
<span class="nv">consumerConfig</span><span class="o">.</span><span class="py">put</span><span class="o">(</span><span class="nv">ConsumerConfigConstants</span><span class="o">.</span><span class="py">STREAM_INITIAL_POSITION</span><span class="o">,</span> <span class="s">"LATEST"</span><span class="o">)</span>

<span class="nv">consumerConfig</span><span class="o">.</span><span class="py">put</span><span class="o">(</span><span class="nv">ConsumerConfigConstants</span><span class="o">.</span><span class="py">RECORD_PUBLISHER_TYPE</span><span class="o">,</span> 
    <span class="nv">ConsumerConfigConstants</span><span class="o">.</span><span class="py">RecordPublisherType</span><span class="o">.</span><span class="py">EFO</span><span class="o">.</span><span class="py">name</span><span class="o">());</span>
<span class="nv">consumerConfig</span><span class="o">.</span><span class="py">put</span><span class="o">(</span><span class="nv">ConsumerConfigConstants</span><span class="o">.</span><span class="py">EFO_CONSUMER_NAME</span><span class="o">,</span> <span class="s">"my-flink-efo-consumer"</span><span class="o">);</span>

<span class="k">val</span> <span class="nv">env</span> <span class="k">=</span> <span class="nv">StreamExecutionEnvironment</span><span class="o">.</span><span class="py">getExecutionEnvironment</span><span class="o">()</span>

<span class="k">val</span> <span class="nv">kinesis</span> <span class="k">=</span> <span class="nv">env</span><span class="o">.</span><span class="py">addSource</span><span class="o">(</span><span class="k">new</span> <span class="nc">FlinkKinesisConsumer</span><span class="o">[</span><span class="kt">String</span><span class="o">](</span>
    <span class="s">"kinesis_stream_name"</span><span class="o">,</span> <span class="k">new</span> <span class="nc">SimpleStringSchema</span><span class="o">,</span> <span class="n">consumerConfig</span><span class="o">))</span></code></pre></figure>

  </div>
</div>

<h4 id="efo-stream-consumer-registrationderegistration">EFO Stream Consumer Registration/Deregistration</h4>

<p>In order to use EFO, a stream consumer must be registered against each stream you wish to consume.
By default, the <code class="highlighter-rouge">FlinkKinesisConsumer</code> will register the stream consumer automatically when the Flink job starts.
The stream consumer will be registered using the name provided by the <code class="highlighter-rouge">EFO_CONSUMER_NAME</code> configuration.
<code class="highlighter-rouge">FlinkKinesisConsumer</code> provides three registration strategies:</p>

<ul>
  <li>Registration
    <ul>
      <li><code class="highlighter-rouge">LAZY</code> (default): Stream consumers are registered when the Flink job starts running.
If the stream consumer already exists, it will be reused.
This is the preferred strategy for the majority of applications.
However, jobs with parallelism greater than 1 will result in tasks competing to register and acquire the stream consumer ARN.
For jobs with very large parallelism this can result in an increased start-up time.
The describe operation has a limit of 20 <a href="https://docs.aws.amazon.com/kinesis/latest/APIReference/API_DescribeStreamConsumer.html">transactions per second</a>,
this means application startup time will increase by roughly <code class="highlighter-rouge">parallelism/20 seconds</code>.</li>
      <li><code class="highlighter-rouge">EAGER</code>: Stream consumers are registered in the <code class="highlighter-rouge">FlinkKinesisConsumer</code> constructor.
If the stream consumer already exists, it will be reused. 
This will result in registration occurring when the job is constructed, 
either on the Flink Job Manager or client environment submitting the job.
Using this strategy results in a single thread registering and retrieving the stream consumer ARN, 
reducing startup time over <code class="highlighter-rouge">LAZY</code> (with large parallelism).
However, consider that the client environment will require access to the AWS services.</li>
      <li><code class="highlighter-rouge">NONE</code>: Stream consumer registration is not performed by <code class="highlighter-rouge">FlinkKinesisConsumer</code>.
Registration must be performed externally using the <a href="https://aws.amazon.com/tools/">AWS CLI or SDK</a>
to invoke <a href="https://docs.aws.amazon.com/kinesis/latest/APIReference/API_RegisterStreamConsumer.html">RegisterStreamConsumer</a>.
Stream consumer ARNs should be provided to the job via the consumer configuration.</li>
    </ul>
  </li>
  <li>Deregistration
    <ul>
      <li><code class="highlighter-rouge">LAZY|EAGER</code> (default): Stream consumers are deregistered when the job is shutdown gracefully.
In the event that a job terminates within executing the shutdown hooks, stream consumers will remain active.
In this situation the stream consumers will be gracefully reused when the application restarts.</li>
      <li><code class="highlighter-rouge">NONE</code>: Stream consumer deregistration is not performed by <code class="highlighter-rouge">FlinkKinesisConsumer</code>.</li>
    </ul>
  </li>
</ul>

<p>Below is an example configuration to use the <code class="highlighter-rouge">EAGER</code> registration strategy:</p>

<div class="codetabs">
  <div data-lang="java">

    <figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="nc">Properties</span> <span class="n">consumerConfig</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">Properties</span><span class="o">();</span>
<span class="n">consumerConfig</span><span class="o">.</span><span class="na">put</span><span class="o">(</span><span class="nc">AWSConfigConstants</span><span class="o">.</span><span class="na">AWS_REGION</span><span class="o">,</span> <span class="s">"us-east-1"</span><span class="o">);</span>
<span class="n">consumerConfig</span><span class="o">.</span><span class="na">put</span><span class="o">(</span><span class="nc">ConsumerConfigConstants</span><span class="o">.</span><span class="na">STREAM_INITIAL_POSITION</span><span class="o">,</span> <span class="s">"LATEST"</span><span class="o">);</span>

<span class="n">consumerConfig</span><span class="o">.</span><span class="na">put</span><span class="o">(</span><span class="nc">ConsumerConfigConstants</span><span class="o">.</span><span class="na">RECORD_PUBLISHER_TYPE</span><span class="o">,</span> 
    <span class="nc">ConsumerConfigConstants</span><span class="o">.</span><span class="na">RecordPublisherType</span><span class="o">.</span><span class="na">EFO</span><span class="o">.</span><span class="na">name</span><span class="o">());</span>
<span class="n">consumerConfig</span><span class="o">.</span><span class="na">put</span><span class="o">(</span><span class="nc">ConsumerConfigConstants</span><span class="o">.</span><span class="na">EFO_CONSUMER_NAME</span><span class="o">,</span> <span class="s">"my-flink-efo-consumer"</span><span class="o">);</span>

<span class="n">consumerConfig</span><span class="o">.</span><span class="na">put</span><span class="o">(</span><span class="nc">ConsumerConfigConstants</span><span class="o">.</span><span class="na">EFO_REGISTRATION_TYPE</span><span class="o">,</span> 
    <span class="nc">ConsumerConfigConstants</span><span class="o">.</span><span class="na">EFORegistrationType</span><span class="o">.</span><span class="na">EAGER</span><span class="o">.</span><span class="na">name</span><span class="o">());</span>

<span class="nc">StreamExecutionEnvironment</span> <span class="n">env</span> <span class="o">=</span> <span class="nc">StreamExecutionEnvironment</span><span class="o">.</span><span class="na">getExecutionEnvironment</span><span class="o">();</span>

<span class="nc">DataStream</span><span class="o">&lt;</span><span class="nc">String</span><span class="o">&gt;</span> <span class="n">kinesis</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="na">addSource</span><span class="o">(</span><span class="k">new</span> <span class="nc">FlinkKinesisConsumer</span><span class="o">&lt;&gt;(</span>
    <span class="s">"kinesis_stream_name"</span><span class="o">,</span> <span class="k">new</span> <span class="nc">SimpleStringSchema</span><span class="o">(),</span> <span class="n">consumerConfig</span><span class="o">));</span></code></pre></figure>

  </div>
  <div data-lang="scala">

    <figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="nv">consumerConfig</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Properties</span><span class="o">()</span>
<span class="nv">consumerConfig</span><span class="o">.</span><span class="py">put</span><span class="o">(</span><span class="nv">AWSConfigConstants</span><span class="o">.</span><span class="py">AWS_REGION</span><span class="o">,</span> <span class="s">"us-east-1"</span><span class="o">)</span>
<span class="nv">consumerConfig</span><span class="o">.</span><span class="py">put</span><span class="o">(</span><span class="nv">ConsumerConfigConstants</span><span class="o">.</span><span class="py">STREAM_INITIAL_POSITION</span><span class="o">,</span> <span class="s">"LATEST"</span><span class="o">)</span>

<span class="nv">consumerConfig</span><span class="o">.</span><span class="py">put</span><span class="o">(</span><span class="nv">ConsumerConfigConstants</span><span class="o">.</span><span class="py">RECORD_PUBLISHER_TYPE</span><span class="o">,</span> 
    <span class="nv">ConsumerConfigConstants</span><span class="o">.</span><span class="py">RecordPublisherType</span><span class="o">.</span><span class="py">EFO</span><span class="o">.</span><span class="py">name</span><span class="o">());</span>
<span class="nv">consumerConfig</span><span class="o">.</span><span class="py">put</span><span class="o">(</span><span class="nv">ConsumerConfigConstants</span><span class="o">.</span><span class="py">EFO_CONSUMER_NAME</span><span class="o">,</span> <span class="s">"my-flink-efo-consumer"</span><span class="o">);</span>

<span class="nv">consumerConfig</span><span class="o">.</span><span class="py">put</span><span class="o">(</span><span class="nv">ConsumerConfigConstants</span><span class="o">.</span><span class="py">EFO_REGISTRATION_TYPE</span><span class="o">,</span> 
    <span class="nv">ConsumerConfigConstants</span><span class="o">.</span><span class="py">EFORegistrationType</span><span class="o">.</span><span class="py">EAGER</span><span class="o">.</span><span class="py">name</span><span class="o">());</span>

<span class="k">val</span> <span class="nv">env</span> <span class="k">=</span> <span class="nv">StreamExecutionEnvironment</span><span class="o">.</span><span class="py">getExecutionEnvironment</span><span class="o">()</span>

<span class="k">val</span> <span class="nv">kinesis</span> <span class="k">=</span> <span class="nv">env</span><span class="o">.</span><span class="py">addSource</span><span class="o">(</span><span class="k">new</span> <span class="nc">FlinkKinesisConsumer</span><span class="o">[</span><span class="kt">String</span><span class="o">](</span>
    <span class="s">"kinesis_stream_name"</span><span class="o">,</span> <span class="k">new</span> <span class="nc">SimpleStringSchema</span><span class="o">,</span> <span class="n">consumerConfig</span><span class="o">))</span></code></pre></figure>

  </div>
</div>

<p>Below is an example configuration to use the <code class="highlighter-rouge">NONE</code> registration strategy:</p>

<div class="codetabs">
  <div data-lang="java">

    <figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="nc">Properties</span> <span class="n">consumerConfig</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">Properties</span><span class="o">();</span>
<span class="n">consumerConfig</span><span class="o">.</span><span class="na">put</span><span class="o">(</span><span class="nc">AWSConfigConstants</span><span class="o">.</span><span class="na">AWS_REGION</span><span class="o">,</span> <span class="s">"us-east-1"</span><span class="o">);</span>
<span class="n">consumerConfig</span><span class="o">.</span><span class="na">put</span><span class="o">(</span><span class="nc">ConsumerConfigConstants</span><span class="o">.</span><span class="na">STREAM_INITIAL_POSITION</span><span class="o">,</span> <span class="s">"LATEST"</span><span class="o">);</span>

<span class="n">consumerConfig</span><span class="o">.</span><span class="na">put</span><span class="o">(</span><span class="nc">ConsumerConfigConstants</span><span class="o">.</span><span class="na">RECORD_PUBLISHER_TYPE</span><span class="o">,</span> 
    <span class="nc">ConsumerConfigConstants</span><span class="o">.</span><span class="na">RecordPublisherType</span><span class="o">.</span><span class="na">EFO</span><span class="o">.</span><span class="na">name</span><span class="o">());</span>
<span class="n">consumerConfig</span><span class="o">.</span><span class="na">put</span><span class="o">(</span><span class="nc">ConsumerConfigConstants</span><span class="o">.</span><span class="na">EFO_CONSUMER_NAME</span><span class="o">,</span> <span class="s">"my-flink-efo-consumer"</span><span class="o">);</span>

<span class="n">consumerConfig</span><span class="o">.</span><span class="na">put</span><span class="o">(</span><span class="nc">ConsumerConfigConstants</span><span class="o">.</span><span class="na">EFO_REGISTRATION_TYPE</span><span class="o">,</span> 
    <span class="nc">ConsumerConfigConstants</span><span class="o">.</span><span class="na">EFORegistrationType</span><span class="o">.</span><span class="na">NONE</span><span class="o">.</span><span class="na">name</span><span class="o">());</span>
<span class="n">consumerConfig</span><span class="o">.</span><span class="na">put</span><span class="o">(</span><span class="nc">ConsumerConfigConstants</span><span class="o">.</span><span class="na">efoConsumerArn</span><span class="o">(</span><span class="s">"stream-name"</span><span class="o">),</span> 
    <span class="s">"arn:aws:kinesis:&lt;region&gt;:&lt;account&gt;&gt;:stream/&lt;stream-name&gt;/consumer/&lt;consumer-name&gt;:&lt;create-timestamp&gt;"</span><span class="o">);</span>

<span class="nc">StreamExecutionEnvironment</span> <span class="n">env</span> <span class="o">=</span> <span class="nc">StreamExecutionEnvironment</span><span class="o">.</span><span class="na">getExecutionEnvironment</span><span class="o">();</span>

<span class="nc">DataStream</span><span class="o">&lt;</span><span class="nc">String</span><span class="o">&gt;</span> <span class="n">kinesis</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="na">addSource</span><span class="o">(</span><span class="k">new</span> <span class="nc">FlinkKinesisConsumer</span><span class="o">&lt;&gt;(</span>
    <span class="s">"kinesis_stream_name"</span><span class="o">,</span> <span class="k">new</span> <span class="nc">SimpleStringSchema</span><span class="o">(),</span> <span class="n">consumerConfig</span><span class="o">));</span></code></pre></figure>

  </div>
  <div data-lang="scala">

    <figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="nv">consumerConfig</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Properties</span><span class="o">()</span>
<span class="nv">consumerConfig</span><span class="o">.</span><span class="py">put</span><span class="o">(</span><span class="nv">AWSConfigConstants</span><span class="o">.</span><span class="py">AWS_REGION</span><span class="o">,</span> <span class="s">"us-east-1"</span><span class="o">)</span>
<span class="nv">consumerConfig</span><span class="o">.</span><span class="py">put</span><span class="o">(</span><span class="nv">ConsumerConfigConstants</span><span class="o">.</span><span class="py">STREAM_INITIAL_POSITION</span><span class="o">,</span> <span class="s">"LATEST"</span><span class="o">)</span>

<span class="nv">consumerConfig</span><span class="o">.</span><span class="py">put</span><span class="o">(</span><span class="nv">ConsumerConfigConstants</span><span class="o">.</span><span class="py">RECORD_PUBLISHER_TYPE</span><span class="o">,</span> 
    <span class="nv">ConsumerConfigConstants</span><span class="o">.</span><span class="py">RecordPublisherType</span><span class="o">.</span><span class="py">EFO</span><span class="o">.</span><span class="py">name</span><span class="o">());</span>
<span class="nv">consumerConfig</span><span class="o">.</span><span class="py">put</span><span class="o">(</span><span class="nv">ConsumerConfigConstants</span><span class="o">.</span><span class="py">EFO_CONSUMER_NAME</span><span class="o">,</span> <span class="s">"my-flink-efo-consumer"</span><span class="o">);</span>

<span class="nv">consumerConfig</span><span class="o">.</span><span class="py">put</span><span class="o">(</span><span class="nv">ConsumerConfigConstants</span><span class="o">.</span><span class="py">EFO_REGISTRATION_TYPE</span><span class="o">,</span> 
    <span class="nv">ConsumerConfigConstants</span><span class="o">.</span><span class="py">EFORegistrationType</span><span class="o">.</span><span class="py">NONE</span><span class="o">.</span><span class="py">name</span><span class="o">());</span>
<span class="nv">consumerConfig</span><span class="o">.</span><span class="py">put</span><span class="o">(</span><span class="nv">ConsumerConfigConstants</span><span class="o">.</span><span class="py">efoConsumerArn</span><span class="o">(</span><span class="s">"stream-name"</span><span class="o">),</span> 
    <span class="s">"arn:aws:kinesis:&lt;region&gt;:&lt;account&gt;&gt;:stream/&lt;stream-name&gt;/consumer/&lt;consumer-name&gt;:&lt;create-timestamp&gt;"</span><span class="o">);</span>

<span class="k">val</span> <span class="nv">env</span> <span class="k">=</span> <span class="nv">StreamExecutionEnvironment</span><span class="o">.</span><span class="py">getExecutionEnvironment</span><span class="o">()</span>

<span class="k">val</span> <span class="nv">kinesis</span> <span class="k">=</span> <span class="nv">env</span><span class="o">.</span><span class="py">addSource</span><span class="o">(</span><span class="k">new</span> <span class="nc">FlinkKinesisConsumer</span><span class="o">[</span><span class="kt">String</span><span class="o">](</span>
    <span class="s">"kinesis_stream_name"</span><span class="o">,</span> <span class="k">new</span> <span class="nc">SimpleStringSchema</span><span class="o">,</span> <span class="n">consumerConfig</span><span class="o">))</span></code></pre></figure>

  </div>
</div>

<h3 id="event-time-for-consumed-records">Event Time for Consumed Records</h3>

<p>If streaming topologies choose to use the <a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/event_time.html">event time notion</a> for record
timestamps, an <em>approximate arrival timestamp</em> will be used by default. This timestamp is attached to records by Kinesis once they
were successfully received and stored by streams. Note that this timestamp is typically referred to as a Kinesis server-side
timestamp, and there are no guarantees about the accuracy or order correctness (i.e., the timestamps may not always be
ascending).</p>

<p>Users can choose to override this default with a custom timestamp, as described <a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/event_timestamps_watermarks.html">here</a>,
or use one from the <a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/event_timestamp_extractors.html">predefined ones</a>. After doing so,
it can be passed to the consumer in the following way:</p>

<div class="codetabs">
  <div data-lang="java">

    <figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="nc">FlinkKinesisConsumer</span><span class="o">&lt;</span><span class="nc">String</span><span class="o">&gt;</span> <span class="n">consumer</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">FlinkKinesisConsumer</span><span class="o">&lt;&gt;(</span>
    <span class="s">"kinesis_stream_name"</span><span class="o">,</span>
    <span class="k">new</span> <span class="nf">SimpleStringSchema</span><span class="o">(),</span>
    <span class="n">kinesisConsumerConfig</span><span class="o">);</span>
<span class="n">consumer</span><span class="o">.</span><span class="na">setPeriodicWatermarkAssigner</span><span class="o">(</span><span class="k">new</span> <span class="nc">CustomAssignerWithPeriodicWatermarks</span><span class="o">());</span>
<span class="nc">DataStream</span><span class="o">&lt;</span><span class="nc">String</span><span class="o">&gt;</span> <span class="n">stream</span> <span class="o">=</span> <span class="n">env</span>
	<span class="o">.</span><span class="na">addSource</span><span class="o">(</span><span class="n">consumer</span><span class="o">)</span>
	<span class="o">.</span><span class="na">print</span><span class="o">();</span></code></pre></figure>

  </div>
  <div data-lang="scala">

    <figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="nv">consumer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">FlinkKinesisConsumer</span><span class="o">[</span><span class="kt">String</span><span class="o">](</span>
    <span class="s">"kinesis_stream_name"</span><span class="o">,</span>
    <span class="k">new</span> <span class="nc">SimpleStringSchema</span><span class="o">(),</span>
    <span class="n">kinesisConsumerConfig</span><span class="o">);</span>
<span class="nv">consumer</span><span class="o">.</span><span class="py">setPeriodicWatermarkAssigner</span><span class="o">(</span><span class="k">new</span> <span class="nc">CustomAssignerWithPeriodicWatermarks</span><span class="o">());</span>
<span class="k">val</span> <span class="nv">stream</span> <span class="k">=</span> <span class="n">env</span>
	<span class="o">.</span><span class="py">addSource</span><span class="o">(</span><span class="n">consumer</span><span class="o">)</span>
	<span class="o">.</span><span class="py">print</span><span class="o">();</span></code></pre></figure>

  </div>
</div>

<p>Internally, an instance of the assigner is executed per shard / consumer thread (see threading model below).
When an assigner is specified, for each record read from Kinesis, the extractTimestamp(T element, long previousElementTimestamp)
is called to assign a timestamp to the record and getCurrentWatermark() to determine the new watermark for the shard.
The watermark of the consumer subtask is then determined as the minimum watermark of all its shards and emitted periodically.
The per shard watermark is essential to deal with varying consumption speed between shards, that otherwise could lead
to issues with downstream logic that relies on the watermark, such as incorrect late data dropping.</p>

<p>By default, the watermark is going to stall if shards do not deliver new records.
The property <code class="highlighter-rouge">ConsumerConfigConstants.SHARD_IDLE_INTERVAL_MILLIS</code> can be used to avoid this potential issue through a
timeout that will allow the watermark to progress despite of idle shards.</p>

<h3 id="event-time-alignment-for-shard-consumers">Event Time Alignment for Shard Consumers</h3>

<p>The Flink Kinesis Consumer optionally supports synchronization between parallel consumer subtasks (and their threads)
to avoid the event time skew related problems described in <a href="https://issues.apache.org/jira/browse/FLINK-10886">Event time synchronization across sources</a>.</p>

<p>To enable synchronization, set the watermark tracker on the consumer:</p>

<div data-lang="java">

  <figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="nc">JobManagerWatermarkTracker</span> <span class="n">watermarkTracker</span> <span class="o">=</span>
    <span class="k">new</span> <span class="nf">JobManagerWatermarkTracker</span><span class="o">(</span><span class="s">"myKinesisSource"</span><span class="o">);</span>
<span class="n">consumer</span><span class="o">.</span><span class="na">setWatermarkTracker</span><span class="o">(</span><span class="n">watermarkTracker</span><span class="o">);</span></code></pre></figure>

</div>

<p>The <code class="highlighter-rouge">JobManagerWatermarkTracker</code> will use a global aggregate to synchronize the per subtask watermarks. Each subtask
uses a per shard queue to control the rate at which records are emitted downstream based on how far ahead of the global
watermark the next record in the queue is.</p>

<p>The “emit ahead” limit is configured via <code class="highlighter-rouge">ConsumerConfigConstants.WATERMARK_LOOKAHEAD_MILLIS</code>. Smaller values reduce
the skew but also the throughput. Larger values will allow the subtask to proceed further before waiting for the global
watermark to advance.</p>

<p>Another variable in the throughput equation is how frequently the watermark is propagated by the tracker.
The interval can be configured via <code class="highlighter-rouge">ConsumerConfigConstants.WATERMARK_SYNC_MILLIS</code>.
Smaller values reduce emitter waits and come at the cost of increased communication with the job manager.</p>

<p>Since records accumulate in the queues when skew occurs, increased memory consumption needs to be expected.
How much depends on the average record size. With larger sizes, it may be necessary to adjust the emitter queue capacity via
<code class="highlighter-rouge">ConsumerConfigConstants.WATERMARK_SYNC_QUEUE_CAPACITY</code>.</p>

<h3 id="threading-model">Threading Model</h3>

<p>The Flink Kinesis Consumer uses multiple threads for shard discovery and data consumption.</p>

<h4 id="shard-discovery">Shard Discovery</h4>

<p>For shard discovery, each parallel consumer subtask will have a single thread that constantly queries Kinesis for shard
information even if the subtask initially did not have shards to read from when the consumer was started. In other words, if
the consumer is run with a parallelism of 10, there will be a total of 10 threads constantly querying Kinesis regardless
of the total amount of shards in the subscribed streams.</p>

<h4 id="polling-default-record-publisher">Polling (default) Record Publisher</h4>

<p>For <code class="highlighter-rouge">POLLING</code> data consumption, a single thread will be created to consume each discovered shard. Threads will terminate when the
shard it is responsible of consuming is closed as a result of stream resharding. In other words, there will always be
one thread per open shard.</p>

<h4 id="enhanced-fan-out-record-publisher">Enhanced Fan-Out Record Publisher</h4>

<p>For <code class="highlighter-rouge">EFO</code> data consumption the threading model is the same as <code class="highlighter-rouge">POLLING</code>, with additional thread pools to handle 
asynchronous communication with Kinesis. AWS SDK v2.x <code class="highlighter-rouge">KinesisAsyncClient</code> uses additional threads for 
Netty to handle IO and asynchronous response. Each parallel consumer subtask will have their own instance of the <code class="highlighter-rouge">KinesisAsyncClient</code>.
In other words, if the consumer is run with a parallelism of 10, there will be a total of 10 <code class="highlighter-rouge">KinesisAsyncClient</code> instances.
A separate client will be created and subsequently destroyed when registering and deregistering stream consumers.</p>

<h3 id="internally-used-kinesis-apis">Internally Used Kinesis APIs</h3>

<p>The Flink Kinesis Consumer uses the <a href="http://aws.amazon.com/sdk-for-java/">AWS Java SDK</a> internally to call Kinesis APIs
for shard discovery and data consumption. Due to Amazon’s <a href="http://docs.aws.amazon.com/streams/latest/dev/service-sizes-and-limits.html">service limits for Kinesis Streams</a>
on the APIs, the consumer will be competing with other non-Flink consuming applications that the user may be running.
Below is a list of APIs called by the consumer with description of how the consumer uses the API, as well as information
on how to deal with any errors or warnings that the Flink Kinesis Consumer may have due to these service limits.</p>

<h4 id="shard-discovery-1">Shard Discovery</h4>

<ul>
  <li><em><a href="https://docs.aws.amazon.com/kinesis/latest/APIReference/API_ListShards.html">ListShards</a></em>: this is constantly called
by a single thread in each parallel consumer subtask to discover any new shards as a result of stream resharding. By default,
the consumer performs the shard discovery at an interval of 10 seconds, and will retry indefinitely until it gets a result
from Kinesis. If this interferes with other non-Flink consuming applications, users can slow down the consumer of
calling this API by setting a value for <code class="highlighter-rouge">ConsumerConfigConstants.SHARD_DISCOVERY_INTERVAL_MILLIS</code> in the supplied
configuration properties. This sets the discovery interval to a different value. Note that this setting directly impacts
the maximum delay of discovering a new shard and starting to consume it, as shards will not be discovered during the interval.</li>
</ul>

<h4 id="polling-default-record-publisher-1">Polling (default) Record Publisher</h4>

<ul>
  <li>
    <p><em><a href="https://docs.aws.amazon.com/kinesis/latest/APIReference/API_GetShardIterator.html">GetShardIterator</a></em>: this is called
only once when per shard consuming threads are started, and will retry if Kinesis complains that the transaction limit for the
API has exceeded, up to a default of 3 attempts. Note that since the rate limit for this API is per shard (not per stream),
the consumer itself should not exceed the limit. Usually, if this happens, users can either try to slow down any other
non-Flink consuming applications of calling this API, or modify the retry behaviour of this API call in the consumer by
setting keys prefixed by <code class="highlighter-rouge">ConsumerConfigConstants.SHARD_GETITERATOR_*</code> in the supplied configuration properties.</p>
  </li>
  <li>
    <p><em><a href="https://docs.aws.amazon.com/kinesis/latest/APIReference/API_GetRecords.html">GetRecords</a></em>: this is constantly called
by per shard consuming threads to fetch records from Kinesis. When a shard has multiple concurrent consumers (when there
are any other non-Flink consuming applications running), the per shard rate limit may be exceeded. By default, on each call
of this API, the consumer will retry if Kinesis complains that the data size / transaction limit for the API has exceeded,
up to a default of 3 attempts. Users can either try to slow down other non-Flink consuming applications, or adjust the throughput
of the consumer by setting the <code class="highlighter-rouge">ConsumerConfigConstants.SHARD_GETRECORDS_MAX</code> and
<code class="highlighter-rouge">ConsumerConfigConstants.SHARD_GETRECORDS_INTERVAL_MILLIS</code> keys in the supplied configuration properties. Setting the former
adjusts the maximum number of records each consuming thread tries to fetch from shards on each call (default is 10,000), while
the latter modifies the sleep interval between each fetch (default is 200). The retry behaviour of the
consumer when calling this API can also be modified by using the other keys prefixed by <code class="highlighter-rouge">ConsumerConfigConstants.SHARD_GETRECORDS_*</code>.</p>
  </li>
</ul>

<h4 id="enhanced-fan-out-record-publisher-1">Enhanced Fan-Out Record Publisher</h4>

<ul>
  <li>
    <p><em><a href="https://docs.aws.amazon.com/kinesis/latest/APIReference/API_SubscribeToShard.html">SubscribeToShard</a></em>: this is called
by per shard consuming threads to obtain shard subscriptions. A shard subscription is typically active for 5 minutes, 
but subscriptions will be reaquired if any recoverable errors are thrown. Once a subscription is acquired, the consumer
will receive a stream of <a href="https://docs.aws.amazon.com/kinesis/latest/APIReference/API_SubscribeToShardEvent.html">SubscribeToShardEvents</a>s.
Retry and backoff parameters can be configured using the <code class="highlighter-rouge">ConsumerConfigConstants.SUBSCRIBE_TO_SHARD_*</code> keys.</p>
  </li>
  <li>
    <p><em><a href="https://docs.aws.amazon.com/kinesis/latest/APIReference/API_DescribeStream.html">DescribeStream</a></em>: this is called 
once per stream, during stream consumer registration. By default, the <code class="highlighter-rouge">LAZY</code> registration strategy will scale the
number of calls by the job parallelism. <code class="highlighter-rouge">EAGER</code> will invoke this once per stream and <code class="highlighter-rouge">NONE</code> will not invoke this API. 
Retry and backoff parameters can be configured using the 
<code class="highlighter-rouge">ConsumerConfigConstants.STREAM_DESCRIBE_*</code> keys.</p>
  </li>
  <li>
    <p><em><a href="https://docs.aws.amazon.com/kinesis/latest/APIReference/API_DescribeStreamConsumer.html">DescribeStreamConsumer</a></em>:
this is called during stream consumer registration and deregistration. For each stream this service will be invoked 
periodically until the stream consumer is reported <code class="highlighter-rouge">ACTIVE</code>/<code class="highlighter-rouge">not found</code> for registration/deregistration. By default,
the <code class="highlighter-rouge">LAZY</code> registration strategy will scale the number of calls by the job parallelism. <code class="highlighter-rouge">EAGER</code> will call the service 
once per stream for registration, and scale the number of calls by the job parallelism for deregistration. 
<code class="highlighter-rouge">NONE</code> will not invoke this service. Retry and backoff parameters can be configured using the 
<code class="highlighter-rouge">ConsumerConfigConstants.DESCRIBE_STREAM_CONSUMER_*</code> keys.</p>
  </li>
  <li>
    <p><em><a href="https://docs.aws.amazon.com/kinesis/latest/APIReference/API_RegisterStreamConsumer.html">RegisterStreamConsumer</a></em>: 
this is called once per stream during stream consumer registration, unless the <code class="highlighter-rouge">NONE</code> registration strategy is configured.
Retry and backoff parameters can be configured using the <code class="highlighter-rouge">ConsumerConfigConstants.REGISTER_STREAM_*</code> keys.</p>
  </li>
  <li>
    <p><em><a href="https://docs.aws.amazon.com/kinesis/latest/APIReference/API_DeregisterStreamConsumer.html">DeregisterStreamConsumer</a></em>: 
this is called once per stream during stream consumer deregistration, unless the <code class="highlighter-rouge">NONE</code> registration strategy is configured.
Retry and backoff parameters can be configured using the <code class="highlighter-rouge">ConsumerConfigConstants.DEREGISTER_STREAM_*</code> keys.</p>
  </li>
</ul>

<h2 id="kinesis-producer">Kinesis Producer</h2>

<p>The <code class="highlighter-rouge">FlinkKinesisProducer</code> uses <a href="http://docs.aws.amazon.com/streams/latest/dev/developing-producers-with-kpl.html">Kinesis Producer Library (KPL)</a> to put data from a Flink stream into a Kinesis stream.</p>

<p>Note that the producer is not participating in Flink’s checkpointing and doesn’t provide exactly-once processing guarantees. Also, the Kinesis producer does not guarantee that records are written in order to the shards (See <a href="https://github.com/awslabs/amazon-kinesis-producer/issues/23">here</a> and <a href="http://docs.aws.amazon.com/kinesis/latest/APIReference/API_PutRecord.html#API_PutRecord_RequestSyntax">here</a> for more details).</p>

<p>In case of a failure or a resharding, data will be written again to Kinesis, leading to duplicates. This behavior is usually called “at-least-once” semantics.</p>

<p>To put data into a Kinesis stream, make sure the stream is marked as “ACTIVE” in the AWS dashboard.</p>

<p>For the monitoring to work, the user accessing the stream needs access to the CloudWatch service.</p>

<div class="codetabs">
  <div data-lang="java">

    <figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="nc">Properties</span> <span class="n">producerConfig</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">Properties</span><span class="o">();</span>
<span class="c1">// Required configs</span>
<span class="n">producerConfig</span><span class="o">.</span><span class="na">put</span><span class="o">(</span><span class="nc">AWSConfigConstants</span><span class="o">.</span><span class="na">AWS_REGION</span><span class="o">,</span> <span class="s">"us-east-1"</span><span class="o">);</span>
<span class="n">producerConfig</span><span class="o">.</span><span class="na">put</span><span class="o">(</span><span class="nc">AWSConfigConstants</span><span class="o">.</span><span class="na">AWS_ACCESS_KEY_ID</span><span class="o">,</span> <span class="s">"aws_access_key_id"</span><span class="o">);</span>
<span class="n">producerConfig</span><span class="o">.</span><span class="na">put</span><span class="o">(</span><span class="nc">AWSConfigConstants</span><span class="o">.</span><span class="na">AWS_SECRET_ACCESS_KEY</span><span class="o">,</span> <span class="s">"aws_secret_access_key"</span><span class="o">);</span>
<span class="c1">// Optional configs</span>
<span class="n">producerConfig</span><span class="o">.</span><span class="na">put</span><span class="o">(</span><span class="s">"AggregationMaxCount"</span><span class="o">,</span> <span class="s">"4294967295"</span><span class="o">);</span>
<span class="n">producerConfig</span><span class="o">.</span><span class="na">put</span><span class="o">(</span><span class="s">"CollectionMaxCount"</span><span class="o">,</span> <span class="s">"1000"</span><span class="o">);</span>
<span class="n">producerConfig</span><span class="o">.</span><span class="na">put</span><span class="o">(</span><span class="s">"RecordTtl"</span><span class="o">,</span> <span class="s">"30000"</span><span class="o">);</span>
<span class="n">producerConfig</span><span class="o">.</span><span class="na">put</span><span class="o">(</span><span class="s">"RequestTimeout"</span><span class="o">,</span> <span class="s">"6000"</span><span class="o">);</span>
<span class="n">producerConfig</span><span class="o">.</span><span class="na">put</span><span class="o">(</span><span class="s">"ThreadPoolSize"</span><span class="o">,</span> <span class="s">"15"</span><span class="o">);</span>

<span class="c1">// Disable Aggregation if it's not supported by a consumer</span>
<span class="c1">// producerConfig.put("AggregationEnabled", "false");</span>
<span class="c1">// Switch KinesisProducer's threading model</span>
<span class="c1">// producerConfig.put("ThreadingModel", "PER_REQUEST");</span>

<span class="nc">FlinkKinesisProducer</span><span class="o">&lt;</span><span class="nc">String</span><span class="o">&gt;</span> <span class="n">kinesis</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">FlinkKinesisProducer</span><span class="o">&lt;&gt;(</span><span class="k">new</span> <span class="nc">SimpleStringSchema</span><span class="o">(),</span> <span class="n">producerConfig</span><span class="o">);</span>
<span class="n">kinesis</span><span class="o">.</span><span class="na">setFailOnError</span><span class="o">(</span><span class="kc">true</span><span class="o">);</span>
<span class="n">kinesis</span><span class="o">.</span><span class="na">setDefaultStream</span><span class="o">(</span><span class="s">"kinesis_stream_name"</span><span class="o">);</span>
<span class="n">kinesis</span><span class="o">.</span><span class="na">setDefaultPartition</span><span class="o">(</span><span class="s">"0"</span><span class="o">);</span>

<span class="nc">DataStream</span><span class="o">&lt;</span><span class="nc">String</span><span class="o">&gt;</span> <span class="n">simpleStringStream</span> <span class="o">=</span> <span class="o">...;</span>
<span class="n">simpleStringStream</span><span class="o">.</span><span class="na">addSink</span><span class="o">(</span><span class="n">kinesis</span><span class="o">);</span></code></pre></figure>

  </div>
  <div data-lang="scala">

    <figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="nv">producerConfig</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Properties</span><span class="o">()</span>
<span class="c1">// Required configs</span>
<span class="nv">producerConfig</span><span class="o">.</span><span class="py">put</span><span class="o">(</span><span class="nv">AWSConfigConstants</span><span class="o">.</span><span class="py">AWS_REGION</span><span class="o">,</span> <span class="s">"us-east-1"</span><span class="o">)</span>
<span class="nv">producerConfig</span><span class="o">.</span><span class="py">put</span><span class="o">(</span><span class="nv">AWSConfigConstants</span><span class="o">.</span><span class="py">AWS_ACCESS_KEY_ID</span><span class="o">,</span> <span class="s">"aws_access_key_id"</span><span class="o">)</span>
<span class="nv">producerConfig</span><span class="o">.</span><span class="py">put</span><span class="o">(</span><span class="nv">AWSConfigConstants</span><span class="o">.</span><span class="py">AWS_SECRET_ACCESS_KEY</span><span class="o">,</span> <span class="s">"aws_secret_access_key"</span><span class="o">)</span>
<span class="c1">// Optional KPL configs</span>
<span class="nv">producerConfig</span><span class="o">.</span><span class="py">put</span><span class="o">(</span><span class="s">"AggregationMaxCount"</span><span class="o">,</span> <span class="s">"4294967295"</span><span class="o">)</span>
<span class="nv">producerConfig</span><span class="o">.</span><span class="py">put</span><span class="o">(</span><span class="s">"CollectionMaxCount"</span><span class="o">,</span> <span class="s">"1000"</span><span class="o">)</span>
<span class="nv">producerConfig</span><span class="o">.</span><span class="py">put</span><span class="o">(</span><span class="s">"RecordTtl"</span><span class="o">,</span> <span class="s">"30000"</span><span class="o">)</span>
<span class="nv">producerConfig</span><span class="o">.</span><span class="py">put</span><span class="o">(</span><span class="s">"RequestTimeout"</span><span class="o">,</span> <span class="s">"6000"</span><span class="o">)</span>
<span class="nv">producerConfig</span><span class="o">.</span><span class="py">put</span><span class="o">(</span><span class="s">"ThreadPoolSize"</span><span class="o">,</span> <span class="s">"15"</span><span class="o">)</span>

<span class="c1">// Disable Aggregation if it's not supported by a consumer</span>
<span class="c1">// producerConfig.put("AggregationEnabled", "false")</span>
<span class="c1">// Switch KinesisProducer's threading model</span>
<span class="c1">// producerConfig.put("ThreadingModel", "PER_REQUEST")</span>

<span class="k">val</span> <span class="nv">kinesis</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">FlinkKinesisProducer</span><span class="o">[</span><span class="kt">String</span><span class="o">](</span><span class="k">new</span> <span class="nc">SimpleStringSchema</span><span class="o">,</span> <span class="n">producerConfig</span><span class="o">)</span>
<span class="nv">kinesis</span><span class="o">.</span><span class="py">setFailOnError</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>
<span class="nv">kinesis</span><span class="o">.</span><span class="py">setDefaultStream</span><span class="o">(</span><span class="s">"kinesis_stream_name"</span><span class="o">)</span>
<span class="nv">kinesis</span><span class="o">.</span><span class="py">setDefaultPartition</span><span class="o">(</span><span class="s">"0"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">simpleStringStream</span> <span class="k">=</span> <span class="o">...</span>
<span class="nv">simpleStringStream</span><span class="o">.</span><span class="py">addSink</span><span class="o">(</span><span class="n">kinesis</span><span class="o">)</span></code></pre></figure>

  </div>
</div>

<p>The above is a simple example of using the producer. To initialize <code class="highlighter-rouge">FlinkKinesisProducer</code>, users are required to pass in <code class="highlighter-rouge">AWS_REGION</code>, <code class="highlighter-rouge">AWS_ACCESS_KEY_ID</code>, and <code class="highlighter-rouge">AWS_SECRET_ACCESS_KEY</code> via a <code class="highlighter-rouge">java.util.Properties</code> instance. Users can also pass in KPL’s configurations as optional parameters to customize the KPL underlying <code class="highlighter-rouge">FlinkKinesisProducer</code>. The full list of KPL configs and explanations can be found <a href="https://github.com/awslabs/amazon-kinesis-producer/blob/master/java/amazon-kinesis-producer-sample/default_config.properties">here</a>. The example demonstrates producing a single Kinesis stream in the AWS region “us-east-1”.</p>

<p>If users don’t specify any KPL configs and values, <code class="highlighter-rouge">FlinkKinesisProducer</code> will use default config values of KPL, except <code class="highlighter-rouge">RateLimit</code>. <code class="highlighter-rouge">RateLimit</code> limits the maximum allowed put rate for a shard, as a percentage of the backend limits. KPL’s default value is 150 but it makes KPL throw <code class="highlighter-rouge">RateLimitExceededException</code> too frequently and breaks Flink sink as a result. Thus <code class="highlighter-rouge">FlinkKinesisProducer</code> overrides KPL’s default value to 100.</p>

<p>Instead of a <code class="highlighter-rouge">SerializationSchema</code>, it also supports a <code class="highlighter-rouge">KinesisSerializationSchema</code>. The <code class="highlighter-rouge">KinesisSerializationSchema</code> allows to send the data to multiple streams. This is
done using the <code class="highlighter-rouge">KinesisSerializationSchema.getTargetStream(T element)</code> method. Returning <code class="highlighter-rouge">null</code> there will instruct the producer to write the element to the default stream.
Otherwise, the returned stream name is used.</p>

<h3 id="threading-model-1">Threading Model</h3>

<p>Since Flink 1.4.0, <code class="highlighter-rouge">FlinkKinesisProducer</code> switches its default underlying KPL from a one-thread-per-request mode to a thread-pool mode. KPL in thread-pool mode uses a queue and thread pool to execute requests to Kinesis. This limits the number of threads that KPL’s native process may create, and therefore greatly lowers CPU utilization and improves efficiency. <strong>Thus, We highly recommend Flink users use thread-pool model.</strong> The default thread pool size is <code class="highlighter-rouge">10</code>. Users can set the pool size in <code class="highlighter-rouge">java.util.Properties</code> instance with key <code class="highlighter-rouge">ThreadPoolSize</code>, as shown in the above example.</p>

<p>Users can still switch back to one-thread-per-request mode by setting a key-value pair of <code class="highlighter-rouge">ThreadingModel</code> and <code class="highlighter-rouge">PER_REQUEST</code> in <code class="highlighter-rouge">java.util.Properties</code>, as shown in the code commented out in above example.</p>

<h3 id="backpressure">Backpressure</h3>

<p>By default, <code class="highlighter-rouge">FlinkKinesisProducer</code> does not backpressure. Instead, records that
cannot be sent because of the rate restriction of 1 MB per second per shard are
buffered in an unbounded queue and dropped when their <code class="highlighter-rouge">RecordTtl</code> expires.</p>

<p>To avoid data loss, you can enable backpressuring by restricting the size of the
internal queue:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>// 200 Bytes per record, 1 shard
kinesis.setQueueLimit(500);
</code></pre></div></div>

<p>The value for <code class="highlighter-rouge">queueLimit</code> depends on the expected record size. To choose a good
value, consider that Kinesis is rate-limited to 1MB per second per shard. If
less than one second’s worth of records is buffered, then the queue may not be
able to operate at full capacity. With the default <code class="highlighter-rouge">RecordMaxBufferedTime</code> of
100ms, a queue size of 100kB per shard should be sufficient. The <code class="highlighter-rouge">queueLimit</code>
can then be computed via</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>queue limit = (number of shards * queue size per shard) / record size
</code></pre></div></div>

<p>E.g. for 200Bytes per record and 8 shards, a queue limit of 4000 is a good
starting point. If the queue size limits throughput (below 1MB per second per
shard), try increasing the queue limit slightly.</p>

<h2 id="using-custom-kinesis-endpoints">Using Custom Kinesis Endpoints</h2>

<p>It is sometimes desirable to have Flink operate as a consumer or producer against a Kinesis VPC endpoint or a non-AWS
Kinesis endpoint such as <a href="https://github.com/mhart/kinesalite">Kinesalite</a>; this is especially useful when performing
functional testing of a Flink application. The AWS endpoint that would normally be inferred by the AWS region set in the
Flink configuration must be overridden via a configuration property.</p>

<p>To override the AWS endpoint, set the <code class="highlighter-rouge">AWSConfigConstants.AWS_ENDPOINT</code> and <code class="highlighter-rouge">AWSConfigConstants.AWS_REGION</code> properties. The region will be used to sign the endpoint URL.</p>

<div class="codetabs">
  <div data-lang="java">

    <figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="nc">Properties</span> <span class="n">producerConfig</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">Properties</span><span class="o">();</span>
<span class="n">producerConfig</span><span class="o">.</span><span class="na">put</span><span class="o">(</span><span class="nc">AWSConfigConstants</span><span class="o">.</span><span class="na">AWS_REGION</span><span class="o">,</span> <span class="s">"us-east-1"</span><span class="o">);</span>
<span class="n">producerConfig</span><span class="o">.</span><span class="na">put</span><span class="o">(</span><span class="nc">AWSConfigConstants</span><span class="o">.</span><span class="na">AWS_ACCESS_KEY_ID</span><span class="o">,</span> <span class="s">"aws_access_key_id"</span><span class="o">);</span>
<span class="n">producerConfig</span><span class="o">.</span><span class="na">put</span><span class="o">(</span><span class="nc">AWSConfigConstants</span><span class="o">.</span><span class="na">AWS_SECRET_ACCESS_KEY</span><span class="o">,</span> <span class="s">"aws_secret_access_key"</span><span class="o">);</span>
<span class="n">producerConfig</span><span class="o">.</span><span class="na">put</span><span class="o">(</span><span class="nc">AWSConfigConstants</span><span class="o">.</span><span class="na">AWS_ENDPOINT</span><span class="o">,</span> <span class="s">"http://localhost:4567"</span><span class="o">);</span></code></pre></figure>

  </div>
  <div data-lang="scala">

    <figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="nv">producerConfig</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Properties</span><span class="o">()</span>
<span class="nv">producerConfig</span><span class="o">.</span><span class="py">put</span><span class="o">(</span><span class="nv">AWSConfigConstants</span><span class="o">.</span><span class="py">AWS_REGION</span><span class="o">,</span> <span class="s">"us-east-1"</span><span class="o">)</span>
<span class="nv">producerConfig</span><span class="o">.</span><span class="py">put</span><span class="o">(</span><span class="nv">AWSConfigConstants</span><span class="o">.</span><span class="py">AWS_ACCESS_KEY_ID</span><span class="o">,</span> <span class="s">"aws_access_key_id"</span><span class="o">)</span>
<span class="nv">producerConfig</span><span class="o">.</span><span class="py">put</span><span class="o">(</span><span class="nv">AWSConfigConstants</span><span class="o">.</span><span class="py">AWS_SECRET_ACCESS_KEY</span><span class="o">,</span> <span class="s">"aws_secret_access_key"</span><span class="o">)</span>
<span class="nv">producerConfig</span><span class="o">.</span><span class="py">put</span><span class="o">(</span><span class="nv">AWSConfigConstants</span><span class="o">.</span><span class="py">AWS_ENDPOINT</span><span class="o">,</span> <span class="s">"http://localhost:4567"</span><span class="o">)</span></code></pre></figure>

  </div>
</div>

<p><a href="#top" class="top pull-right"><span class="glyphicon glyphicon-chevron-up"></span> Back to top</a></p>



<div class="footer">
  <a href="https://cwiki.apache.org/confluence/display/FLINK/Flink+Translation+Specifications" target="_blank">
    
      Want to contribute translation?
    
  </a>
</div>


        </div>
      </div>
    </div><!-- /.container -->

    <!-- default code tab -->
    <script>var defaultCodeTab = "";</script>

    <!-- jQuery (necessary for Bootstrap's JavaScript plugins) -->
    <script src="//ci.apache.org/projects/flink/flink-docs-release-1.12/page/js/jquery.min.js"></script>
    <!-- Include all compiled plugins (below), or include individual files as needed -->
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.4/js/bootstrap.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/anchor-js/3.1.0/anchor.min.js"></script>
    <script src="//ci.apache.org/projects/flink/flink-docs-release-1.12/page/js/flink.js"></script>

    <!-- Google Analytics -->
    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-52545728-1', 'auto');
      ga('send', 'pageview');
    </script>

    <!-- Disqus -->
    
  </body>
</html>
