<!--
Licensed to the Apache Software Foundation (ASF) under one
or more contributor license agreements.  See the NOTICE file
distributed with this work for additional information
regarding copyright ownership.  The ASF licenses this file
to you under the Apache License, Version 2.0 (the
"License"); you may not use this file except in compliance
with the License.  You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing,
software distributed under the License is distributed on an
"AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
KIND, either express or implied.  See the License for the
specific language governing permissions and limitations
under the License.
-->
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->
    <title>Apache Flink 1.12 Documentation: Concepts & Common API</title>
    <link rel="shortcut icon" href="//ci.apache.org/projects/flink/flink-docs-release-1.12/page/favicon.ico" type="image/x-icon">
    <link rel="icon" href="//ci.apache.org/projects/flink/flink-docs-release-1.12/page/favicon.ico" type="image/x-icon">
    <link rel="canonical" href="//ci.apache.org/projects/flink/flink-docs-stable/dev/table/common.html">

    <!-- Bootstrap -->
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.4/css/bootstrap.min.css">
    <link rel="stylesheet" href="//ci.apache.org/projects/flink/flink-docs-release-1.12/page/css/flink.css">
    <link rel="stylesheet" href="//ci.apache.org/projects/flink/flink-docs-release-1.12/page/css/syntax.css">
    <link rel="stylesheet" href="//ci.apache.org/projects/flink/flink-docs-release-1.12/page/css/codetabs.css">
    <link rel="stylesheet" href="//ci.apache.org/projects/flink/flink-docs-release-1.12/page/font-awesome/css/font-awesome.min.css">
    
    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
      <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->
  </head>
  <body>
    

    <!-- Main content. -->
    <div class="container">
      
      <div class="row">
        <div class="col-lg-3" id="sidenavcol">
          <div class="sidenav-logo">
  <p><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/"><img class="bottom" alt="Apache Flink" src="//ci.apache.org/projects/flink/flink-docs-release-1.12/page/img/navbar-brand-logo.jpg"></a> v1.12</p>
</div>
<ul id="sidenav">
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/"><i class="fa fa-home title" aria-hidden="true"></i> Home</a></li><hr class="section-break"></hr>
<li><a href="#collapse-2" data-toggle="collapse"><i class="fa fa-rocket title appetizer" aria-hidden="true"></i> Try Flink<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-2"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/try-flink/local_installation.html">Local Installation</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/try-flink/datastream_api.html">Fraud Detection with the DataStream API</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/try-flink/table_api.html">Real Time Reporting with the Table API</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/try-flink/flink-operations-playground.html">Flink Operations Playground</a></li>
</ul></div></li>
<li><a href="#collapse-8" data-toggle="collapse"><i class="fa fa-hand-paper-o title appetizer" aria-hidden="true"></i> Learn Flink<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-8"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/learn-flink/">Overview</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/learn-flink/datastream_api.html">Intro to the DataStream API</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/learn-flink/etl.html">Data Pipelines & ETL</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/learn-flink/streaming_analytics.html">Streaming Analytics</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/learn-flink/event_driven.html">Event-driven Applications</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/learn-flink/fault_tolerance.html">Fault Tolerance</a></li>
</ul></div></li>
<li><a href="#collapse-15" data-toggle="collapse"><i class="fa fa-map-o title appetizer" aria-hidden="true"></i> Concepts<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-15"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/concepts/index.html">Overview</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/concepts/stateful-stream-processing.html">Stateful Stream Processing</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/concepts/timely-stream-processing.html">Timely Stream Processing</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/concepts/flink-architecture.html">Flink Architecture</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/concepts/glossary.html">Glossary</a></li>
</ul></div></li><hr class="section-break"></hr>
<li><a href="#collapse-21" data-toggle="collapse"class="active"><i class="fa fa-code title maindish" aria-hidden="true"></i> Application Development</a><div class="collapse in" id="collapse-21"><ul>
<li><a href="#collapse-22" data-toggle="collapse">DataStream API<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-22"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/datastream_api.html">Overview</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/datastream_execution_mode.html">Execution Mode (Batch/Streaming)</a></li>
<li><a href="#collapse-24" data-toggle="collapse">Event Time<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-24"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/event_time.html">Overview</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/event_timestamps_watermarks.html">Generating Watermarks</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/event_timestamp_extractors.html">Builtin Watermark Generators</a></li>
</ul></div></li>
<li><a href="#collapse-28" data-toggle="collapse">State & Fault Tolerance<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-28"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/stream/state/">Overview</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/stream/state/state.html">Working with State</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/stream/state/broadcast_state.html">The Broadcast State Pattern</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/stream/state/checkpointing.html">Checkpointing</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/stream/state/queryable_state.html">Queryable State</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/stream/state/state_backends.html">State Backends</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/stream/state/schema_evolution.html">State Schema Evolution</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/stream/state/custom_serialization.html">Custom State Serialization</a></li>
</ul></div></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/user_defined_functions.html">User-Defined Functions</a></li>
<li><a href="#collapse-38" data-toggle="collapse">Operators<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-38"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/stream/operators/">Overview</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/stream/operators/windows.html">Windows</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/stream/operators/joining.html">Joining</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/stream/operators/process_function.html">Process Function</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/stream/operators/asyncio.html">Async I/O</a></li>
</ul></div></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/stream/sources.html">Data Sources</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/stream/side_output.html">Side Outputs</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/application_parameters.html">Handling Application Parameters</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/stream/testing.html">Testing</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/stream/experimental.html">Experimental Features</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/scala_api_extensions.html">Scala API Extensions</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/java_lambdas.html">Java Lambda Expressions</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/project-configuration.html">Project Configuration</a></li>
</ul></div></li>
<li><a href="#collapse-53" data-toggle="collapse">DataSet API<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-53"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/batch/">Overview</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/batch/dataset_transformations.html">Transformations</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/batch/iterations.html">Iterations</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/batch/zip_elements_guide.html">Zipping Elements</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/batch/hadoop_compatibility.html">Hadoop Compatibility</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/local_execution.html">Local Execution</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/cluster_execution.html">Cluster Execution</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/batch/examples.html">Batch Examples</a></li>
</ul></div></li>
<li><a href="#collapse-62" data-toggle="collapse"class="active">Table API & SQL</a><div class="collapse in" id="collapse-62"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/">Overview</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/common.html" class="active">Concepts & Common API</a></li>
<li><a href="#collapse-64" data-toggle="collapse">Streaming Concepts<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-64"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/streaming/">Overview</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/streaming/dynamic_tables.html">Dynamic Tables</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/streaming/time_attributes.html">Time Attributes</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/streaming/joins.html">Joins in Continuous Queries</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/streaming/temporal_tables.html">Temporal Tables</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/streaming/match_recognize.html">Detecting Patterns</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/streaming/query_configuration.html">Query Configuration</a></li>
</ul></div></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/types.html">Data Types</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/tableApi.html">Table API</a></li>
<li><a href="#collapse-74" data-toggle="collapse">SQL<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-74"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/sql/">Overview</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/sql/queries.html">Queries</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/sql/create.html">CREATE Statements</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/sql/drop.html">DROP Statements</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/sql/alter.html">ALTER Statements</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/sql/insert.html">INSERT Statement</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/sql/hints.html">SQL Hints</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/sql/describe.html">DESCRIBE Statements</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/sql/explain.html">EXPLAIN Statements</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/sql/use.html">USE Statements</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/sql/show.html">SHOW Statements</a></li>
</ul></div></li>
<li><a href="#collapse-86" data-toggle="collapse">Functions<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-86"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/functions/">Overview</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/functions/systemFunctions.html">System (Built-in) Functions</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/functions/udfs.html">User-defined Functions</a></li>
</ul></div></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/modules.html">Modules</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/catalogs.html">Catalogs</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/sqlClient.html">SQL Client</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/config.html">Configuration</a></li>
<li><a href="#collapse-94" data-toggle="collapse">Performance Tuning<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-94"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/tuning/streaming_aggregation_optimization.html">Streaming Aggregation</a></li>
</ul></div></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/sourceSinks.html">User-defined Sources & Sinks</a></li>
</ul></div></li>
<li><a href="#collapse-99" data-toggle="collapse">Python API<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-99"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/python/">Overview</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/python/installation.html">Installation</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/python/table_api_tutorial.html">Table API Tutorial</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/python/datastream_tutorial.html">DataStream API Tutorial</a></li>
<li><a href="#collapse-103" data-toggle="collapse">Table API User's Guide<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-103"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/python/table-api-users-guide/intro_to_table_api.html">Intro to the Python Table API</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/python/table-api-users-guide/table_environment.html">TableEnvironment</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/python/table-api-users-guide/operations.html">Operations</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/python/table-api-users-guide/python_types.html">Data Types</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/python/table-api-users-guide/built_in_functions.html">System (Built-in) Functions</a></li>
<li><a href="#collapse-109" data-toggle="collapse">User Defined Functions<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-109"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/python/table-api-users-guide/udfs/python_udfs.html">General User-defined Functions</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/python/table-api-users-guide/udfs/vectorized_python_udfs.html">Vectorized User-defined Functions</a></li>
</ul></div></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/python/table-api-users-guide/conversion_of_pandas.html">Conversions between PyFlink Table and Pandas DataFrame</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/python/table-api-users-guide/dependency_management.html">Dependency Management</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/python/table-api-users-guide/sql.html">SQL</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/python/table-api-users-guide/catalogs.html">Catalogs</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/python/table-api-users-guide/metrics.html">Metrics</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/python/table-api-users-guide/python_table_api_connectors.html">Connectors</a></li>
</ul></div></li>
<li><a href="#collapse-120" data-toggle="collapse">DataStream API User's Guide<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-120"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/python/datastream-api-users-guide/data_types.html">Data Types</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/python/datastream-api-users-guide/operators.html">Operators</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/python/datastream-api-users-guide/dependency_management.html">Dependency Management</a></li>
</ul></div></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/python/python_config.html">Configuration</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/python/environment_variables.html">Environment Variables</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/python/faq.html">FAQ</a></li>
</ul></div></li>
<li><a href="#collapse-129" data-toggle="collapse">Data Types & Serialization<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-129"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/types_serialization.html">Overview</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/custom_serializers.html">Custom Serializers</a></li>
</ul></div></li>
<li><a href="#collapse-132" data-toggle="collapse">Managing Execution<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-132"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/execution_configuration.html">Execution Configuration</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/packaging.html">Program Packaging</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/parallel.html">Parallel Execution</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/execution_plans.html">Execution Plans</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/task_failure_recovery.html">Task Failure Recovery</a></li>
</ul></div></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/migration.html">API Migration Guides</a></li>
</ul></div></li>
<li><a href="#collapse-141" data-toggle="collapse"><i class="fa fa-book title maindish" aria-hidden="true"></i> Libraries<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-141"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/libs/cep.html">Event Processing (CEP)</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/libs/state_processor_api.html">State Processor API</a></li>
<li><a href="#collapse-144" data-toggle="collapse">Graphs: Gelly<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-144"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/libs/gelly/">Overview</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/libs/gelly/graph_api.html">Graph API</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/libs/gelly/iterative_graph_processing.html">Iterative Graph Processing</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/libs/gelly/library_methods.html">Library Methods</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/libs/gelly/graph_algorithms.html">Graph Algorithms</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/libs/gelly/graph_generators.html">Graph Generators</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/libs/gelly/bipartite_graph.html">Bipartite Graph</a></li>
</ul></div></li>
</ul></div></li>
<li><a href="#collapse-153" data-toggle="collapse"><i class="fa fa-random title maindish" aria-hidden="true"></i> Connectors<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-153"><ul>
<li><a href="#collapse-154" data-toggle="collapse">DataStream Connectors<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-154"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/connectors/">Overview</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/connectors/guarantees.html">Fault Tolerance Guarantees</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/connectors/kafka.html">Kafka</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/connectors/cassandra.html">Cassandra</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/connectors/kinesis.html">Kinesis</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/connectors/elasticsearch.html">Elasticsearch</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/connectors/file_sink.html">File Sink</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/connectors/streamfile_sink.html">Streaming File Sink</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/connectors/rabbitmq.html">RabbitMQ</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/connectors/nifi.html">NiFi</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/connectors/pubsub.html">Google Cloud PubSub</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/connectors/twitter.html">Twitter</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/connectors/jdbc.html">JDBC</a></li>
</ul></div></li>
<li><a href="#collapse-168" data-toggle="collapse">Table & SQL Connectors<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-168"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/connectors/">Overview</a></li>
<li><a href="#collapse-169" data-toggle="collapse">Formats<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-169"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/connectors/formats/">Overview</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/connectors/formats/csv.html">CSV</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/connectors/formats/json.html">JSON</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/connectors/formats/avro-confluent.html">Confluent Avro</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/connectors/formats/avro.html">Avro</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/connectors/formats/debezium.html">Debezium</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/connectors/formats/canal.html">Canal</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/connectors/formats/maxwell.html">Maxwell</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/connectors/formats/parquet.html">Parquet</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/connectors/formats/orc.html">Orc</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/connectors/formats/raw.html">Raw</a></li>
</ul></div></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/connectors/kafka.html">Kafka</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/connectors/upsert-kafka.html">Upsert Kafka</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/connectors/kinesis.html">Kinesis</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/connectors/jdbc.html">JDBC</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/connectors/elasticsearch.html">Elasticsearch</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/connectors/filesystem.html">FileSystem</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/connectors/hbase.html">HBase</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/connectors/datagen.html">DataGen</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/connectors/print.html">Print</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/connectors/blackhole.html">BlackHole</a></li>
<li><a href="#collapse-191" data-toggle="collapse">Hive<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-191"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/connectors/hive/">Overview</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/connectors/hive/hive_catalog.html">Hive Catalog</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/connectors/hive/hive_dialect.html">Hive Dialect</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/connectors/hive/hive_read_write.html">Hive Read & Write</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/connectors/hive/hive_functions.html">Hive Functions</a></li>
</ul></div></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/connectors/downloads.html">Download</a></li>
</ul></div></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/batch/connectors.html">DataSet Connectors</a></li>
</ul></div></li>
<li><a href="#collapse-201" data-toggle="collapse"><i class="fa fa-sliders title maindish" aria-hidden="true"></i> Deployment<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-201"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/deployment/">Overview</a></li>
<li><a href="#collapse-202" data-toggle="collapse">Resource Providers<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-202"><ul>
<li><a href="#collapse-203" data-toggle="collapse">Standalone<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-203"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/deployment/resource-providers/standalone/">Overview</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/deployment/resource-providers/standalone/local.html">Local Cluster</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/deployment/resource-providers/standalone/docker.html">Docker</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/deployment/resource-providers/standalone/kubernetes.html">Kubernetes</a></li>
</ul></div></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/deployment/resource-providers/native_kubernetes.html">Native Kubernetes</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/deployment/resource-providers/yarn.html">YARN</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/deployment/resource-providers/mesos.html">Mesos</a></li>
</ul></div></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/deployment/config.html">Configuration</a></li>
<li><a href="#collapse-213" data-toggle="collapse">Memory Configuration<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-213"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/deployment/memory/mem_setup.html">Set up Flink's Process Memory</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/deployment/memory/mem_setup_tm.html">Set up TaskManager Memory</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/deployment/memory/mem_setup_jobmanager.html">Set up JobManager Memory</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/deployment/memory/mem_tuning.html">Memory tuning guide</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/deployment/memory/mem_trouble.html">Troubleshooting</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/deployment/memory/mem_migration.html">Migration Guide</a></li>
</ul></div></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/deployment/cli.html">Command-Line Interface</a></li>
<li><a href="#collapse-222" data-toggle="collapse">File Systems<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-222"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/deployment/filesystems/">Overview</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/deployment/filesystems/common.html">Common Configurations</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/deployment/filesystems/s3.html">Amazon S3</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/deployment/filesystems/oss.html">Aliyun OSS</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/deployment/filesystems/azure.html">Azure Blob Storage</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/deployment/filesystems/plugins.html">Plugins</a></li>
</ul></div></li>
<li><a href="#collapse-229" data-toggle="collapse">High Availability (HA)<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-229"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/deployment/ha/">Overview</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/deployment/ha/zookeeper_ha.html">ZooKeeper HA Services</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/deployment/ha/kubernetes_ha.html">Kubernetes HA Services</a></li>
</ul></div></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/deployment/metric_reporters.html">Metric Reporters</a></li>
<li><a href="#collapse-234" data-toggle="collapse">Security<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-234"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/deployment/security/security-ssl.html">SSL Setup</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/deployment/security/security-kerberos.html">Kerberos</a></li>
</ul></div></li>
<li><a href="#collapse-238" data-toggle="collapse">REPLs<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-238"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/deployment/repls/python_shell.html">Python REPL</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/deployment/repls/scala_shell.html">Scala REPL</a></li>
</ul></div></li>
<li><a href="#collapse-242" data-toggle="collapse">Advanced<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-242"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/deployment/advanced/external_resources.html">External Resources</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/deployment/advanced/historyserver.html">History Server</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/deployment/advanced/logging.html">Logging</a></li>
</ul></div></li>
</ul></div></li>
<li><a href="#collapse-248" data-toggle="collapse"><i class="fa fa-cogs title maindish" aria-hidden="true"></i> Operations<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-248"><ul>
<li><a href="#collapse-249" data-toggle="collapse">State & Fault Tolerance<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-249"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/ops/state/checkpoints.html">Checkpoints</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/ops/state/savepoints.html">Savepoints</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/ops/state/state_backends.html">State Backends</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/ops/state/large_state_tuning.html">Tuning Checkpoints and Large State</a></li>
</ul></div></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/ops/metrics.html">Metrics</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/ops/rest_api.html">REST API</a></li>
<li><a href="#collapse-257" data-toggle="collapse">Debugging<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-257"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/ops/debugging/debugging_event_time.html">Debugging Windows & Event Time</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/ops/debugging/debugging_classloading.html">Debugging Classloading</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/ops/debugging/application_profiling.html">Application Profiling & Debugging</a></li>
</ul></div></li>
<li><a href="#collapse-262" data-toggle="collapse">Monitoring<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-262"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/ops/monitoring/checkpoint_monitoring.html">Monitoring Checkpointing</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/ops/monitoring/back_pressure.html">Monitoring Back Pressure</a></li>
</ul></div></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/ops/upgrading.html">Upgrading Applications and Flink Versions</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/ops/production_ready.html">Production Readiness Checklist</a></li>
</ul></div></li><hr class="section-break"></hr>
<li><a href="#collapse-269" data-toggle="collapse"><i class="fa fa-cogs title dessert" aria-hidden="true"></i> Flink Development<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-269"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/flinkDev/ide_setup.html">Importing Flink into an IDE</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/flinkDev/building.html">Building Flink from Source</a></li>
</ul></div></li>
<li><a href="#collapse-273" data-toggle="collapse"><i class="fa fa-book title dessert" aria-hidden="true"></i> Internals<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-273"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/internals/job_scheduling.html">Jobs and Scheduling</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/internals/task_lifecycle.html">Task Lifecycle</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/internals/filesystems.html">File Systems</a></li>
</ul></div></li>
  <li class="divider"></li>
  <li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/api/java"><i class="fa fa-external-link title" aria-hidden="true"></i> Javadocs</a></li>
  <li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/api/scala/index.html#org.apache.flink.api.scala.package"><i class="fa fa-external-link title" aria-hidden="true"></i> Scaladocs</a></li>
  <li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/api/python"><i class="fa fa-external-link title" aria-hidden="true"></i> Pythondocs</a></li>
  <li><a href="http://flink.apache.org"><i class="fa fa-external-link title" aria-hidden="true"></i> Project Page</a></li>
</ul>

<div class="sidenav-search-box">
  <form class="navbar-form" role="search" action="//ci.apache.org/projects/flink/flink-docs-release-1.12/search-results.html">
    <div class="form-group">
      <input type="text" class="form-control" size="16px" name="q" placeholder="Search">
    </div>
    <button type="submit" class="btn btn-default">Go</button>
  </form>
</div>

<div class="sidenav-versions">
  <div class="dropdown">
    <button class="btn btn-default dropdown-toggle" type="button" data-toggle="dropdown">Pick Docs Version<span class="caret"></span></button>
    <ul class="dropdown-menu">
      <li><a href="http://ci.apache.org/projects/flink/flink-docs-release-1.11">v1.11</a></li>
      <li><a href="http://ci.apache.org/projects/flink/flink-docs-release-1.10">v1.10</a></li>
      <li><a href="http://ci.apache.org/projects/flink/flink-docs-release-1.9">v1.9</a></li>
      <li><a href="http://ci.apache.org/projects/flink/flink-docs-release-1.8">v1.8</a></li>
      <li><a href="http://ci.apache.org/projects/flink/flink-docs-release-1.7">v1.7</a></li>
      <li><a href="http://ci.apache.org/projects/flink/flink-docs-release-1.6">v1.6</a></li>
      <li><a href="http://ci.apache.org/projects/flink/flink-docs-release-1.5">v1.5</a></li>
      <li><a href="http://ci.apache.org/projects/flink/flink-docs-release-1.4">v1.4</a></li>
      <li><a href="http://ci.apache.org/projects/flink/flink-docs-release-1.3">v1.3</a></li>
      <li><a href="http://ci.apache.org/projects/flink/flink-docs-release-1.2">v1.2</a></li>
      <li><a href="http://ci.apache.org/projects/flink/flink-docs-release-1.1">v1.1</a></li>
      <li><a href="http://ci.apache.org/projects/flink/flink-docs-release-1.0">v1.0</a></li>
    </ul>
  </div>
</div>

<div class="sidenav-languages"><!-- link to the Chinese home page when current is blog page -->
    <a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/table/common.html">
      <button type="submit" class="btn btn-default">中文版</button>
    </a>
</div>

        </div>
        <div class="col-lg-9 content" id="contentcol">

          

<ol class="breadcrumb">
  
    <li><i class="fa fa-code title maindish" aria-hidden="true"></i> Application Development</li>
  
    <li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/">Table API & SQL</a></li>
  
    <li class="active">Concepts & Common API</li>
</ol>

<h1>Concepts & Common API</h1>




<p>The Table API and SQL are integrated in a joint API. The central concept of this API is a <code class="highlighter-rouge">Table</code> which serves as input and output of queries. This document shows the common structure of programs with Table API and SQL queries, how to register a <code class="highlighter-rouge">Table</code>, how to query a <code class="highlighter-rouge">Table</code>, and how to emit a <code class="highlighter-rouge">Table</code>.</p>

<ul id="markdown-toc">
  <li><a href="#main-differences-between-the-two-planners" id="markdown-toc-main-differences-between-the-two-planners">Main Differences Between the Two Planners</a></li>
  <li><a href="#structure-of-table-api-and-sql-programs" id="markdown-toc-structure-of-table-api-and-sql-programs">Structure of Table API and SQL Programs</a></li>
  <li><a href="#create-a-tableenvironment" id="markdown-toc-create-a-tableenvironment">Create a TableEnvironment</a></li>
  <li><a href="#create-tables-in-the-catalog" id="markdown-toc-create-tables-in-the-catalog">Create Tables in the Catalog</a>    <ul>
      <li><a href="#temporary-vs-permanent-tables" id="markdown-toc-temporary-vs-permanent-tables">Temporary vs Permanent tables.</a></li>
      <li><a href="#create-a-table" id="markdown-toc-create-a-table">Create a Table</a></li>
      <li><a href="#expanding-table-identifiers" id="markdown-toc-expanding-table-identifiers">Expanding Table identifiers</a></li>
    </ul>
  </li>
  <li><a href="#query-a-table" id="markdown-toc-query-a-table">Query a Table</a>    <ul>
      <li><a href="#table-api" id="markdown-toc-table-api">Table API</a></li>
      <li><a href="#sql" id="markdown-toc-sql">SQL</a></li>
      <li><a href="#mixing-table-api-and-sql" id="markdown-toc-mixing-table-api-and-sql">Mixing Table API and SQL</a></li>
    </ul>
  </li>
  <li><a href="#emit-a-table" id="markdown-toc-emit-a-table">Emit a Table</a></li>
  <li><a href="#translate-and-execute-a-query" id="markdown-toc-translate-and-execute-a-query">Translate and Execute a Query</a></li>
  <li><a href="#integration-with-datastream-and-dataset-api" id="markdown-toc-integration-with-datastream-and-dataset-api">Integration with DataStream and DataSet API</a>    <ul>
      <li><a href="#implicit-conversion-for-scala" id="markdown-toc-implicit-conversion-for-scala">Implicit Conversion for Scala</a></li>
      <li><a href="#create-a-view-from-a-datastream-or-dataset" id="markdown-toc-create-a-view-from-a-datastream-or-dataset">Create a View from a DataStream or DataSet</a></li>
      <li><a href="#convert-a-datastream-or-dataset-into-a-table" id="markdown-toc-convert-a-datastream-or-dataset-into-a-table">Convert a DataStream or DataSet into a Table</a></li>
      <li><a href="#convert-a-table-into-a-datastream-or-dataset" id="markdown-toc-convert-a-table-into-a-datastream-or-dataset">Convert a Table into a DataStream or DataSet</a></li>
      <li><a href="#mapping-of-data-types-to-table-schema" id="markdown-toc-mapping-of-data-types-to-table-schema">Mapping of Data Types to Table Schema</a></li>
    </ul>
  </li>
  <li><a href="#query-optimization" id="markdown-toc-query-optimization">Query Optimization</a></li>
  <li><a href="#explaining-a-table" id="markdown-toc-explaining-a-table">Explaining a Table</a></li>
</ul>

<h2 id="main-differences-between-the-two-planners">Main Differences Between the Two Planners</h2>

<ol>
  <li>Blink treats batch jobs as a special case of streaming. As such, the conversion between Table and DataSet is also not supported, and batch jobs will not be translated into <code class="highlighter-rouge">DateSet</code> programs but translated into <code class="highlighter-rouge">DataStream</code> programs, the same as the streaming jobs.</li>
  <li>The Blink planner does not support <code class="highlighter-rouge">BatchTableSource</code>, use bounded <code class="highlighter-rouge">StreamTableSource</code> instead of it.</li>
  <li>The implementations of <code class="highlighter-rouge">FilterableTableSource</code> for the old planner and the Blink planner are incompatible. The old planner will push down <code class="highlighter-rouge">PlannerExpression</code>s into <code class="highlighter-rouge">FilterableTableSource</code>, while the Blink planner will push down <code class="highlighter-rouge">Expression</code>s.</li>
  <li>String based key-value config options (Please see the documentation about <a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/config.html">Configuration</a> for details) are only used for the Blink planner.</li>
  <li>The implementation(<code class="highlighter-rouge">CalciteConfig</code>) of <code class="highlighter-rouge">PlannerConfig</code> in two planners is different.</li>
  <li>The Blink planner will optimize multiple-sinks into one DAG on both <code class="highlighter-rouge">TableEnvironment</code> and <code class="highlighter-rouge">StreamTableEnvironment</code>. The old planner will always optimize each sink into a new DAG, where all DAGs are independent of each other.</li>
  <li>The old planner does not support catalog statistics now, while the Blink planner does.</li>
</ol>

<h2 id="structure-of-table-api-and-sql-programs">Structure of Table API and SQL Programs</h2>

<p>All Table API and SQL programs for batch and streaming follow the same pattern. The following code example shows the common structure of Table API and SQL programs.</p>

<div class="codetabs">
  <div data-lang="java">

    <figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="c1">// create a TableEnvironment for specific planner batch or streaming</span>
<span class="nc">TableEnvironment</span> <span class="n">tableEnv</span> <span class="o">=</span> <span class="o">...;</span> <span class="c1">// see "Create a TableEnvironment" section</span>

<span class="c1">// create a Table</span>
<span class="n">tableEnv</span><span class="o">.</span><span class="na">connect</span><span class="o">(...).</span><span class="na">createTemporaryTable</span><span class="o">(</span><span class="s">"table1"</span><span class="o">);</span>
<span class="c1">// register an output Table</span>
<span class="n">tableEnv</span><span class="o">.</span><span class="na">connect</span><span class="o">(...).</span><span class="na">createTemporaryTable</span><span class="o">(</span><span class="s">"outputTable"</span><span class="o">);</span>

<span class="c1">// create a Table object from a Table API query</span>
<span class="nc">Table</span> <span class="n">tapiResult</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="na">from</span><span class="o">(</span><span class="s">"table1"</span><span class="o">).</span><span class="na">select</span><span class="o">(...);</span>
<span class="c1">// create a Table object from a SQL query</span>
<span class="nc">Table</span> <span class="n">sqlResult</span>  <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="na">sqlQuery</span><span class="o">(</span><span class="s">"SELECT ... FROM table1 ... "</span><span class="o">);</span>

<span class="c1">// emit a Table API result Table to a TableSink, same for SQL result</span>
<span class="nc">TableResult</span> <span class="n">tableResult</span> <span class="o">=</span> <span class="n">tapiResult</span><span class="o">.</span><span class="na">executeInsert</span><span class="o">(</span><span class="s">"outputTable"</span><span class="o">);</span>
<span class="n">tableResult</span><span class="o">...</span></code></pre></figure>

  </div>

  <div data-lang="scala">

    <figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="c1">// create a TableEnvironment for specific planner batch or streaming</span>
<span class="k">val</span> <span class="nv">tableEnv</span> <span class="k">=</span> <span class="o">...</span> <span class="c1">// see "Create a TableEnvironment" section</span>

<span class="c1">// create a Table</span>
<span class="nv">tableEnv</span><span class="o">.</span><span class="py">connect</span><span class="o">(...).</span><span class="py">createTemporaryTable</span><span class="o">(</span><span class="s">"table1"</span><span class="o">)</span>
<span class="c1">// register an output Table</span>
<span class="nv">tableEnv</span><span class="o">.</span><span class="py">connect</span><span class="o">(...).</span><span class="py">createTemporaryTable</span><span class="o">(</span><span class="s">"outputTable"</span><span class="o">)</span>

<span class="c1">// create a Table from a Table API query</span>
<span class="k">val</span> <span class="nv">tapiResult</span> <span class="k">=</span> <span class="nv">tableEnv</span><span class="o">.</span><span class="py">from</span><span class="o">(</span><span class="s">"table1"</span><span class="o">).</span><span class="py">select</span><span class="o">(...)</span>
<span class="c1">// create a Table from a SQL query</span>
<span class="k">val</span> <span class="nv">sqlResult</span>  <span class="k">=</span> <span class="nv">tableEnv</span><span class="o">.</span><span class="py">sqlQuery</span><span class="o">(</span><span class="s">"SELECT ... FROM table1 ..."</span><span class="o">)</span>

<span class="c1">// emit a Table API result Table to a TableSink, same for SQL result</span>
<span class="k">val</span> <span class="nv">tableResult</span> <span class="k">=</span> <span class="nv">tapiResult</span><span class="o">.</span><span class="py">executeInsert</span><span class="o">(</span><span class="s">"outputTable"</span><span class="o">)</span>
<span class="n">tableResult</span><span class="o">...</span></code></pre></figure>

  </div>

  <div data-lang="python">

    <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="c1"># create a TableEnvironment for specific planner batch or streaming
</span><span class="n">table_env</span> <span class="o">=</span> <span class="p">...</span> <span class="c1"># see "Create a TableEnvironment" section
</span>
<span class="c1"># register a Table
</span><span class="n">table_env</span><span class="p">.</span><span class="n">connect</span><span class="p">(...).</span><span class="n">create_temporary_table</span><span class="p">(</span><span class="s">"table1"</span><span class="p">)</span>

<span class="c1"># register an output Table
</span><span class="n">table_env</span><span class="p">.</span><span class="n">connect</span><span class="p">(...).</span><span class="n">create_temporary_table</span><span class="p">(</span><span class="s">"outputTable"</span><span class="p">)</span>

<span class="c1"># create a Table from a Table API query
</span><span class="n">tapi_result</span> <span class="o">=</span> <span class="n">table_env</span><span class="p">.</span><span class="n">from_path</span><span class="p">(</span><span class="s">"table1"</span><span class="p">).</span><span class="n">select</span><span class="p">(...)</span>
<span class="c1"># create a Table from a SQL query
</span><span class="n">sql_result</span>  <span class="o">=</span> <span class="n">table_env</span><span class="p">.</span><span class="n">sql_query</span><span class="p">(</span><span class="s">"SELECT ... FROM table1 ..."</span><span class="p">)</span>

<span class="c1"># emit a Table API result Table to a TableSink, same for SQL result
</span><span class="n">table_result</span> <span class="o">=</span> <span class="n">tapi_result</span><span class="p">.</span><span class="n">execute_insert</span><span class="p">(</span><span class="s">"outputTable"</span><span class="p">)</span>
<span class="n">table_result</span><span class="p">...</span></code></pre></figure>

  </div>
</div>

<p><strong>Note:</strong> Table API and SQL queries can be easily integrated with and embedded into DataStream or DataSet programs. Have a look at the <a href="#integration-with-datastream-and-dataset-api">Integration with DataStream and DataSet API</a> section to learn how DataStreams and DataSets can be converted into Tables and vice versa.</p>

<p><a href="#top" class="top pull-right"><span class="glyphicon glyphicon-chevron-up"></span> Back to top</a></p>

<h2 id="create-a-tableenvironment">Create a TableEnvironment</h2>

<p>The <code class="highlighter-rouge">TableEnvironment</code> is a central concept of the Table API and SQL integration. It is responsible for:</p>

<ul>
  <li>Registering a <code class="highlighter-rouge">Table</code> in the internal catalog</li>
  <li>Registering catalogs</li>
  <li>Loading pluggable modules</li>
  <li>Executing SQL queries</li>
  <li>Registering a user-defined (scalar, table, or aggregation) function</li>
  <li>Converting a <code class="highlighter-rouge">DataStream</code> or <code class="highlighter-rouge">DataSet</code> into a <code class="highlighter-rouge">Table</code></li>
  <li>Holding a reference to an <code class="highlighter-rouge">ExecutionEnvironment</code> or <code class="highlighter-rouge">StreamExecutionEnvironment</code></li>
</ul>

<p>A <code class="highlighter-rouge">Table</code> is always bound to a specific <code class="highlighter-rouge">TableEnvironment</code>. It is not possible to combine tables of different TableEnvironments in the same query, e.g., to join or union them.</p>

<p>A <code class="highlighter-rouge">TableEnvironment</code> is created by calling the static <code class="highlighter-rouge">BatchTableEnvironment.create()</code> or <code class="highlighter-rouge">StreamTableEnvironment.create()</code> method with a <code class="highlighter-rouge">StreamExecutionEnvironment</code> or an <code class="highlighter-rouge">ExecutionEnvironment</code> and an optional <code class="highlighter-rouge">TableConfig</code>. The <code class="highlighter-rouge">TableConfig</code> can be used to configure the <code class="highlighter-rouge">TableEnvironment</code> or to customize the query optimization and translation process (see <a href="#query-optimization">Query Optimization</a>).</p>

<p>Make sure to choose the specific planner <code class="highlighter-rouge">BatchTableEnvironment</code>/<code class="highlighter-rouge">StreamTableEnvironment</code> that matches your programming language.</p>

<p>If both planner jars are on the classpath (the default behavior), you should explicitly set which planner to use in the current program.</p>

<div class="codetabs">
  <div data-lang="java">

    <figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="c1">// **********************</span>
<span class="c1">// FLINK STREAMING QUERY</span>
<span class="c1">// **********************</span>
<span class="kn">import</span> <span class="nn">org.apache.flink.streaming.api.environment.StreamExecutionEnvironment</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.flink.table.api.EnvironmentSettings</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.flink.table.api.bridge.java.StreamTableEnvironment</span><span class="o">;</span>

<span class="nc">EnvironmentSettings</span> <span class="n">fsSettings</span> <span class="o">=</span> <span class="nc">EnvironmentSettings</span><span class="o">.</span><span class="na">newInstance</span><span class="o">().</span><span class="na">useOldPlanner</span><span class="o">().</span><span class="na">inStreamingMode</span><span class="o">().</span><span class="na">build</span><span class="o">();</span>
<span class="nc">StreamExecutionEnvironment</span> <span class="n">fsEnv</span> <span class="o">=</span> <span class="nc">StreamExecutionEnvironment</span><span class="o">.</span><span class="na">getExecutionEnvironment</span><span class="o">();</span>
<span class="nc">StreamTableEnvironment</span> <span class="n">fsTableEnv</span> <span class="o">=</span> <span class="nc">StreamTableEnvironment</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="n">fsEnv</span><span class="o">,</span> <span class="n">fsSettings</span><span class="o">);</span>
<span class="c1">// or TableEnvironment fsTableEnv = TableEnvironment.create(fsSettings);</span>

<span class="c1">// ******************</span>
<span class="c1">// FLINK BATCH QUERY</span>
<span class="c1">// ******************</span>
<span class="kn">import</span> <span class="nn">org.apache.flink.api.java.ExecutionEnvironment</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.flink.table.api.bridge.java.BatchTableEnvironment</span><span class="o">;</span>

<span class="nc">ExecutionEnvironment</span> <span class="n">fbEnv</span> <span class="o">=</span> <span class="nc">ExecutionEnvironment</span><span class="o">.</span><span class="na">getExecutionEnvironment</span><span class="o">();</span>
<span class="nc">BatchTableEnvironment</span> <span class="n">fbTableEnv</span> <span class="o">=</span> <span class="nc">BatchTableEnvironment</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="n">fbEnv</span><span class="o">);</span>

<span class="c1">// **********************</span>
<span class="c1">// BLINK STREAMING QUERY</span>
<span class="c1">// **********************</span>
<span class="kn">import</span> <span class="nn">org.apache.flink.streaming.api.environment.StreamExecutionEnvironment</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.flink.table.api.EnvironmentSettings</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.flink.table.api.bridge.java.StreamTableEnvironment</span><span class="o">;</span>

<span class="nc">StreamExecutionEnvironment</span> <span class="n">bsEnv</span> <span class="o">=</span> <span class="nc">StreamExecutionEnvironment</span><span class="o">.</span><span class="na">getExecutionEnvironment</span><span class="o">();</span>
<span class="nc">EnvironmentSettings</span> <span class="n">bsSettings</span> <span class="o">=</span> <span class="nc">EnvironmentSettings</span><span class="o">.</span><span class="na">newInstance</span><span class="o">().</span><span class="na">useBlinkPlanner</span><span class="o">().</span><span class="na">inStreamingMode</span><span class="o">().</span><span class="na">build</span><span class="o">();</span>
<span class="nc">StreamTableEnvironment</span> <span class="n">bsTableEnv</span> <span class="o">=</span> <span class="nc">StreamTableEnvironment</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="n">bsEnv</span><span class="o">,</span> <span class="n">bsSettings</span><span class="o">);</span>
<span class="c1">// or TableEnvironment bsTableEnv = TableEnvironment.create(bsSettings);</span>

<span class="c1">// ******************</span>
<span class="c1">// BLINK BATCH QUERY</span>
<span class="c1">// ******************</span>
<span class="kn">import</span> <span class="nn">org.apache.flink.table.api.EnvironmentSettings</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.flink.table.api.TableEnvironment</span><span class="o">;</span>

<span class="nc">EnvironmentSettings</span> <span class="n">bbSettings</span> <span class="o">=</span> <span class="nc">EnvironmentSettings</span><span class="o">.</span><span class="na">newInstance</span><span class="o">().</span><span class="na">useBlinkPlanner</span><span class="o">().</span><span class="na">inBatchMode</span><span class="o">().</span><span class="na">build</span><span class="o">();</span>
<span class="nc">TableEnvironment</span> <span class="n">bbTableEnv</span> <span class="o">=</span> <span class="nc">TableEnvironment</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="n">bbSettings</span><span class="o">);</span></code></pre></figure>

  </div>

  <div data-lang="scala">

    <figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="c1">// **********************</span>
<span class="c1">// FLINK STREAMING QUERY</span>
<span class="c1">// **********************</span>
<span class="k">import</span> <span class="nn">org.apache.flink.streaming.api.scala.StreamExecutionEnvironment</span>
<span class="k">import</span> <span class="nn">org.apache.flink.table.api.EnvironmentSettings</span>
<span class="k">import</span> <span class="nn">org.apache.flink.table.api.bridge.scala.StreamTableEnvironment</span>

<span class="k">val</span> <span class="nv">fsSettings</span> <span class="k">=</span> <span class="nv">EnvironmentSettings</span><span class="o">.</span><span class="py">newInstance</span><span class="o">().</span><span class="py">useOldPlanner</span><span class="o">().</span><span class="py">inStreamingMode</span><span class="o">().</span><span class="py">build</span><span class="o">()</span>
<span class="k">val</span> <span class="nv">fsEnv</span> <span class="k">=</span> <span class="nv">StreamExecutionEnvironment</span><span class="o">.</span><span class="py">getExecutionEnvironment</span>
<span class="k">val</span> <span class="nv">fsTableEnv</span> <span class="k">=</span> <span class="nv">StreamTableEnvironment</span><span class="o">.</span><span class="py">create</span><span class="o">(</span><span class="n">fsEnv</span><span class="o">,</span> <span class="n">fsSettings</span><span class="o">)</span>
<span class="c1">// or val fsTableEnv = TableEnvironment.create(fsSettings)</span>

<span class="c1">// ******************</span>
<span class="c1">// FLINK BATCH QUERY</span>
<span class="c1">// ******************</span>
<span class="k">import</span> <span class="nn">org.apache.flink.api.scala.ExecutionEnvironment</span>
<span class="k">import</span> <span class="nn">org.apache.flink.table.api.bridge.scala.BatchTableEnvironment</span>

<span class="k">val</span> <span class="nv">fbEnv</span> <span class="k">=</span> <span class="nv">ExecutionEnvironment</span><span class="o">.</span><span class="py">getExecutionEnvironment</span>
<span class="k">val</span> <span class="nv">fbTableEnv</span> <span class="k">=</span> <span class="nv">BatchTableEnvironment</span><span class="o">.</span><span class="py">create</span><span class="o">(</span><span class="n">fbEnv</span><span class="o">)</span>

<span class="c1">// **********************</span>
<span class="c1">// BLINK STREAMING QUERY</span>
<span class="c1">// **********************</span>
<span class="k">import</span> <span class="nn">org.apache.flink.streaming.api.scala.StreamExecutionEnvironment</span>
<span class="k">import</span> <span class="nn">org.apache.flink.table.api.EnvironmentSettings</span>
<span class="k">import</span> <span class="nn">org.apache.flink.table.api.bridge.scala.StreamTableEnvironment</span>

<span class="k">val</span> <span class="nv">bsEnv</span> <span class="k">=</span> <span class="nv">StreamExecutionEnvironment</span><span class="o">.</span><span class="py">getExecutionEnvironment</span>
<span class="k">val</span> <span class="nv">bsSettings</span> <span class="k">=</span> <span class="nv">EnvironmentSettings</span><span class="o">.</span><span class="py">newInstance</span><span class="o">().</span><span class="py">useBlinkPlanner</span><span class="o">().</span><span class="py">inStreamingMode</span><span class="o">().</span><span class="py">build</span><span class="o">()</span>
<span class="k">val</span> <span class="nv">bsTableEnv</span> <span class="k">=</span> <span class="nv">StreamTableEnvironment</span><span class="o">.</span><span class="py">create</span><span class="o">(</span><span class="n">bsEnv</span><span class="o">,</span> <span class="n">bsSettings</span><span class="o">)</span>
<span class="c1">// or val bsTableEnv = TableEnvironment.create(bsSettings)</span>

<span class="c1">// ******************</span>
<span class="c1">// BLINK BATCH QUERY</span>
<span class="c1">// ******************</span>
<span class="k">import</span> <span class="nn">org.apache.flink.table.api.</span><span class="o">{</span><span class="nc">EnvironmentSettings</span><span class="o">,</span> <span class="nc">TableEnvironment</span><span class="o">}</span>

<span class="k">val</span> <span class="nv">bbSettings</span> <span class="k">=</span> <span class="nv">EnvironmentSettings</span><span class="o">.</span><span class="py">newInstance</span><span class="o">().</span><span class="py">useBlinkPlanner</span><span class="o">().</span><span class="py">inBatchMode</span><span class="o">().</span><span class="py">build</span><span class="o">()</span>
<span class="k">val</span> <span class="nv">bbTableEnv</span> <span class="k">=</span> <span class="nv">TableEnvironment</span><span class="o">.</span><span class="py">create</span><span class="o">(</span><span class="n">bbSettings</span><span class="o">)</span></code></pre></figure>

  </div>

  <div data-lang="python">

    <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="c1"># **********************
# FLINK STREAMING QUERY
# **********************
</span><span class="kn">from</span> <span class="nn">pyflink.datastream</span> <span class="kn">import</span> <span class="n">StreamExecutionEnvironment</span>
<span class="kn">from</span> <span class="nn">pyflink.table</span> <span class="kn">import</span> <span class="n">StreamTableEnvironment</span><span class="p">,</span> <span class="n">EnvironmentSettings</span>

<span class="n">f_s_env</span> <span class="o">=</span> <span class="n">StreamExecutionEnvironment</span><span class="p">.</span><span class="n">get_execution_environment</span><span class="p">()</span>
<span class="n">f_s_settings</span> <span class="o">=</span> <span class="n">EnvironmentSettings</span><span class="p">.</span><span class="n">new_instance</span><span class="p">().</span><span class="n">use_old_planner</span><span class="p">().</span><span class="n">in_streaming_mode</span><span class="p">().</span><span class="n">build</span><span class="p">()</span>
<span class="n">f_s_t_env</span> <span class="o">=</span> <span class="n">StreamTableEnvironment</span><span class="p">.</span><span class="n">create</span><span class="p">(</span><span class="n">f_s_env</span><span class="p">,</span> <span class="n">environment_settings</span><span class="o">=</span><span class="n">f_s_settings</span><span class="p">)</span>

<span class="c1"># ******************
# FLINK BATCH QUERY
# ******************
</span><span class="kn">from</span> <span class="nn">pyflink.dataset</span> <span class="kn">import</span> <span class="n">ExecutionEnvironment</span>
<span class="kn">from</span> <span class="nn">pyflink.table</span> <span class="kn">import</span> <span class="n">BatchTableEnvironment</span>

<span class="n">f_b_env</span> <span class="o">=</span> <span class="n">ExecutionEnvironment</span><span class="p">.</span><span class="n">get_execution_environment</span><span class="p">()</span>
<span class="n">f_b_t_env</span> <span class="o">=</span> <span class="n">BatchTableEnvironment</span><span class="p">.</span><span class="n">create</span><span class="p">(</span><span class="n">f_b_env</span><span class="p">,</span> <span class="n">table_config</span><span class="p">)</span>

<span class="c1"># **********************
# BLINK STREAMING QUERY
# **********************
</span><span class="kn">from</span> <span class="nn">pyflink.datastream</span> <span class="kn">import</span> <span class="n">StreamExecutionEnvironment</span>
<span class="kn">from</span> <span class="nn">pyflink.table</span> <span class="kn">import</span> <span class="n">StreamTableEnvironment</span><span class="p">,</span> <span class="n">EnvironmentSettings</span>

<span class="n">b_s_env</span> <span class="o">=</span> <span class="n">StreamExecutionEnvironment</span><span class="p">.</span><span class="n">get_execution_environment</span><span class="p">()</span>
<span class="n">b_s_settings</span> <span class="o">=</span> <span class="n">EnvironmentSettings</span><span class="p">.</span><span class="n">new_instance</span><span class="p">().</span><span class="n">use_blink_planner</span><span class="p">().</span><span class="n">in_streaming_mode</span><span class="p">().</span><span class="n">build</span><span class="p">()</span>
<span class="n">b_s_t_env</span> <span class="o">=</span> <span class="n">StreamTableEnvironment</span><span class="p">.</span><span class="n">create</span><span class="p">(</span><span class="n">b_s_env</span><span class="p">,</span> <span class="n">environment_settings</span><span class="o">=</span><span class="n">b_s_settings</span><span class="p">)</span>

<span class="c1"># ******************
# BLINK BATCH QUERY
# ******************
</span><span class="kn">from</span> <span class="nn">pyflink.table</span> <span class="kn">import</span> <span class="n">EnvironmentSettings</span><span class="p">,</span> <span class="n">BatchTableEnvironment</span>

<span class="n">b_b_settings</span> <span class="o">=</span> <span class="n">EnvironmentSettings</span><span class="p">.</span><span class="n">new_instance</span><span class="p">().</span><span class="n">use_blink_planner</span><span class="p">().</span><span class="n">in_batch_mode</span><span class="p">().</span><span class="n">build</span><span class="p">()</span>
<span class="n">b_b_t_env</span> <span class="o">=</span> <span class="n">BatchTableEnvironment</span><span class="p">.</span><span class="n">create</span><span class="p">(</span><span class="n">environment_settings</span><span class="o">=</span><span class="n">b_b_settings</span><span class="p">)</span></code></pre></figure>

  </div>
</div>

<p><strong>Note:</strong> If there is only one planner jar in <code class="highlighter-rouge">/lib</code> directory, you can use <code class="highlighter-rouge">useAnyPlanner</code> (<code class="highlighter-rouge">use_any_planner</code> for python) to create specific <code class="highlighter-rouge">EnvironmentSettings</code>.</p>

<p><a href="#top" class="top pull-right"><span class="glyphicon glyphicon-chevron-up"></span> Back to top</a></p>

<h2 id="create-tables-in-the-catalog">Create Tables in the Catalog</h2>

<p>A <code class="highlighter-rouge">TableEnvironment</code> maintains a map of catalogs of tables which are created with an identifier. Each
identifier consists of 3 parts: catalog name, database name and object name. If a catalog or database is not
specified, the current default value will be used (see examples in the <a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/common.html#table-identifier-expanding">Table identifier expanding</a> section).</p>

<p>Tables can be either virtual (<code class="highlighter-rouge">VIEWS</code>) or regular (<code class="highlighter-rouge">TABLES</code>). <code class="highlighter-rouge">VIEWS</code> can be created from an
existing <code class="highlighter-rouge">Table</code> object, usually the result of a Table API or SQL query. <code class="highlighter-rouge">TABLES</code> describe
external data, such as a file, database table, or message queue.</p>

<h3 id="temporary-vs-permanent-tables">Temporary vs Permanent tables.</h3>

<p>Tables may either be temporary, and tied to the lifecycle of a single Flink session, or permanent,
and visible across multiple Flink sessions and clusters.</p>

<p>Permanent tables require a <a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/catalogs.html">catalog</a> (such as Hive Metastore)
to maintain metadata about the table. Once a permanent table is created, it is visible to any Flink
session that is connected to the catalog and will continue to exist until the table is explicitly
dropped.</p>

<p>On the other hand, temporary tables are always stored in memory and only exist for the duration of
the Flink session they are created within. These tables are not visible to other sessions. They are
not bound to any catalog or database but can be created in the namespace of one. Temporary tables
are not dropped if their corresponding database is removed.</p>

<h4 id="shadowing">Shadowing</h4>

<p>It is possible to register a temporary table with the same identifier as an existing permanent
table. The temporary table shadows the permanent one and makes the permanent table inaccessible as
long as the temporary one exists. All queries with that identifier will be executed against the
temporary table.</p>

<p>This might be useful for experimentation. It allows running exactly the same query first against a
temporary table that e.g. has just a subset of data, or the data is obfuscated. Once verified that
the query is correct it can be run against the real production table.</p>

<h3 id="create-a-table">Create a Table</h3>

<h4 id="virtual-tables">Virtual Tables</h4>

<p>A <code class="highlighter-rouge">Table</code> API object corresponds to a <code class="highlighter-rouge">VIEW</code> (virtual table) in a SQL terms. It encapsulates a logical
query plan. It can be created in a catalog as follows:</p>

<div class="codetabs">
  <div data-lang="java">

    <figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="c1">// get a TableEnvironment</span>
<span class="nc">TableEnvironment</span> <span class="n">tableEnv</span> <span class="o">=</span> <span class="o">...;</span> <span class="c1">// see "Create a TableEnvironment" section</span>

<span class="c1">// table is the result of a simple projection query </span>
<span class="nc">Table</span> <span class="n">projTable</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="na">from</span><span class="o">(</span><span class="s">"X"</span><span class="o">).</span><span class="na">select</span><span class="o">(...);</span>

<span class="c1">// register the Table projTable as table "projectedTable"</span>
<span class="n">tableEnv</span><span class="o">.</span><span class="na">createTemporaryView</span><span class="o">(</span><span class="s">"projectedTable"</span><span class="o">,</span> <span class="n">projTable</span><span class="o">);</span></code></pre></figure>

  </div>

  <div data-lang="scala">

    <figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="c1">// get a TableEnvironment</span>
<span class="k">val</span> <span class="nv">tableEnv</span> <span class="k">=</span> <span class="o">...</span> <span class="c1">// see "Create a TableEnvironment" section</span>

<span class="c1">// table is the result of a simple projection query </span>
<span class="k">val</span> <span class="nv">projTable</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="nv">tableEnv</span><span class="o">.</span><span class="py">from</span><span class="o">(</span><span class="s">"X"</span><span class="o">).</span><span class="py">select</span><span class="o">(...)</span>

<span class="c1">// register the Table projTable as table "projectedTable"</span>
<span class="nv">tableEnv</span><span class="o">.</span><span class="py">createTemporaryView</span><span class="o">(</span><span class="s">"projectedTable"</span><span class="o">,</span> <span class="n">projTable</span><span class="o">)</span></code></pre></figure>

  </div>

  <div data-lang="python">

    <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="c1"># get a TableEnvironment
</span><span class="n">table_env</span> <span class="o">=</span> <span class="p">...</span> <span class="c1"># see "Create a TableEnvironment" section
</span>
<span class="c1"># table is the result of a simple projection query 
</span><span class="n">proj_table</span> <span class="o">=</span> <span class="n">table_env</span><span class="p">.</span><span class="n">from_path</span><span class="p">(</span><span class="s">"X"</span><span class="p">).</span><span class="n">select</span><span class="p">(...)</span>

<span class="c1"># register the Table projTable as table "projectedTable"
</span><span class="n">table_env</span><span class="p">.</span><span class="n">register_table</span><span class="p">(</span><span class="s">"projectedTable"</span><span class="p">,</span> <span class="n">proj_table</span><span class="p">)</span></code></pre></figure>

  </div>
</div>

<p><strong>Note:</strong> <code class="highlighter-rouge">Table</code> objects are similar to <code class="highlighter-rouge">VIEW</code>’s from relational database
systems, i.e., the query that defines the <code class="highlighter-rouge">Table</code> is not optimized but will be inlined when another
query references the registered <code class="highlighter-rouge">Table</code>. If multiple queries reference the same registered <code class="highlighter-rouge">Table</code>,
it will be inlined for each referencing query and executed multiple times, i.e., the result of the
registered <code class="highlighter-rouge">Table</code> will <em>not</em> be shared.</p>

<p><a href="#top" class="top pull-right"><span class="glyphicon glyphicon-chevron-up"></span> Back to top</a></p>

<h4 id="connector-tables">Connector Tables</h4>

<p>It is also possible to create a <code class="highlighter-rouge">TABLE</code> as known from relational databases from a <a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/connect.html">connector</a> declaration.
The connector describes the external system that stores the data of a table. Storage systems such as Apache Kafka or a regular file system can be declared here.</p>

<div class="codetabs">
  <div data-lang="java">

    <figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="n">tableEnvironment</span>
  <span class="o">.</span><span class="na">connect</span><span class="o">(...)</span>
  <span class="o">.</span><span class="na">withFormat</span><span class="o">(...)</span>
  <span class="o">.</span><span class="na">withSchema</span><span class="o">(...)</span>
  <span class="o">.</span><span class="na">inAppendMode</span><span class="o">()</span>
  <span class="o">.</span><span class="na">createTemporaryTable</span><span class="o">(</span><span class="s">"MyTable"</span><span class="o">)</span></code></pre></figure>

  </div>

  <div data-lang="scala">

    <figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="n">tableEnvironment</span>
  <span class="o">.</span><span class="py">connect</span><span class="o">(...)</span>
  <span class="o">.</span><span class="py">withFormat</span><span class="o">(...)</span>
  <span class="o">.</span><span class="py">withSchema</span><span class="o">(...)</span>
  <span class="o">.</span><span class="py">inAppendMode</span><span class="o">()</span>
  <span class="o">.</span><span class="py">createTemporaryTable</span><span class="o">(</span><span class="s">"MyTable"</span><span class="o">)</span></code></pre></figure>

  </div>

  <div data-lang="python">

    <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">table_environment</span> \
    <span class="p">.</span><span class="n">connect</span><span class="p">(...)</span> \
    <span class="p">.</span><span class="n">with_format</span><span class="p">(...)</span> \
    <span class="p">.</span><span class="n">with_schema</span><span class="p">(...)</span> \
    <span class="p">.</span><span class="n">in_append_mode</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">create_temporary_table</span><span class="p">(</span><span class="s">"MyTable"</span><span class="p">)</span></code></pre></figure>

  </div>

  <div data-lang="DDL">

    <figure class="highlight"><pre><code class="language-sql" data-lang="sql"><span class="n">tableEnvironment</span><span class="p">.</span><span class="n">executeSql</span><span class="p">(</span><span class="nv">"CREATE [TEMPORARY] TABLE MyTable (...) WITH (...)"</span><span class="p">)</span></code></pre></figure>

  </div>
</div>

<h3 id="expanding-table-identifiers">Expanding Table identifiers</h3>

<p>Tables are always registered with a 3-part identifier consisting of catalog, database, and table name.</p>

<p>Users can set one catalog and one database inside it to be the “current catalog” and “current database”.
With them, the first two parts in the 3-parts identifier mentioned above can be optional - if they are not provided,
the current catalog and current database will be referred. Users can switch the current catalog and current database via
table API or SQL.</p>

<p>Identifiers follow SQL requirements which means that they can be escaped with a backtick character (<code class="highlighter-rouge">`</code>).</p>

<div class="codetabs">
  <div data-lang="java">

    <figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="nc">TableEnvironment</span> <span class="n">tEnv</span> <span class="o">=</span> <span class="o">...;</span>
<span class="n">tEnv</span><span class="o">.</span><span class="na">useCatalog</span><span class="o">(</span><span class="s">"custom_catalog"</span><span class="o">);</span>
<span class="n">tEnv</span><span class="o">.</span><span class="na">useDatabase</span><span class="o">(</span><span class="s">"custom_database"</span><span class="o">);</span>

<span class="nc">Table</span> <span class="n">table</span> <span class="o">=</span> <span class="o">...;</span>

<span class="c1">// register the view named 'exampleView' in the catalog named 'custom_catalog'</span>
<span class="c1">// in the database named 'custom_database' </span>
<span class="n">tableEnv</span><span class="o">.</span><span class="na">createTemporaryView</span><span class="o">(</span><span class="s">"exampleView"</span><span class="o">,</span> <span class="n">table</span><span class="o">);</span>

<span class="c1">// register the view named 'exampleView' in the catalog named 'custom_catalog'</span>
<span class="c1">// in the database named 'other_database' </span>
<span class="n">tableEnv</span><span class="o">.</span><span class="na">createTemporaryView</span><span class="o">(</span><span class="s">"other_database.exampleView"</span><span class="o">,</span> <span class="n">table</span><span class="o">);</span>

<span class="c1">// register the view named 'example.View' in the catalog named 'custom_catalog'</span>
<span class="c1">// in the database named 'custom_database' </span>
<span class="n">tableEnv</span><span class="o">.</span><span class="na">createTemporaryView</span><span class="o">(</span><span class="s">"`example.View`"</span><span class="o">,</span> <span class="n">table</span><span class="o">);</span>

<span class="c1">// register the view named 'exampleView' in the catalog named 'other_catalog'</span>
<span class="c1">// in the database named 'other_database' </span>
<span class="n">tableEnv</span><span class="o">.</span><span class="na">createTemporaryView</span><span class="o">(</span><span class="s">"other_catalog.other_database.exampleView"</span><span class="o">,</span> <span class="n">table</span><span class="o">);</span></code></pre></figure>

  </div>

  <div data-lang="scala">

    <figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="c1">// get a TableEnvironment</span>
<span class="k">val</span> <span class="nv">tEnv</span><span class="k">:</span> <span class="kt">TableEnvironment</span> <span class="o">=</span> <span class="o">...;</span>
<span class="nv">tEnv</span><span class="o">.</span><span class="py">useCatalog</span><span class="o">(</span><span class="s">"custom_catalog"</span><span class="o">)</span>
<span class="nv">tEnv</span><span class="o">.</span><span class="py">useDatabase</span><span class="o">(</span><span class="s">"custom_database"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">table</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="o">...;</span>

<span class="c1">// register the view named 'exampleView' in the catalog named 'custom_catalog'</span>
<span class="c1">// in the database named 'custom_database' </span>
<span class="nv">tableEnv</span><span class="o">.</span><span class="py">createTemporaryView</span><span class="o">(</span><span class="s">"exampleView"</span><span class="o">,</span> <span class="n">table</span><span class="o">)</span>

<span class="c1">// register the view named 'exampleView' in the catalog named 'custom_catalog'</span>
<span class="c1">// in the database named 'other_database' </span>
<span class="nv">tableEnv</span><span class="o">.</span><span class="py">createTemporaryView</span><span class="o">(</span><span class="s">"other_database.exampleView"</span><span class="o">,</span> <span class="n">table</span><span class="o">)</span>

<span class="c1">// register the view named 'example.View' in the catalog named 'custom_catalog'</span>
<span class="c1">// in the database named 'custom_database' </span>
<span class="nv">tableEnv</span><span class="o">.</span><span class="py">createTemporaryView</span><span class="o">(</span><span class="s">"`example.View`"</span><span class="o">,</span> <span class="n">table</span><span class="o">)</span>

<span class="c1">// register the view named 'exampleView' in the catalog named 'other_catalog'</span>
<span class="c1">// in the database named 'other_database' </span>
<span class="nv">tableEnv</span><span class="o">.</span><span class="py">createTemporaryView</span><span class="o">(</span><span class="s">"other_catalog.other_database.exampleView"</span><span class="o">,</span> <span class="n">table</span><span class="o">)</span></code></pre></figure>

  </div>

</div>

<h2 id="query-a-table">Query a Table</h2>

<h3 id="table-api">Table API</h3>

<p>The Table API is a language-integrated query API for Scala and Java. In contrast to SQL, queries are not specified as Strings but are composed step-by-step in the host language.</p>

<p>The API is based on the <code class="highlighter-rouge">Table</code> class which represents a table (streaming or batch) and offers methods to apply relational operations. These methods return a new <code class="highlighter-rouge">Table</code> object, which represents the result of applying the relational operation on the input <code class="highlighter-rouge">Table</code>. Some relational operations are composed of multiple method calls such as <code class="highlighter-rouge">table.groupBy(...).select()</code>, where <code class="highlighter-rouge">groupBy(...)</code> specifies a grouping of <code class="highlighter-rouge">table</code>, and <code class="highlighter-rouge">select(...)</code> the projection on the grouping of <code class="highlighter-rouge">table</code>.</p>

<p>The <a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/tableApi.html">Table API</a> document describes all Table API operations that are supported on streaming and batch tables.</p>

<p>The following example shows a simple Table API aggregation query:</p>

<div class="codetabs">
  <div data-lang="java">

    <figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="c1">// get a TableEnvironment</span>
<span class="nc">TableEnvironment</span> <span class="n">tableEnv</span> <span class="o">=</span> <span class="o">...;</span> <span class="c1">// see "Create a TableEnvironment" section</span>

<span class="c1">// register Orders table</span>

<span class="c1">// scan registered Orders table</span>
<span class="nc">Table</span> <span class="n">orders</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="na">from</span><span class="o">(</span><span class="s">"Orders"</span><span class="o">);</span>
<span class="c1">// compute revenue for all customers from France</span>
<span class="nc">Table</span> <span class="n">revenue</span> <span class="o">=</span> <span class="n">orders</span>
  <span class="o">.</span><span class="na">filter</span><span class="o">(</span><span class="err">$</span><span class="o">(</span><span class="s">"cCountry"</span><span class="o">).</span><span class="na">isEqual</span><span class="o">(</span><span class="s">"FRANCE"</span><span class="o">))</span>
  <span class="o">.</span><span class="na">groupBy</span><span class="o">(</span><span class="err">$</span><span class="o">(</span><span class="s">"cID"</span><span class="o">),</span> <span class="err">$</span><span class="o">(</span><span class="s">"cName"</span><span class="o">)</span>
  <span class="o">.</span><span class="na">select</span><span class="o">(</span><span class="err">$</span><span class="o">(</span><span class="s">"cID"</span><span class="o">),</span> <span class="err">$</span><span class="o">(</span><span class="s">"cName"</span><span class="o">),</span> <span class="err">$</span><span class="o">(</span><span class="s">"revenue"</span><span class="o">).</span><span class="na">sum</span><span class="o">().</span><span class="na">as</span><span class="o">(</span><span class="s">"revSum"</span><span class="o">));</span>

<span class="c1">// emit or convert Table</span>
<span class="c1">// execute query</span></code></pre></figure>

  </div>

  <div data-lang="scala">

    <figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="c1">// get a TableEnvironment</span>
<span class="k">val</span> <span class="nv">tableEnv</span> <span class="k">=</span> <span class="o">...</span> <span class="c1">// see "Create a TableEnvironment" section</span>

<span class="c1">// register Orders table</span>

<span class="c1">// scan registered Orders table</span>
<span class="k">val</span> <span class="nv">orders</span> <span class="k">=</span> <span class="nv">tableEnv</span><span class="o">.</span><span class="py">from</span><span class="o">(</span><span class="s">"Orders"</span><span class="o">)</span>
<span class="c1">// compute revenue for all customers from France</span>
<span class="k">val</span> <span class="nv">revenue</span> <span class="k">=</span> <span class="n">orders</span>
  <span class="o">.</span><span class="py">filter</span><span class="o">(</span><span class="n">$</span><span class="s">"cCountry"</span> <span class="o">===</span> <span class="s">"FRANCE"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">groupBy</span><span class="o">(</span><span class="n">$</span><span class="s">"cID"</span><span class="o">,</span> <span class="n">$</span><span class="s">"cName"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">select</span><span class="o">(</span><span class="n">$</span><span class="s">"cID"</span><span class="o">,</span> <span class="n">$</span><span class="s">"cName"</span><span class="o">,</span> <span class="n">$</span><span class="s">"revenue"</span><span class="o">.</span><span class="py">sum</span> <span class="nc">AS</span> <span class="s">"revSum"</span><span class="o">)</span>

<span class="c1">// emit or convert Table</span>
<span class="c1">// execute query</span></code></pre></figure>

    <p><strong>Note:</strong> The Scala Table API uses Scala String interpolation that starts with a dollar sign (<code class="highlighter-rouge">$</code>) to reference the attributes of a <code class="highlighter-rouge">Table</code>. The Table API uses Scala implicits. Make sure to import</p>
    <ul>
      <li><code class="highlighter-rouge">org.apache.flink.table.api._</code> - for implicit expression conversions</li>
      <li><code class="highlighter-rouge">org.apache.flink.api.scala._</code> and <code class="highlighter-rouge">org.apache.flink.table.api.bridge.scala._</code> if you want to convert from/to DataStream.</li>
    </ul>
  </div>

  <div data-lang="python">

    <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="c1"># get a TableEnvironment
</span><span class="n">table_env</span> <span class="o">=</span> <span class="c1"># see "Create a TableEnvironment" section
</span>
<span class="c1"># register Orders table
</span>
<span class="c1"># scan registered Orders table
</span><span class="n">orders</span> <span class="o">=</span> <span class="n">table_env</span><span class="p">.</span><span class="n">from_path</span><span class="p">(</span><span class="s">"Orders"</span><span class="p">)</span>
<span class="c1"># compute revenue for all customers from France
</span><span class="n">revenue</span> <span class="o">=</span> <span class="n">orders</span> \
    <span class="p">.</span><span class="nb">filter</span><span class="p">(</span><span class="n">orders</span><span class="p">.</span><span class="n">cCountry</span> <span class="o">==</span> <span class="s">'FRANCE'</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">group_by</span><span class="p">(</span><span class="n">orders</span><span class="p">.</span><span class="n">cID</span><span class="p">,</span> <span class="n">orders</span><span class="p">.</span><span class="n">cName</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="n">orders</span><span class="p">.</span><span class="n">cID</span><span class="p">,</span> <span class="n">orders</span><span class="p">.</span><span class="n">cName</span><span class="p">,</span> <span class="n">orders</span><span class="p">.</span><span class="n">revenue</span><span class="p">.</span><span class="nb">sum</span><span class="p">.</span><span class="n">alias</span><span class="p">(</span><span class="s">'revSum'</span><span class="p">))</span>

<span class="c1"># emit or convert Table
# execute query</span></code></pre></figure>

  </div>
</div>

<p><a href="#top" class="top pull-right"><span class="glyphicon glyphicon-chevron-up"></span> Back to top</a></p>

<h3 id="sql">SQL</h3>

<p>Flink’s SQL integration is based on <a href="https://calcite.apache.org">Apache Calcite</a>, which implements the SQL standard. SQL queries are specified as regular Strings.</p>

<p>The <a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/sql/">SQL</a> document describes Flink’s SQL support for streaming and batch tables.</p>

<p>The following example shows how to specify a query and return the result as a <code class="highlighter-rouge">Table</code>.</p>

<div class="codetabs">
  <div data-lang="java">

    <figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="c1">// get a TableEnvironment</span>
<span class="nc">TableEnvironment</span> <span class="n">tableEnv</span> <span class="o">=</span> <span class="o">...;</span> <span class="c1">// see "Create a TableEnvironment" section</span>

<span class="c1">// register Orders table</span>

<span class="c1">// compute revenue for all customers from France</span>
<span class="nc">Table</span> <span class="n">revenue</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="na">sqlQuery</span><span class="o">(</span>
    <span class="s">"SELECT cID, cName, SUM(revenue) AS revSum "</span> <span class="o">+</span>
    <span class="s">"FROM Orders "</span> <span class="o">+</span>
    <span class="s">"WHERE cCountry = 'FRANCE' "</span> <span class="o">+</span>
    <span class="s">"GROUP BY cID, cName"</span>
  <span class="o">);</span>

<span class="c1">// emit or convert Table</span>
<span class="c1">// execute query</span></code></pre></figure>

  </div>

  <div data-lang="scala">

    <figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="c1">// get a TableEnvironment</span>
<span class="k">val</span> <span class="nv">tableEnv</span> <span class="k">=</span> <span class="o">...</span> <span class="c1">// see "Create a TableEnvironment" section</span>

<span class="c1">// register Orders table</span>

<span class="c1">// compute revenue for all customers from France</span>
<span class="k">val</span> <span class="nv">revenue</span> <span class="k">=</span> <span class="nv">tableEnv</span><span class="o">.</span><span class="py">sqlQuery</span><span class="o">(</span><span class="s">"""
  |SELECT cID, cName, SUM(revenue) AS revSum
  |FROM Orders
  |WHERE cCountry = 'FRANCE'
  |GROUP BY cID, cName
  """</span><span class="o">.</span><span class="py">stripMargin</span><span class="o">)</span>

<span class="c1">// emit or convert Table</span>
<span class="c1">// execute query</span></code></pre></figure>

  </div>

  <div data-lang="python">

    <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="c1"># get a TableEnvironment
</span><span class="n">table_env</span> <span class="o">=</span> <span class="p">...</span> <span class="c1"># see "Create a TableEnvironment" section
</span>
<span class="c1"># register Orders table
</span>
<span class="c1"># compute revenue for all customers from France
</span><span class="n">revenue</span> <span class="o">=</span> <span class="n">table_env</span><span class="p">.</span><span class="n">sql_query</span><span class="p">(</span>
    <span class="s">"SELECT cID, cName, SUM(revenue) AS revSum "</span>
    <span class="s">"FROM Orders "</span>
    <span class="s">"WHERE cCountry = 'FRANCE' "</span>
    <span class="s">"GROUP BY cID, cName"</span>
<span class="p">)</span>

<span class="c1"># emit or convert Table
# execute query</span></code></pre></figure>

  </div>
</div>

<p>The following example shows how to specify an update query that inserts its result into a registered table.</p>

<div class="codetabs">
  <div data-lang="java">

    <figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="c1">// get a TableEnvironment</span>
<span class="nc">TableEnvironment</span> <span class="n">tableEnv</span> <span class="o">=</span> <span class="o">...;</span> <span class="c1">// see "Create a TableEnvironment" section</span>

<span class="c1">// register "Orders" table</span>
<span class="c1">// register "RevenueFrance" output table</span>

<span class="c1">// compute revenue for all customers from France and emit to "RevenueFrance"</span>
<span class="n">tableEnv</span><span class="o">.</span><span class="na">executeSql</span><span class="o">(</span>
    <span class="s">"INSERT INTO RevenueFrance "</span> <span class="o">+</span>
    <span class="s">"SELECT cID, cName, SUM(revenue) AS revSum "</span> <span class="o">+</span>
    <span class="s">"FROM Orders "</span> <span class="o">+</span>
    <span class="s">"WHERE cCountry = 'FRANCE' "</span> <span class="o">+</span>
    <span class="s">"GROUP BY cID, cName"</span>
  <span class="o">);</span></code></pre></figure>

  </div>

  <div data-lang="scala">

    <figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="c1">// get a TableEnvironment</span>
<span class="k">val</span> <span class="nv">tableEnv</span> <span class="k">=</span> <span class="o">...</span> <span class="c1">// see "Create a TableEnvironment" section</span>

<span class="c1">// register "Orders" table</span>
<span class="c1">// register "RevenueFrance" output table</span>

<span class="c1">// compute revenue for all customers from France and emit to "RevenueFrance"</span>
<span class="nv">tableEnv</span><span class="o">.</span><span class="py">executeSql</span><span class="o">(</span><span class="s">"""
  |INSERT INTO RevenueFrance
  |SELECT cID, cName, SUM(revenue) AS revSum
  |FROM Orders
  |WHERE cCountry = 'FRANCE'
  |GROUP BY cID, cName
  """</span><span class="o">.</span><span class="py">stripMargin</span><span class="o">)</span></code></pre></figure>

  </div>

  <div data-lang="python">

    <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="c1"># get a TableEnvironment
</span><span class="n">table_env</span> <span class="o">=</span> <span class="p">...</span> <span class="c1"># see "Create a TableEnvironment" section
</span>
<span class="c1"># register "Orders" table
# register "RevenueFrance" output table
</span>
<span class="c1"># compute revenue for all customers from France and emit to "RevenueFrance"
</span><span class="n">table_env</span><span class="p">.</span><span class="n">execute_sql</span><span class="p">(</span>
    <span class="s">"INSERT INTO RevenueFrance "</span>
    <span class="s">"SELECT cID, cName, SUM(revenue) AS revSum "</span>
    <span class="s">"FROM Orders "</span>
    <span class="s">"WHERE cCountry = 'FRANCE' "</span>
    <span class="s">"GROUP BY cID, cName"</span>
<span class="p">)</span></code></pre></figure>

  </div>
</div>

<p><a href="#top" class="top pull-right"><span class="glyphicon glyphicon-chevron-up"></span> Back to top</a></p>

<h3 id="mixing-table-api-and-sql">Mixing Table API and SQL</h3>

<p>Table API and SQL queries can be easily mixed because both return <code class="highlighter-rouge">Table</code> objects:</p>

<ul>
  <li>A Table API query can be defined on the <code class="highlighter-rouge">Table</code> object returned by a SQL query.</li>
  <li>A SQL query can be defined on the result of a Table API query by <a href="#register-a-table">registering the resulting Table</a> in the <code class="highlighter-rouge">TableEnvironment</code> and referencing it in the <code class="highlighter-rouge">FROM</code> clause of the SQL query.</li>
</ul>

<p><a href="#top" class="top pull-right"><span class="glyphicon glyphicon-chevron-up"></span> Back to top</a></p>

<h2 id="emit-a-table">Emit a Table</h2>

<p>A <code class="highlighter-rouge">Table</code> is emitted by writing it to a <code class="highlighter-rouge">TableSink</code>. A <code class="highlighter-rouge">TableSink</code> is a generic interface to support a wide variety of file formats (e.g. CSV, Apache Parquet, Apache Avro), storage systems (e.g., JDBC, Apache HBase, Apache Cassandra, Elasticsearch), or messaging systems (e.g., Apache Kafka, RabbitMQ).</p>

<p>A batch <code class="highlighter-rouge">Table</code> can only be written to a <code class="highlighter-rouge">BatchTableSink</code>, while a streaming <code class="highlighter-rouge">Table</code> requires either an <code class="highlighter-rouge">AppendStreamTableSink</code>, a <code class="highlighter-rouge">RetractStreamTableSink</code>, or an <code class="highlighter-rouge">UpsertStreamTableSink</code>.</p>

<p>Please see the documentation about <a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/sourceSinks.html">Table Sources &amp; Sinks</a> for details about available sinks and instructions for how to implement a custom <code class="highlighter-rouge">TableSink</code>.</p>

<p>The <code class="highlighter-rouge">Table.executeInsert(String tableName)</code> method emits the <code class="highlighter-rouge">Table</code> to a registered <code class="highlighter-rouge">TableSink</code>. The method looks up the <code class="highlighter-rouge">TableSink</code> from the catalog by the name and validates that the schema of the <code class="highlighter-rouge">Table</code> is identical to the schema of the <code class="highlighter-rouge">TableSink</code>.</p>

<p>The following examples shows how to emit a <code class="highlighter-rouge">Table</code>:</p>

<div class="codetabs">
  <div data-lang="java">

    <figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="c1">// get a TableEnvironment</span>
<span class="nc">TableEnvironment</span> <span class="n">tableEnv</span> <span class="o">=</span> <span class="o">...;</span> <span class="c1">// see "Create a TableEnvironment" section</span>

<span class="c1">// create an output Table</span>
<span class="kd">final</span> <span class="nc">Schema</span> <span class="n">schema</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">Schema</span><span class="o">()</span>
    <span class="o">.</span><span class="na">field</span><span class="o">(</span><span class="s">"a"</span><span class="o">,</span> <span class="nc">DataTypes</span><span class="o">.</span><span class="na">INT</span><span class="o">())</span>
    <span class="o">.</span><span class="na">field</span><span class="o">(</span><span class="s">"b"</span><span class="o">,</span> <span class="nc">DataTypes</span><span class="o">.</span><span class="na">STRING</span><span class="o">())</span>
    <span class="o">.</span><span class="na">field</span><span class="o">(</span><span class="s">"c"</span><span class="o">,</span> <span class="nc">DataTypes</span><span class="o">.</span><span class="na">BIGINT</span><span class="o">());</span>

<span class="n">tableEnv</span><span class="o">.</span><span class="na">connect</span><span class="o">(</span><span class="k">new</span> <span class="nc">FileSystem</span><span class="o">().</span><span class="na">path</span><span class="o">(</span><span class="s">"/path/to/file"</span><span class="o">))</span>
    <span class="o">.</span><span class="na">withFormat</span><span class="o">(</span><span class="k">new</span> <span class="nc">Csv</span><span class="o">().</span><span class="na">fieldDelimiter</span><span class="o">(</span><span class="sc">'|'</span><span class="o">).</span><span class="na">deriveSchema</span><span class="o">())</span>
    <span class="o">.</span><span class="na">withSchema</span><span class="o">(</span><span class="n">schema</span><span class="o">)</span>
    <span class="o">.</span><span class="na">createTemporaryTable</span><span class="o">(</span><span class="s">"CsvSinkTable"</span><span class="o">);</span>

<span class="c1">// compute a result Table using Table API operators and/or SQL queries</span>
<span class="nc">Table</span> <span class="n">result</span> <span class="o">=</span> <span class="o">...</span>

<span class="c1">// emit the result Table to the registered TableSink</span>
<span class="n">result</span><span class="o">.</span><span class="na">executeInsert</span><span class="o">(</span><span class="s">"CsvSinkTable"</span><span class="o">);</span></code></pre></figure>

  </div>

  <div data-lang="scala">

    <figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="c1">// get a TableEnvironment</span>
<span class="k">val</span> <span class="nv">tableEnv</span> <span class="k">=</span> <span class="o">...</span> <span class="c1">// see "Create a TableEnvironment" section</span>

<span class="c1">// create an output Table</span>
<span class="k">val</span> <span class="nv">schema</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Schema</span><span class="o">()</span>
    <span class="o">.</span><span class="py">field</span><span class="o">(</span><span class="s">"a"</span><span class="o">,</span> <span class="nv">DataTypes</span><span class="o">.</span><span class="py">INT</span><span class="o">())</span>
    <span class="o">.</span><span class="py">field</span><span class="o">(</span><span class="s">"b"</span><span class="o">,</span> <span class="nv">DataTypes</span><span class="o">.</span><span class="py">STRING</span><span class="o">())</span>
    <span class="o">.</span><span class="py">field</span><span class="o">(</span><span class="s">"c"</span><span class="o">,</span> <span class="nv">DataTypes</span><span class="o">.</span><span class="py">BIGINT</span><span class="o">())</span>

<span class="nv">tableEnv</span><span class="o">.</span><span class="py">connect</span><span class="o">(</span><span class="k">new</span> <span class="nc">FileSystem</span><span class="o">().</span><span class="py">path</span><span class="o">(</span><span class="s">"/path/to/file"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">withFormat</span><span class="o">(</span><span class="k">new</span> <span class="nc">Csv</span><span class="o">().</span><span class="py">fieldDelimiter</span><span class="o">(</span><span class="sc">'|'</span><span class="o">).</span><span class="py">deriveSchema</span><span class="o">())</span>
    <span class="o">.</span><span class="py">withSchema</span><span class="o">(</span><span class="n">schema</span><span class="o">)</span>
    <span class="o">.</span><span class="py">createTemporaryTable</span><span class="o">(</span><span class="s">"CsvSinkTable"</span><span class="o">)</span>

<span class="c1">// compute a result Table using Table API operators and/or SQL queries</span>
<span class="k">val</span> <span class="nv">result</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="o">...</span>

<span class="c1">// emit the result Table to the registered TableSink</span>
<span class="nv">result</span><span class="o">.</span><span class="py">executeInsert</span><span class="o">(</span><span class="s">"CsvSinkTable"</span><span class="o">)</span></code></pre></figure>

  </div>

  <div data-lang="python">

    <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="c1"># get a TableEnvironment
</span><span class="n">table_env</span> <span class="o">=</span> <span class="p">...</span> <span class="c1"># see "Create a TableEnvironment" section
</span>
<span class="c1"># create a TableSink
</span><span class="n">table_env</span><span class="p">.</span><span class="n">connect</span><span class="p">(</span><span class="n">FileSystem</span><span class="p">().</span><span class="n">path</span><span class="p">(</span><span class="s">"/path/to/file"</span><span class="p">)))</span>
    <span class="p">.</span><span class="n">with_format</span><span class="p">(</span><span class="n">Csv</span><span class="p">()</span>
                 <span class="p">.</span><span class="n">field_delimiter</span><span class="p">(</span><span class="s">','</span><span class="p">)</span>
                 <span class="p">.</span><span class="n">deriveSchema</span><span class="p">())</span>
    <span class="p">.</span><span class="n">with_schema</span><span class="p">(</span><span class="n">Schema</span><span class="p">()</span>
                 <span class="p">.</span><span class="n">field</span><span class="p">(</span><span class="s">"a"</span><span class="p">,</span> <span class="n">DataTypes</span><span class="p">.</span><span class="n">INT</span><span class="p">())</span>
                 <span class="p">.</span><span class="n">field</span><span class="p">(</span><span class="s">"b"</span><span class="p">,</span> <span class="n">DataTypes</span><span class="p">.</span><span class="n">STRING</span><span class="p">())</span>
                 <span class="p">.</span><span class="n">field</span><span class="p">(</span><span class="s">"c"</span><span class="p">,</span> <span class="n">DataTypes</span><span class="p">.</span><span class="n">BIGINT</span><span class="p">()))</span>
    <span class="p">.</span><span class="n">create_temporary_table</span><span class="p">(</span><span class="s">"CsvSinkTable"</span><span class="p">)</span>

<span class="c1"># compute a result Table using Table API operators and/or SQL queries
</span><span class="n">result</span> <span class="o">=</span> <span class="p">...</span>

<span class="c1"># emit the result Table to the registered TableSink
</span><span class="n">result</span><span class="p">.</span><span class="n">execute_insert</span><span class="p">(</span><span class="s">"CsvSinkTable"</span><span class="p">)</span></code></pre></figure>

  </div>
</div>

<p><a href="#top" class="top pull-right"><span class="glyphicon glyphicon-chevron-up"></span> Back to top</a></p>

<h2 id="translate-and-execute-a-query">Translate and Execute a Query</h2>

<p>The behavior of translating and executing a query is different for the two planners.</p>

<div class="codetabs">

  <div data-lang="Blink planner">
    <p>Table API and SQL queries are translated into <a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/datastream_api.html">DataStream</a> programs whether their input is streaming or batch. A query is internally represented as a logical query plan and is translated in two phases:</p>

    <ol>
      <li>Optimization of the logical plan,</li>
      <li>Translation into a DataStream program.</li>
    </ol>

    <p>a Table API or SQL query is translated when:</p>

    <ul>
      <li><code class="highlighter-rouge">TableEnvironment.executeSql()</code> is called. This method is used for executing a given statement, and the sql query is translated immediately once this method is called.</li>
      <li><code class="highlighter-rouge">Table.executeInsert()</code> is called. This method is used for inserting the table content to the given sink path, and the Table API is translated immediately once this method is called.</li>
      <li><code class="highlighter-rouge">Table.execute()</code> is called. This method is used for collecting the table content to local client, and the Table API is translated immediately once this method is called.</li>
      <li><code class="highlighter-rouge">StatementSet.execute()</code> is called. A <code class="highlighter-rouge">Table</code> (emitted to a sink through <code class="highlighter-rouge">StatementSet.addInsert()</code>) or an INSERT statement (specified through <code class="highlighter-rouge">StatementSet.addInsertSql()</code>) will be buffered in <code class="highlighter-rouge">StatementSet</code> first. They are translated once <code class="highlighter-rouge">StatementSet.execute()</code> is called. All sinks will be optimized into one DAG.</li>
      <li>A <code class="highlighter-rouge">Table</code> is translated when it is converted into a <code class="highlighter-rouge">DataStream</code> (see <a href="#integration-with-datastream-and-dataset-api">Integration with DataStream and DataSet API</a>). Once translated, it’s a regular DataStream program and is executed when <code class="highlighter-rouge">StreamExecutionEnvironment.execute()</code> is called.</li>
    </ul>

    <p><span class="label label-danger">Attention</span> <strong>Since 1.11 version, <code class="highlighter-rouge">sqlUpdate()</code> method and <code class="highlighter-rouge">insertInto()</code> method are deprecated. If the Table program is built from these two methods, we must use <code class="highlighter-rouge">StreamTableEnvironment.execute()</code> method instead of <code class="highlighter-rouge">StreamExecutionEnvironment.execute()</code> method to execute it.</strong></p>

  </div>

  <div data-lang="Old planner">
    <p>Table API and SQL queries are translated into <a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/datastream_api.html">DataStream</a> or <a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/batch/">DataSet</a> programs depending on whether their input is a streaming or batch input. A query is internally represented as a logical query plan and is translated in two phases:</p>

    <ol>
      <li>Optimization of the logical plan</li>
      <li>Translation into a DataStream or DataSet program</li>
    </ol>

    <p>A Table API or SQL query is translated when:</p>

    <ul>
      <li><code class="highlighter-rouge">TableEnvironment.executeSql()</code> is called. This method is used for executing a given statement, and the sql query is translated immediately once this method is called.</li>
      <li><code class="highlighter-rouge">Table.executeInsert()</code> is called. This method is used for inserting the table content to the given sink path, and the Table API is translated immediately once this method is called.</li>
      <li><code class="highlighter-rouge">Table.execute()</code> is called. This method is used for collecting the table content to local client, and the Table API is translated immediately once this method is called.</li>
      <li><code class="highlighter-rouge">StatementSet.execute()</code> is called. A <code class="highlighter-rouge">Table</code> (emitted to a sink through <code class="highlighter-rouge">StatementSet.addInsert()</code>) or an INSERT statement (specified through <code class="highlighter-rouge">StatementSet.addInsertSql()</code>) will be buffered in <code class="highlighter-rouge">StatementSet</code> first. They are translated once <code class="highlighter-rouge">StatementSet.execute()</code> is called. Each sink will be optimized independently. The execution graph contains multiple independent sub-DAGs.</li>
      <li>For streaming, a <code class="highlighter-rouge">Table</code> is translated when it is converted into a <code class="highlighter-rouge">DataStream</code> (see <a href="#integration-with-datastream-and-dataset-api">Integration with DataStream and DataSet API</a>). Once translated, it’s a regular DataStream program and is executed when <code class="highlighter-rouge">StreamExecutionEnvironment.execute()</code> is called. For batch, a <code class="highlighter-rouge">Table</code> is translated when it is converted into a <code class="highlighter-rouge">DataSet</code> (see <a href="#integration-with-datastream-and-dataset-api">Integration with DataStream and DataSet API</a>). Once translated, it’s a regular DataSet program and is executed when <code class="highlighter-rouge">ExecutionEnvironment.execute()</code> is called.</li>
    </ul>

    <p><span class="label label-danger">Attention</span> <strong>Since 1.11 version, <code class="highlighter-rouge">sqlUpdate()</code> method and <code class="highlighter-rouge">insertInto()</code> method are deprecated. For streaming, if the Table program is built from these two methods, we must use <code class="highlighter-rouge">StreamTableEnvironment.execute()</code> method instead of <code class="highlighter-rouge">StreamExecutionEnvironment.execute()</code> method to execute it. For batch, if the Table program is built from these two methods, we must use <code class="highlighter-rouge">BatchTableEnvironment.execute()</code> method instead of <code class="highlighter-rouge">ExecutionEnvironment.execute()</code> method to execute it.</strong></p>

  </div>

</div>

<p><a href="#top" class="top pull-right"><span class="glyphicon glyphicon-chevron-up"></span> Back to top</a></p>

<h2 id="integration-with-datastream-and-dataset-api">Integration with DataStream and DataSet API</h2>

<p>Both planners on stream can integrate with the <code class="highlighter-rouge">DataStream</code> API. Only old planner can integrate with the <code class="highlighter-rouge">DataSet API</code>, Blink planner on batch could not be combined with both.
<strong>Note:</strong> The <code class="highlighter-rouge">DataSet</code> API discussed below is only relevant for the old planner on batch.</p>

<p>Table API and SQL queries can be easily integrated with and embedded into <a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/datastream_api.html">DataStream</a> and <a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/batch/">DataSet</a> programs. For instance, it is possible to query an external table (for example from a RDBMS), do some pre-processing, such as filtering, projecting, aggregating, or joining with meta data, and then further process the data with either the DataStream or DataSet API (and any of the libraries built on top of these APIs, such as CEP or Gelly). Inversely, a Table API or SQL query can also be applied on the result of a DataStream or DataSet program.</p>

<p>This interaction can be achieved by converting a <code class="highlighter-rouge">DataStream</code> or <code class="highlighter-rouge">DataSet</code> into a <code class="highlighter-rouge">Table</code> and vice versa. In this section, we describe how these conversions are done.</p>

<h3 id="implicit-conversion-for-scala">Implicit Conversion for Scala</h3>

<p>The Scala Table API features implicit conversions for the <code class="highlighter-rouge">DataSet</code>, <code class="highlighter-rouge">DataStream</code>, and <code class="highlighter-rouge">Table</code> classes. These conversions are enabled by importing the package <code class="highlighter-rouge">org.apache.flink.table.api.bridge.scala._</code> in addition to <code class="highlighter-rouge">org.apache.flink.api.scala._</code> for the Scala DataStream API.</p>

<h3 id="create-a-view-from-a-datastream-or-dataset">Create a View from a DataStream or DataSet</h3>

<p>A <code class="highlighter-rouge">DataStream</code> or <code class="highlighter-rouge">DataSet</code> can be registered in a <code class="highlighter-rouge">TableEnvironment</code> as a View. The schema of the resulting view depends on the data type of the registered <code class="highlighter-rouge">DataStream</code> or <code class="highlighter-rouge">DataSet</code>. Please check the section about <a href="#mapping-of-data-types-to-table-schema">mapping of data types to table schema</a> for details.</p>

<p><strong>Note:</strong> Views created from a <code class="highlighter-rouge">DataStream</code> or <code class="highlighter-rouge">DataSet</code> can be registered as temporary views only.</p>

<div class="codetabs">
  <div data-lang="java">

    <figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="c1">// get StreamTableEnvironment</span>
<span class="c1">// registration of a DataSet in a BatchTableEnvironment is equivalent</span>
<span class="nc">StreamTableEnvironment</span> <span class="n">tableEnv</span> <span class="o">=</span> <span class="o">...;</span> <span class="c1">// see "Create a TableEnvironment" section</span>

<span class="nc">DataStream</span><span class="o">&lt;</span><span class="nc">Tuple2</span><span class="o">&lt;</span><span class="nc">Long</span><span class="o">,</span> <span class="nc">String</span><span class="o">&gt;&gt;</span> <span class="n">stream</span> <span class="o">=</span> <span class="o">...</span>

<span class="c1">// register the DataStream as View "myTable" with fields "f0", "f1"</span>
<span class="n">tableEnv</span><span class="o">.</span><span class="na">createTemporaryView</span><span class="o">(</span><span class="s">"myTable"</span><span class="o">,</span> <span class="n">stream</span><span class="o">);</span>

<span class="c1">// register the DataStream as View "myTable2" with fields "myLong", "myString"</span>
<span class="n">tableEnv</span><span class="o">.</span><span class="na">createTemporaryView</span><span class="o">(</span><span class="s">"myTable2"</span><span class="o">,</span> <span class="n">stream</span><span class="o">,</span> <span class="err">$</span><span class="o">(</span><span class="s">"myLong"</span><span class="o">),</span> <span class="err">$</span><span class="o">(</span><span class="s">"myString"</span><span class="o">));</span></code></pre></figure>

  </div>

  <div data-lang="scala">

    <figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="c1">// get TableEnvironment </span>
<span class="c1">// registration of a DataSet is equivalent</span>
<span class="k">val</span> <span class="nv">tableEnv</span><span class="k">:</span> <span class="kt">StreamTableEnvironment</span> <span class="o">=</span> <span class="o">...</span> <span class="c1">// see "Create a TableEnvironment" section</span>

<span class="k">val</span> <span class="nv">stream</span><span class="k">:</span> <span class="kt">DataStream</span><span class="o">[(</span><span class="kt">Long</span>, <span class="kt">String</span><span class="o">)]</span> <span class="k">=</span> <span class="o">...</span>

<span class="c1">// register the DataStream as View "myTable" with fields "f0", "f1"</span>
<span class="nv">tableEnv</span><span class="o">.</span><span class="py">createTemporaryView</span><span class="o">(</span><span class="s">"myTable"</span><span class="o">,</span> <span class="n">stream</span><span class="o">)</span>

<span class="c1">// register the DataStream as View "myTable2" with fields "myLong", "myString"</span>
<span class="nv">tableEnv</span><span class="o">.</span><span class="py">createTemporaryView</span><span class="o">(</span><span class="s">"myTable2"</span><span class="o">,</span> <span class="n">stream</span><span class="o">,</span> <span class="ss">'myLong</span><span class="o">,</span> <span class="ss">'myString</span><span class="o">)</span></code></pre></figure>

  </div>
</div>

<p><a href="#top" class="top pull-right"><span class="glyphicon glyphicon-chevron-up"></span> Back to top</a></p>

<h3 id="convert-a-datastream-or-dataset-into-a-table">Convert a DataStream or DataSet into a Table</h3>

<p>Instead of registering a <code class="highlighter-rouge">DataStream</code> or <code class="highlighter-rouge">DataSet</code> in a <code class="highlighter-rouge">TableEnvironment</code>, it can also be directly converted into a <code class="highlighter-rouge">Table</code>. This is convenient if you want to use the Table in a Table API query.</p>

<div class="codetabs">
  <div data-lang="java">

    <figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="c1">// get StreamTableEnvironment</span>
<span class="c1">// registration of a DataSet in a BatchTableEnvironment is equivalent</span>
<span class="nc">StreamTableEnvironment</span> <span class="n">tableEnv</span> <span class="o">=</span> <span class="o">...;</span> <span class="c1">// see "Create a TableEnvironment" section</span>

<span class="nc">DataStream</span><span class="o">&lt;</span><span class="nc">Tuple2</span><span class="o">&lt;</span><span class="nc">Long</span><span class="o">,</span> <span class="nc">String</span><span class="o">&gt;&gt;</span> <span class="n">stream</span> <span class="o">=</span> <span class="o">...</span>

<span class="c1">// Convert the DataStream into a Table with default fields "f0", "f1"</span>
<span class="nc">Table</span> <span class="n">table1</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="na">fromDataStream</span><span class="o">(</span><span class="n">stream</span><span class="o">);</span>

<span class="c1">// Convert the DataStream into a Table with fields "myLong", "myString"</span>
<span class="nc">Table</span> <span class="n">table2</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="na">fromDataStream</span><span class="o">(</span><span class="n">stream</span><span class="o">,</span> <span class="err">$</span><span class="o">(</span><span class="s">"myLong"</span><span class="o">),</span> <span class="err">$</span><span class="o">(</span><span class="s">"myString"</span><span class="o">));</span></code></pre></figure>

  </div>

  <div data-lang="scala">

    <figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="c1">// get TableEnvironment</span>
<span class="c1">// registration of a DataSet is equivalent</span>
<span class="k">val</span> <span class="nv">tableEnv</span> <span class="k">=</span> <span class="o">...</span> <span class="c1">// see "Create a TableEnvironment" section</span>

<span class="k">val</span> <span class="nv">stream</span><span class="k">:</span> <span class="kt">DataStream</span><span class="o">[(</span><span class="kt">Long</span>, <span class="kt">String</span><span class="o">)]</span> <span class="k">=</span> <span class="o">...</span>

<span class="c1">// convert the DataStream into a Table with default fields "_1", "_2"</span>
<span class="k">val</span> <span class="nv">table1</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="nv">tableEnv</span><span class="o">.</span><span class="py">fromDataStream</span><span class="o">(</span><span class="n">stream</span><span class="o">)</span>

<span class="c1">// convert the DataStream into a Table with fields "myLong", "myString"</span>
<span class="k">val</span> <span class="nv">table2</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="nv">tableEnv</span><span class="o">.</span><span class="py">fromDataStream</span><span class="o">(</span><span class="n">stream</span><span class="o">,</span> <span class="n">$</span><span class="s">"myLong"</span><span class="o">,</span> <span class="n">$</span><span class="s">"myString"</span><span class="o">)</span></code></pre></figure>

  </div>
</div>

<p><a href="#top" class="top pull-right"><span class="glyphicon glyphicon-chevron-up"></span> Back to top</a></p>

<h3 id="convert-a-table-into-a-datastream-or-dataset">Convert a Table into a DataStream or DataSet</h3>

<p>A <code class="highlighter-rouge">Table</code> can be converted into a <code class="highlighter-rouge">DataStream</code> or <code class="highlighter-rouge">DataSet</code>. In this way, custom DataStream or DataSet programs can be run on the result of a Table API or SQL query.</p>

<p>When converting a <code class="highlighter-rouge">Table</code> into a <code class="highlighter-rouge">DataStream</code> or <code class="highlighter-rouge">DataSet</code>, you need to specify the data type of the resulting <code class="highlighter-rouge">DataStream</code> or <code class="highlighter-rouge">DataSet</code>, i.e., the data type into which the rows of the <code class="highlighter-rouge">Table</code> are to be converted. Often the most convenient conversion type is <code class="highlighter-rouge">Row</code>. The following list gives an overview of the features of the different options:</p>

<ul>
  <li><strong>Row</strong>: fields are mapped by position, arbitrary number of fields, support for <code class="highlighter-rouge">null</code> values, no type-safe access.</li>
  <li><strong>POJO</strong>: fields are mapped by name (POJO fields must be named as <code class="highlighter-rouge">Table</code> fields), arbitrary number of fields, support for <code class="highlighter-rouge">null</code> values, type-safe access.</li>
  <li><strong>Case Class</strong>: fields are mapped by position, no support for <code class="highlighter-rouge">null</code> values, type-safe access.</li>
  <li><strong>Tuple</strong>: fields are mapped by position, limitation to 22 (Scala) or 25 (Java) fields, no support for <code class="highlighter-rouge">null</code> values, type-safe access.</li>
  <li><strong>Atomic Type</strong>: <code class="highlighter-rouge">Table</code> must have a single field, no support for <code class="highlighter-rouge">null</code> values, type-safe access.</li>
</ul>

<h4 id="convert-a-table-into-a-datastream">Convert a Table into a DataStream</h4>

<p>A <code class="highlighter-rouge">Table</code> that is the result of a streaming query will be updated dynamically, i.e., it is changing as new records arrive on the query’s input streams. Hence, the <code class="highlighter-rouge">DataStream</code> into which such a dynamic query is converted needs to encode the updates of the table.</p>

<p>There are two modes to convert a <code class="highlighter-rouge">Table</code> into a <code class="highlighter-rouge">DataStream</code>:</p>

<ol>
  <li><strong>Append Mode</strong>: This mode can only be used if the dynamic <code class="highlighter-rouge">Table</code> is only modified by <code class="highlighter-rouge">INSERT</code> changes, i.e, it is append-only and previously emitted results are never updated.</li>
  <li><strong>Retract Mode</strong>: This mode can always be used. It encodes <code class="highlighter-rouge">INSERT</code> and <code class="highlighter-rouge">DELETE</code> changes with a <code class="highlighter-rouge">boolean</code> flag.</li>
</ol>

<div class="codetabs">
  <div data-lang="java">

    <figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="c1">// get StreamTableEnvironment. </span>
<span class="nc">StreamTableEnvironment</span> <span class="n">tableEnv</span> <span class="o">=</span> <span class="o">...;</span> <span class="c1">// see "Create a TableEnvironment" section</span>

<span class="c1">// Table with two fields (String name, Integer age)</span>
<span class="nc">Table</span> <span class="n">table</span> <span class="o">=</span> <span class="o">...</span>

<span class="c1">// convert the Table into an append DataStream of Row by specifying the class</span>
<span class="nc">DataStream</span><span class="o">&lt;</span><span class="nc">Row</span><span class="o">&gt;</span> <span class="n">dsRow</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="na">toAppendStream</span><span class="o">(</span><span class="n">table</span><span class="o">,</span> <span class="nc">Row</span><span class="o">.</span><span class="na">class</span><span class="o">);</span>

<span class="c1">// convert the Table into an append DataStream of Tuple2&lt;String, Integer&gt; </span>
<span class="c1">//   via a TypeInformation</span>
<span class="nc">TupleTypeInfo</span><span class="o">&lt;</span><span class="nc">Tuple2</span><span class="o">&lt;</span><span class="nc">String</span><span class="o">,</span> <span class="nc">Integer</span><span class="o">&gt;&gt;</span> <span class="n">tupleType</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">TupleTypeInfo</span><span class="o">&lt;&gt;(</span>
  <span class="nc">Types</span><span class="o">.</span><span class="na">STRING</span><span class="o">(),</span>
  <span class="nc">Types</span><span class="o">.</span><span class="na">INT</span><span class="o">());</span>
<span class="nc">DataStream</span><span class="o">&lt;</span><span class="nc">Tuple2</span><span class="o">&lt;</span><span class="nc">String</span><span class="o">,</span> <span class="nc">Integer</span><span class="o">&gt;&gt;</span> <span class="n">dsTuple</span> <span class="o">=</span> 
  <span class="n">tableEnv</span><span class="o">.</span><span class="na">toAppendStream</span><span class="o">(</span><span class="n">table</span><span class="o">,</span> <span class="n">tupleType</span><span class="o">);</span>

<span class="c1">// convert the Table into a retract DataStream of Row.</span>
<span class="c1">//   A retract stream of type X is a DataStream&lt;Tuple2&lt;Boolean, X&gt;&gt;. </span>
<span class="c1">//   The boolean field indicates the type of the change. </span>
<span class="c1">//   True is INSERT, false is DELETE.</span>
<span class="nc">DataStream</span><span class="o">&lt;</span><span class="nc">Tuple2</span><span class="o">&lt;</span><span class="nc">Boolean</span><span class="o">,</span> <span class="nc">Row</span><span class="o">&gt;&gt;</span> <span class="n">retractStream</span> <span class="o">=</span> 
  <span class="n">tableEnv</span><span class="o">.</span><span class="na">toRetractStream</span><span class="o">(</span><span class="n">table</span><span class="o">,</span> <span class="nc">Row</span><span class="o">.</span><span class="na">class</span><span class="o">);</span></code></pre></figure>

  </div>

  <div data-lang="scala">

    <figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="c1">// get TableEnvironment. </span>
<span class="c1">// registration of a DataSet is equivalent</span>
<span class="k">val</span> <span class="nv">tableEnv</span><span class="k">:</span> <span class="kt">StreamTableEnvironment</span> <span class="o">=</span> <span class="o">...</span> <span class="c1">// see "Create a TableEnvironment" section</span>

<span class="c1">// Table with two fields (String name, Integer age)</span>
<span class="k">val</span> <span class="nv">table</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="o">...</span>

<span class="c1">// convert the Table into an append DataStream of Row</span>
<span class="k">val</span> <span class="nv">dsRow</span><span class="k">:</span> <span class="kt">DataStream</span><span class="o">[</span><span class="kt">Row</span><span class="o">]</span> <span class="k">=</span> <span class="nv">tableEnv</span><span class="o">.</span><span class="py">toAppendStream</span><span class="o">[</span><span class="kt">Row</span><span class="o">](</span><span class="n">table</span><span class="o">)</span>

<span class="c1">// convert the Table into an append DataStream of Tuple2[String, Int]</span>
<span class="k">val</span> <span class="nv">dsTuple</span><span class="k">:</span> <span class="kt">DataStream</span><span class="o">[(</span><span class="kt">String</span>, <span class="kt">Int</span><span class="o">)]</span> <span class="n">dsTuple</span> <span class="k">=</span> 
  <span class="nv">tableEnv</span><span class="o">.</span><span class="py">toAppendStream</span><span class="o">[(</span><span class="kt">String</span>, <span class="kt">Int</span><span class="o">)](</span><span class="n">table</span><span class="o">)</span>

<span class="c1">// convert the Table into a retract DataStream of Row.</span>
<span class="c1">//   A retract stream of type X is a DataStream[(Boolean, X)]. </span>
<span class="c1">//   The boolean field indicates the type of the change. </span>
<span class="c1">//   True is INSERT, false is DELETE.</span>
<span class="k">val</span> <span class="nv">retractStream</span><span class="k">:</span> <span class="kt">DataStream</span><span class="o">[(</span><span class="kt">Boolean</span>, <span class="kt">Row</span><span class="o">)]</span> <span class="k">=</span> <span class="nv">tableEnv</span><span class="o">.</span><span class="py">toRetractStream</span><span class="o">[</span><span class="kt">Row</span><span class="o">](</span><span class="n">table</span><span class="o">)</span></code></pre></figure>

  </div>
</div>

<p><strong>Note:</strong> A detailed discussion about dynamic tables and their properties is given in the <a href="streaming/dynamic_tables.html">Dynamic Tables</a> document.</p>

<p><span class="label label-danger">Attention</span> <strong>Once the Table is converted to a DataStream, please use the <code class="highlighter-rouge">StreamExecutionEnvironment.execute()</code> method to execute the DataStream program.</strong></p>

<h4 id="convert-a-table-into-a-dataset">Convert a Table into a DataSet</h4>

<p>A <code class="highlighter-rouge">Table</code> is converted into a <code class="highlighter-rouge">DataSet</code> as follows:</p>

<div class="codetabs">
  <div data-lang="java">

    <figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="c1">// get BatchTableEnvironment</span>
<span class="nc">BatchTableEnvironment</span> <span class="n">tableEnv</span> <span class="o">=</span> <span class="nc">BatchTableEnvironment</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="n">env</span><span class="o">);</span>

<span class="c1">// Table with two fields (String name, Integer age)</span>
<span class="nc">Table</span> <span class="n">table</span> <span class="o">=</span> <span class="o">...</span>

<span class="c1">// convert the Table into a DataSet of Row by specifying a class</span>
<span class="nc">DataSet</span><span class="o">&lt;</span><span class="nc">Row</span><span class="o">&gt;</span> <span class="n">dsRow</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="na">toDataSet</span><span class="o">(</span><span class="n">table</span><span class="o">,</span> <span class="nc">Row</span><span class="o">.</span><span class="na">class</span><span class="o">);</span>

<span class="c1">// convert the Table into a DataSet of Tuple2&lt;String, Integer&gt; via a TypeInformation</span>
<span class="nc">TupleTypeInfo</span><span class="o">&lt;</span><span class="nc">Tuple2</span><span class="o">&lt;</span><span class="nc">String</span><span class="o">,</span> <span class="nc">Integer</span><span class="o">&gt;&gt;</span> <span class="n">tupleType</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">TupleTypeInfo</span><span class="o">&lt;&gt;(</span>
  <span class="nc">Types</span><span class="o">.</span><span class="na">STRING</span><span class="o">(),</span>
  <span class="nc">Types</span><span class="o">.</span><span class="na">INT</span><span class="o">());</span>
<span class="nc">DataSet</span><span class="o">&lt;</span><span class="nc">Tuple2</span><span class="o">&lt;</span><span class="nc">String</span><span class="o">,</span> <span class="nc">Integer</span><span class="o">&gt;&gt;</span> <span class="n">dsTuple</span> <span class="o">=</span> 
  <span class="n">tableEnv</span><span class="o">.</span><span class="na">toDataSet</span><span class="o">(</span><span class="n">table</span><span class="o">,</span> <span class="n">tupleType</span><span class="o">);</span></code></pre></figure>

  </div>

  <div data-lang="scala">

    <figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="c1">// get TableEnvironment </span>
<span class="c1">// registration of a DataSet is equivalent</span>
<span class="k">val</span> <span class="nv">tableEnv</span> <span class="k">=</span> <span class="nv">BatchTableEnvironment</span><span class="o">.</span><span class="py">create</span><span class="o">(</span><span class="n">env</span><span class="o">)</span>

<span class="c1">// Table with two fields (String name, Integer age)</span>
<span class="k">val</span> <span class="nv">table</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="o">...</span>

<span class="c1">// convert the Table into a DataSet of Row</span>
<span class="k">val</span> <span class="nv">dsRow</span><span class="k">:</span> <span class="kt">DataSet</span><span class="o">[</span><span class="kt">Row</span><span class="o">]</span> <span class="k">=</span> <span class="nv">tableEnv</span><span class="o">.</span><span class="py">toDataSet</span><span class="o">[</span><span class="kt">Row</span><span class="o">](</span><span class="n">table</span><span class="o">)</span>

<span class="c1">// convert the Table into a DataSet of Tuple2[String, Int]</span>
<span class="k">val</span> <span class="nv">dsTuple</span><span class="k">:</span> <span class="kt">DataSet</span><span class="o">[(</span><span class="kt">String</span>, <span class="kt">Int</span><span class="o">)]</span> <span class="k">=</span> <span class="nv">tableEnv</span><span class="o">.</span><span class="py">toDataSet</span><span class="o">[(</span><span class="kt">String</span>, <span class="kt">Int</span><span class="o">)](</span><span class="n">table</span><span class="o">)</span></code></pre></figure>

  </div>
</div>

<p><span class="label label-danger">Attention</span> <strong>Once the Table is converted to a DataSet, we must use the ExecutionEnvironment.execute method to execute the DataSet program.</strong></p>

<p><a href="#top" class="top pull-right"><span class="glyphicon glyphicon-chevron-up"></span> Back to top</a></p>

<h3 id="mapping-of-data-types-to-table-schema">Mapping of Data Types to Table Schema</h3>

<p>Flink’s DataStream and DataSet APIs support very diverse types. Composite types such as Tuples (built-in Scala and Flink Java tuples), POJOs, Scala case classes, and Flink’s Row type allow for nested data structures with multiple fields that can be accessed in table expressions. Other types are treated as atomic types. In the following, we describe how the Table API converts these types into an internal row representation and show examples of converting a <code class="highlighter-rouge">DataStream</code> into a <code class="highlighter-rouge">Table</code>.</p>

<p>The mapping of a data type to a table schema can happen in two ways: <strong>based on the field positions</strong> or <strong>based on the field names</strong>.</p>

<p><strong>Position-based Mapping</strong></p>

<p>Position-based mapping can be used to give fields a more meaningful name while keeping the field order. This mapping is available for composite data types <em>with a defined field order</em> as well as atomic types. Composite data types such as tuples, rows, and case classes have such a field order. However, fields of a POJO must be mapped based on the field names (see next section). Fields can be projected out but can’t be renamed using an alias <code class="highlighter-rouge">as</code>.</p>

<p>When defining a position-based mapping, the specified names must not exist in the input data type, otherwise the API will assume that the mapping should happen based on the field names. If no field names are specified, the default field names and field order of the composite type are used or <code class="highlighter-rouge">f0</code> for atomic types.</p>

<div class="codetabs">
  <div data-lang="java">

    <figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="c1">// get a StreamTableEnvironment, works for BatchTableEnvironment equivalently</span>
<span class="nc">StreamTableEnvironment</span> <span class="n">tableEnv</span> <span class="o">=</span> <span class="o">...;</span> <span class="c1">// see "Create a TableEnvironment" section;</span>

<span class="nc">DataStream</span><span class="o">&lt;</span><span class="nc">Tuple2</span><span class="o">&lt;</span><span class="nc">Long</span><span class="o">,</span> <span class="nc">Integer</span><span class="o">&gt;&gt;</span> <span class="n">stream</span> <span class="o">=</span> <span class="o">...</span>

<span class="c1">// convert DataStream into Table with default field names "f0" and "f1"</span>
<span class="nc">Table</span> <span class="n">table</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="na">fromDataStream</span><span class="o">(</span><span class="n">stream</span><span class="o">);</span>

<span class="c1">// convert DataStream into Table with field "myLong" only</span>
<span class="nc">Table</span> <span class="n">table</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="na">fromDataStream</span><span class="o">(</span><span class="n">stream</span><span class="o">,</span> <span class="err">$</span><span class="o">(</span><span class="s">"myLong"</span><span class="o">));</span>

<span class="c1">// convert DataStream into Table with field names "myLong" and "myInt"</span>
<span class="nc">Table</span> <span class="n">table</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="na">fromDataStream</span><span class="o">(</span><span class="n">stream</span><span class="o">,</span> <span class="err">$</span><span class="o">(</span><span class="s">"myLong"</span><span class="o">),</span> <span class="err">$</span><span class="o">(</span><span class="s">"myInt"</span><span class="o">));</span></code></pre></figure>

  </div>

  <div data-lang="scala">

    <figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="c1">// get a TableEnvironment</span>
<span class="k">val</span> <span class="nv">tableEnv</span><span class="k">:</span> <span class="kt">StreamTableEnvironment</span> <span class="o">=</span> <span class="o">...</span> <span class="c1">// see "Create a TableEnvironment" section</span>

<span class="k">val</span> <span class="nv">stream</span><span class="k">:</span> <span class="kt">DataStream</span><span class="o">[(</span><span class="kt">Long</span>, <span class="kt">Int</span><span class="o">)]</span> <span class="k">=</span> <span class="o">...</span>

<span class="c1">// convert DataStream into Table with default field names "_1" and "_2"</span>
<span class="k">val</span> <span class="nv">table</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="nv">tableEnv</span><span class="o">.</span><span class="py">fromDataStream</span><span class="o">(</span><span class="n">stream</span><span class="o">)</span>

<span class="c1">// convert DataStream into Table with field "myLong" only</span>
<span class="k">val</span> <span class="nv">table</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="nv">tableEnv</span><span class="o">.</span><span class="py">fromDataStream</span><span class="o">(</span><span class="n">stream</span><span class="o">,</span> <span class="n">$</span><span class="s">"myLong"</span><span class="o">)</span>

<span class="c1">// convert DataStream into Table with field names "myLong" and "myInt"</span>
<span class="k">val</span> <span class="nv">table</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="nv">tableEnv</span><span class="o">.</span><span class="py">fromDataStream</span><span class="o">(</span><span class="n">stream</span><span class="o">,</span> <span class="n">$</span><span class="s">"myLong"</span><span class="o">,</span> <span class="n">$</span><span class="s">"myInt"</span><span class="o">)</span></code></pre></figure>

  </div>
</div>

<p><strong>Name-based Mapping</strong></p>

<p>Name-based mapping can be used for any data type including POJOs. It is the most flexible way of defining a table schema mapping. All fields in the mapping are referenced by name and can be possibly renamed using an alias <code class="highlighter-rouge">as</code>. Fields can be reordered and projected out.</p>

<p>If no field names are specified, the default field names and field order of the composite type are used or <code class="highlighter-rouge">f0</code> for atomic types.</p>

<div class="codetabs">
  <div data-lang="java">

    <figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="c1">// get a StreamTableEnvironment, works for BatchTableEnvironment equivalently</span>
<span class="nc">StreamTableEnvironment</span> <span class="n">tableEnv</span> <span class="o">=</span> <span class="o">...;</span> <span class="c1">// see "Create a TableEnvironment" section</span>

<span class="nc">DataStream</span><span class="o">&lt;</span><span class="nc">Tuple2</span><span class="o">&lt;</span><span class="nc">Long</span><span class="o">,</span> <span class="nc">Integer</span><span class="o">&gt;&gt;</span> <span class="n">stream</span> <span class="o">=</span> <span class="o">...</span>

<span class="c1">// convert DataStream into Table with default field names "f0" and "f1"</span>
<span class="nc">Table</span> <span class="n">table</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="na">fromDataStream</span><span class="o">(</span><span class="n">stream</span><span class="o">);</span>

<span class="c1">// convert DataStream into Table with field "f1" only</span>
<span class="nc">Table</span> <span class="n">table</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="na">fromDataStream</span><span class="o">(</span><span class="n">stream</span><span class="o">,</span> <span class="err">$</span><span class="o">(</span><span class="s">"f1"</span><span class="o">));</span>

<span class="c1">// convert DataStream into Table with swapped fields</span>
<span class="nc">Table</span> <span class="n">table</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="na">fromDataStream</span><span class="o">(</span><span class="n">stream</span><span class="o">,</span> <span class="err">$</span><span class="o">(</span><span class="s">"f1"</span><span class="o">),</span> <span class="err">$</span><span class="o">(</span><span class="s">"f0"</span><span class="o">));</span>

<span class="c1">// convert DataStream into Table with swapped fields and field names "myInt" and "myLong"</span>
<span class="nc">Table</span> <span class="n">table</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="na">fromDataStream</span><span class="o">(</span><span class="n">stream</span><span class="o">,</span> <span class="err">$</span><span class="o">(</span><span class="s">"f1"</span><span class="o">).</span><span class="na">as</span><span class="o">(</span><span class="s">"myInt"</span><span class="o">),</span> <span class="err">$</span><span class="o">(</span><span class="s">"f0"</span><span class="o">).</span><span class="na">as</span><span class="o">(</span><span class="s">"myLong"</span><span class="o">));</span></code></pre></figure>

  </div>

  <div data-lang="scala">

    <figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="c1">// get a TableEnvironment</span>
<span class="k">val</span> <span class="nv">tableEnv</span><span class="k">:</span> <span class="kt">StreamTableEnvironment</span> <span class="o">=</span> <span class="o">...</span> <span class="c1">// see "Create a TableEnvironment" section</span>

<span class="k">val</span> <span class="nv">stream</span><span class="k">:</span> <span class="kt">DataStream</span><span class="o">[(</span><span class="kt">Long</span>, <span class="kt">Int</span><span class="o">)]</span> <span class="k">=</span> <span class="o">...</span>

<span class="c1">// convert DataStream into Table with default field names "_1" and "_2"</span>
<span class="k">val</span> <span class="nv">table</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="nv">tableEnv</span><span class="o">.</span><span class="py">fromDataStream</span><span class="o">(</span><span class="n">stream</span><span class="o">)</span>

<span class="c1">// convert DataStream into Table with field "_2" only</span>
<span class="k">val</span> <span class="nv">table</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="nv">tableEnv</span><span class="o">.</span><span class="py">fromDataStream</span><span class="o">(</span><span class="n">stream</span><span class="o">,</span> <span class="n">$</span><span class="s">"_2"</span><span class="o">)</span>

<span class="c1">// convert DataStream into Table with swapped fields</span>
<span class="k">val</span> <span class="nv">table</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="nv">tableEnv</span><span class="o">.</span><span class="py">fromDataStream</span><span class="o">(</span><span class="n">stream</span><span class="o">,</span> <span class="n">$</span><span class="s">"_2"</span><span class="o">,</span> <span class="n">$</span><span class="s">"_1"</span><span class="o">)</span>

<span class="c1">// convert DataStream into Table with swapped fields and field names "myInt" and "myLong"</span>
<span class="k">val</span> <span class="nv">table</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="nv">tableEnv</span><span class="o">.</span><span class="py">fromDataStream</span><span class="o">(</span><span class="n">stream</span><span class="o">,</span> <span class="n">$</span><span class="s">"_2"</span> <span class="n">as</span> <span class="s">"myInt"</span><span class="o">,</span> <span class="n">$</span><span class="s">"_1"</span> <span class="n">as</span> <span class="s">"myLong"</span><span class="o">)</span></code></pre></figure>

  </div>
</div>

<h4 id="atomic-types">Atomic Types</h4>

<p>Flink treats primitives (<code class="highlighter-rouge">Integer</code>, <code class="highlighter-rouge">Double</code>, <code class="highlighter-rouge">String</code>) or generic types (types that cannot be analyzed and decomposed) as atomic types. A <code class="highlighter-rouge">DataStream</code> or <code class="highlighter-rouge">DataSet</code> of an atomic type is converted into a <code class="highlighter-rouge">Table</code> with a single attribute. The type of the attribute is inferred from the atomic type and the name of the attribute can be specified.</p>

<div class="codetabs">
  <div data-lang="java">

    <figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="c1">// get a StreamTableEnvironment, works for BatchTableEnvironment equivalently</span>
<span class="nc">StreamTableEnvironment</span> <span class="n">tableEnv</span> <span class="o">=</span> <span class="o">...;</span> <span class="c1">// see "Create a TableEnvironment" section</span>

<span class="nc">DataStream</span><span class="o">&lt;</span><span class="nc">Long</span><span class="o">&gt;</span> <span class="n">stream</span> <span class="o">=</span> <span class="o">...</span>

<span class="c1">// convert DataStream into Table with default field name "f0"</span>
<span class="nc">Table</span> <span class="n">table</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="na">fromDataStream</span><span class="o">(</span><span class="n">stream</span><span class="o">);</span>

<span class="c1">// convert DataStream into Table with field name "myLong"</span>
<span class="nc">Table</span> <span class="n">table</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="na">fromDataStream</span><span class="o">(</span><span class="n">stream</span><span class="o">,</span> <span class="err">$</span><span class="o">(</span><span class="s">"myLong"</span><span class="o">));</span></code></pre></figure>

  </div>

  <div data-lang="scala">

    <figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="c1">// get a TableEnvironment</span>
<span class="k">val</span> <span class="nv">tableEnv</span><span class="k">:</span> <span class="kt">StreamTableEnvironment</span> <span class="o">=</span> <span class="o">...</span> <span class="c1">// see "Create a TableEnvironment" section</span>

<span class="k">val</span> <span class="nv">stream</span><span class="k">:</span> <span class="kt">DataStream</span><span class="o">[</span><span class="kt">Long</span><span class="o">]</span> <span class="k">=</span> <span class="o">...</span>

<span class="c1">// convert DataStream into Table with default field name "f0"</span>
<span class="k">val</span> <span class="nv">table</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="nv">tableEnv</span><span class="o">.</span><span class="py">fromDataStream</span><span class="o">(</span><span class="n">stream</span><span class="o">)</span>

<span class="c1">// convert DataStream into Table with field name "myLong"</span>
<span class="k">val</span> <span class="nv">table</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="nv">tableEnv</span><span class="o">.</span><span class="py">fromDataStream</span><span class="o">(</span><span class="n">stream</span><span class="o">,</span> <span class="n">$</span><span class="s">"myLong"</span><span class="o">)</span></code></pre></figure>

  </div>
</div>

<h4 id="tuples-scala-and-java-and-case-classes-scala-only">Tuples (Scala and Java) and Case Classes (Scala only)</h4>

<p>Flink supports Scala’s built-in tuples and provides its own tuple classes for Java. DataStreams and DataSets of both kinds of tuples can be converted into tables. Fields can be renamed by providing names for all fields (mapping based on position). If no field names are specified, the default field names are used. If the original field names (<code class="highlighter-rouge">f0</code>, <code class="highlighter-rouge">f1</code>, … for Flink Tuples and <code class="highlighter-rouge">_1</code>, <code class="highlighter-rouge">_2</code>, … for Scala Tuples) are referenced, the API assumes that the mapping is name-based instead of position-based. Name-based mapping allows for reordering fields and projection with alias (<code class="highlighter-rouge">as</code>).</p>

<div class="codetabs">
  <div data-lang="java">

    <figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="c1">// get a StreamTableEnvironment, works for BatchTableEnvironment equivalently</span>
<span class="nc">StreamTableEnvironment</span> <span class="n">tableEnv</span> <span class="o">=</span> <span class="o">...;</span> <span class="c1">// see "Create a TableEnvironment" section</span>

<span class="nc">DataStream</span><span class="o">&lt;</span><span class="nc">Tuple2</span><span class="o">&lt;</span><span class="nc">Long</span><span class="o">,</span> <span class="nc">String</span><span class="o">&gt;&gt;</span> <span class="n">stream</span> <span class="o">=</span> <span class="o">...</span>

<span class="c1">// convert DataStream into Table with default field names "f0", "f1"</span>
<span class="nc">Table</span> <span class="n">table</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="na">fromDataStream</span><span class="o">(</span><span class="n">stream</span><span class="o">);</span>

<span class="c1">// convert DataStream into Table with renamed field names "myLong", "myString" (position-based)</span>
<span class="nc">Table</span> <span class="n">table</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="na">fromDataStream</span><span class="o">(</span><span class="n">stream</span><span class="o">,</span> <span class="err">$</span><span class="o">(</span><span class="s">"myLong"</span><span class="o">),</span> <span class="err">$</span><span class="o">(</span><span class="s">"myString"</span><span class="o">));</span>

<span class="c1">// convert DataStream into Table with reordered fields "f1", "f0" (name-based)</span>
<span class="nc">Table</span> <span class="n">table</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="na">fromDataStream</span><span class="o">(</span><span class="n">stream</span><span class="o">,</span> <span class="err">$</span><span class="o">(</span><span class="s">"f1"</span><span class="o">),</span> <span class="err">$</span><span class="o">(</span><span class="s">"f0"</span><span class="o">));</span>

<span class="c1">// convert DataStream into Table with projected field "f1" (name-based)</span>
<span class="nc">Table</span> <span class="n">table</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="na">fromDataStream</span><span class="o">(</span><span class="n">stream</span><span class="o">,</span> <span class="err">$</span><span class="o">(</span><span class="s">"f1"</span><span class="o">));</span>

<span class="c1">// convert DataStream into Table with reordered and aliased fields "myString", "myLong" (name-based)</span>
<span class="nc">Table</span> <span class="n">table</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="na">fromDataStream</span><span class="o">(</span><span class="n">stream</span><span class="o">,</span> <span class="err">$</span><span class="o">(</span><span class="s">"f1"</span><span class="o">).</span><span class="na">as</span><span class="o">(</span><span class="s">"myString"</span><span class="o">),</span> <span class="err">$</span><span class="o">(</span><span class="s">"f0"</span><span class="o">).</span><span class="na">as</span><span class="o">(</span><span class="s">"myLong"</span><span class="o">));</span></code></pre></figure>

  </div>

  <div data-lang="scala">

    <figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="c1">// get a TableEnvironment</span>
<span class="k">val</span> <span class="nv">tableEnv</span><span class="k">:</span> <span class="kt">StreamTableEnvironment</span> <span class="o">=</span> <span class="o">...</span> <span class="c1">// see "Create a TableEnvironment" section</span>

<span class="k">val</span> <span class="nv">stream</span><span class="k">:</span> <span class="kt">DataStream</span><span class="o">[(</span><span class="kt">Long</span>, <span class="kt">String</span><span class="o">)]</span> <span class="k">=</span> <span class="o">...</span>

<span class="c1">// convert DataStream into Table with renamed default field names '_1, '_2</span>
<span class="k">val</span> <span class="nv">table</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="nv">tableEnv</span><span class="o">.</span><span class="py">fromDataStream</span><span class="o">(</span><span class="n">stream</span><span class="o">)</span>

<span class="c1">// convert DataStream into Table with field names "myLong", "myString" (position-based)</span>
<span class="k">val</span> <span class="nv">table</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="nv">tableEnv</span><span class="o">.</span><span class="py">fromDataStream</span><span class="o">(</span><span class="n">stream</span><span class="o">,</span> <span class="n">$</span><span class="s">"myLong"</span><span class="o">,</span> <span class="n">$</span><span class="s">"myString"</span><span class="o">)</span>

<span class="c1">// convert DataStream into Table with reordered fields "_2", "_1" (name-based)</span>
<span class="k">val</span> <span class="nv">table</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="nv">tableEnv</span><span class="o">.</span><span class="py">fromDataStream</span><span class="o">(</span><span class="n">stream</span><span class="o">,</span> <span class="n">$</span><span class="s">"_2"</span><span class="o">,</span> <span class="n">$</span><span class="s">"_1"</span><span class="o">)</span>

<span class="c1">// convert DataStream into Table with projected field "_2" (name-based)</span>
<span class="k">val</span> <span class="nv">table</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="nv">tableEnv</span><span class="o">.</span><span class="py">fromDataStream</span><span class="o">(</span><span class="n">stream</span><span class="o">,</span> <span class="n">$</span><span class="s">"_2"</span><span class="o">)</span>

<span class="c1">// convert DataStream into Table with reordered and aliased fields "myString", "myLong" (name-based)</span>
<span class="k">val</span> <span class="nv">table</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="nv">tableEnv</span><span class="o">.</span><span class="py">fromDataStream</span><span class="o">(</span><span class="n">stream</span><span class="o">,</span> <span class="n">$</span><span class="s">"_2"</span> <span class="n">as</span> <span class="s">"myString"</span><span class="o">,</span> <span class="n">$</span><span class="s">"_1"</span> <span class="n">as</span> <span class="s">"myLong"</span><span class="o">)</span>

<span class="c1">// define case class</span>
<span class="k">case</span> <span class="k">class</span> <span class="nc">Person</span><span class="o">(</span><span class="n">name</span><span class="k">:</span> <span class="kt">String</span><span class="o">,</span> <span class="n">age</span><span class="k">:</span> <span class="kt">Int</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">streamCC</span><span class="k">:</span> <span class="kt">DataStream</span><span class="o">[</span><span class="kt">Person</span><span class="o">]</span> <span class="k">=</span> <span class="o">...</span>

<span class="c1">// convert DataStream into Table with default field names 'name, 'age</span>
<span class="k">val</span> <span class="nv">table</span> <span class="k">=</span> <span class="nv">tableEnv</span><span class="o">.</span><span class="py">fromDataStream</span><span class="o">(</span><span class="n">streamCC</span><span class="o">)</span>

<span class="c1">// convert DataStream into Table with field names 'myName, 'myAge (position-based)</span>
<span class="k">val</span> <span class="nv">table</span> <span class="k">=</span> <span class="nv">tableEnv</span><span class="o">.</span><span class="py">fromDataStream</span><span class="o">(</span><span class="n">streamCC</span><span class="o">,</span> <span class="n">$</span><span class="s">"myName"</span><span class="o">,</span> <span class="n">$</span><span class="s">"myAge"</span><span class="o">)</span>

<span class="c1">// convert DataStream into Table with reordered and aliased fields "myAge", "myName" (name-based)</span>
<span class="k">val</span> <span class="nv">table</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="nv">tableEnv</span><span class="o">.</span><span class="py">fromDataStream</span><span class="o">(</span><span class="n">stream</span><span class="o">,</span> <span class="n">$</span><span class="s">"age"</span> <span class="n">as</span> <span class="s">"myAge"</span><span class="o">,</span> <span class="n">$</span><span class="s">"name"</span> <span class="n">as</span> <span class="s">"myName"</span><span class="o">)</span></code></pre></figure>

  </div>
</div>

<h4 id="pojo-java-and-scala">POJO (Java and Scala)</h4>

<p>Flink supports POJOs as composite types. The rules for what determines a POJO are documented <a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/types_serialization.html#pojos">here</a>.</p>

<p>When converting a POJO <code class="highlighter-rouge">DataStream</code> or <code class="highlighter-rouge">DataSet</code> into a <code class="highlighter-rouge">Table</code> without specifying field names, the names of the original POJO fields are used. The name mapping requires the original names and cannot be done by positions. Fields can be renamed using an alias (with the <code class="highlighter-rouge">as</code> keyword), reordered, and projected.</p>

<div class="codetabs">
  <div data-lang="java">

    <figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="c1">// get a StreamTableEnvironment, works for BatchTableEnvironment equivalently</span>
<span class="nc">StreamTableEnvironment</span> <span class="n">tableEnv</span> <span class="o">=</span> <span class="o">...;</span> <span class="c1">// see "Create a TableEnvironment" section</span>

<span class="c1">// Person is a POJO with fields "name" and "age"</span>
<span class="nc">DataStream</span><span class="o">&lt;</span><span class="nc">Person</span><span class="o">&gt;</span> <span class="n">stream</span> <span class="o">=</span> <span class="o">...</span>

<span class="c1">// convert DataStream into Table with default field names "age", "name" (fields are ordered by name!)</span>
<span class="nc">Table</span> <span class="n">table</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="na">fromDataStream</span><span class="o">(</span><span class="n">stream</span><span class="o">);</span>

<span class="c1">// convert DataStream into Table with renamed fields "myAge", "myName" (name-based)</span>
<span class="nc">Table</span> <span class="n">table</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="na">fromDataStream</span><span class="o">(</span><span class="n">stream</span><span class="o">,</span> <span class="err">$</span><span class="o">(</span><span class="s">"age"</span><span class="o">).</span><span class="na">as</span><span class="o">(</span><span class="s">"myAge"</span><span class="o">),</span> <span class="err">$</span><span class="o">(</span><span class="s">"name"</span><span class="o">).</span><span class="na">as</span><span class="o">(</span><span class="s">"myName"</span><span class="o">));</span>

<span class="c1">// convert DataStream into Table with projected field "name" (name-based)</span>
<span class="nc">Table</span> <span class="n">table</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="na">fromDataStream</span><span class="o">(</span><span class="n">stream</span><span class="o">,</span> <span class="err">$</span><span class="o">(</span><span class="s">"name"</span><span class="o">));</span>

<span class="c1">// convert DataStream into Table with projected and renamed field "myName" (name-based)</span>
<span class="nc">Table</span> <span class="n">table</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="na">fromDataStream</span><span class="o">(</span><span class="n">stream</span><span class="o">,</span> <span class="err">$</span><span class="o">(</span><span class="s">"name"</span><span class="o">).</span><span class="na">as</span><span class="o">(</span><span class="s">"myName"</span><span class="o">));</span></code></pre></figure>

  </div>

  <div data-lang="scala">

    <figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="c1">// get a TableEnvironment</span>
<span class="k">val</span> <span class="nv">tableEnv</span><span class="k">:</span> <span class="kt">StreamTableEnvironment</span> <span class="o">=</span> <span class="o">...</span> <span class="c1">// see "Create a TableEnvironment" section</span>

<span class="c1">// Person is a POJO with field names "name" and "age"</span>
<span class="k">val</span> <span class="nv">stream</span><span class="k">:</span> <span class="kt">DataStream</span><span class="o">[</span><span class="kt">Person</span><span class="o">]</span> <span class="k">=</span> <span class="o">...</span>

<span class="c1">// convert DataStream into Table with default field names "age", "name" (fields are ordered by name!)</span>
<span class="k">val</span> <span class="nv">table</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="nv">tableEnv</span><span class="o">.</span><span class="py">fromDataStream</span><span class="o">(</span><span class="n">stream</span><span class="o">)</span>

<span class="c1">// convert DataStream into Table with renamed fields "myAge", "myName" (name-based)</span>
<span class="k">val</span> <span class="nv">table</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="nv">tableEnv</span><span class="o">.</span><span class="py">fromDataStream</span><span class="o">(</span><span class="n">stream</span><span class="o">,</span> <span class="n">$</span><span class="s">"age"</span> <span class="n">as</span> <span class="s">"myAge"</span><span class="o">,</span> <span class="n">$</span><span class="s">"name"</span> <span class="n">as</span> <span class="s">"myName"</span><span class="o">)</span>

<span class="c1">// convert DataStream into Table with projected field "name" (name-based)</span>
<span class="k">val</span> <span class="nv">table</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="nv">tableEnv</span><span class="o">.</span><span class="py">fromDataStream</span><span class="o">(</span><span class="n">stream</span><span class="o">,</span> <span class="n">$</span><span class="s">"name"</span><span class="o">)</span>

<span class="c1">// convert DataStream into Table with projected and renamed field "myName" (name-based)</span>
<span class="k">val</span> <span class="nv">table</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="nv">tableEnv</span><span class="o">.</span><span class="py">fromDataStream</span><span class="o">(</span><span class="n">stream</span><span class="o">,</span> <span class="n">$</span><span class="s">"name"</span> <span class="n">as</span> <span class="s">"myName"</span><span class="o">)</span></code></pre></figure>

  </div>
</div>

<h4 id="row">Row</h4>

<p>The <code class="highlighter-rouge">Row</code> data type supports an arbitrary number of fields and fields with <code class="highlighter-rouge">null</code> values. Field names can be specified via a <code class="highlighter-rouge">RowTypeInfo</code> or when converting a <code class="highlighter-rouge">Row</code> <code class="highlighter-rouge">DataStream</code> or <code class="highlighter-rouge">DataSet</code> into a <code class="highlighter-rouge">Table</code>. The row type supports mapping of fields by position and by name. Fields can be renamed by providing names for all fields (mapping based on position) or selected individually for projection/ordering/renaming (mapping based on name).</p>

<div class="codetabs">
  <div data-lang="java">

    <figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="c1">// get a StreamTableEnvironment, works for BatchTableEnvironment equivalently</span>
<span class="nc">StreamTableEnvironment</span> <span class="n">tableEnv</span> <span class="o">=</span> <span class="o">...;</span> <span class="c1">// see "Create a TableEnvironment" section</span>

<span class="c1">// DataStream of Row with two fields "name" and "age" specified in `RowTypeInfo`</span>
<span class="nc">DataStream</span><span class="o">&lt;</span><span class="nc">Row</span><span class="o">&gt;</span> <span class="n">stream</span> <span class="o">=</span> <span class="o">...</span>

<span class="c1">// convert DataStream into Table with default field names "name", "age"</span>
<span class="nc">Table</span> <span class="n">table</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="na">fromDataStream</span><span class="o">(</span><span class="n">stream</span><span class="o">);</span>

<span class="c1">// convert DataStream into Table with renamed field names "myName", "myAge" (position-based)</span>
<span class="nc">Table</span> <span class="n">table</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="na">fromDataStream</span><span class="o">(</span><span class="n">stream</span><span class="o">,</span> <span class="err">$</span><span class="o">(</span><span class="s">"myName"</span><span class="o">),</span> <span class="err">$</span><span class="o">(</span><span class="s">"myAge"</span><span class="o">));</span>

<span class="c1">// convert DataStream into Table with renamed fields "myName", "myAge" (name-based)</span>
<span class="nc">Table</span> <span class="n">table</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="na">fromDataStream</span><span class="o">(</span><span class="n">stream</span><span class="o">,</span> <span class="err">$</span><span class="o">(</span><span class="s">"name"</span><span class="o">).</span><span class="na">as</span><span class="o">(</span><span class="s">"myName"</span><span class="o">),</span> <span class="err">$</span><span class="o">(</span><span class="s">"age"</span><span class="o">).</span><span class="na">as</span><span class="o">(</span><span class="s">"myAge"</span><span class="o">));</span>

<span class="c1">// convert DataStream into Table with projected field "name" (name-based)</span>
<span class="nc">Table</span> <span class="n">table</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="na">fromDataStream</span><span class="o">(</span><span class="n">stream</span><span class="o">,</span> <span class="err">$</span><span class="o">(</span><span class="s">"name"</span><span class="o">));</span>

<span class="c1">// convert DataStream into Table with projected and renamed field "myName" (name-based)</span>
<span class="nc">Table</span> <span class="n">table</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="na">fromDataStream</span><span class="o">(</span><span class="n">stream</span><span class="o">,</span> <span class="err">$</span><span class="o">(</span><span class="s">"name"</span><span class="o">).</span><span class="na">as</span><span class="o">(</span><span class="s">"myName"</span><span class="o">));</span></code></pre></figure>

  </div>

  <div data-lang="scala">

    <figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="c1">// get a TableEnvironment</span>
<span class="k">val</span> <span class="nv">tableEnv</span><span class="k">:</span> <span class="kt">StreamTableEnvironment</span> <span class="o">=</span> <span class="o">...</span> <span class="c1">// see "Create a TableEnvironment" section</span>

<span class="c1">// DataStream of Row with two fields "name" and "age" specified in `RowTypeInfo`</span>
<span class="k">val</span> <span class="nv">stream</span><span class="k">:</span> <span class="kt">DataStream</span><span class="o">[</span><span class="kt">Row</span><span class="o">]</span> <span class="k">=</span> <span class="o">...</span>

<span class="c1">// convert DataStream into Table with default field names "name", "age"</span>
<span class="k">val</span> <span class="nv">table</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="nv">tableEnv</span><span class="o">.</span><span class="py">fromDataStream</span><span class="o">(</span><span class="n">stream</span><span class="o">)</span>

<span class="c1">// convert DataStream into Table with renamed field names "myName", "myAge" (position-based)</span>
<span class="k">val</span> <span class="nv">table</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="nv">tableEnv</span><span class="o">.</span><span class="py">fromDataStream</span><span class="o">(</span><span class="n">stream</span><span class="o">,</span> <span class="n">$</span><span class="s">"myName"</span><span class="o">,</span> <span class="n">$</span><span class="s">"myAge"</span><span class="o">)</span>

<span class="c1">// convert DataStream into Table with renamed fields "myName", "myAge" (name-based)</span>
<span class="k">val</span> <span class="nv">table</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="nv">tableEnv</span><span class="o">.</span><span class="py">fromDataStream</span><span class="o">(</span><span class="n">stream</span><span class="o">,</span> <span class="n">$</span><span class="s">"name"</span> <span class="n">as</span> <span class="s">"myName"</span><span class="o">,</span> <span class="n">$</span><span class="s">"age"</span> <span class="n">as</span> <span class="s">"myAge"</span><span class="o">)</span>

<span class="c1">// convert DataStream into Table with projected field "name" (name-based)</span>
<span class="k">val</span> <span class="nv">table</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="nv">tableEnv</span><span class="o">.</span><span class="py">fromDataStream</span><span class="o">(</span><span class="n">stream</span><span class="o">,</span> <span class="n">$</span><span class="s">"name"</span><span class="o">)</span>

<span class="c1">// convert DataStream into Table with projected and renamed field "myName" (name-based)</span>
<span class="k">val</span> <span class="nv">table</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="nv">tableEnv</span><span class="o">.</span><span class="py">fromDataStream</span><span class="o">(</span><span class="n">stream</span><span class="o">,</span> <span class="n">$</span><span class="s">"name"</span> <span class="n">as</span> <span class="s">"myName"</span><span class="o">)</span></code></pre></figure>

  </div>
</div>

<p><a href="#top" class="top pull-right"><span class="glyphicon glyphicon-chevron-up"></span> Back to top</a></p>

<h2 id="query-optimization">Query Optimization</h2>

<div class="codetabs">
  <div data-lang="Blink planner">
    <p>Apache Flink leverages and extends Apache Calcite to perform sophisticated query optimization.
This includes a series of rule and cost-based optimizations such as:</p>

    <ul>
      <li>Subquery decorrelation based on Apache Calcite</li>
      <li>Project pruning</li>
      <li>Partition pruning</li>
      <li>Filter push-down</li>
      <li>Sub-plan deduplication to avoid duplicate computation</li>
      <li>Special subquery rewriting, including two parts:
        <ul>
          <li>Converts IN and EXISTS into left semi-joins</li>
          <li>Converts NOT IN and NOT EXISTS into left anti-join</li>
        </ul>
      </li>
      <li>Optional join reordering
        <ul>
          <li>Enabled via <code class="highlighter-rouge">table.optimizer.join-reorder-enabled</code></li>
        </ul>
      </li>
    </ul>

    <p><strong>Note:</strong> IN/EXISTS/NOT IN/NOT EXISTS are currently only supported in conjunctive conditions in subquery rewriting.</p>

    <p>The optimizer makes intelligent decisions, based not only on the plan but also rich statistics available from the data sources and fine-grain costs for each operator such as io, cpu, network, and memory.</p>

    <p>Advanced users may provide custom optimizations via a <code class="highlighter-rouge">CalciteConfig</code> object that can be provided to the table environment by calling <code class="highlighter-rouge">TableEnvironment#getConfig#setPlannerConfig</code>.</p>
  </div>

  <div data-lang="Old planner">
    <p>Apache Flink leverages Apache Calcite to optimize and translate queries. The optimization currently performed include projection and filter push-down, subquery decorrelation, and other kinds of query rewriting. Old planner does not yet optimize the order of joins, but executes them in the same order as defined in the query (order of Tables in the <code class="highlighter-rouge">FROM</code> clause and/or order of join predicates in the <code class="highlighter-rouge">WHERE</code> clause).</p>

    <p>It is possible to tweak the set of optimization rules which are applied in different phases by providing a <code class="highlighter-rouge">CalciteConfig</code> object. This can be created via a builder by calling <code class="highlighter-rouge">CalciteConfig.createBuilder())</code> and is provided to the TableEnvironment by calling <code class="highlighter-rouge">tableEnv.getConfig.setPlannerConfig(calciteConfig)</code>.</p>
  </div>
</div>

<h2 id="explaining-a-table">Explaining a Table</h2>

<p>The Table API provides a mechanism to explain the logical and optimized query plans to compute a <code class="highlighter-rouge">Table</code>. 
This is done through the <code class="highlighter-rouge">Table.explain()</code> method or <code class="highlighter-rouge">StatementSet.explain()</code> method. <code class="highlighter-rouge">Table.explain()</code>returns the plan of a <code class="highlighter-rouge">Table</code>. <code class="highlighter-rouge">StatementSet.explain()</code> returns the plan of multiple sinks. It returns a String describing three plans:</p>

<ol>
  <li>the Abstract Syntax Tree of the relational query, i.e., the unoptimized logical query plan,</li>
  <li>the optimized logical query plan, and</li>
  <li>the physical execution plan.</li>
</ol>

<p><code class="highlighter-rouge">TableEnvironment.explainSql()</code> and <code class="highlighter-rouge">TableEnvironment.executeSql()</code> support execute a <code class="highlighter-rouge">EXPLAIN</code> statement to get the plans, Please refer to <a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/sql/explain.html">EXPLAIN</a> page.</p>

<p>The following code shows an example and the corresponding output for given <code class="highlighter-rouge">Table</code> using <code class="highlighter-rouge">Table.explain()</code> method:</p>

<div class="codetabs">
  <div data-lang="java">

    <figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="nc">StreamExecutionEnvironment</span> <span class="n">env</span> <span class="o">=</span> <span class="nc">StreamExecutionEnvironment</span><span class="o">.</span><span class="na">getExecutionEnvironment</span><span class="o">();</span>
<span class="nc">StreamTableEnvironment</span> <span class="n">tEnv</span> <span class="o">=</span> <span class="nc">StreamTableEnvironment</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="n">env</span><span class="o">);</span>

<span class="nc">DataStream</span><span class="o">&lt;</span><span class="nc">Tuple2</span><span class="o">&lt;</span><span class="nc">Integer</span><span class="o">,</span> <span class="nc">String</span><span class="o">&gt;&gt;</span> <span class="n">stream1</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="na">fromElements</span><span class="o">(</span><span class="k">new</span> <span class="nc">Tuple2</span><span class="o">&lt;&gt;(</span><span class="mi">1</span><span class="o">,</span> <span class="s">"hello"</span><span class="o">));</span>
<span class="nc">DataStream</span><span class="o">&lt;</span><span class="nc">Tuple2</span><span class="o">&lt;</span><span class="nc">Integer</span><span class="o">,</span> <span class="nc">String</span><span class="o">&gt;&gt;</span> <span class="n">stream2</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="na">fromElements</span><span class="o">(</span><span class="k">new</span> <span class="nc">Tuple2</span><span class="o">&lt;&gt;(</span><span class="mi">1</span><span class="o">,</span> <span class="s">"hello"</span><span class="o">));</span>

<span class="c1">// explain Table API</span>
<span class="nc">Table</span> <span class="n">table1</span> <span class="o">=</span> <span class="n">tEnv</span><span class="o">.</span><span class="na">fromDataStream</span><span class="o">(</span><span class="n">stream1</span><span class="o">,</span> <span class="err">$</span><span class="o">(</span><span class="s">"count"</span><span class="o">),</span> <span class="err">$</span><span class="o">(</span><span class="s">"word"</span><span class="o">));</span>
<span class="nc">Table</span> <span class="n">table2</span> <span class="o">=</span> <span class="n">tEnv</span><span class="o">.</span><span class="na">fromDataStream</span><span class="o">(</span><span class="n">stream2</span><span class="o">,</span> <span class="err">$</span><span class="o">(</span><span class="s">"count"</span><span class="o">),</span> <span class="err">$</span><span class="o">(</span><span class="s">"word"</span><span class="o">));</span>
<span class="nc">Table</span> <span class="n">table</span> <span class="o">=</span> <span class="n">table1</span>
  <span class="o">.</span><span class="na">where</span><span class="o">(</span><span class="err">$</span><span class="o">(</span><span class="s">"word"</span><span class="o">).</span><span class="na">like</span><span class="o">(</span><span class="s">"F%"</span><span class="o">))</span>
  <span class="o">.</span><span class="na">unionAll</span><span class="o">(</span><span class="n">table2</span><span class="o">);</span>
<span class="nc">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="n">table</span><span class="o">.</span><span class="na">explain</span><span class="o">());</span></code></pre></figure>

  </div>

  <div data-lang="scala">

    <figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="nv">env</span> <span class="k">=</span> <span class="nv">StreamExecutionEnvironment</span><span class="o">.</span><span class="py">getExecutionEnvironment</span>
<span class="k">val</span> <span class="nv">tEnv</span> <span class="k">=</span> <span class="nv">StreamTableEnvironment</span><span class="o">.</span><span class="py">create</span><span class="o">(</span><span class="n">env</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">table1</span> <span class="k">=</span> <span class="nv">env</span><span class="o">.</span><span class="py">fromElements</span><span class="o">((</span><span class="mi">1</span><span class="o">,</span> <span class="s">"hello"</span><span class="o">)).</span><span class="py">toTable</span><span class="o">(</span><span class="n">tEnv</span><span class="o">,</span> <span class="n">$</span><span class="s">"count"</span><span class="o">,</span> <span class="n">$</span><span class="s">"word"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">table2</span> <span class="k">=</span> <span class="nv">env</span><span class="o">.</span><span class="py">fromElements</span><span class="o">((</span><span class="mi">1</span><span class="o">,</span> <span class="s">"hello"</span><span class="o">)).</span><span class="py">toTable</span><span class="o">(</span><span class="n">tEnv</span><span class="o">,</span> <span class="n">$</span><span class="s">"count"</span><span class="o">,</span> <span class="n">$</span><span class="s">"word"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">table</span> <span class="k">=</span> <span class="n">table1</span>
  <span class="o">.</span><span class="py">where</span><span class="o">(</span><span class="n">$</span><span class="s">"word"</span><span class="o">.</span><span class="py">like</span><span class="o">(</span><span class="s">"F%"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">unionAll</span><span class="o">(</span><span class="n">table2</span><span class="o">)</span>
<span class="nf">println</span><span class="o">(</span><span class="nv">table</span><span class="o">.</span><span class="py">explain</span><span class="o">())</span></code></pre></figure>

  </div>

  <div data-lang="python">

    <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">env</span> <span class="o">=</span> <span class="n">StreamExecutionEnvironment</span><span class="p">.</span><span class="n">get_execution_environment</span><span class="p">()</span>
<span class="n">t_env</span> <span class="o">=</span> <span class="n">StreamTableEnvironment</span><span class="p">.</span><span class="n">create</span><span class="p">(</span><span class="n">env</span><span class="p">)</span>

<span class="n">table1</span> <span class="o">=</span> <span class="n">t_env</span><span class="p">.</span><span class="n">from_elements</span><span class="p">([(</span><span class="mi">1</span><span class="p">,</span> <span class="s">"hello"</span><span class="p">)],</span> <span class="p">[</span><span class="s">"count"</span><span class="p">,</span> <span class="s">"word"</span><span class="p">])</span>
<span class="n">table2</span> <span class="o">=</span> <span class="n">t_env</span><span class="p">.</span><span class="n">from_elements</span><span class="p">([(</span><span class="mi">1</span><span class="p">,</span> <span class="s">"hello"</span><span class="p">)],</span> <span class="p">[</span><span class="s">"count"</span><span class="p">,</span> <span class="s">"word"</span><span class="p">])</span>
<span class="n">table</span> <span class="o">=</span> <span class="n">table1</span> \
    <span class="p">.</span><span class="n">where</span><span class="p">(</span><span class="n">table1</span><span class="p">.</span><span class="n">word</span><span class="p">.</span><span class="n">like</span><span class="p">(</span><span class="s">'F%'</span><span class="p">))</span> \
    <span class="p">.</span><span class="n">union_all</span><span class="p">(</span><span class="n">table2</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">table</span><span class="p">.</span><span class="n">explain</span><span class="p">())</span></code></pre></figure>

  </div>
</div>

<p>The result of the above exmaple is</p>
<div>

<figure class="highlight"><pre><code class="language-text" data-lang="text">== Abstract Syntax Tree ==
LogicalUnion(all=[true])
  LogicalFilter(condition=[LIKE($1, _UTF-16LE'F%')])
    FlinkLogicalDataStreamScan(id=[1], fields=[count, word])
  FlinkLogicalDataStreamScan(id=[2], fields=[count, word])

== Optimized Logical Plan ==
DataStreamUnion(all=[true], union all=[count, word])
  DataStreamCalc(select=[count, word], where=[LIKE(word, _UTF-16LE'F%')])
    DataStreamScan(id=[1], fields=[count, word])
  DataStreamScan(id=[2], fields=[count, word])

== Physical Execution Plan ==
Stage 1 : Data Source
	content : collect elements with CollectionInputFormat

Stage 2 : Data Source
	content : collect elements with CollectionInputFormat

	Stage 3 : Operator
		content : from: (count, word)
		ship_strategy : REBALANCE

		Stage 4 : Operator
			content : where: (LIKE(word, _UTF-16LE'F%')), select: (count, word)
			ship_strategy : FORWARD

			Stage 5 : Operator
				content : from: (count, word)
				ship_strategy : REBALANCE</code></pre></figure>

</div>

<p>The following code shows an example and the corresponding output for multiple-sinks plan using <code class="highlighter-rouge">StatementSet.explain()</code> method:</p>

<div class="codetabs">
  <div data-lang="java">

    <figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="nc">EnvironmentSettings</span> <span class="n">settings</span> <span class="o">=</span> <span class="nc">EnvironmentSettings</span><span class="o">.</span><span class="na">newInstance</span><span class="o">().</span><span class="na">useBlinkPlanner</span><span class="o">().</span><span class="na">inStreamingMode</span><span class="o">().</span><span class="na">build</span><span class="o">();</span>
<span class="nc">TableEnvironment</span> <span class="n">tEnv</span> <span class="o">=</span> <span class="nc">TableEnvironment</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="n">settings</span><span class="o">);</span>

<span class="kd">final</span> <span class="nc">Schema</span> <span class="n">schema</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">Schema</span><span class="o">()</span>
    <span class="o">.</span><span class="na">field</span><span class="o">(</span><span class="s">"count"</span><span class="o">,</span> <span class="nc">DataTypes</span><span class="o">.</span><span class="na">INT</span><span class="o">())</span>
    <span class="o">.</span><span class="na">field</span><span class="o">(</span><span class="s">"word"</span><span class="o">,</span> <span class="nc">DataTypes</span><span class="o">.</span><span class="na">STRING</span><span class="o">());</span>

<span class="n">tEnv</span><span class="o">.</span><span class="na">connect</span><span class="o">(</span><span class="k">new</span> <span class="nc">FileSystem</span><span class="o">().</span><span class="na">path</span><span class="o">(</span><span class="s">"/source/path1"</span><span class="o">))</span>
    <span class="o">.</span><span class="na">withFormat</span><span class="o">(</span><span class="k">new</span> <span class="nc">Csv</span><span class="o">().</span><span class="na">deriveSchema</span><span class="o">())</span>
    <span class="o">.</span><span class="na">withSchema</span><span class="o">(</span><span class="n">schema</span><span class="o">)</span>
    <span class="o">.</span><span class="na">createTemporaryTable</span><span class="o">(</span><span class="s">"MySource1"</span><span class="o">);</span>
<span class="n">tEnv</span><span class="o">.</span><span class="na">connect</span><span class="o">(</span><span class="k">new</span> <span class="nc">FileSystem</span><span class="o">().</span><span class="na">path</span><span class="o">(</span><span class="s">"/source/path2"</span><span class="o">))</span>
    <span class="o">.</span><span class="na">withFormat</span><span class="o">(</span><span class="k">new</span> <span class="nc">Csv</span><span class="o">().</span><span class="na">deriveSchema</span><span class="o">())</span>
    <span class="o">.</span><span class="na">withSchema</span><span class="o">(</span><span class="n">schema</span><span class="o">)</span>
    <span class="o">.</span><span class="na">createTemporaryTable</span><span class="o">(</span><span class="s">"MySource2"</span><span class="o">);</span>
<span class="n">tEnv</span><span class="o">.</span><span class="na">connect</span><span class="o">(</span><span class="k">new</span> <span class="nc">FileSystem</span><span class="o">().</span><span class="na">path</span><span class="o">(</span><span class="s">"/sink/path1"</span><span class="o">))</span>
    <span class="o">.</span><span class="na">withFormat</span><span class="o">(</span><span class="k">new</span> <span class="nc">Csv</span><span class="o">().</span><span class="na">deriveSchema</span><span class="o">())</span>
    <span class="o">.</span><span class="na">withSchema</span><span class="o">(</span><span class="n">schema</span><span class="o">)</span>
    <span class="o">.</span><span class="na">createTemporaryTable</span><span class="o">(</span><span class="s">"MySink1"</span><span class="o">);</span>
<span class="n">tEnv</span><span class="o">.</span><span class="na">connect</span><span class="o">(</span><span class="k">new</span> <span class="nc">FileSystem</span><span class="o">().</span><span class="na">path</span><span class="o">(</span><span class="s">"/sink/path2"</span><span class="o">))</span>
    <span class="o">.</span><span class="na">withFormat</span><span class="o">(</span><span class="k">new</span> <span class="nc">Csv</span><span class="o">().</span><span class="na">deriveSchema</span><span class="o">())</span>
    <span class="o">.</span><span class="na">withSchema</span><span class="o">(</span><span class="n">schema</span><span class="o">)</span>
    <span class="o">.</span><span class="na">createTemporaryTable</span><span class="o">(</span><span class="s">"MySink2"</span><span class="o">);</span>
    
<span class="nc">StatementSet</span> <span class="n">stmtSet</span> <span class="o">=</span> <span class="n">tEnv</span><span class="o">.</span><span class="na">createStatementSet</span><span class="o">();</span>

<span class="nc">Table</span> <span class="n">table1</span> <span class="o">=</span> <span class="n">tEnv</span><span class="o">.</span><span class="na">from</span><span class="o">(</span><span class="s">"MySource1"</span><span class="o">).</span><span class="na">where</span><span class="o">(</span><span class="err">$</span><span class="o">(</span><span class="s">"word"</span><span class="o">).</span><span class="na">like</span><span class="o">(</span><span class="s">"F%"</span><span class="o">));</span>
<span class="n">stmtSet</span><span class="o">.</span><span class="na">addInsert</span><span class="o">(</span><span class="s">"MySink1"</span><span class="o">,</span> <span class="n">table1</span><span class="o">);</span>

<span class="nc">Table</span> <span class="n">table2</span> <span class="o">=</span> <span class="n">table1</span><span class="o">.</span><span class="na">unionAll</span><span class="o">(</span><span class="n">tEnv</span><span class="o">.</span><span class="na">from</span><span class="o">(</span><span class="s">"MySource2"</span><span class="o">));</span>
<span class="n">stmtSet</span><span class="o">.</span><span class="na">addInsert</span><span class="o">(</span><span class="s">"MySink2"</span><span class="o">,</span> <span class="n">table2</span><span class="o">);</span>

<span class="nc">String</span> <span class="n">explanation</span> <span class="o">=</span> <span class="n">stmtSet</span><span class="o">.</span><span class="na">explain</span><span class="o">();</span>
<span class="nc">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="n">explanation</span><span class="o">);</span></code></pre></figure>

  </div>

  <div data-lang="scala">

    <figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="nv">settings</span> <span class="k">=</span> <span class="nv">EnvironmentSettings</span><span class="o">.</span><span class="py">newInstance</span><span class="o">.</span><span class="py">useBlinkPlanner</span><span class="o">.</span><span class="py">inStreamingMode</span><span class="o">.</span><span class="py">build</span>
<span class="k">val</span> <span class="nv">tEnv</span> <span class="k">=</span> <span class="nv">TableEnvironment</span><span class="o">.</span><span class="py">create</span><span class="o">(</span><span class="n">settings</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">schema</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Schema</span><span class="o">()</span>
    <span class="o">.</span><span class="py">field</span><span class="o">(</span><span class="s">"count"</span><span class="o">,</span> <span class="nv">DataTypes</span><span class="o">.</span><span class="py">INT</span><span class="o">())</span>
    <span class="o">.</span><span class="py">field</span><span class="o">(</span><span class="s">"word"</span><span class="o">,</span> <span class="nv">DataTypes</span><span class="o">.</span><span class="py">STRING</span><span class="o">())</span>

<span class="nv">tEnv</span><span class="o">.</span><span class="py">connect</span><span class="o">(</span><span class="k">new</span> <span class="nc">FileSystem</span><span class="o">().</span><span class="py">path</span><span class="o">(</span><span class="s">"/source/path1"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">withFormat</span><span class="o">(</span><span class="k">new</span> <span class="nc">Csv</span><span class="o">().</span><span class="py">deriveSchema</span><span class="o">())</span>
    <span class="o">.</span><span class="py">withSchema</span><span class="o">(</span><span class="n">schema</span><span class="o">)</span>
    <span class="o">.</span><span class="py">createTemporaryTable</span><span class="o">(</span><span class="s">"MySource1"</span><span class="o">)</span>
<span class="nv">tEnv</span><span class="o">.</span><span class="py">connect</span><span class="o">(</span><span class="k">new</span> <span class="nc">FileSystem</span><span class="o">().</span><span class="py">path</span><span class="o">(</span><span class="s">"/source/path2"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">withFormat</span><span class="o">(</span><span class="k">new</span> <span class="nc">Csv</span><span class="o">().</span><span class="py">deriveSchema</span><span class="o">())</span>
    <span class="o">.</span><span class="py">withSchema</span><span class="o">(</span><span class="n">schema</span><span class="o">)</span>
    <span class="o">.</span><span class="py">createTemporaryTable</span><span class="o">(</span><span class="s">"MySource2"</span><span class="o">)</span>
<span class="nv">tEnv</span><span class="o">.</span><span class="py">connect</span><span class="o">(</span><span class="k">new</span> <span class="nc">FileSystem</span><span class="o">().</span><span class="py">path</span><span class="o">(</span><span class="s">"/sink/path1"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">withFormat</span><span class="o">(</span><span class="k">new</span> <span class="nc">Csv</span><span class="o">().</span><span class="py">deriveSchema</span><span class="o">())</span>
    <span class="o">.</span><span class="py">withSchema</span><span class="o">(</span><span class="n">schema</span><span class="o">)</span>
    <span class="o">.</span><span class="py">createTemporaryTable</span><span class="o">(</span><span class="s">"MySink1"</span><span class="o">)</span>
<span class="nv">tEnv</span><span class="o">.</span><span class="py">connect</span><span class="o">(</span><span class="k">new</span> <span class="nc">FileSystem</span><span class="o">().</span><span class="py">path</span><span class="o">(</span><span class="s">"/sink/path2"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">withFormat</span><span class="o">(</span><span class="k">new</span> <span class="nc">Csv</span><span class="o">().</span><span class="py">deriveSchema</span><span class="o">())</span>
    <span class="o">.</span><span class="py">withSchema</span><span class="o">(</span><span class="n">schema</span><span class="o">)</span>
    <span class="o">.</span><span class="py">createTemporaryTable</span><span class="o">(</span><span class="s">"MySink2"</span><span class="o">)</span>
    
<span class="k">val</span> <span class="nv">stmtSet</span> <span class="k">=</span> <span class="nv">tEnv</span><span class="o">.</span><span class="py">createStatementSet</span><span class="o">()</span>

<span class="k">val</span> <span class="nv">table1</span> <span class="k">=</span> <span class="nv">tEnv</span><span class="o">.</span><span class="py">from</span><span class="o">(</span><span class="s">"MySource1"</span><span class="o">).</span><span class="py">where</span><span class="o">(</span><span class="n">$</span><span class="s">"word"</span><span class="o">.</span><span class="py">like</span><span class="o">(</span><span class="s">"F%"</span><span class="o">))</span>
<span class="nv">stmtSet</span><span class="o">.</span><span class="py">addInsert</span><span class="o">(</span><span class="s">"MySink1"</span><span class="o">,</span> <span class="n">table1</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">table2</span> <span class="k">=</span> <span class="nv">table1</span><span class="o">.</span><span class="py">unionAll</span><span class="o">(</span><span class="nv">tEnv</span><span class="o">.</span><span class="py">from</span><span class="o">(</span><span class="s">"MySource2"</span><span class="o">))</span>
<span class="nv">stmtSet</span><span class="o">.</span><span class="py">addInsert</span><span class="o">(</span><span class="s">"MySink2"</span><span class="o">,</span> <span class="n">table2</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">explanation</span> <span class="k">=</span> <span class="nv">stmtSet</span><span class="o">.</span><span class="py">explain</span><span class="o">()</span>
<span class="nf">println</span><span class="o">(</span><span class="n">explanation</span><span class="o">)</span></code></pre></figure>

  </div>

  <div data-lang="python">

    <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">settings</span> <span class="o">=</span> <span class="n">EnvironmentSettings</span><span class="p">.</span><span class="n">new_instance</span><span class="p">().</span><span class="n">use_blink_planner</span><span class="p">().</span><span class="n">in_streaming_mode</span><span class="p">().</span><span class="n">build</span><span class="p">()</span>
<span class="n">t_env</span> <span class="o">=</span> <span class="n">TableEnvironment</span><span class="p">.</span><span class="n">create</span><span class="p">(</span><span class="n">environment_settings</span><span class="o">=</span><span class="n">settings</span><span class="p">)</span>

<span class="n">schema</span> <span class="o">=</span> <span class="n">Schema</span><span class="p">()</span>
    <span class="p">.</span><span class="n">field</span><span class="p">(</span><span class="s">"count"</span><span class="p">,</span> <span class="n">DataTypes</span><span class="p">.</span><span class="n">INT</span><span class="p">())</span>
    <span class="p">.</span><span class="n">field</span><span class="p">(</span><span class="s">"word"</span><span class="p">,</span> <span class="n">DataTypes</span><span class="p">.</span><span class="n">STRING</span><span class="p">())</span>

<span class="n">t_env</span><span class="p">.</span><span class="n">connect</span><span class="p">(</span><span class="n">FileSystem</span><span class="p">().</span><span class="n">path</span><span class="p">(</span><span class="s">"/source/path1"</span><span class="p">)))</span>
    <span class="p">.</span><span class="n">with_format</span><span class="p">(</span><span class="n">Csv</span><span class="p">().</span><span class="n">deriveSchema</span><span class="p">())</span>
    <span class="p">.</span><span class="n">with_schema</span><span class="p">(</span><span class="n">schema</span><span class="p">)</span>
    <span class="p">.</span><span class="n">create_temporary_table</span><span class="p">(</span><span class="s">"MySource1"</span><span class="p">)</span>
<span class="n">t_env</span><span class="p">.</span><span class="n">connect</span><span class="p">(</span><span class="n">FileSystem</span><span class="p">().</span><span class="n">path</span><span class="p">(</span><span class="s">"/source/path2"</span><span class="p">)))</span>
    <span class="p">.</span><span class="n">with_format</span><span class="p">(</span><span class="n">Csv</span><span class="p">().</span><span class="n">deriveSchema</span><span class="p">())</span>
    <span class="p">.</span><span class="n">with_schema</span><span class="p">(</span><span class="n">schema</span><span class="p">)</span>
    <span class="p">.</span><span class="n">create_temporary_table</span><span class="p">(</span><span class="s">"MySource2"</span><span class="p">)</span>
<span class="n">t_env</span><span class="p">.</span><span class="n">connect</span><span class="p">(</span><span class="n">FileSystem</span><span class="p">().</span><span class="n">path</span><span class="p">(</span><span class="s">"/sink/path1"</span><span class="p">)))</span>
    <span class="p">.</span><span class="n">with_format</span><span class="p">(</span><span class="n">Csv</span><span class="p">().</span><span class="n">deriveSchema</span><span class="p">())</span>
    <span class="p">.</span><span class="n">with_schema</span><span class="p">(</span><span class="n">schema</span><span class="p">)</span>
    <span class="p">.</span><span class="n">create_temporary_table</span><span class="p">(</span><span class="s">"MySink1"</span><span class="p">)</span>
<span class="n">t_env</span><span class="p">.</span><span class="n">connect</span><span class="p">(</span><span class="n">FileSystem</span><span class="p">().</span><span class="n">path</span><span class="p">(</span><span class="s">"/sink/path2"</span><span class="p">)))</span>
    <span class="p">.</span><span class="n">with_format</span><span class="p">(</span><span class="n">Csv</span><span class="p">().</span><span class="n">deriveSchema</span><span class="p">())</span>
    <span class="p">.</span><span class="n">with_schema</span><span class="p">(</span><span class="n">schema</span><span class="p">)</span>
    <span class="p">.</span><span class="n">create_temporary_table</span><span class="p">(</span><span class="s">"MySink2"</span><span class="p">)</span>
    
<span class="n">stmt_set</span> <span class="o">=</span> <span class="n">t_env</span><span class="p">.</span><span class="n">create_statement_set</span><span class="p">()</span>

<span class="n">table1</span> <span class="o">=</span> <span class="n">t_env</span><span class="p">.</span><span class="n">from_path</span><span class="p">(</span><span class="s">"MySource1"</span><span class="p">).</span><span class="n">where</span><span class="p">(</span><span class="n">col</span><span class="p">(</span><span class="s">'word'</span><span class="p">).</span><span class="n">like</span><span class="p">(</span><span class="s">'F%'</span><span class="p">))</span>
<span class="n">stmt_set</span><span class="p">.</span><span class="n">add_insert</span><span class="p">(</span><span class="s">"MySink1"</span><span class="p">,</span> <span class="n">table1</span><span class="p">)</span>

<span class="n">table2</span> <span class="o">=</span> <span class="n">table1</span><span class="p">.</span><span class="n">union_all</span><span class="p">(</span><span class="n">t_env</span><span class="p">.</span><span class="n">from_path</span><span class="p">(</span><span class="s">"MySource2"</span><span class="p">))</span>
<span class="n">stmt_set</span><span class="p">.</span><span class="n">add_insert</span><span class="p">(</span><span class="s">"MySink2"</span><span class="p">,</span> <span class="n">table2</span><span class="p">)</span>

<span class="n">explanation</span> <span class="o">=</span> <span class="n">stmt_set</span><span class="p">.</span><span class="n">explain</span><span class="p">()</span>
<span class="k">print</span><span class="p">(</span><span class="n">explanation</span><span class="p">)</span></code></pre></figure>

  </div>
</div>

<p>the result of multiple-sinks plan is</p>
<div>

<figure class="highlight"><pre><code class="language-text" data-lang="text">== Abstract Syntax Tree ==
LogicalLegacySink(name=[MySink1], fields=[count, word])
+- LogicalFilter(condition=[LIKE($1, _UTF-16LE'F%')])
   +- LogicalTableScan(table=[[default_catalog, default_database, MySource1, source: [CsvTableSource(read fields: count, word)]]])

LogicalLegacySink(name=[MySink2], fields=[count, word])
+- LogicalUnion(all=[true])
   :- LogicalFilter(condition=[LIKE($1, _UTF-16LE'F%')])
   :  +- LogicalTableScan(table=[[default_catalog, default_database, MySource1, source: [CsvTableSource(read fields: count, word)]]])
   +- LogicalTableScan(table=[[default_catalog, default_database, MySource2, source: [CsvTableSource(read fields: count, word)]]])

== Optimized Logical Plan ==
Calc(select=[count, word], where=[LIKE(word, _UTF-16LE'F%')], reuse_id=[1])
+- TableSourceScan(table=[[default_catalog, default_database, MySource1, source: [CsvTableSource(read fields: count, word)]]], fields=[count, word])

LegacySink(name=[MySink1], fields=[count, word])
+- Reused(reference_id=[1])

LegacySink(name=[MySink2], fields=[count, word])
+- Union(all=[true], union=[count, word])
   :- Reused(reference_id=[1])
   +- TableSourceScan(table=[[default_catalog, default_database, MySource2, source: [CsvTableSource(read fields: count, word)]]], fields=[count, word])

== Physical Execution Plan ==
Stage 1 : Data Source
	content : collect elements with CollectionInputFormat

	Stage 2 : Operator
		content : CsvTableSource(read fields: count, word)
		ship_strategy : REBALANCE

		Stage 3 : Operator
			content : SourceConversion(table:Buffer(default_catalog, default_database, MySource1, source: [CsvTableSource(read fields: count, word)]), fields:(count, word))
			ship_strategy : FORWARD

			Stage 4 : Operator
				content : Calc(where: (word LIKE _UTF-16LE'F%'), select: (count, word))
				ship_strategy : FORWARD

				Stage 5 : Operator
					content : SinkConversionToRow
					ship_strategy : FORWARD

					Stage 6 : Operator
						content : Map
						ship_strategy : FORWARD

Stage 8 : Data Source
	content : collect elements with CollectionInputFormat

	Stage 9 : Operator
		content : CsvTableSource(read fields: count, word)
		ship_strategy : REBALANCE

		Stage 10 : Operator
			content : SourceConversion(table:Buffer(default_catalog, default_database, MySource2, source: [CsvTableSource(read fields: count, word)]), fields:(count, word))
			ship_strategy : FORWARD

			Stage 12 : Operator
				content : SinkConversionToRow
				ship_strategy : FORWARD

				Stage 13 : Operator
					content : Map
					ship_strategy : FORWARD

					Stage 7 : Data Sink
						content : Sink: CsvTableSink(count, word)
						ship_strategy : FORWARD

						Stage 14 : Data Sink
							content : Sink: CsvTableSink(count, word)
							ship_strategy : FORWARD</code></pre></figure>

</div>

<p><a href="#top" class="top pull-right"><span class="glyphicon glyphicon-chevron-up"></span> Back to top</a></p>




<div class="footer">
  <a href="https://cwiki.apache.org/confluence/display/FLINK/Flink+Translation+Specifications" target="_blank">
    
      Want to contribute translation?
    
  </a>
</div>


        </div>
      </div>
    </div><!-- /.container -->

    <!-- default code tab -->
    <script>var defaultCodeTab = "";</script>

    <!-- jQuery (necessary for Bootstrap's JavaScript plugins) -->
    <script src="//ci.apache.org/projects/flink/flink-docs-release-1.12/page/js/jquery.min.js"></script>
    <!-- Include all compiled plugins (below), or include individual files as needed -->
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.4/js/bootstrap.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/anchor-js/3.1.0/anchor.min.js"></script>
    <script src="//ci.apache.org/projects/flink/flink-docs-release-1.12/page/js/flink.js"></script>

    <!-- Google Analytics -->
    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-52545728-1', 'auto');
      ga('send', 'pageview');
    </script>

    <!-- Disqus -->
    
  </body>
</html>
