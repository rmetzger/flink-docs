<!--
Licensed to the Apache Software Foundation (ASF) under one
or more contributor license agreements.  See the NOTICE file
distributed with this work for additional information
regarding copyright ownership.  The ASF licenses this file
to you under the Apache License, Version 2.0 (the
"License"); you may not use this file except in compliance
with the License.  You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing,
software distributed under the License is distributed on an
"AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
KIND, either express or implied.  See the License for the
specific language governing permissions and limitations
under the License.
-->
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->
    <title>Apache Flink 1.12 Documentation: SQL Client</title>
    <link rel="shortcut icon" href="//ci.apache.org/projects/flink/flink-docs-release-1.12/page/favicon.ico" type="image/x-icon">
    <link rel="icon" href="//ci.apache.org/projects/flink/flink-docs-release-1.12/page/favicon.ico" type="image/x-icon">
    <link rel="canonical" href="//ci.apache.org/projects/flink/flink-docs-stable/dev/table/sqlClient.html">

    <!-- Bootstrap -->
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.4/css/bootstrap.min.css">
    <link rel="stylesheet" href="//ci.apache.org/projects/flink/flink-docs-release-1.12/page/css/flink.css">
    <link rel="stylesheet" href="//ci.apache.org/projects/flink/flink-docs-release-1.12/page/css/syntax.css">
    <link rel="stylesheet" href="//ci.apache.org/projects/flink/flink-docs-release-1.12/page/css/codetabs.css">
    <link rel="stylesheet" href="//ci.apache.org/projects/flink/flink-docs-release-1.12/page/font-awesome/css/font-awesome.min.css">
    
    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
      <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->
  </head>
  <body>
    

    <!-- Main content. -->
    <div class="container">
      
      <div class="row">
        <div class="col-lg-3" id="sidenavcol">
          <div class="sidenav-logo">
  <p><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/"><img class="bottom" alt="Apache Flink" src="//ci.apache.org/projects/flink/flink-docs-release-1.12/page/img/navbar-brand-logo.jpg"></a> v1.12</p>
</div>
<ul id="sidenav">
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/"><i class="fa fa-home title" aria-hidden="true"></i> Home</a></li><hr class="section-break"></hr>
<li><a href="#collapse-2" data-toggle="collapse"><i class="fa fa-rocket title appetizer" aria-hidden="true"></i> Try Flink<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-2"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/try-flink/local_installation.html">Local Installation</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/try-flink/datastream_api.html">Fraud Detection with the DataStream API</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/try-flink/table_api.html">Real Time Reporting with the Table API</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/try-flink/flink-operations-playground.html">Flink Operations Playground</a></li>
</ul></div></li>
<li><a href="#collapse-8" data-toggle="collapse"><i class="fa fa-hand-paper-o title appetizer" aria-hidden="true"></i> Learn Flink<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-8"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/learn-flink/">Overview</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/learn-flink/datastream_api.html">Intro to the DataStream API</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/learn-flink/etl.html">Data Pipelines & ETL</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/learn-flink/streaming_analytics.html">Streaming Analytics</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/learn-flink/event_driven.html">Event-driven Applications</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/learn-flink/fault_tolerance.html">Fault Tolerance</a></li>
</ul></div></li>
<li><a href="#collapse-15" data-toggle="collapse"><i class="fa fa-map-o title appetizer" aria-hidden="true"></i> Concepts<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-15"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/concepts/index.html">Overview</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/concepts/stateful-stream-processing.html">Stateful Stream Processing</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/concepts/timely-stream-processing.html">Timely Stream Processing</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/concepts/flink-architecture.html">Flink Architecture</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/concepts/glossary.html">Glossary</a></li>
</ul></div></li><hr class="section-break"></hr>
<li><a href="#collapse-21" data-toggle="collapse"class="active"><i class="fa fa-code title maindish" aria-hidden="true"></i> Application Development</a><div class="collapse in" id="collapse-21"><ul>
<li><a href="#collapse-22" data-toggle="collapse">DataStream API<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-22"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/datastream_api.html">Overview</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/datastream_execution_mode.html">Execution Mode (Batch/Streaming)</a></li>
<li><a href="#collapse-24" data-toggle="collapse">Event Time<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-24"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/event_time.html">Overview</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/event_timestamps_watermarks.html">Generating Watermarks</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/event_timestamp_extractors.html">Builtin Watermark Generators</a></li>
</ul></div></li>
<li><a href="#collapse-28" data-toggle="collapse">State & Fault Tolerance<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-28"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/stream/state/">Overview</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/stream/state/state.html">Working with State</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/stream/state/broadcast_state.html">The Broadcast State Pattern</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/stream/state/checkpointing.html">Checkpointing</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/stream/state/queryable_state.html">Queryable State</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/stream/state/state_backends.html">State Backends</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/stream/state/schema_evolution.html">State Schema Evolution</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/stream/state/custom_serialization.html">Custom State Serialization</a></li>
</ul></div></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/user_defined_functions.html">User-Defined Functions</a></li>
<li><a href="#collapse-38" data-toggle="collapse">Operators<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-38"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/stream/operators/">Overview</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/stream/operators/windows.html">Windows</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/stream/operators/joining.html">Joining</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/stream/operators/process_function.html">Process Function</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/stream/operators/asyncio.html">Async I/O</a></li>
</ul></div></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/stream/sources.html">Data Sources</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/stream/side_output.html">Side Outputs</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/application_parameters.html">Handling Application Parameters</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/stream/testing.html">Testing</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/stream/experimental.html">Experimental Features</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/scala_api_extensions.html">Scala API Extensions</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/java_lambdas.html">Java Lambda Expressions</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/project-configuration.html">Project Configuration</a></li>
</ul></div></li>
<li><a href="#collapse-53" data-toggle="collapse">DataSet API<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-53"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/batch/">Overview</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/batch/dataset_transformations.html">Transformations</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/batch/iterations.html">Iterations</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/batch/zip_elements_guide.html">Zipping Elements</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/batch/hadoop_compatibility.html">Hadoop Compatibility</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/local_execution.html">Local Execution</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/cluster_execution.html">Cluster Execution</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/batch/examples.html">Batch Examples</a></li>
</ul></div></li>
<li><a href="#collapse-62" data-toggle="collapse"class="active">Table API & SQL</a><div class="collapse in" id="collapse-62"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/">Overview</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/common.html">Concepts & Common API</a></li>
<li><a href="#collapse-64" data-toggle="collapse">Streaming Concepts<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-64"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/streaming/">Overview</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/streaming/dynamic_tables.html">Dynamic Tables</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/streaming/time_attributes.html">Time Attributes</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/streaming/joins.html">Joins in Continuous Queries</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/streaming/temporal_tables.html">Temporal Tables</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/streaming/match_recognize.html">Detecting Patterns</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/streaming/query_configuration.html">Query Configuration</a></li>
</ul></div></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/types.html">Data Types</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/tableApi.html">Table API</a></li>
<li><a href="#collapse-74" data-toggle="collapse">SQL<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-74"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/sql/">Overview</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/sql/queries.html">Queries</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/sql/create.html">CREATE Statements</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/sql/drop.html">DROP Statements</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/sql/alter.html">ALTER Statements</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/sql/insert.html">INSERT Statement</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/sql/hints.html">SQL Hints</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/sql/describe.html">DESCRIBE Statements</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/sql/explain.html">EXPLAIN Statements</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/sql/use.html">USE Statements</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/sql/show.html">SHOW Statements</a></li>
</ul></div></li>
<li><a href="#collapse-86" data-toggle="collapse">Functions<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-86"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/functions/">Overview</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/functions/systemFunctions.html">System (Built-in) Functions</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/functions/udfs.html">User-defined Functions</a></li>
</ul></div></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/modules.html">Modules</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/catalogs.html">Catalogs</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/sqlClient.html" class="active">SQL Client</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/config.html">Configuration</a></li>
<li><a href="#collapse-94" data-toggle="collapse">Performance Tuning<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-94"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/tuning/streaming_aggregation_optimization.html">Streaming Aggregation</a></li>
</ul></div></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/sourceSinks.html">User-defined Sources & Sinks</a></li>
</ul></div></li>
<li><a href="#collapse-99" data-toggle="collapse">Python API<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-99"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/python/">Overview</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/python/installation.html">Installation</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/python/table_api_tutorial.html">Table API Tutorial</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/python/datastream_tutorial.html">DataStream API Tutorial</a></li>
<li><a href="#collapse-103" data-toggle="collapse">Table API User's Guide<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-103"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/python/table-api-users-guide/intro_to_table_api.html">Intro to the Python Table API</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/python/table-api-users-guide/table_environment.html">TableEnvironment</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/python/table-api-users-guide/operations.html">Operations</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/python/table-api-users-guide/python_types.html">Data Types</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/python/table-api-users-guide/built_in_functions.html">System (Built-in) Functions</a></li>
<li><a href="#collapse-109" data-toggle="collapse">User Defined Functions<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-109"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/python/table-api-users-guide/udfs/python_udfs.html">General User-defined Functions</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/python/table-api-users-guide/udfs/vectorized_python_udfs.html">Vectorized User-defined Functions</a></li>
</ul></div></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/python/table-api-users-guide/conversion_of_pandas.html">Conversions between PyFlink Table and Pandas DataFrame</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/python/table-api-users-guide/dependency_management.html">Dependency Management</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/python/table-api-users-guide/sql.html">SQL</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/python/table-api-users-guide/catalogs.html">Catalogs</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/python/table-api-users-guide/metrics.html">Metrics</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/python/table-api-users-guide/python_table_api_connectors.html">Connectors</a></li>
</ul></div></li>
<li><a href="#collapse-120" data-toggle="collapse">DataStream API User's Guide<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-120"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/python/datastream-api-users-guide/data_types.html">Data Types</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/python/datastream-api-users-guide/operators.html">Operators</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/python/datastream-api-users-guide/dependency_management.html">Dependency Management</a></li>
</ul></div></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/python/python_config.html">Configuration</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/python/environment_variables.html">Environment Variables</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/python/faq.html">FAQ</a></li>
</ul></div></li>
<li><a href="#collapse-129" data-toggle="collapse">Data Types & Serialization<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-129"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/types_serialization.html">Overview</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/custom_serializers.html">Custom Serializers</a></li>
</ul></div></li>
<li><a href="#collapse-132" data-toggle="collapse">Managing Execution<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-132"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/execution_configuration.html">Execution Configuration</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/packaging.html">Program Packaging</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/parallel.html">Parallel Execution</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/execution_plans.html">Execution Plans</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/task_failure_recovery.html">Task Failure Recovery</a></li>
</ul></div></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/migration.html">API Migration Guides</a></li>
</ul></div></li>
<li><a href="#collapse-141" data-toggle="collapse"><i class="fa fa-book title maindish" aria-hidden="true"></i> Libraries<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-141"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/libs/cep.html">Event Processing (CEP)</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/libs/state_processor_api.html">State Processor API</a></li>
<li><a href="#collapse-144" data-toggle="collapse">Graphs: Gelly<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-144"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/libs/gelly/">Overview</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/libs/gelly/graph_api.html">Graph API</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/libs/gelly/iterative_graph_processing.html">Iterative Graph Processing</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/libs/gelly/library_methods.html">Library Methods</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/libs/gelly/graph_algorithms.html">Graph Algorithms</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/libs/gelly/graph_generators.html">Graph Generators</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/libs/gelly/bipartite_graph.html">Bipartite Graph</a></li>
</ul></div></li>
</ul></div></li>
<li><a href="#collapse-153" data-toggle="collapse"><i class="fa fa-random title maindish" aria-hidden="true"></i> Connectors<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-153"><ul>
<li><a href="#collapse-154" data-toggle="collapse">DataStream Connectors<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-154"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/connectors/">Overview</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/connectors/guarantees.html">Fault Tolerance Guarantees</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/connectors/kafka.html">Kafka</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/connectors/cassandra.html">Cassandra</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/connectors/kinesis.html">Kinesis</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/connectors/elasticsearch.html">Elasticsearch</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/connectors/file_sink.html">File Sink</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/connectors/streamfile_sink.html">Streaming File Sink</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/connectors/rabbitmq.html">RabbitMQ</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/connectors/nifi.html">NiFi</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/connectors/pubsub.html">Google Cloud PubSub</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/connectors/twitter.html">Twitter</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/connectors/jdbc.html">JDBC</a></li>
</ul></div></li>
<li><a href="#collapse-168" data-toggle="collapse">Table & SQL Connectors<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-168"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/connectors/">Overview</a></li>
<li><a href="#collapse-169" data-toggle="collapse">Formats<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-169"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/connectors/formats/">Overview</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/connectors/formats/csv.html">CSV</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/connectors/formats/json.html">JSON</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/connectors/formats/avro-confluent.html">Confluent Avro</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/connectors/formats/avro.html">Avro</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/connectors/formats/debezium.html">Debezium</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/connectors/formats/canal.html">Canal</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/connectors/formats/maxwell.html">Maxwell</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/connectors/formats/parquet.html">Parquet</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/connectors/formats/orc.html">Orc</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/connectors/formats/raw.html">Raw</a></li>
</ul></div></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/connectors/kafka.html">Kafka</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/connectors/upsert-kafka.html">Upsert Kafka</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/connectors/kinesis.html">Kinesis</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/connectors/jdbc.html">JDBC</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/connectors/elasticsearch.html">Elasticsearch</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/connectors/filesystem.html">FileSystem</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/connectors/hbase.html">HBase</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/connectors/datagen.html">DataGen</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/connectors/print.html">Print</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/connectors/blackhole.html">BlackHole</a></li>
<li><a href="#collapse-191" data-toggle="collapse">Hive<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-191"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/connectors/hive/">Overview</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/connectors/hive/hive_catalog.html">Hive Catalog</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/connectors/hive/hive_dialect.html">Hive Dialect</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/connectors/hive/hive_read_write.html">Hive Read & Write</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/connectors/hive/hive_functions.html">Hive Functions</a></li>
</ul></div></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/connectors/downloads.html">Download</a></li>
</ul></div></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/batch/connectors.html">DataSet Connectors</a></li>
</ul></div></li>
<li><a href="#collapse-201" data-toggle="collapse"><i class="fa fa-sliders title maindish" aria-hidden="true"></i> Deployment<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-201"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/deployment/">Overview</a></li>
<li><a href="#collapse-202" data-toggle="collapse">Resource Providers<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-202"><ul>
<li><a href="#collapse-203" data-toggle="collapse">Standalone<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-203"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/deployment/resource-providers/standalone/">Overview</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/deployment/resource-providers/standalone/local.html">Local Cluster</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/deployment/resource-providers/standalone/docker.html">Docker</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/deployment/resource-providers/standalone/kubernetes.html">Kubernetes</a></li>
</ul></div></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/deployment/resource-providers/native_kubernetes.html">Native Kubernetes</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/deployment/resource-providers/yarn.html">YARN</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/deployment/resource-providers/mesos.html">Mesos</a></li>
</ul></div></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/deployment/config.html">Configuration</a></li>
<li><a href="#collapse-213" data-toggle="collapse">Memory Configuration<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-213"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/deployment/memory/mem_setup.html">Set up Flink's Process Memory</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/deployment/memory/mem_setup_tm.html">Set up TaskManager Memory</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/deployment/memory/mem_setup_jobmanager.html">Set up JobManager Memory</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/deployment/memory/mem_tuning.html">Memory tuning guide</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/deployment/memory/mem_trouble.html">Troubleshooting</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/deployment/memory/mem_migration.html">Migration Guide</a></li>
</ul></div></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/deployment/cli.html">Command-Line Interface</a></li>
<li><a href="#collapse-222" data-toggle="collapse">File Systems<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-222"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/deployment/filesystems/">Overview</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/deployment/filesystems/common.html">Common Configurations</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/deployment/filesystems/s3.html">Amazon S3</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/deployment/filesystems/oss.html">Aliyun OSS</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/deployment/filesystems/azure.html">Azure Blob Storage</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/deployment/filesystems/plugins.html">Plugins</a></li>
</ul></div></li>
<li><a href="#collapse-229" data-toggle="collapse">High Availability (HA)<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-229"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/deployment/ha/">Overview</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/deployment/ha/zookeeper_ha.html">ZooKeeper HA Services</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/deployment/ha/kubernetes_ha.html">Kubernetes HA Services</a></li>
</ul></div></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/deployment/metric_reporters.html">Metric Reporters</a></li>
<li><a href="#collapse-234" data-toggle="collapse">Security<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-234"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/deployment/security/security-ssl.html">SSL Setup</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/deployment/security/security-kerberos.html">Kerberos</a></li>
</ul></div></li>
<li><a href="#collapse-238" data-toggle="collapse">REPLs<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-238"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/deployment/repls/python_shell.html">Python REPL</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/deployment/repls/scala_shell.html">Scala REPL</a></li>
</ul></div></li>
<li><a href="#collapse-242" data-toggle="collapse">Advanced<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-242"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/deployment/advanced/external_resources.html">External Resources</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/deployment/advanced/historyserver.html">History Server</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/deployment/advanced/logging.html">Logging</a></li>
</ul></div></li>
</ul></div></li>
<li><a href="#collapse-248" data-toggle="collapse"><i class="fa fa-cogs title maindish" aria-hidden="true"></i> Operations<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-248"><ul>
<li><a href="#collapse-249" data-toggle="collapse">State & Fault Tolerance<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-249"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/ops/state/checkpoints.html">Checkpoints</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/ops/state/savepoints.html">Savepoints</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/ops/state/state_backends.html">State Backends</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/ops/state/large_state_tuning.html">Tuning Checkpoints and Large State</a></li>
</ul></div></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/ops/metrics.html">Metrics</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/ops/rest_api.html">REST API</a></li>
<li><a href="#collapse-257" data-toggle="collapse">Debugging<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-257"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/ops/debugging/debugging_event_time.html">Debugging Windows & Event Time</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/ops/debugging/debugging_classloading.html">Debugging Classloading</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/ops/debugging/application_profiling.html">Application Profiling & Debugging</a></li>
</ul></div></li>
<li><a href="#collapse-262" data-toggle="collapse">Monitoring<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-262"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/ops/monitoring/checkpoint_monitoring.html">Monitoring Checkpointing</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/ops/monitoring/back_pressure.html">Monitoring Back Pressure</a></li>
</ul></div></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/ops/upgrading.html">Upgrading Applications and Flink Versions</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/ops/production_ready.html">Production Readiness Checklist</a></li>
</ul></div></li><hr class="section-break"></hr>
<li><a href="#collapse-269" data-toggle="collapse"><i class="fa fa-cogs title dessert" aria-hidden="true"></i> Flink Development<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-269"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/flinkDev/ide_setup.html">Importing Flink into an IDE</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/flinkDev/building.html">Building Flink from Source</a></li>
</ul></div></li>
<li><a href="#collapse-273" data-toggle="collapse"><i class="fa fa-book title dessert" aria-hidden="true"></i> Internals<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-273"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/internals/job_scheduling.html">Jobs and Scheduling</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/internals/task_lifecycle.html">Task Lifecycle</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/internals/filesystems.html">File Systems</a></li>
</ul></div></li>
  <li class="divider"></li>
  <li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/api/java"><i class="fa fa-external-link title" aria-hidden="true"></i> Javadocs</a></li>
  <li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/api/scala/index.html#org.apache.flink.api.scala.package"><i class="fa fa-external-link title" aria-hidden="true"></i> Scaladocs</a></li>
  <li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/api/python"><i class="fa fa-external-link title" aria-hidden="true"></i> Pythondocs</a></li>
  <li><a href="http://flink.apache.org"><i class="fa fa-external-link title" aria-hidden="true"></i> Project Page</a></li>
</ul>

<div class="sidenav-search-box">
  <form class="navbar-form" role="search" action="//ci.apache.org/projects/flink/flink-docs-release-1.12/search-results.html">
    <div class="form-group">
      <input type="text" class="form-control" size="16px" name="q" placeholder="Search">
    </div>
    <button type="submit" class="btn btn-default">Go</button>
  </form>
</div>

<div class="sidenav-versions">
  <div class="dropdown">
    <button class="btn btn-default dropdown-toggle" type="button" data-toggle="dropdown">Pick Docs Version<span class="caret"></span></button>
    <ul class="dropdown-menu">
      <li><a href="http://ci.apache.org/projects/flink/flink-docs-release-1.11">v1.11</a></li>
      <li><a href="http://ci.apache.org/projects/flink/flink-docs-release-1.10">v1.10</a></li>
      <li><a href="http://ci.apache.org/projects/flink/flink-docs-release-1.9">v1.9</a></li>
      <li><a href="http://ci.apache.org/projects/flink/flink-docs-release-1.8">v1.8</a></li>
      <li><a href="http://ci.apache.org/projects/flink/flink-docs-release-1.7">v1.7</a></li>
      <li><a href="http://ci.apache.org/projects/flink/flink-docs-release-1.6">v1.6</a></li>
      <li><a href="http://ci.apache.org/projects/flink/flink-docs-release-1.5">v1.5</a></li>
      <li><a href="http://ci.apache.org/projects/flink/flink-docs-release-1.4">v1.4</a></li>
      <li><a href="http://ci.apache.org/projects/flink/flink-docs-release-1.3">v1.3</a></li>
      <li><a href="http://ci.apache.org/projects/flink/flink-docs-release-1.2">v1.2</a></li>
      <li><a href="http://ci.apache.org/projects/flink/flink-docs-release-1.1">v1.1</a></li>
      <li><a href="http://ci.apache.org/projects/flink/flink-docs-release-1.0">v1.0</a></li>
    </ul>
  </div>
</div>

<div class="sidenav-languages"><!-- link to the Chinese home page when current is blog page -->
    <a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/table/sqlClient.html">
      <button type="submit" class="btn btn-default">中文版</button>
    </a>
</div>

        </div>
        <div class="col-lg-9 content" id="contentcol">

          

<ol class="breadcrumb">
  
    <li><i class="fa fa-code title maindish" aria-hidden="true"></i> Application Development</li>
  
    <li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/">Table API & SQL</a></li>
  
    <li class="active">SQL Client</li>
</ol>

<h1>SQL Client</h1>




<p>Flink’s Table &amp; SQL API makes it possible to work with queries written in the SQL language, but these queries need to be embedded within a table program that is written in either Java or Scala. Moreover, these programs need to be packaged with a build tool before being submitted to a cluster. This more or less limits the usage of Flink to Java/Scala programmers.</p>

<p>The <em>SQL Client</em> aims to provide an easy way of writing, debugging, and submitting table programs to a Flink cluster without a single line of Java or Scala code. The <em>SQL Client CLI</em> allows for retrieving and visualizing real-time results from the running distributed application on the command line.</p>

<p><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/fig/sql_client_demo.gif"><img class="offset" src="//ci.apache.org/projects/flink/flink-docs-release-1.12/fig/sql_client_demo.gif" alt="Animated demo of the Flink SQL Client CLI running table programs on a cluster" width="80%" /></a></p>

<ul id="markdown-toc">
  <li><a href="#getting-started" id="markdown-toc-getting-started">Getting Started</a>    <ul>
      <li><a href="#starting-the-sql-client-cli" id="markdown-toc-starting-the-sql-client-cli">Starting the SQL Client CLI</a></li>
      <li><a href="#running-sql-queries" id="markdown-toc-running-sql-queries">Running SQL Queries</a></li>
    </ul>
  </li>
  <li><a href="#configuration" id="markdown-toc-configuration">Configuration</a>    <ul>
      <li><a href="#environment-files" id="markdown-toc-environment-files">Environment Files</a></li>
      <li><a href="#dependencies" id="markdown-toc-dependencies">Dependencies</a></li>
      <li><a href="#user-defined-functions" id="markdown-toc-user-defined-functions">User-defined Functions</a></li>
    </ul>
  </li>
  <li><a href="#catalogs" id="markdown-toc-catalogs">Catalogs</a></li>
  <li><a href="#detached-sql-queries" id="markdown-toc-detached-sql-queries">Detached SQL Queries</a></li>
  <li><a href="#sql-views" id="markdown-toc-sql-views">SQL Views</a></li>
  <li><a href="#temporal-tables" id="markdown-toc-temporal-tables">Temporal Tables</a></li>
  <li><a href="#limitations--future" id="markdown-toc-limitations--future">Limitations &amp; Future</a></li>
</ul>

<h2 id="getting-started">Getting Started</h2>

<p>This section describes how to setup and run your first Flink SQL program from the command-line.</p>

<p>The SQL Client is bundled in the regular Flink distribution and thus runnable out-of-the-box. It requires only a running Flink cluster where table programs can be executed. For more information about setting up a Flink cluster see the <a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/deployment/resource-providers/standalone/">Cluster &amp; Deployment</a> part. If you simply want to try out the SQL Client, you can also start a local cluster with one worker using the following command:</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">./bin/start-cluster.sh</code></pre></figure>

<h3 id="starting-the-sql-client-cli">Starting the SQL Client CLI</h3>

<p>The SQL Client scripts are also located in the binary directory of Flink. <a href="sqlClient.html#limitations--future">In the future</a>, a user will have two possibilities of starting the SQL Client CLI either by starting an embedded standalone process or by connecting to a remote SQL Client Gateway. At the moment only the <code class="highlighter-rouge">embedded</code> mode is supported. You can start the CLI by calling:</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">./bin/sql-client.sh embedded</code></pre></figure>

<p>By default, the SQL Client will read its configuration from the environment file located in <code class="highlighter-rouge">./conf/sql-client-defaults.yaml</code>. See the <a href="sqlClient.html#environment-files">configuration part</a> for more information about the structure of environment files.</p>

<h3 id="running-sql-queries">Running SQL Queries</h3>

<p>Once the CLI has been started, you can use the <code class="highlighter-rouge">HELP</code> command to list all available SQL statements. For validating your setup and cluster connection, you can enter your first SQL query and press the <code class="highlighter-rouge">Enter</code> key to execute it:</p>

<figure class="highlight"><pre><code class="language-sql" data-lang="sql"><span class="k">SELECT</span> <span class="s1">'Hello World'</span><span class="p">;</span></code></pre></figure>

<p>This query requires no table source and produces a single row result. The CLI will retrieve results from the cluster and visualize them. You can close the result view by pressing the <code class="highlighter-rouge">Q</code> key.</p>

<p>The CLI supports <strong>three modes</strong> for maintaining and visualizing results.</p>

<p>The <strong>table mode</strong> materializes results in memory and visualizes them in a regular, paginated table representation. It can be enabled by executing the following command in the CLI:</p>

<figure class="highlight"><pre><code class="language-text" data-lang="text">SET execution.result-mode=table;</code></pre></figure>

<p>The <strong>changelog mode</strong> does not materialize results and visualizes the result stream that is produced by a <a href="streaming/dynamic_tables.html#continuous-queries">continuous query</a> consisting of insertions (<code class="highlighter-rouge">+</code>) and retractions (<code class="highlighter-rouge">-</code>).</p>

<figure class="highlight"><pre><code class="language-text" data-lang="text">SET execution.result-mode=changelog;</code></pre></figure>

<p>The <strong>tableau mode</strong> is more like a traditional way which will display the results in the screen directly with a tableau format.
The displaying content will be influenced by the query execution type(<code class="highlighter-rouge">execution.type</code>).</p>

<figure class="highlight"><pre><code class="language-text" data-lang="text">SET execution.result-mode=tableau;</code></pre></figure>

<p>Note that when you use this mode with streaming query, the result will be continuously printed on the console. If the input data of 
this query is bounded, the job will terminate after Flink processed all input data, and the printing will also be stopped automatically.
Otherwise, if you want to terminate a running query, just type <code class="highlighter-rouge">CTRL-C</code> in this case, the job and the printing will be stopped.</p>

<p>You can use the following query to see all the result modes in action:</p>

<figure class="highlight"><pre><code class="language-sql" data-lang="sql"><span class="k">SELECT</span> <span class="n">name</span><span class="p">,</span> <span class="k">COUNT</span><span class="p">(</span><span class="o">*</span><span class="p">)</span> <span class="k">AS</span> <span class="n">cnt</span> <span class="k">FROM</span> <span class="p">(</span><span class="k">VALUES</span> <span class="p">(</span><span class="s1">'Bob'</span><span class="p">),</span> <span class="p">(</span><span class="s1">'Alice'</span><span class="p">),</span> <span class="p">(</span><span class="s1">'Greg'</span><span class="p">),</span> <span class="p">(</span><span class="s1">'Bob'</span><span class="p">))</span> <span class="k">AS</span> <span class="n">NameTable</span><span class="p">(</span><span class="n">name</span><span class="p">)</span> <span class="k">GROUP</span> <span class="k">BY</span> <span class="n">name</span><span class="p">;</span></code></pre></figure>

<p>This query performs a bounded word count example.</p>

<p>In <em>changelog mode</em>, the visualized changelog should be similar to:</p>

<figure class="highlight"><pre><code class="language-text" data-lang="text">+ Bob, 1
+ Alice, 1
+ Greg, 1
- Bob, 1
+ Bob, 2</code></pre></figure>

<p>In <em>table mode</em>, the visualized result table is continuously updated until the table program ends with:</p>

<figure class="highlight"><pre><code class="language-text" data-lang="text">Bob, 2
Alice, 1
Greg, 1</code></pre></figure>

<p>In <em>tableau mode</em>, if you ran the query in streaming mode, the displayed result would be:</p>

<figure class="highlight"><pre><code class="language-text" data-lang="text">+-----+----------------------+----------------------+
| +/- |                 name |                  cnt |
+-----+----------------------+----------------------+
|   + |                  Bob |                    1 |
|   + |                Alice |                    1 |
|   + |                 Greg |                    1 |
|   - |                  Bob |                    1 |
|   + |                  Bob |                    2 |
+-----+----------------------+----------------------+
Received a total of 5 rows</code></pre></figure>

<p>And if you ran the query in batch mode, the displayed result would be:</p>

<figure class="highlight"><pre><code class="language-text" data-lang="text">+-------+-----+
|  name | cnt |
+-------+-----+
| Alice |   1 |
|   Bob |   2 |
|  Greg |   1 |
+-------+-----+
3 rows in set</code></pre></figure>

<p>All these result modes can be useful during the prototyping of SQL queries. In all these modes, results are stored in the Java heap memory of the SQL Client. In order to keep the CLI interface responsive, the changelog mode only shows the latest 1000 changes. The table mode allows for navigating through bigger results that are only limited by the available main memory and the configured <a href="sqlClient.html#configuration">maximum number of rows</a> (<code class="highlighter-rouge">max-table-result-rows</code>).</p>

<p><span class="label label-danger">Attention</span> Queries that are executed in a batch environment, can only be retrieved using the <code class="highlighter-rouge">table</code> or <code class="highlighter-rouge">tableau</code> result mode.</p>

<p>After a query is defined, it can be submitted to the cluster as a long-running, detached Flink job. For this, a target system that stores the results needs to be specified using the <a href="sqlClient.html#detached-sql-queries">INSERT INTO statement</a>. The <a href="sqlClient.html#configuration">configuration section</a> explains how to declare table sources for reading data, how to declare table sinks for writing data, and how to configure other table program properties.</p>

<p><a href="#top" class="top pull-right"><span class="glyphicon glyphicon-chevron-up"></span> Back to top</a></p>

<h2 id="configuration">Configuration</h2>

<p>The SQL Client can be started with the following optional CLI commands. They are discussed in detail in the subsequent paragraphs.</p>

<figure class="highlight"><pre><code class="language-text" data-lang="text">./bin/sql-client.sh embedded --help

Mode "embedded" submits Flink jobs from the local machine.

  Syntax: embedded [OPTIONS]
  "embedded" mode options:
     -d,--defaults &lt;environment file&gt;      The environment properties with which
                                           every new session is initialized.
                                           Properties might be overwritten by
                                           session properties.
     -e,--environment &lt;environment file&gt;   The environment properties to be
                                           imported into the session. It might
                                           overwrite default environment
                                           properties.
     -h,--help                             Show the help message with
                                           descriptions of all options.
     -hist,--history &lt;History file path&gt;   The file which you want to save the
                                           command history into. If not
                                           specified, we will auto-generate one
                                           under your user's home directory.
     -j,--jar &lt;JAR file&gt;                   A JAR file to be imported into the
                                           session. The file might contain
                                           user-defined classes needed for the
                                           execution of statements such as
                                           functions, table sources, or sinks.
                                           Can be used multiple times.
     -l,--library &lt;JAR directory&gt;          A JAR file directory with which every
                                           new session is initialized. The files
                                           might contain user-defined classes
                                           needed for the execution of
                                           statements such as functions, table
                                           sources, or sinks. Can be used
                                           multiple times.
     -pyarch,--pyArchives &lt;arg&gt;            Add python archive files for job. The
                                           archive files will be extracted to
                                           the working directory of python UDF
                                           worker. Currently only zip-format is
                                           supported. For each archive file, a
                                           target directory be specified. If the
                                           target directory name is specified,
                                           the archive file will be extracted to
                                           a name can directory with the
                                           specified name. Otherwise, the
                                           archive file will be extracted to a
                                           directory with the same name of the
                                           archive file. The files uploaded via
                                           this option are accessible via
                                           relative path. '#' could be used as
                                           the separator of the archive file
                                           path and the target directory name.
                                           Comma (',') could be used as the
                                           separator to specify multiple archive
                                           files. This option can be used to
                                           upload the virtual environment, the
                                           data files used in Python UDF (e.g.:
                                           --pyArchives
                                           file:///tmp/py37.zip,file:///tmp/data
                                           .zip#data --pyExecutable
                                           py37.zip/py37/bin/python). The data
                                           files could be accessed in Python
                                           UDF, e.g.: f = open('data/data.txt',
                                           'r').
     -pyexec,--pyExecutable &lt;arg&gt;          Specify the path of the python
                                           interpreter used to execute the
                                           python UDF worker (e.g.:
                                           --pyExecutable
                                           /usr/local/bin/python3). The python
                                           UDF worker depends on Python 3.5+,
                                           Apache Beam (version == 2.23.0), Pip
                                           (version &gt;= 7.1.0) and SetupTools
                                           (version &gt;= 37.0.0). Please ensure
                                           that the specified environment meets
                                           the above requirements.
     -pyfs,--pyFiles &lt;pythonFiles&gt;         Attach custom python files for job.
                                           These files will be added to the
                                           PYTHONPATH of both the local client
                                           and the remote python UDF worker. The
                                           standard python resource file
                                           suffixes such as .py/.egg/.zip or
                                           directory are all supported. Comma
                                           (',') could be used as the separator
                                           to specify multiple files (e.g.:
                                           --pyFiles
                                           file:///tmp/myresource.zip,hdfs:///$n
                                           amenode_address/myresource2.zip).
     -pyreq,--pyRequirements &lt;arg&gt;         Specify a requirements.txt file which
                                           defines the third-party dependencies.
                                           These dependencies will be installed
                                           and added to the PYTHONPATH of the
                                           python UDF worker. A directory which
                                           contains the installation packages of
                                           these dependencies could be specified
                                           optionally. Use '#' as the separator
                                           if the optional parameter exists
                                           (e.g.: --pyRequirements
                                           file:///tmp/requirements.txt#file:///
                                           tmp/cached_dir).
     -s,--session &lt;session identifier&gt;     The identifier for a session.
                                           'default' is the default identifier.
     -u,--update &lt;SQL update statement&gt;    Experimental (for testing only!):
                                           Instructs the SQL Client to
                                           immediately execute the given update
                                           statement after starting up. The
                                           process is shut down after the
                                           statement has been submitted to the
                                           cluster and returns an appropriate
                                           return code. Currently, this feature
                                           is only supported for INSERT INTO
                                           statements that declare the target
                                           sink table.</code></pre></figure>

<p><a href="#top" class="top pull-right"><span class="glyphicon glyphicon-chevron-up"></span> Back to top</a></p>

<h3 id="environment-files">Environment Files</h3>

<p>A SQL query needs a configuration environment in which it is executed. The so-called <em>environment files</em> define available catalogs, table sources and sinks, user-defined functions, and other properties required for execution and deployment.</p>

<p>Every environment file is a regular <a href="http://yaml.org/">YAML file</a>. An example of such a file is presented below.</p>

<figure class="highlight"><pre><code class="language-yaml" data-lang="yaml"><span class="c1"># Define tables here such as sources, sinks, views, or temporal tables.</span>

<span class="na">tables</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">MyTableSource</span>
    <span class="na">type</span><span class="pi">:</span> <span class="s">source-table</span>
    <span class="na">update-mode</span><span class="pi">:</span> <span class="s">append</span>
    <span class="na">connector</span><span class="pi">:</span>
      <span class="na">type</span><span class="pi">:</span> <span class="s">filesystem</span>
      <span class="na">path</span><span class="pi">:</span> <span class="s2">"</span><span class="s">/path/to/something.csv"</span>
    <span class="na">format</span><span class="pi">:</span>
      <span class="na">type</span><span class="pi">:</span> <span class="s">csv</span>
      <span class="na">fields</span><span class="pi">:</span>
        <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">MyField1</span>
          <span class="na">data-type</span><span class="pi">:</span> <span class="s">INT</span>
        <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">MyField2</span>
          <span class="na">data-type</span><span class="pi">:</span> <span class="s">VARCHAR</span>
      <span class="na">line-delimiter</span><span class="pi">:</span> <span class="s2">"</span><span class="se">\n</span><span class="s">"</span>
      <span class="na">comment-prefix</span><span class="pi">:</span> <span class="s2">"</span><span class="s">#"</span>
    <span class="na">schema</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">MyField1</span>
        <span class="na">data-type</span><span class="pi">:</span> <span class="s">INT</span>
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">MyField2</span>
        <span class="na">data-type</span><span class="pi">:</span> <span class="s">VARCHAR</span>
  <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">MyCustomView</span>
    <span class="na">type</span><span class="pi">:</span> <span class="s">view</span>
    <span class="na">query</span><span class="pi">:</span> <span class="s2">"</span><span class="s">SELECT</span><span class="nv"> </span><span class="s">MyField2</span><span class="nv"> </span><span class="s">FROM</span><span class="nv"> </span><span class="s">MyTableSource"</span>

<span class="c1"># Define user-defined functions here.</span>

<span class="na">functions</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">myUDF</span>
    <span class="na">from</span><span class="pi">:</span> <span class="s">class</span>
    <span class="na">class</span><span class="pi">:</span> <span class="s">foo.bar.AggregateUDF</span>
    <span class="na">constructor</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="m">7.6</span>
      <span class="pi">-</span> <span class="no">false</span>

<span class="c1"># Define available catalogs</span>

<span class="na">catalogs</span><span class="pi">:</span>
   <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">catalog_1</span>
     <span class="na">type</span><span class="pi">:</span> <span class="s">hive</span>
     <span class="na">property-version</span><span class="pi">:</span> <span class="m">1</span>
     <span class="na">hive-conf-dir</span><span class="pi">:</span> <span class="s">...</span>
   <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">catalog_2</span>
     <span class="na">type</span><span class="pi">:</span> <span class="s">hive</span>
     <span class="na">property-version</span><span class="pi">:</span> <span class="m">1</span>
     <span class="na">default-database</span><span class="pi">:</span> <span class="s">mydb2</span>
     <span class="na">hive-conf-dir</span><span class="pi">:</span> <span class="s">...</span>

<span class="c1"># Properties that change the fundamental execution behavior of a table program.</span>

<span class="na">execution</span><span class="pi">:</span>
  <span class="na">planner</span><span class="pi">:</span> <span class="s">blink</span>                    <span class="c1"># optional: either 'blink' (default) or 'old'</span>
  <span class="na">type</span><span class="pi">:</span> <span class="s">streaming</span>                   <span class="c1"># required: execution mode either 'batch' or 'streaming'</span>
  <span class="na">result-mode</span><span class="pi">:</span> <span class="s">table</span>                <span class="c1"># required: either 'table' or 'changelog'</span>
  <span class="na">max-table-result-rows</span><span class="pi">:</span> <span class="m">1000000</span>    <span class="c1"># optional: maximum number of maintained rows in</span>
                                    <span class="c1">#   'table' mode (1000000 by default, smaller 1 means unlimited)</span>
  <span class="na">time-characteristic</span><span class="pi">:</span> <span class="s">event-time</span>   <span class="c1"># optional: 'processing-time' or 'event-time' (default)</span>
  <span class="na">parallelism</span><span class="pi">:</span> <span class="m">1</span>                    <span class="c1"># optional: Flink's parallelism (1 by default)</span>
  <span class="na">periodic-watermarks-interval</span><span class="pi">:</span> <span class="m">200</span> <span class="c1"># optional: interval for periodic watermarks (200 ms by default)</span>
  <span class="na">max-parallelism</span><span class="pi">:</span> <span class="m">16</span>               <span class="c1"># optional: Flink's maximum parallelism (128 by default)</span>
  <span class="na">min-idle-state-retention</span><span class="pi">:</span> <span class="m">0</span>       <span class="c1"># optional: table program's minimum idle state time</span>
  <span class="na">max-idle-state-retention</span><span class="pi">:</span> <span class="m">0</span>       <span class="c1"># optional: table program's maximum idle state time</span>
  <span class="na">current-catalog</span><span class="pi">:</span> <span class="s">catalog_1</span>        <span class="c1"># optional: name of the current catalog of the session ('default_catalog' by default)</span>
  <span class="na">current-database</span><span class="pi">:</span> <span class="s">mydb1</span>           <span class="c1"># optional: name of the current database of the current catalog</span>
                                    <span class="c1">#   (default database of the current catalog by default)</span>
  <span class="na">restart-strategy</span><span class="pi">:</span>                 <span class="c1"># optional: restart strategy</span>
    <span class="na">type</span><span class="pi">:</span> <span class="s">fallback</span>                  <span class="c1">#   "fallback" to global restart strategy by default</span>

<span class="c1"># Configuration options for adjusting and tuning table programs.</span>

<span class="c1"># A full list of options and their default values can be found</span>
<span class="c1"># on the dedicated "Configuration" page.</span>
<span class="na">configuration</span><span class="pi">:</span>
  <span class="s">table.optimizer.join-reorder-enabled</span><span class="pi">:</span> <span class="no">true</span>
  <span class="s">table.exec.spill-compression.enabled</span><span class="pi">:</span> <span class="no">true</span>
  <span class="s">table.exec.spill-compression.block-size</span><span class="pi">:</span> <span class="s">128kb</span>

<span class="c1"># Properties that describe the cluster to which table programs are submitted to.</span>

<span class="na">deployment</span><span class="pi">:</span>
  <span class="na">response-timeout</span><span class="pi">:</span> <span class="s">5000</span></code></pre></figure>

<p>This configuration:</p>

<ul>
  <li>defines an environment with a table source <code class="highlighter-rouge">MyTableSource</code> that reads from a CSV file,</li>
  <li>defines a view <code class="highlighter-rouge">MyCustomView</code> that declares a virtual table using a SQL query,</li>
  <li>defines a user-defined function <code class="highlighter-rouge">myUDF</code> that can be instantiated using the class name and two constructor parameters,</li>
  <li>connects to two Hive catalogs and uses <code class="highlighter-rouge">catalog_1</code> as the current catalog with <code class="highlighter-rouge">mydb1</code> as the current database of the catalog,</li>
  <li>uses the blink planner in streaming mode for running statements with event-time characteristic and a parallelism of 1,</li>
  <li>runs exploratory queries in the <code class="highlighter-rouge">table</code> result mode,</li>
  <li>and makes some planner adjustments around join reordering and spilling via configuration options.</li>
</ul>

<p>Depending on the use case, a configuration can be split into multiple files. Therefore, environment files can be created for general purposes (<em>defaults environment file</em> using <code class="highlighter-rouge">--defaults</code>) as well as on a per-session basis (<em>session environment file</em> using <code class="highlighter-rouge">--environment</code>). Every CLI session is initialized with the default properties followed by the session properties. For example, the defaults environment file could specify all table sources that should be available for querying in every session whereas the session environment file only declares a specific state retention time and parallelism. Both default and session environment files can be passed when starting the CLI application. If no default environment file has been specified, the SQL Client searches for <code class="highlighter-rouge">./conf/sql-client-defaults.yaml</code> in Flink’s configuration directory.</p>

<p><span class="label label-danger">Attention</span> Properties that have been set within a CLI session (e.g. using the <code class="highlighter-rouge">SET</code> command) have highest precedence:</p>

<figure class="highlight"><pre><code class="language-text" data-lang="text">CLI commands &gt; session environment file &gt; defaults environment file</code></pre></figure>

<h4 id="restart-strategies">Restart Strategies</h4>

<p>Restart strategies control how Flink jobs are restarted in case of a failure. Similar to <a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/task_failure_recovery.html#restart-strategies">global restart strategies</a> for a Flink cluster, a more fine-grained restart configuration can be declared in an environment file.</p>

<p>The following strategies are supported:</p>

<figure class="highlight"><pre><code class="language-yaml" data-lang="yaml"><span class="na">execution</span><span class="pi">:</span>
  <span class="c1"># falls back to the global strategy defined in flink-conf.yaml</span>
  <span class="na">restart-strategy</span><span class="pi">:</span>
    <span class="na">type</span><span class="pi">:</span> <span class="s">fallback</span>

  <span class="c1"># job fails directly and no restart is attempted</span>
  <span class="na">restart-strategy</span><span class="pi">:</span>
    <span class="na">type</span><span class="pi">:</span> <span class="s">none</span>

  <span class="c1"># attempts a given number of times to restart the job</span>
  <span class="na">restart-strategy</span><span class="pi">:</span>
    <span class="na">type</span><span class="pi">:</span> <span class="s">fixed-delay</span>
    <span class="na">attempts</span><span class="pi">:</span> <span class="m">3</span>      <span class="c1"># retries before job is declared as failed (default: Integer.MAX_VALUE)</span>
    <span class="na">delay</span><span class="pi">:</span> <span class="m">10000</span>     <span class="c1"># delay in ms between retries (default: 10 s)</span>

  <span class="c1"># attempts as long as the maximum number of failures per time interval is not exceeded</span>
  <span class="na">restart-strategy</span><span class="pi">:</span>
    <span class="na">type</span><span class="pi">:</span> <span class="s">failure-rate</span>
    <span class="na">max-failures-per-interval</span><span class="pi">:</span> <span class="m">1</span>   <span class="c1"># retries in interval until failing (default: 1)</span>
    <span class="na">failure-rate-interval</span><span class="pi">:</span> <span class="m">60000</span>   <span class="c1"># measuring interval in ms for failure rate</span>
    <span class="na">delay</span><span class="pi">:</span> <span class="m">10000</span>                   <span class="c1"># delay in ms between retries (default: 10 s)</span></code></pre></figure>

<p><a href="#top" class="top pull-right"><span class="glyphicon glyphicon-chevron-up"></span> Back to top</a></p>

<h3 id="dependencies">Dependencies</h3>

<p>The SQL Client does not require to setup a Java project using Maven or SBT. Instead, you can pass the dependencies as regular JAR files that get submitted to the cluster. You can either specify each JAR file separately (using <code class="highlighter-rouge">--jar</code>) or define entire library directories (using <code class="highlighter-rouge">--library</code>). For connectors to external systems (such as Apache Kafka) and corresponding data formats (such as JSON), Flink provides <strong>ready-to-use JAR bundles</strong>. These JAR files can be downloaded for each release from the Maven central repository.</p>

<p>The full list of offered SQL JARs and documentation about how to use them can be found on the <a href="connect.html">connection to external systems page</a>.</p>

<p>The following example shows an environment file that defines a table source reading JSON data from Apache Kafka.</p>

<figure class="highlight"><pre><code class="language-yaml" data-lang="yaml"><span class="na">tables</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">TaxiRides</span>
    <span class="na">type</span><span class="pi">:</span> <span class="s">source-table</span>
    <span class="na">update-mode</span><span class="pi">:</span> <span class="s">append</span>
    <span class="na">connector</span><span class="pi">:</span>
      <span class="na">property-version</span><span class="pi">:</span> <span class="m">1</span>
      <span class="na">type</span><span class="pi">:</span> <span class="s">kafka</span>
      <span class="na">version</span><span class="pi">:</span> <span class="s2">"</span><span class="s">0.11"</span>
      <span class="na">topic</span><span class="pi">:</span> <span class="s">TaxiRides</span>
      <span class="na">startup-mode</span><span class="pi">:</span> <span class="s">earliest-offset</span>
      <span class="na">properties</span><span class="pi">:</span>
        <span class="s">bootstrap.servers</span><span class="pi">:</span> <span class="s">localhost:9092</span>
        <span class="s">group.id</span><span class="pi">:</span> <span class="s">testGroup</span>
    <span class="na">format</span><span class="pi">:</span>
      <span class="na">property-version</span><span class="pi">:</span> <span class="m">1</span>
      <span class="na">type</span><span class="pi">:</span> <span class="s">json</span>
      <span class="na">schema</span><span class="pi">:</span> <span class="s2">"</span><span class="s">ROW&lt;rideId</span><span class="nv"> </span><span class="s">LONG,</span><span class="nv"> </span><span class="s">lon</span><span class="nv"> </span><span class="s">FLOAT,</span><span class="nv"> </span><span class="s">lat</span><span class="nv"> </span><span class="s">FLOAT,</span><span class="nv"> </span><span class="s">rideTime</span><span class="nv"> </span><span class="s">TIMESTAMP&gt;"</span>
    <span class="na">schema</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">rideId</span>
        <span class="na">data-type</span><span class="pi">:</span> <span class="s">BIGINT</span>
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">lon</span>
        <span class="na">data-type</span><span class="pi">:</span> <span class="s">FLOAT</span>
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">lat</span>
        <span class="na">data-type</span><span class="pi">:</span> <span class="s">FLOAT</span>
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">rowTime</span>
        <span class="na">data-type</span><span class="pi">:</span> <span class="s">TIMESTAMP(3)</span>
        <span class="na">rowtime</span><span class="pi">:</span>
          <span class="na">timestamps</span><span class="pi">:</span>
            <span class="na">type</span><span class="pi">:</span> <span class="s2">"</span><span class="s">from-field"</span>
            <span class="na">from</span><span class="pi">:</span> <span class="s2">"</span><span class="s">rideTime"</span>
          <span class="na">watermarks</span><span class="pi">:</span>
            <span class="na">type</span><span class="pi">:</span> <span class="s2">"</span><span class="s">periodic-bounded"</span>
            <span class="na">delay</span><span class="pi">:</span> <span class="s2">"</span><span class="s">60000"</span>
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">procTime</span>
        <span class="na">data-type</span><span class="pi">:</span> <span class="s">TIMESTAMP(3)</span>
        <span class="na">proctime</span><span class="pi">:</span> <span class="no">true</span></code></pre></figure>

<p>The resulting schema of the <code class="highlighter-rouge">TaxiRide</code> table contains most of the fields of the JSON schema. Furthermore, it adds a rowtime attribute <code class="highlighter-rouge">rowTime</code> and processing-time attribute <code class="highlighter-rouge">procTime</code>.</p>

<p>Both <code class="highlighter-rouge">connector</code> and <code class="highlighter-rouge">format</code> allow to define a property version (which is currently version <code class="highlighter-rouge">1</code>) for future backwards compatibility.</p>

<p><a href="#top" class="top pull-right"><span class="glyphicon glyphicon-chevron-up"></span> Back to top</a></p>

<h3 id="user-defined-functions">User-defined Functions</h3>

<p>The SQL Client allows users to create custom, user-defined functions to be used in SQL queries. Currently, these functions are restricted to be defined programmatically in Java/Scala classes or Python files.</p>

<p>In order to provide a Java/Scala user-defined function, you need to first implement and compile a function class that extends <code class="highlighter-rouge">ScalarFunction</code>, <code class="highlighter-rouge">AggregateFunction</code> or <code class="highlighter-rouge">TableFunction</code> (see <a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/functions/udfs.html">User-defined Functions</a>). One or more functions can then be packaged into a dependency JAR for the SQL Client.</p>

<p>In order to provide a Python user-defined function, you need to write a Python function and decorate it with the <code class="highlighter-rouge">pyflink.table.udf.udf</code> or <code class="highlighter-rouge">pyflink.table.udf.udtf</code> decorator (see <a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/python/table-api-users-guide/udfs/python_udfs.html">Python UDFs</a>). One or more functions can then be placed into a Python file. The Python file and related dependencies need to be specified via the configuration (see <a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/python/python_config.html">Python Configuration</a>) in environment file or the command line options (see <a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/deployment/cli.html#usage">Command Line Usage</a>).</p>

<p>All functions must be declared in an environment file before being called. For each item in the list of <code class="highlighter-rouge">functions</code>, one must specify</p>

<ul>
  <li>a <code class="highlighter-rouge">name</code> under which the function is registered,</li>
  <li>the source of the function using <code class="highlighter-rouge">from</code> (restricted to be <code class="highlighter-rouge">class</code> (Java/Scala UDF) or <code class="highlighter-rouge">python</code> (Python UDF) for now),</li>
</ul>

<p>The Java/Scala UDF must specify:</p>

<ul>
  <li>the <code class="highlighter-rouge">class</code> which indicates the fully qualified class name of the function and an optional list of <code class="highlighter-rouge">constructor</code> parameters for instantiation.</li>
</ul>

<p>The Python UDF must specify:</p>

<ul>
  <li>the <code class="highlighter-rouge">fully-qualified-name</code> which indicates the fully qualified name, i.e the “[module name].[object name]” of the function.</li>
</ul>

<figure class="highlight"><pre><code class="language-yaml" data-lang="yaml"><span class="na">functions</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">java_udf</span>               <span class="c1"># required: name of the function</span>
    <span class="na">from</span><span class="pi">:</span> <span class="s">class</span>                  <span class="c1"># required: source of the function</span>
    <span class="na">class</span><span class="pi">:</span> <span class="s">...</span>                   <span class="c1"># required: fully qualified class name of the function</span>
    <span class="na">constructor</span><span class="pi">:</span>                 <span class="c1"># optional: constructor parameters of the function class</span>
      <span class="pi">-</span> <span class="s">...</span>                      <span class="c1"># optional: a literal parameter with implicit type</span>
      <span class="pi">-</span> <span class="na">class</span><span class="pi">:</span> <span class="s">...</span>               <span class="c1"># optional: full class name of the parameter</span>
        <span class="na">constructor</span><span class="pi">:</span>             <span class="c1"># optional: constructor parameters of the parameter's class</span>
          <span class="pi">-</span> <span class="na">type</span><span class="pi">:</span> <span class="s">...</span>            <span class="c1"># optional: type of the literal parameter</span>
            <span class="na">value</span><span class="pi">:</span> <span class="s">...</span>           <span class="c1"># optional: value of the literal parameter</span>
  <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">python_udf</span>             <span class="c1"># required: name of the function</span>
    <span class="na">from</span><span class="pi">:</span> <span class="s">python</span>                 <span class="c1"># required: source of the function </span>
    <span class="na">fully-qualified-name</span><span class="pi">:</span> <span class="s">...</span>    <span class="c1"># required: fully qualified class name of the function      </span></code></pre></figure>

<p>For Java/Scala UDF, make sure that the order and types of the specified parameters strictly match one of the constructors of your function class.</p>

<h4 id="constructor-parameters">Constructor Parameters</h4>

<p>Depending on the user-defined function, it might be necessary to parameterize the implementation before using it in SQL statements.</p>

<p>As shown in the example before, when declaring a user-defined function, a class can be configured using constructor parameters in one of the following three ways:</p>

<p><strong>A literal value with implicit type:</strong> The SQL Client will automatically derive the type according to the literal value itself. Currently, only values of <code class="highlighter-rouge">BOOLEAN</code>, <code class="highlighter-rouge">INT</code>, <code class="highlighter-rouge">DOUBLE</code> and <code class="highlighter-rouge">VARCHAR</code> are supported here.
If the automatic derivation does not work as expected (e.g., you need a VARCHAR <code class="highlighter-rouge">false</code>), use explicit types instead.</p>

<figure class="highlight"><pre><code class="language-yaml" data-lang="yaml"><span class="pi">-</span> <span class="no">true</span>         <span class="c1"># -&gt; BOOLEAN (case sensitive)</span>
<span class="pi">-</span> <span class="m">42</span>           <span class="c1"># -&gt; INT</span>
<span class="pi">-</span> <span class="m">1234.222</span>     <span class="c1"># -&gt; DOUBLE</span>
<span class="pi">-</span> <span class="s">foo</span>          <span class="c1"># -&gt; VARCHAR</span></code></pre></figure>

<p><strong>A literal value with explicit type:</strong> Explicitly declare the parameter with <code class="highlighter-rouge">type</code> and <code class="highlighter-rouge">value</code> properties for type-safety.</p>

<figure class="highlight"><pre><code class="language-yaml" data-lang="yaml"><span class="pi">-</span> <span class="na">type</span><span class="pi">:</span> <span class="s">DECIMAL</span>
  <span class="na">value</span><span class="pi">:</span> <span class="s">11111111111111111</span></code></pre></figure>

<p>The table below illustrates the supported Java parameter types and the corresponding SQL type strings.</p>

<table>
  <thead>
    <tr>
      <th style="text-align: left">Java type</th>
      <th style="text-align: left">SQL type</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: left"><code class="highlighter-rouge">java.math.BigDecimal</code></td>
      <td style="text-align: left"><code class="highlighter-rouge">DECIMAL</code></td>
    </tr>
    <tr>
      <td style="text-align: left"><code class="highlighter-rouge">java.lang.Boolean</code></td>
      <td style="text-align: left"><code class="highlighter-rouge">BOOLEAN</code></td>
    </tr>
    <tr>
      <td style="text-align: left"><code class="highlighter-rouge">java.lang.Byte</code></td>
      <td style="text-align: left"><code class="highlighter-rouge">TINYINT</code></td>
    </tr>
    <tr>
      <td style="text-align: left"><code class="highlighter-rouge">java.lang.Double</code></td>
      <td style="text-align: left"><code class="highlighter-rouge">DOUBLE</code></td>
    </tr>
    <tr>
      <td style="text-align: left"><code class="highlighter-rouge">java.lang.Float</code></td>
      <td style="text-align: left"><code class="highlighter-rouge">REAL</code>, <code class="highlighter-rouge">FLOAT</code></td>
    </tr>
    <tr>
      <td style="text-align: left"><code class="highlighter-rouge">java.lang.Integer</code></td>
      <td style="text-align: left"><code class="highlighter-rouge">INTEGER</code>, <code class="highlighter-rouge">INT</code></td>
    </tr>
    <tr>
      <td style="text-align: left"><code class="highlighter-rouge">java.lang.Long</code></td>
      <td style="text-align: left"><code class="highlighter-rouge">BIGINT</code></td>
    </tr>
    <tr>
      <td style="text-align: left"><code class="highlighter-rouge">java.lang.Short</code></td>
      <td style="text-align: left"><code class="highlighter-rouge">SMALLINT</code></td>
    </tr>
    <tr>
      <td style="text-align: left"><code class="highlighter-rouge">java.lang.String</code></td>
      <td style="text-align: left"><code class="highlighter-rouge">VARCHAR</code></td>
    </tr>
  </tbody>
</table>

<p>More types (e.g., <code class="highlighter-rouge">TIMESTAMP</code> or <code class="highlighter-rouge">ARRAY</code>), primitive types, and <code class="highlighter-rouge">null</code> are not supported yet.</p>

<p><strong>A (nested) class instance:</strong> Besides literal values, you can also create (nested) class instances for constructor parameters by specifying the <code class="highlighter-rouge">class</code> and <code class="highlighter-rouge">constructor</code> properties.
This process can be recursively performed until all the constructor parameters are represented with literal values.</p>

<figure class="highlight"><pre><code class="language-yaml" data-lang="yaml"><span class="pi">-</span> <span class="na">class</span><span class="pi">:</span> <span class="s">foo.bar.paramClass</span>
  <span class="na">constructor</span><span class="pi">:</span>
    <span class="pi">-</span> <span class="s">StarryName</span>
    <span class="pi">-</span> <span class="na">class</span><span class="pi">:</span> <span class="s">java.lang.Integer</span>
      <span class="na">constructor</span><span class="pi">:</span>
        <span class="pi">-</span> <span class="na">class</span><span class="pi">:</span> <span class="s">java.lang.String</span>
          <span class="na">constructor</span><span class="pi">:</span>
            <span class="pi">-</span> <span class="na">type</span><span class="pi">:</span> <span class="s">VARCHAR</span>
              <span class="na">value</span><span class="pi">:</span> <span class="s">3</span></code></pre></figure>

<p><a href="#top" class="top pull-right"><span class="glyphicon glyphicon-chevron-up"></span> Back to top</a></p>

<h2 id="catalogs">Catalogs</h2>

<p>Catalogs can be defined as a set of YAML properties and are automatically registered to the environment upon starting SQL Client.</p>

<p>Users can specify which catalog they want to use as the current catalog in SQL CLI, and which database of the catalog they want to use as the current database.</p>

<figure class="highlight"><pre><code class="language-yaml" data-lang="yaml"><span class="na">catalogs</span><span class="pi">:</span>
   <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">catalog_1</span>
     <span class="na">type</span><span class="pi">:</span> <span class="s">hive</span>
     <span class="na">property-version</span><span class="pi">:</span> <span class="m">1</span>
     <span class="na">default-database</span><span class="pi">:</span> <span class="s">mydb2</span>
     <span class="na">hive-conf-dir</span><span class="pi">:</span> <span class="s">&lt;path of Hive conf directory&gt;</span>
   <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">catalog_2</span>
     <span class="na">type</span><span class="pi">:</span> <span class="s">hive</span>
     <span class="na">property-version</span><span class="pi">:</span> <span class="m">1</span>
     <span class="na">hive-conf-dir</span><span class="pi">:</span> <span class="s">&lt;path of Hive conf directory&gt;</span>

<span class="na">execution</span><span class="pi">:</span>
   <span class="s">...</span>
   <span class="s">current-catalog</span><span class="pi">:</span> <span class="s">catalog_1</span>
   <span class="na">current-database</span><span class="pi">:</span> <span class="s">mydb1</span></code></pre></figure>

<p>For more information about catalogs, see <a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/catalogs.html">Catalogs</a>.</p>

<h2 id="detached-sql-queries">Detached SQL Queries</h2>

<p>In order to define end-to-end SQL pipelines, SQL’s <code class="highlighter-rouge">INSERT INTO</code> statement can be used for submitting long-running, detached queries to a Flink cluster. These queries produce their results into an external system instead of the SQL Client. This allows for dealing with higher parallelism and larger amounts of data. The CLI itself does not have any control over a detached query after submission.</p>

<figure class="highlight"><pre><code class="language-sql" data-lang="sql"><span class="k">INSERT</span> <span class="k">INTO</span> <span class="n">MyTableSink</span> <span class="k">SELECT</span> <span class="o">*</span> <span class="k">FROM</span> <span class="n">MyTableSource</span></code></pre></figure>

<p>The table sink <code class="highlighter-rouge">MyTableSink</code> has to be declared in the environment file. See the <a href="connect.html">connection page</a> for more information about supported external systems and their configuration. An example for an Apache Kafka table sink is shown below.</p>

<figure class="highlight"><pre><code class="language-yaml" data-lang="yaml"><span class="na">tables</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">MyTableSink</span>
    <span class="na">type</span><span class="pi">:</span> <span class="s">sink-table</span>
    <span class="na">update-mode</span><span class="pi">:</span> <span class="s">append</span>
    <span class="na">connector</span><span class="pi">:</span>
      <span class="na">property-version</span><span class="pi">:</span> <span class="m">1</span>
      <span class="na">type</span><span class="pi">:</span> <span class="s">kafka</span>
      <span class="na">version</span><span class="pi">:</span> <span class="s2">"</span><span class="s">0.11"</span>
      <span class="na">topic</span><span class="pi">:</span> <span class="s">OutputTopic</span>
      <span class="na">properties</span><span class="pi">:</span>
        <span class="s">bootstrap.servers</span><span class="pi">:</span> <span class="s">localhost:9092</span>
        <span class="s">group.id</span><span class="pi">:</span> <span class="s">testGroup</span>
    <span class="na">format</span><span class="pi">:</span>
      <span class="na">property-version</span><span class="pi">:</span> <span class="m">1</span>
      <span class="na">type</span><span class="pi">:</span> <span class="s">json</span>
      <span class="na">derive-schema</span><span class="pi">:</span> <span class="no">true</span>
    <span class="na">schema</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">rideId</span>
        <span class="na">data-type</span><span class="pi">:</span> <span class="s">BIGINT</span>
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">lon</span>
        <span class="na">data-type</span><span class="pi">:</span> <span class="s">FLOAT</span>
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">lat</span>
        <span class="na">data-type</span><span class="pi">:</span> <span class="s">FLOAT</span>
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">rideTime</span>
        <span class="na">data-type</span><span class="pi">:</span> <span class="s">TIMESTAMP(3)</span></code></pre></figure>

<p>The SQL Client makes sure that a statement is successfully submitted to the cluster. Once the query is submitted, the CLI will show information about the Flink job.</p>

<figure class="highlight"><pre><code class="language-text" data-lang="text">[INFO] Table update statement has been successfully submitted to the cluster:
Cluster ID: StandaloneClusterId
Job ID: 6f922fe5cba87406ff23ae4a7bb79044
Web interface: http://localhost:8081</code></pre></figure>

<p><span class="label label-danger">Attention</span> The SQL Client does not track the status of the running Flink job after submission. The CLI process can be shutdown after the submission without affecting the detached query. Flink’s <a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/task_failure_recovery.html#restart-strategies">restart strategy</a> takes care of the fault-tolerance. A query can be cancelled using Flink’s web interface, command-line, or REST API.</p>

<p><a href="#top" class="top pull-right"><span class="glyphicon glyphicon-chevron-up"></span> Back to top</a></p>

<h2 id="sql-views">SQL Views</h2>

<p>Views allow to define virtual tables from SQL queries. The view definition is parsed and validated immediately. However, the actual execution happens when the view is accessed during the submission of a general <code class="highlighter-rouge">INSERT INTO</code> or <code class="highlighter-rouge">SELECT</code> statement.</p>

<p>Views can either be defined in <a href="sqlClient.html#environment-files">environment files</a> or within the CLI session.</p>

<p>The following example shows how to define multiple views in a file. The views are registered in the order in which they are defined in the environment file. Reference chains such as <em>view A depends on view B depends on view C</em> are supported.</p>

<figure class="highlight"><pre><code class="language-yaml" data-lang="yaml"><span class="na">tables</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">MyTableSource</span>
    <span class="c1"># ...</span>
  <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">MyRestrictedView</span>
    <span class="na">type</span><span class="pi">:</span> <span class="s">view</span>
    <span class="na">query</span><span class="pi">:</span> <span class="s2">"</span><span class="s">SELECT</span><span class="nv"> </span><span class="s">MyField2</span><span class="nv"> </span><span class="s">FROM</span><span class="nv"> </span><span class="s">MyTableSource"</span>
  <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">MyComplexView</span>
    <span class="na">type</span><span class="pi">:</span> <span class="s">view</span>
    <span class="na">query</span><span class="pi">:</span> <span class="pi">&gt;</span>
      <span class="s">SELECT MyField2 + 42, CAST(MyField1 AS VARCHAR)</span>
      <span class="s">FROM MyTableSource</span>
      <span class="s">WHERE MyField2 &gt; 200</span></code></pre></figure>

<p>Similar to table sources and sinks, views defined in a session environment file have highest precedence.</p>

<p>Views can also be created within a CLI session using the <code class="highlighter-rouge">CREATE VIEW</code> statement:</p>

<figure class="highlight"><pre><code class="language-text" data-lang="text">CREATE VIEW MyNewView AS SELECT MyField2 FROM MyTableSource;</code></pre></figure>

<p>Views created within a CLI session can also be removed again using the <code class="highlighter-rouge">DROP VIEW</code> statement:</p>

<figure class="highlight"><pre><code class="language-text" data-lang="text">DROP VIEW MyNewView;</code></pre></figure>

<p><span class="label label-danger">Attention</span> The definition of views in the CLI is limited to the mentioned syntax above. Defining a schema for views or escaping whitespaces in table names will be supported in future versions.</p>

<p><a href="#top" class="top pull-right"><span class="glyphicon glyphicon-chevron-up"></span> Back to top</a></p>

<h2 id="temporal-tables">Temporal Tables</h2>

<p>A <a href="./streaming/temporal_tables.html">temporal table</a> allows for a (parameterized) view on a changing history table that returns the content of a table at a specific point in time. This is especially useful for joining a table with the content of another table at a particular timestamp. More information can be found in the <a href="./streaming/joins.html#join-with-a-temporal-table">temporal table joins</a> page.</p>

<p>The following example shows how to define a temporal table <code class="highlighter-rouge">SourceTemporalTable</code>:</p>

<figure class="highlight"><pre><code class="language-yaml" data-lang="yaml"><span class="na">tables</span><span class="pi">:</span>

  <span class="c1"># Define the table source (or view) that contains updates to a temporal table</span>
  <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">HistorySource</span>
    <span class="na">type</span><span class="pi">:</span> <span class="s">source-table</span>
    <span class="na">update-mode</span><span class="pi">:</span> <span class="s">append</span>
    <span class="na">connector</span><span class="pi">:</span> <span class="c1"># ...</span>
    <span class="na">format</span><span class="pi">:</span> <span class="c1"># ...</span>
    <span class="na">schema</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">integerField</span>
        <span class="na">data-type</span><span class="pi">:</span> <span class="s">INT</span>
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">stringField</span>
        <span class="na">data-type</span><span class="pi">:</span> <span class="s">STRING</span>
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">rowtimeField</span>
        <span class="na">data-type</span><span class="pi">:</span> <span class="s">TIMESTAMP(3)</span>
        <span class="na">rowtime</span><span class="pi">:</span>
          <span class="na">timestamps</span><span class="pi">:</span>
            <span class="na">type</span><span class="pi">:</span> <span class="s">from-field</span>
            <span class="na">from</span><span class="pi">:</span> <span class="s">rowtimeField</span>
          <span class="na">watermarks</span><span class="pi">:</span>
            <span class="na">type</span><span class="pi">:</span> <span class="s">from-source</span>

  <span class="c1"># Define a temporal table over the changing history table with time attribute and primary key</span>
  <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">SourceTemporalTable</span>
    <span class="na">type</span><span class="pi">:</span> <span class="s">temporal-table</span>
    <span class="na">history-table</span><span class="pi">:</span> <span class="s">HistorySource</span>
    <span class="na">primary-key</span><span class="pi">:</span> <span class="s">integerField</span>
    <span class="na">time-attribute</span><span class="pi">:</span> <span class="s">rowtimeField</span>  <span class="c1"># could also be a proctime field</span></code></pre></figure>

<p>As shown in the example, definitions of table sources, views, and temporal tables can be mixed with each other. They are registered in the order in which they are defined in the environment file. For example, a temporal table can reference a view which can depend on another view or table source.</p>

<p><a href="#top" class="top pull-right"><span class="glyphicon glyphicon-chevron-up"></span> Back to top</a></p>

<h2 id="limitations--future">Limitations &amp; Future</h2>

<p>The current SQL Client only supports embedded mode. In the future, the community plans to extend its functionality by providing a REST-based SQL Client Gateway, see more in <a href="https://cwiki.apache.org/confluence/display/FLINK/FLIP-24+-+SQL+Client">FLIP-24</a> and <a href="https://cwiki.apache.org/confluence/display/FLINK/FLIP-91%3A+Support+SQL+Client+Gateway">FLIP-91</a>.</p>

<p><a href="#top" class="top pull-right"><span class="glyphicon glyphicon-chevron-up"></span> Back to top</a></p>



<div class="footer">
  <a href="https://cwiki.apache.org/confluence/display/FLINK/Flink+Translation+Specifications" target="_blank">
    
      Want to contribute translation?
    
  </a>
</div>


        </div>
      </div>
    </div><!-- /.container -->

    <!-- default code tab -->
    <script>var defaultCodeTab = "";</script>

    <!-- jQuery (necessary for Bootstrap's JavaScript plugins) -->
    <script src="//ci.apache.org/projects/flink/flink-docs-release-1.12/page/js/jquery.min.js"></script>
    <!-- Include all compiled plugins (below), or include individual files as needed -->
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.4/js/bootstrap.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/anchor-js/3.1.0/anchor.min.js"></script>
    <script src="//ci.apache.org/projects/flink/flink-docs-release-1.12/page/js/flink.js"></script>

    <!-- Google Analytics -->
    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-52545728-1', 'auto');
      ga('send', 'pageview');
    </script>

    <!-- Disqus -->
    
  </body>
</html>
