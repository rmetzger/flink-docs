<!--
Licensed to the Apache Software Foundation (ASF) under one
or more contributor license agreements.  See the NOTICE file
distributed with this work for additional information
regarding copyright ownership.  The ASF licenses this file
to you under the Apache License, Version 2.0 (the
"License"); you may not use this file except in compliance
with the License.  You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing,
software distributed under the License is distributed on an
"AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
KIND, either express or implied.  See the License for the
specific language governing permissions and limitations
under the License.
-->
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->
    <title>Apache Flink 1.12 Documentation: File Sink</title>
    <link rel="shortcut icon" href="//ci.apache.org/projects/flink/flink-docs-release-1.12/page/favicon.ico" type="image/x-icon">
    <link rel="icon" href="//ci.apache.org/projects/flink/flink-docs-release-1.12/page/favicon.ico" type="image/x-icon">
    <link rel="canonical" href="//ci.apache.org/projects/flink/flink-docs-stable/zh/dev/connectors/file_sink.html">

    <!-- Bootstrap -->
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.4/css/bootstrap.min.css">
    <link rel="stylesheet" href="//ci.apache.org/projects/flink/flink-docs-release-1.12/page/css/flink.css">
    <link rel="stylesheet" href="//ci.apache.org/projects/flink/flink-docs-release-1.12/page/css/syntax.css">
    <link rel="stylesheet" href="//ci.apache.org/projects/flink/flink-docs-release-1.12/page/css/codetabs.css">
    <link rel="stylesheet" href="//ci.apache.org/projects/flink/flink-docs-release-1.12/page/font-awesome/css/font-awesome.min.css">
    
    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
      <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->
  </head>
  <body>
    

    <!-- Main content. -->
    <div class="container">
      
      <div class="row">
        <div class="col-lg-3" id="sidenavcol">
          <div class="sidenav-logo">
  <p><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/"><img class="bottom" alt="Apache Flink" src="//ci.apache.org/projects/flink/flink-docs-release-1.12/page/img/navbar-brand-logo.jpg"></a> v1.12</p>
</div>
<ul id="sidenav">
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/"><i class="fa fa-home title" aria-hidden="true"></i> Home</a></li><hr class="section-break"></hr>
<li><a href="#collapse-2" data-toggle="collapse"><i class="fa fa-rocket title appetizer" aria-hidden="true"></i> Try Flink<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-2"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/try-flink/local_installation.html">本地模式安装</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/try-flink/datastream_api.html">基于 DataStream API 实现欺诈检测</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/try-flink/table_api.html">基于 Table API 实现实时报表</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/try-flink/flink-operations-playground.html">Flink 操作场景</a></li>
</ul></div></li>
<li><a href="#collapse-8" data-toggle="collapse"><i class="fa fa-hand-paper-o title appetizer" aria-hidden="true"></i> 实践练习<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-8"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/learn-flink/">概览</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/learn-flink/datastream_api.html">DataStream API 简介</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/learn-flink/etl.html">数据管道 & ETL</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/learn-flink/streaming_analytics.html">流式分析</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/learn-flink/event_driven.html">事件驱动应用</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/learn-flink/fault_tolerance.html">容错处理</a></li>
</ul></div></li>
<li><a href="#collapse-15" data-toggle="collapse"><i class="fa fa-map-o title appetizer" aria-hidden="true"></i> 概念透析<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-15"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/concepts/index.html">概览</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/concepts/stateful-stream-processing.html">有状态流处理</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/concepts/timely-stream-processing.html">及时流处理</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/concepts/flink-architecture.html">Flink 架构</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/concepts/glossary.html">词汇表</a></li>
</ul></div></li><hr class="section-break"></hr>
<li><a href="#collapse-21" data-toggle="collapse"><i class="fa fa-code title maindish" aria-hidden="true"></i> 应用开发<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-21"><ul>
<li><a href="#collapse-22" data-toggle="collapse">DataStream API<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-22"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/datastream_api.html">概览</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/datastream_execution_mode.html">Execution Mode (Batch/Streaming)</a></li>
<li><a href="#collapse-24" data-toggle="collapse">事件时间<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-24"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/event_time.html">概览</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/event_timestamps_watermarks.html">生成 Watermark</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/event_timestamp_extractors.html">内置 Watermark 生成器</a></li>
</ul></div></li>
<li><a href="#collapse-28" data-toggle="collapse">状态与容错<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-28"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/stream/state/">概览</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/stream/state/state.html">Working with State</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/stream/state/broadcast_state.html">Broadcast State 模式</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/stream/state/checkpointing.html">Checkpointing</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/stream/state/queryable_state.html">Queryable State</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/stream/state/state_backends.html">State Backends</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/stream/state/schema_evolution.html">状态数据结构升级</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/stream/state/custom_serialization.html">自定义状态序列化</a></li>
</ul></div></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/user_defined_functions.html">用户自定义 Functions</a></li>
<li><a href="#collapse-38" data-toggle="collapse">算子<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-38"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/stream/operators/">概览</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/stream/operators/windows.html">窗口</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/stream/operators/joining.html">Joining</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/stream/operators/process_function.html">Process Function</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/stream/operators/asyncio.html">异步 I/O</a></li>
</ul></div></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/stream/sources.html">Data Sources</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/stream/side_output.html">旁路输出</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/application_parameters.html">Handling Application Parameters</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/stream/testing.html">测试</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/stream/experimental.html">实验功能</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/scala_api_extensions.html">Scala API Extensions</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/java_lambdas.html">Java Lambda 表达式</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/project-configuration.html">Project Configuration</a></li>
</ul></div></li>
<li><a href="#collapse-53" data-toggle="collapse">DataSet API<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-53"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/batch/">概览</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/batch/dataset_transformations.html">Transformations</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/batch/iterations.html">迭代</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/batch/zip_elements_guide.html">Zipping Elements</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/batch/hadoop_compatibility.html">Hadoop 兼容</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/local_execution.html">本地执行</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/cluster_execution.html">集群执行</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/batch/examples.html">Batch 示例</a></li>
</ul></div></li>
<li><a href="#collapse-62" data-toggle="collapse">Table API & SQL<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-62"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/table/">概览</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/table/common.html">概念与通用 API</a></li>
<li><a href="#collapse-64" data-toggle="collapse">流式概念<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-64"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/table/streaming/">概览</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/table/streaming/dynamic_tables.html">动态表 (Dynamic Table)</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/table/streaming/time_attributes.html">时间属性</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/table/streaming/joins.html">流上的 Join</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/table/streaming/temporal_tables.html">时态表（Temporal Tables）</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/table/streaming/match_recognize.html">模式检测</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/table/streaming/query_configuration.html">Query Configuration</a></li>
</ul></div></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/table/types.html">数据类型</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/table/tableApi.html">Table API</a></li>
<li><a href="#collapse-74" data-toggle="collapse">SQL<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-74"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/table/sql/">概览</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/table/sql/queries.html">查询语句</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/table/sql/create.html">CREATE 语句</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/table/sql/drop.html">DROP 语句</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/table/sql/alter.html">ALTER 语句</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/table/sql/insert.html">INSERT 语句</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/table/sql/hints.html">SQL Hints</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/table/sql/describe.html">DESCRIBE 语句</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/table/sql/explain.html">EXPLAIN 语句</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/table/sql/use.html">USE 语句</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/table/sql/show.html">SHOW 语句</a></li>
</ul></div></li>
<li><a href="#collapse-86" data-toggle="collapse">函数<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-86"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/table/functions/">概览</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/table/functions/systemFunctions.html">系统（内置）函数</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/table/functions/udfs.html">自定义函数</a></li>
</ul></div></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/table/modules.html">模块</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/table/catalogs.html">Catalogs</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/table/sqlClient.html">SQL 客户端</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/table/config.html">配置</a></li>
<li><a href="#collapse-94" data-toggle="collapse">Performance Tuning<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-94"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/table/tuning/streaming_aggregation_optimization.html">流式聚合</a></li>
</ul></div></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/table/sourceSinks.html">User-defined Sources & Sinks</a></li>
</ul></div></li>
<li><a href="#collapse-99" data-toggle="collapse">Python API<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-99"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/python/">概览</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/python/installation.html">环境安装</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/python/table_api_tutorial.html">Table API 教程</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/python/datastream_tutorial.html">DataStream API 教程</a></li>
<li><a href="#collapse-103" data-toggle="collapse">Table API用户指南<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-103"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/python/table-api-users-guide/intro_to_table_api.html">Python Table API 简介</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/python/table-api-users-guide/table_environment.html">TableEnvironment</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/python/table-api-users-guide/operations.html">Operations</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/python/table-api-users-guide/python_types.html">数据类型</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/python/table-api-users-guide/built_in_functions.html">系统（内置）函数</a></li>
<li><a href="#collapse-109" data-toggle="collapse">自定义函数<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-109"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/python/table-api-users-guide/udfs/python_udfs.html">普通自定义函数（UDF）</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/python/table-api-users-guide/udfs/vectorized_python_udfs.html">向量化自定义函数</a></li>
</ul></div></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/python/table-api-users-guide/conversion_of_pandas.html">PyFlink Table 和 Pandas DataFrame 互转</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/python/table-api-users-guide/dependency_management.html">依赖管理</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/python/table-api-users-guide/sql.html">SQL</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/python/table-api-users-guide/catalogs.html">Catalogs</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/python/table-api-users-guide/metrics.html">指标</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/python/table-api-users-guide/python_table_api_connectors.html">连接器</a></li>
</ul></div></li>
<li><a href="#collapse-120" data-toggle="collapse">DataStream API用户指南<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-120"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/python/datastream-api-users-guide/data_types.html">数据类型</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/python/datastream-api-users-guide/operators.html">算子</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/python/datastream-api-users-guide/dependency_management.html">依赖管理</a></li>
</ul></div></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/python/python_config.html">配置</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/python/environment_variables.html">环境变量</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/python/faq.html">常见问题</a></li>
</ul></div></li>
<li><a href="#collapse-129" data-toggle="collapse">数据类型以及序列化<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-129"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/types_serialization.html">概览</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/custom_serializers.html">自定义序列化器</a></li>
</ul></div></li>
<li><a href="#collapse-132" data-toggle="collapse">管理执行<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-132"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/execution_configuration.html">执行配置</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/packaging.html">程序打包</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/parallel.html">并行执行</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/execution_plans.html">执行计划</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/task_failure_recovery.html">Task 故障恢复</a></li>
</ul></div></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/migration.html">API 迁移指南</a></li>
</ul></div></li>
<li><a href="#collapse-141" data-toggle="collapse"><i class="fa fa-book title maindish" aria-hidden="true"></i> Libraries<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-141"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/libs/cep.html">事件处理 (CEP)</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/libs/state_processor_api.html">State Processor API</a></li>
<li><a href="#collapse-144" data-toggle="collapse">图计算: Gelly<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-144"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/libs/gelly/">概览</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/libs/gelly/graph_api.html">Graph API</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/libs/gelly/iterative_graph_processing.html">Iterative Graph Processing</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/libs/gelly/library_methods.html">Library Methods</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/libs/gelly/graph_algorithms.html">Graph Algorithms</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/libs/gelly/graph_generators.html">Graph Generators</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/libs/gelly/bipartite_graph.html">Bipartite Graph</a></li>
</ul></div></li>
</ul></div></li>
<li><a href="#collapse-153" data-toggle="collapse"class="active"><i class="fa fa-random title maindish" aria-hidden="true"></i> Connectors</a><div class="collapse in" id="collapse-153"><ul>
<li><a href="#collapse-154" data-toggle="collapse"class="active">DataStream Connectors</a><div class="collapse in" id="collapse-154"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/connectors/">概览</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/connectors/guarantees.html">容错保证</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/connectors/kafka.html">Kafka</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/connectors/cassandra.html">Cassandra</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/connectors/kinesis.html">Kinesis</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/connectors/elasticsearch.html">Elasticsearch</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/connectors/file_sink.html" class="active">File Sink</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/connectors/streamfile_sink.html">Streaming File Sink</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/connectors/rabbitmq.html">RabbitMQ</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/connectors/nifi.html">NiFi</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/connectors/pubsub.html">Google Cloud PubSub</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/connectors/twitter.html">Twitter</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/connectors/jdbc.html">JDBC</a></li>
</ul></div></li>
<li><a href="#collapse-168" data-toggle="collapse">Table & SQL Connectors<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-168"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/table/connectors/">概览</a></li>
<li><a href="#collapse-169" data-toggle="collapse">Formats<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-169"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/table/connectors/formats/">概览</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/table/connectors/formats/csv.html">CSV</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/table/connectors/formats/json.html">JSON</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/table/connectors/formats/avro-confluent.html">Confluent Avro</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/table/connectors/formats/avro.html">Avro</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/table/connectors/formats/debezium.html">Debezium</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/table/connectors/formats/canal.html">Canal</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/table/connectors/formats/maxwell.html">Maxwell</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/table/connectors/formats/parquet.html">Parquet</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/table/connectors/formats/orc.html">Orc</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/table/connectors/formats/raw.html">Raw</a></li>
</ul></div></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/table/connectors/kafka.html">Kafka</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/table/connectors/upsert-kafka.html">Upsert Kafka</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/table/connectors/kinesis.html">Kinesis</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/table/connectors/jdbc.html">JDBC</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/table/connectors/elasticsearch.html">Elasticsearch</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/table/connectors/filesystem.html">FileSystem</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/table/connectors/hbase.html">HBase</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/table/connectors/datagen.html">DataGen</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/table/connectors/print.html">Print</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/table/connectors/blackhole.html">BlackHole</a></li>
<li><a href="#collapse-191" data-toggle="collapse">Hive<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-191"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/table/connectors/hive/">概览</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/table/connectors/hive/hive_catalog.html">Hive Catalog</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/table/connectors/hive/hive_dialect.html">Hive 方言</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/table/connectors/hive/hive_read_write.html">Hive Read & Write</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/table/connectors/hive/hive_functions.html">Hive 函数</a></li>
</ul></div></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/table/connectors/downloads.html">下载</a></li>
</ul></div></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/batch/connectors.html">DataSet Connectors</a></li>
</ul></div></li>
<li><a href="#collapse-201" data-toggle="collapse"><i class="fa fa-sliders title maindish" aria-hidden="true"></i> Deployment<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-201"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/deployment/">概览</a></li>
<li><a href="#collapse-202" data-toggle="collapse">Resource Providers<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-202"><ul>
<li><a href="#collapse-203" data-toggle="collapse">Standalone<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-203"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/deployment/resource-providers/standalone/">概览</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/deployment/resource-providers/standalone/local.html">本地集群</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/deployment/resource-providers/standalone/docker.html">Docker</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/deployment/resource-providers/standalone/kubernetes.html">Kubernetes</a></li>
</ul></div></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/deployment/resource-providers/native_kubernetes.html">Native Kubernetes</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/deployment/resource-providers/yarn.html">YARN</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/deployment/resource-providers/mesos.html">Mesos</a></li>
</ul></div></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/deployment/config.html">配置参数</a></li>
<li><a href="#collapse-213" data-toggle="collapse">内存配置<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-213"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/deployment/memory/mem_setup.html">配置 Flink 进程的内存</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/deployment/memory/mem_setup_tm.html">配置 TaskManager 内存</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/deployment/memory/mem_setup_jobmanager.html">配置 JobManager 内存</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/deployment/memory/mem_tuning.html">调优指南</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/deployment/memory/mem_trouble.html">常见问题</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/deployment/memory/mem_migration.html">升级指南</a></li>
</ul></div></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/deployment/cli.html">Command-Line Interface</a></li>
<li><a href="#collapse-222" data-toggle="collapse">文件系统<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-222"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/deployment/filesystems/">概览</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/deployment/filesystems/common.html">通用配置</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/deployment/filesystems/s3.html">Amazon S3</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/deployment/filesystems/oss.html">阿里云 OSS</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/deployment/filesystems/azure.html">Azure Blob 存储</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/deployment/filesystems/plugins.html">Plugins</a></li>
</ul></div></li>
<li><a href="#collapse-229" data-toggle="collapse">High Availability (HA)<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-229"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/deployment/ha/">概览</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/deployment/ha/zookeeper_ha.html">ZooKeeper HA Services</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/deployment/ha/kubernetes_ha.html">Kubernetes HA Services</a></li>
</ul></div></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/deployment/metric_reporters.html">Metric Reporters</a></li>
<li><a href="#collapse-234" data-toggle="collapse">Security<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-234"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/deployment/security/security-ssl.html">SSL 设置</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/deployment/security/security-kerberos.html">Kerberos</a></li>
</ul></div></li>
<li><a href="#collapse-238" data-toggle="collapse">REPLs<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-238"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/deployment/repls/python_shell.html">Python REPL</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/deployment/repls/scala_shell.html">Scala REPL</a></li>
</ul></div></li>
<li><a href="#collapse-242" data-toggle="collapse">Advanced<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-242"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/deployment/advanced/external_resources.html">扩展资源</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/deployment/advanced/historyserver.html">History Server</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/deployment/advanced/logging.html">日志</a></li>
</ul></div></li>
</ul></div></li>
<li><a href="#collapse-248" data-toggle="collapse"><i class="fa fa-cogs title maindish" aria-hidden="true"></i> Operations<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-248"><ul>
<li><a href="#collapse-249" data-toggle="collapse">状态与容错<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-249"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/ops/state/checkpoints.html">Checkpoints</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/ops/state/savepoints.html">Savepoints</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/ops/state/state_backends.html">State Backends</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/ops/state/large_state_tuning.html">大状态与 Checkpoint 调优</a></li>
</ul></div></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/ops/metrics.html">指标</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/ops/rest_api.html">REST API</a></li>
<li><a href="#collapse-257" data-toggle="collapse">Debugging<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-257"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/ops/debugging/debugging_event_time.html">调试窗口与事件时间</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/ops/debugging/debugging_classloading.html">调试类加载</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/ops/debugging/application_profiling.html">应用程序分析</a></li>
</ul></div></li>
<li><a href="#collapse-262" data-toggle="collapse">Monitoring<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-262"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/ops/monitoring/checkpoint_monitoring.html">监控 Checkpoint</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/ops/monitoring/back_pressure.html">监控反压</a></li>
</ul></div></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/ops/upgrading.html">升级应用程序和 Flink 版本</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/ops/production_ready.html">生产就绪情况核对清单</a></li>
</ul></div></li><hr class="section-break"></hr>
<li><a href="#collapse-269" data-toggle="collapse"><i class="fa fa-cogs title dessert" aria-hidden="true"></i> Flink 开发<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-269"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/flinkDev/ide_setup.html">导入 Flink 到 IDE 中</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/flinkDev/building.html">从源码构建 Flink</a></li>
</ul></div></li>
<li><a href="#collapse-273" data-toggle="collapse"><i class="fa fa-book title dessert" aria-hidden="true"></i> 内幕<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-273"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/internals/job_scheduling.html">作业调度</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/internals/task_lifecycle.html">Task 生命周期</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/internals/filesystems.html">文件系统</a></li>
</ul></div></li>
  <li class="divider"></li>
  <li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/api/java"><i class="fa fa-external-link title" aria-hidden="true"></i> Javadocs</a></li>
  <li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/api/scala/index.html#org.apache.flink.api.scala.package"><i class="fa fa-external-link title" aria-hidden="true"></i> Scaladocs</a></li>
  <li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/api/python"><i class="fa fa-external-link title" aria-hidden="true"></i> Pythondocs</a></li>
  <li><a href="http://flink.apache.org"><i class="fa fa-external-link title" aria-hidden="true"></i> Project Page</a></li>
</ul>

<div class="sidenav-search-box">
  <form class="navbar-form" role="search" action="//ci.apache.org/projects/flink/flink-docs-release-1.12/search-results.html">
    <div class="form-group">
      <input type="text" class="form-control" size="16px" name="q" placeholder="Search">
    </div>
    <button type="submit" class="btn btn-default">Go</button>
  </form>
</div>

<div class="sidenav-versions">
  <div class="dropdown">
    <button class="btn btn-default dropdown-toggle" type="button" data-toggle="dropdown">选择文档版本<span class="caret"></span></button>
    <ul class="dropdown-menu">
      <li><a href="http://ci.apache.org/projects/flink/flink-docs-release-1.11">v1.11</a></li>
      <li><a href="http://ci.apache.org/projects/flink/flink-docs-release-1.10">v1.10</a></li>
      <li><a href="http://ci.apache.org/projects/flink/flink-docs-release-1.9">v1.9</a></li>
      <li><a href="http://ci.apache.org/projects/flink/flink-docs-release-1.8">v1.8</a></li>
      <li><a href="http://ci.apache.org/projects/flink/flink-docs-release-1.7">v1.7</a></li>
      <li><a href="http://ci.apache.org/projects/flink/flink-docs-release-1.6">v1.6</a></li>
      <li><a href="http://ci.apache.org/projects/flink/flink-docs-release-1.5">v1.5</a></li>
      <li><a href="http://ci.apache.org/projects/flink/flink-docs-release-1.4">v1.4</a></li>
      <li><a href="http://ci.apache.org/projects/flink/flink-docs-release-1.3">v1.3</a></li>
      <li><a href="http://ci.apache.org/projects/flink/flink-docs-release-1.2">v1.2</a></li>
      <li><a href="http://ci.apache.org/projects/flink/flink-docs-release-1.1">v1.1</a></li>
      <li><a href="http://ci.apache.org/projects/flink/flink-docs-release-1.0">v1.0</a></li>
    </ul>
  </div>
</div>

<div class="sidenav-languages"><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/connectors/file_sink.html">
      <button type="submit" class="btn btn-default">English</button>
    </a>
</div>

        </div>
        <div class="col-lg-9 content" id="contentcol">

          

<ol class="breadcrumb">
  
    <li><i class="fa fa-random title maindish" aria-hidden="true"></i> Connectors</li>
  
    <li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/connectors/">DataStream Connectors</a></li>
  
    <li class="active">File Sink</li>
</ol>

<h1>File Sink</h1>




<ul id="markdown-toc">
  <li><a href="#文件格式" id="markdown-toc-文件格式">文件格式</a>    <ul>
      <li><a href="#行编码格式" id="markdown-toc-行编码格式">行编码格式</a></li>
      <li><a href="#批量编码格式" id="markdown-toc-批量编码格式">批量编码格式</a></li>
    </ul>
  </li>
  <li><a href="#桶分配" id="markdown-toc-桶分配">桶分配</a></li>
  <li><a href="#滚动策略" id="markdown-toc-滚动策略">滚动策略</a></li>
  <li><a href="#部分文件part-file-生命周期" id="markdown-toc-部分文件part-file-生命周期">部分文件（part file） 生命周期</a>    <ul>
      <li><a href="#部分文件的配置项" id="markdown-toc-部分文件的配置项">部分文件的配置项</a></li>
    </ul>
  </li>
  <li><a href="#重要注意事项" id="markdown-toc-重要注意事项">重要注意事项</a>    <ul>
      <li><a href="#通用注意事项" id="markdown-toc-通用注意事项">通用注意事项</a></li>
      <li><a href="#batch-模式" id="markdown-toc-batch-模式">Batch 模式</a></li>
      <li><a href="#s3-特有的注意事项" id="markdown-toc-s3-特有的注意事项">S3 特有的注意事项</a></li>
    </ul>
  </li>
</ul>

<p>这个连接器提供了一个在流和批模式下统一的 Sink 来将分区文件写入到支持 <a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/deployment/filesystems/">Flink <code class="highlighter-rouge">FileSystem</code></a> 接口的文件系统中，它对于流和批模式可以提供相同的一致性语义保证。File Sink 是现有的 <a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/connectors/streamfile_sink.html">Streaming File Sink</a> 的一个升级版本，后者仅在流模式下提供了精确一致性。</p>

<p>File Sink 会将数据写入到桶中。由于输入流可能是无界的，因此每个桶中的数据被划分为多个有限大小的文件。如何分桶是可以配置的，默认使用基于时间的分桶策略，这种策略每个小时创建一个新的桶，桶中包含的文件将记录所有该小时内从流中接收到的数据。</p>

<p>桶目录中的实际输出数据会被划分为多个部分文件（part file），每一个接收桶数据的 Sink Subtask ，至少包含一个部分文件（part file）。额外的部分文件（part file）将根据滚动策略创建，滚动策略是可以配置的。对于行编码格式（参考 <a href="#file-formats">File Formats</a> ）默认的策略是根据文件大小和超时时间来滚动文件。超时时间指打开文件的最长持续时间，以及文件关闭前的最长非活动时间。批量编码格式必须在每次 Checkpoint 时滚动文件，但是用户也可以指定额外的基于文件大小和超时时间的策略。</p>

<div class="alert alert-info">
     <b>重要:</b> 在流模式下使用 FileSink 时需要启用 Checkpoint ，每次做 Checkpoint 时写入完成。如果 Checkpoint 被禁用，部分文件（part file）将永远处于 'in-progress' 或 'pending' 状态，下游系统无法安全地读取。
 </div>

<p><img src="//ci.apache.org/projects/flink/flink-docs-release-1.12/fig/streamfilesink_bucketing.png" class="center" style="width: 100%;" /></p>

<h2 id="文件格式">文件格式</h2>

<p><code class="highlighter-rouge">FileSink</code> 支持行编码格式和批量编码格式，比如 <a href="http://parquet.apache.org">Apache Parquet</a> 。
这两种变体随附了各自的构建器，可以使用以下静态方法创建：</p>

<ul>
  <li>Row-encoded sink: <code class="highlighter-rouge">FileSink.forRowFormat(basePath, rowEncoder)</code></li>
  <li>Bulk-encoded sink: <code class="highlighter-rouge">FileSink.forBulkFormat(basePath, bulkWriterFactory)</code></li>
</ul>

<p>创建行或批量编码的 Sink 时，我们需要指定存储桶的基本路径和数据的编码逻辑。</p>

<p>更多配置操作以及不同数据格式的实现请参考 <a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/api/java/org/apache/flink/connector/file/sink/FileSink.html">FileSink</a> 。</p>

<h3 id="行编码格式">行编码格式</h3>

<p>行编码格式需要指定一个 <a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/api/java/org/apache/flink/api/common/serialization/Encoder.html">Encoder</a> 。Encoder 负责为每个处于 In-progress 状态文件的<code class="highlighter-rouge">OutputStream</code> 序列化数据。</p>

<p>除了桶分配器之外，<a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/api/java/org/apache/flink/connector/file/sink/FileSink.RowFormatBuilder.html">RowFormatBuilder</a>  还允许用户指定：</p>

<ul>
  <li>Custom <a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/api/java/org/apache/flink/streaming/api/functions/sink/filesystem/RollingPolicy.html">RollingPolicy</a> ：自定义滚动策略以覆盖默认的 DefaultRollingPolicy。</li>
  <li>bucketCheckInterval （默认为1分钟）：毫秒间隔，用于基于时间的滚动策略。</li>
</ul>

<p>字符串元素写入示例：</p>

<div class="codetabs">
  <div data-lang="java">

    <figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="kn">import</span> <span class="nn">org.apache.flink.api.common.serialization.SimpleStringEncoder</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.flink.core.fs.Path</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.flink.connector.file.sink.FileSink</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.flink.streaming.api.functions.sink.filesystem.rollingpolicies.DefaultRollingPolicy</span><span class="o">;</span>

<span class="nc">DataStream</span><span class="o">&lt;</span><span class="nc">String</span><span class="o">&gt;</span> <span class="n">input</span> <span class="o">=</span> <span class="o">...;</span>

<span class="kd">final</span> <span class="nc">FileSink</span><span class="o">&lt;</span><span class="nc">String</span><span class="o">&gt;</span> <span class="n">sink</span> <span class="o">=</span> <span class="nc">FileSink</span>
    <span class="o">.</span><span class="na">forRowFormat</span><span class="o">(</span><span class="k">new</span> <span class="nc">Path</span><span class="o">(</span><span class="n">outputPath</span><span class="o">),</span> <span class="k">new</span> <span class="nc">SimpleStringEncoder</span><span class="o">&lt;</span><span class="nc">String</span><span class="o">&gt;(</span><span class="s">"UTF-8"</span><span class="o">))</span>
    <span class="o">.</span><span class="na">withRollingPolicy</span><span class="o">(</span>
        <span class="nc">DefaultRollingPolicy</span><span class="o">.</span><span class="na">builder</span><span class="o">()</span>
            <span class="o">.</span><span class="na">withRolloverInterval</span><span class="o">(</span><span class="nc">TimeUnit</span><span class="o">.</span><span class="na">MINUTES</span><span class="o">.</span><span class="na">toMillis</span><span class="o">(</span><span class="mi">15</span><span class="o">))</span>
            <span class="o">.</span><span class="na">withInactivityInterval</span><span class="o">(</span><span class="nc">TimeUnit</span><span class="o">.</span><span class="na">MINUTES</span><span class="o">.</span><span class="na">toMillis</span><span class="o">(</span><span class="mi">5</span><span class="o">))</span>
            <span class="o">.</span><span class="na">withMaxPartSize</span><span class="o">(</span><span class="mi">1024</span> <span class="o">*</span> <span class="mi">1024</span> <span class="o">*</span> <span class="mi">1024</span><span class="o">)</span>
            <span class="o">.</span><span class="na">build</span><span class="o">())</span>
	<span class="o">.</span><span class="na">build</span><span class="o">();</span>

<span class="n">input</span><span class="o">.</span><span class="na">sinkTo</span><span class="o">(</span><span class="n">sink</span><span class="o">);</span></code></pre></figure>

  </div>
  <div data-lang="scala">

    <figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">import</span> <span class="nn">org.apache.flink.api.common.serialization.SimpleStringEncoder</span>
<span class="k">import</span> <span class="nn">org.apache.flink.core.fs.Path</span>
<span class="k">import</span> <span class="nn">org.apache.flink.connector.file.sink.FileSink</span>
<span class="k">import</span> <span class="nn">org.apache.flink.streaming.api.functions.sink.filesystem.rollingpolicies.DefaultRollingPolicy</span>

<span class="k">val</span> <span class="nv">input</span><span class="k">:</span> <span class="kt">DataStream</span><span class="o">[</span><span class="kt">String</span><span class="o">]</span> <span class="k">=</span> <span class="o">...</span>

<span class="k">val</span> <span class="nv">sink</span><span class="k">:</span> <span class="kt">FileSink</span><span class="o">[</span><span class="kt">String</span><span class="o">]</span> <span class="k">=</span> <span class="nc">FileSink</span>
    <span class="o">.</span><span class="py">forRowFormat</span><span class="o">(</span><span class="k">new</span> <span class="nc">Path</span><span class="o">(</span><span class="n">outputPath</span><span class="o">),</span> <span class="k">new</span> <span class="nc">SimpleStringEncoder</span><span class="o">[</span><span class="kt">String</span><span class="o">](</span><span class="s">"UTF-8"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">withRollingPolicy</span><span class="o">(</span>
        <span class="nv">DefaultRollingPolicy</span><span class="o">.</span><span class="py">builder</span><span class="o">()</span>
            <span class="o">.</span><span class="py">withRolloverInterval</span><span class="o">(</span><span class="nv">TimeUnit</span><span class="o">.</span><span class="py">MINUTES</span><span class="o">.</span><span class="py">toMillis</span><span class="o">(</span><span class="mi">15</span><span class="o">))</span>
            <span class="o">.</span><span class="py">withInactivityInterval</span><span class="o">(</span><span class="nv">TimeUnit</span><span class="o">.</span><span class="py">MINUTES</span><span class="o">.</span><span class="py">toMillis</span><span class="o">(</span><span class="mi">5</span><span class="o">))</span>
            <span class="o">.</span><span class="py">withMaxPartSize</span><span class="o">(</span><span class="mi">1024</span> <span class="o">*</span> <span class="mi">1024</span> <span class="o">*</span> <span class="mi">1024</span><span class="o">)</span>
            <span class="o">.</span><span class="py">build</span><span class="o">())</span>
    <span class="o">.</span><span class="py">build</span><span class="o">()</span>

<span class="nv">input</span><span class="o">.</span><span class="py">sinkTo</span><span class="o">(</span><span class="n">sink</span><span class="o">)</span></code></pre></figure>

  </div>
</div>

<p>这个例子创建了一个简单的 Sink ，将记录分配给默认的一小时时间桶。它还指定了一个滚动策略，该策略在以下三种情况下滚动处于 In-progress 状态的部分文件（part file）：</p>

<ul>
  <li>它至少包含 15 分钟的数据</li>
  <li>最近 5 分钟没有收到新的记录</li>
  <li>文件大小达到 1GB （写入最后一条记录后）</li>
</ul>

<h3 id="批量编码格式">批量编码格式</h3>

<p>批量编码 Sink 的创建与行编码 Sink 相似，不过在这里我们不是指定编码器  <code class="highlighter-rouge">Encoder</code> 而是指定 <a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/api/java/org/apache/flink/api/common/serialization/BulkWriter.Factory.html">BulkWriter.Factory</a> 。
<code class="highlighter-rouge">BulkWriter</code> 定义了如何添加、刷新元素，以及如何批量编码。</p>

<p>Flink 有四个内置的 BulkWriter Factory ：</p>

<ul>
  <li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/api/java/org/apache/flink/formats/parquet/ParquetWriterFactory.html">ParquetWriterFactory</a></li>
  <li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/api/java/org/apache/flink/formats/avro/AvroWriterFactory.html">AvroWriterFactory</a></li>
  <li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/api/java/org/apache/flink/formats/sequencefile/SequenceFileWriterFactory.html">SequenceFileWriterFactory</a></li>
  <li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/api/java/org/apache/flink/formats/compress/CompressWriterFactory.html">CompressWriterFactory</a></li>
  <li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/api/java/org/apache/flink/orc/writer/OrcBulkWriterFactory.html">OrcBulkWriterFactory</a></li>
</ul>

<div class="alert alert-info">
     <b>重要:</b> 批量编码模式仅支持 OnCheckpointRollingPolicy 策略, 在每次 checkpoint 的时候滚动文件。
     <b>重要:</b> 批量编码模式必须使用继承自 CheckpointRollingPolicy 的滚动策略, 这些策略必须在每次 checkpoint 的时候滚动文件，但是用户也可以进一步指定额外的基于文件大小和超时时间的策略。
</div>

<h4 id="parquet-格式">Parquet 格式</h4>

<p>Flink 包含为不同 Avro 类型，创建 ParquetWriterFactory 的便捷方法，更多信息请参考 <a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/api/java/org/apache/flink/formats/parquet/avro/ParquetAvroWriters.html">ParquetAvroWriters</a> 。</p>

<p>要编写其他 Parquet 兼容的数据格式，用户需要创建 ParquetWriterFactory 并实现 <a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/api/java/org/apache/flink/formats/parquet/ParquetBuilder.html">ParquetBuilder</a> 接口。</p>

<p>在应用中使用 Parquet 批量编码器，你需要添加以下依赖：</p>

<figure class="highlight"><pre><code class="language-xml" data-lang="xml"><span class="nt">&lt;dependency&gt;</span>
  <span class="nt">&lt;groupId&gt;</span>org.apache.flink<span class="nt">&lt;/groupId&gt;</span>
  <span class="nt">&lt;artifactId&gt;</span>flink-parquet_2.11<span class="nt">&lt;/artifactId&gt;</span>
  <span class="nt">&lt;version&gt;</span>1.12.0<span class="nt">&lt;/version&gt;</span>
<span class="nt">&lt;/dependency&gt;</span></code></pre></figure>

<p>这个例子使用 FileSink 将 Avro 数据写入 Parquet 格式：</p>

<div class="codetabs">
  <div data-lang="java">

    <figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="kn">import</span> <span class="nn">org.apache.flink.connector.file.sink.FileSink</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.flink.formats.parquet.avro.ParquetAvroWriters</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.avro.Schema</span><span class="o">;</span>


<span class="nc">Schema</span> <span class="n">schema</span> <span class="o">=</span> <span class="o">...;</span>
<span class="nc">DataStream</span><span class="o">&lt;</span><span class="nc">GenericRecord</span><span class="o">&gt;</span> <span class="n">stream</span> <span class="o">=</span> <span class="o">...;</span>

<span class="kd">final</span> <span class="nc">FileSink</span><span class="o">&lt;</span><span class="nc">GenericRecord</span><span class="o">&gt;</span> <span class="n">sink</span> <span class="o">=</span> <span class="nc">FileSink</span>
	<span class="o">.</span><span class="na">forBulkFormat</span><span class="o">(</span><span class="n">outputBasePath</span><span class="o">,</span> <span class="nc">ParquetAvroWriters</span><span class="o">.</span><span class="na">forGenericRecord</span><span class="o">(</span><span class="n">schema</span><span class="o">))</span>
	<span class="o">.</span><span class="na">build</span><span class="o">();</span>

<span class="n">input</span><span class="o">.</span><span class="na">sinkTo</span><span class="o">(</span><span class="n">sink</span><span class="o">);</span></code></pre></figure>

  </div>
  <div data-lang="scala">

    <figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">import</span> <span class="nn">org.apache.flink.connector.file.sink.FileSink</span><span class="o">;</span>
<span class="k">import</span> <span class="nn">org.apache.flink.formats.parquet.avro.ParquetAvroWriters</span>
<span class="k">import</span> <span class="nn">org.apache.avro.Schema</span>

<span class="k">val</span> <span class="nv">schema</span><span class="k">:</span> <span class="kt">Schema</span> <span class="o">=</span> <span class="o">...</span>
<span class="k">val</span> <span class="nv">input</span><span class="k">:</span> <span class="kt">DataStream</span><span class="o">[</span><span class="kt">GenericRecord</span><span class="o">]</span> <span class="k">=</span> <span class="o">...</span>

<span class="k">val</span> <span class="nv">sink</span><span class="k">:</span> <span class="kt">FileSink</span><span class="o">[</span><span class="kt">GenericRecord</span><span class="o">]</span> <span class="k">=</span> <span class="nc">FileSink</span>
    <span class="o">.</span><span class="py">forBulkFormat</span><span class="o">(</span><span class="n">outputBasePath</span><span class="o">,</span> <span class="nv">ParquetAvroWriters</span><span class="o">.</span><span class="py">forGenericRecord</span><span class="o">(</span><span class="n">schema</span><span class="o">))</span>
    <span class="o">.</span><span class="py">build</span><span class="o">()</span>

<span class="nv">input</span><span class="o">.</span><span class="py">sinkTo</span><span class="o">(</span><span class="n">sink</span><span class="o">)</span></code></pre></figure>

  </div>
</div>

<p>类似的，将 Protobuf 数据写入到 Parquet 格式可以通过：</p>

<div class="codetabs">
  <div data-lang="java">

    <figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="kn">import</span> <span class="nn">org.apache.flink.connector.file.sink.FileSink</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.flink.formats.parquet.protobuf.ParquetProtoWriters</span><span class="o">;</span>

<span class="c1">// ProtoRecord is a generated protobuf Message class.</span>
<span class="nc">DataStream</span><span class="o">&lt;</span><span class="nc">ProtoRecord</span><span class="o">&gt;</span> <span class="n">stream</span> <span class="o">=</span> <span class="o">...;</span>

<span class="kd">final</span> <span class="nc">FileSink</span><span class="o">&lt;</span><span class="nc">ProtoRecord</span><span class="o">&gt;</span> <span class="n">sink</span> <span class="o">=</span> <span class="nc">FileSink</span>
	<span class="o">.</span><span class="na">forBulkFormat</span><span class="o">(</span><span class="n">outputBasePath</span><span class="o">,</span> <span class="nc">ParquetProtoWriters</span><span class="o">.</span><span class="na">forType</span><span class="o">(</span><span class="nc">ProtoRecord</span><span class="o">.</span><span class="na">class</span><span class="o">))</span>
	<span class="o">.</span><span class="na">build</span><span class="o">();</span>

<span class="n">input</span><span class="o">.</span><span class="na">sinkTo</span><span class="o">(</span><span class="n">sink</span><span class="o">);</span></code></pre></figure>

  </div>
  <div data-lang="scala">

    <figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">import</span> <span class="nn">org.apache.flink.connector.file.sink.FileSink</span><span class="o">;</span>
<span class="k">import</span> <span class="nn">org.apache.flink.formats.parquet.protobuf.ParquetProtoWriters</span>

<span class="c1">// ProtoRecord is a generated protobuf Message class.</span>
<span class="k">val</span> <span class="nv">input</span><span class="k">:</span> <span class="kt">DataStream</span><span class="o">[</span><span class="kt">ProtoRecord</span><span class="o">]</span> <span class="k">=</span> <span class="o">...</span>

<span class="k">val</span> <span class="nv">sink</span><span class="k">:</span> <span class="kt">FileSink</span><span class="o">[</span><span class="kt">ProtoRecord</span><span class="o">]</span> <span class="k">=</span> <span class="nc">FileSink</span>
    <span class="o">.</span><span class="py">forBulkFormat</span><span class="o">(</span><span class="n">outputBasePath</span><span class="o">,</span> <span class="nv">ParquetProtoWriters</span><span class="o">.</span><span class="py">forType</span><span class="o">(</span><span class="n">classOf</span><span class="o">[</span><span class="kt">ProtoRecord</span><span class="o">]))</span>
    <span class="o">.</span><span class="py">build</span><span class="o">()</span>

<span class="nv">input</span><span class="o">.</span><span class="py">sinkTo</span><span class="o">(</span><span class="n">sink</span><span class="o">)</span></code></pre></figure>

  </div>
</div>

<h4 id="avro格式">Avro格式</h4>

<p>Flink 也提供了将数据写入 Avro 文件的内置支持。对于创建 AvroWriterFactory 的快捷方法，更多信息可以参考 
<a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/api/java/org/apache/flink/formats/avro/AvroWriters.html">AvroWriters</a>.</p>

<p>使用Avro相关的Writer需要在项目中添加以下依赖：</p>

<figure class="highlight"><pre><code class="language-xml" data-lang="xml"><span class="nt">&lt;dependency&gt;</span>
  <span class="nt">&lt;groupId&gt;</span>org.apache.flink<span class="nt">&lt;/groupId&gt;</span>
  <span class="nt">&lt;artifactId&gt;</span>flink-avro<span class="nt">&lt;/artifactId&gt;</span>
  <span class="nt">&lt;version&gt;</span>1.12.0<span class="nt">&lt;/version&gt;</span>
<span class="nt">&lt;/dependency&gt;</span></code></pre></figure>

<p>将数据写入 Avro 文件的 FileSink 算子可以通过如下方式创建：</p>

<div class="codetabs">
  <div data-lang="java">

    <figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="kn">import</span> <span class="nn">org.apache.flink.connector.file.sink.FileSink</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.flink.formats.avro.AvroWriters</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.avro.Schema</span><span class="o">;</span>


<span class="nc">Schema</span> <span class="n">schema</span> <span class="o">=</span> <span class="o">...;</span>
<span class="nc">DataStream</span><span class="o">&lt;</span><span class="nc">GenericRecord</span><span class="o">&gt;</span> <span class="n">stream</span> <span class="o">=</span> <span class="o">...;</span>

<span class="kd">final</span> <span class="nc">FileSink</span><span class="o">&lt;</span><span class="nc">GenericRecord</span><span class="o">&gt;</span> <span class="n">sink</span> <span class="o">=</span> <span class="nc">FileSink</span>
	<span class="o">.</span><span class="na">forBulkFormat</span><span class="o">(</span><span class="n">outputBasePath</span><span class="o">,</span> <span class="nc">AvroWriters</span><span class="o">.</span><span class="na">forGenericRecord</span><span class="o">(</span><span class="n">schema</span><span class="o">))</span>
	<span class="o">.</span><span class="na">build</span><span class="o">();</span>

<span class="n">input</span><span class="o">.</span><span class="na">sinkTo</span><span class="o">(</span><span class="n">sink</span><span class="o">);</span></code></pre></figure>

  </div>
  <div data-lang="scala">

    <figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">import</span> <span class="nn">org.apache.flink.connector.file.sink.FileSink</span><span class="o">;</span>
<span class="k">import</span> <span class="nn">org.apache.flink.formats.avro.AvroWriters</span>
<span class="k">import</span> <span class="nn">org.apache.avro.Schema</span>

<span class="k">val</span> <span class="nv">schema</span><span class="k">:</span> <span class="kt">Schema</span> <span class="o">=</span> <span class="o">...</span>
<span class="k">val</span> <span class="nv">input</span><span class="k">:</span> <span class="kt">DataStream</span><span class="o">[</span><span class="kt">GenericRecord</span><span class="o">]</span> <span class="k">=</span> <span class="o">...</span>

<span class="k">val</span> <span class="nv">sink</span><span class="k">:</span> <span class="kt">FileSink</span><span class="o">[</span><span class="kt">GenericRecord</span><span class="o">]</span> <span class="k">=</span> <span class="nc">FileSink</span>
    <span class="o">.</span><span class="py">forBulkFormat</span><span class="o">(</span><span class="n">outputBasePath</span><span class="o">,</span> <span class="nv">AvroWriters</span><span class="o">.</span><span class="py">forGenericRecord</span><span class="o">(</span><span class="n">schema</span><span class="o">))</span>
    <span class="o">.</span><span class="py">build</span><span class="o">()</span>

<span class="nv">input</span><span class="o">.</span><span class="py">sinkTo</span><span class="o">(</span><span class="n">sink</span><span class="o">)</span></code></pre></figure>

  </div>
</div>

<p>如果想要创建自定义的 Avro Writer，例如启用压缩等，用户可以实现 <a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/api/java/org/apache/flink/formats/avro/AvroBuilder.html">AvroBuilder</a>
接口并自行创建一个 <code class="highlighter-rouge">AvroWriterFactory</code> 实例：</p>

<div class="codetabs">
  <div data-lang="java">

    <figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="nc">AvroWriterFactory</span><span class="o">&lt;?&gt;</span> <span class="n">factory</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">AvroWriterFactory</span><span class="o">&lt;&gt;((</span><span class="nc">AvroBuilder</span><span class="o">&lt;</span><span class="nc">Address</span><span class="o">&gt;)</span> <span class="n">out</span> <span class="o">-&gt;</span> <span class="o">{</span>
	<span class="nc">Schema</span> <span class="n">schema</span> <span class="o">=</span> <span class="nc">ReflectData</span><span class="o">.</span><span class="na">get</span><span class="o">().</span><span class="na">getSchema</span><span class="o">(</span><span class="nc">Address</span><span class="o">.</span><span class="na">class</span><span class="o">);</span>
	<span class="nc">DatumWriter</span><span class="o">&lt;</span><span class="nc">Address</span><span class="o">&gt;</span> <span class="n">datumWriter</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">ReflectDatumWriter</span><span class="o">&lt;&gt;(</span><span class="n">schema</span><span class="o">);</span>

	<span class="nc">DataFileWriter</span><span class="o">&lt;</span><span class="nc">Address</span><span class="o">&gt;</span> <span class="n">dataFileWriter</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">DataFileWriter</span><span class="o">&lt;&gt;(</span><span class="n">datumWriter</span><span class="o">);</span>
	<span class="n">dataFileWriter</span><span class="o">.</span><span class="na">setCodec</span><span class="o">(</span><span class="nc">CodecFactory</span><span class="o">.</span><span class="na">snappyCodec</span><span class="o">());</span>
	<span class="n">dataFileWriter</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="n">schema</span><span class="o">,</span> <span class="n">out</span><span class="o">);</span>
	<span class="k">return</span> <span class="n">dataFileWriter</span><span class="o">;</span>
<span class="o">});</span>

<span class="nc">DataStream</span><span class="o">&lt;</span><span class="nc">Address</span><span class="o">&gt;</span> <span class="n">stream</span> <span class="o">=</span> <span class="o">...</span>
<span class="n">stream</span><span class="o">.</span><span class="na">sinkTo</span><span class="o">(</span><span class="nc">FileSink</span><span class="o">.</span><span class="na">forBulkFormat</span><span class="o">(</span>
	<span class="n">outputBasePath</span><span class="o">,</span>
	<span class="n">factory</span><span class="o">).</span><span class="na">build</span><span class="o">());</span></code></pre></figure>

  </div>
  <div data-lang="scala">

    <figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="nv">factory</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">AvroWriterFactory</span><span class="o">[</span><span class="kt">Address</span><span class="o">](</span><span class="k">new</span> <span class="nc">AvroBuilder</span><span class="o">[</span><span class="kt">Address</span><span class="o">]()</span> <span class="o">{</span>
    <span class="k">override</span> <span class="k">def</span> <span class="nf">createWriter</span><span class="o">(</span><span class="n">out</span><span class="k">:</span> <span class="kt">OutputStream</span><span class="o">)</span><span class="k">:</span> <span class="kt">DataFileWriter</span><span class="o">[</span><span class="kt">Address</span><span class="o">]</span> <span class="k">=</span> <span class="o">{</span>
        <span class="k">val</span> <span class="nv">schema</span> <span class="k">=</span> <span class="nv">ReflectData</span><span class="o">.</span><span class="py">get</span><span class="o">.</span><span class="py">getSchema</span><span class="o">(</span><span class="n">classOf</span><span class="o">[</span><span class="kt">Address</span><span class="o">])</span>
        <span class="k">val</span> <span class="nv">datumWriter</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">ReflectDatumWriter</span><span class="o">[</span><span class="kt">Address</span><span class="o">](</span><span class="n">schema</span><span class="o">)</span>

        <span class="k">val</span> <span class="nv">dataFileWriter</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DataFileWriter</span><span class="o">[</span><span class="kt">Address</span><span class="o">](</span><span class="n">datumWriter</span><span class="o">)</span>
        <span class="nv">dataFileWriter</span><span class="o">.</span><span class="py">setCodec</span><span class="o">(</span><span class="nv">CodecFactory</span><span class="o">.</span><span class="py">snappyCodec</span><span class="o">)</span>
        <span class="nv">dataFileWriter</span><span class="o">.</span><span class="py">create</span><span class="o">(</span><span class="n">schema</span><span class="o">,</span> <span class="n">out</span><span class="o">)</span>
        <span class="n">dataFileWriter</span>
    <span class="o">}</span>
<span class="o">})</span>

<span class="k">val</span> <span class="nv">stream</span><span class="k">:</span> <span class="kt">DataStream</span><span class="o">[</span><span class="kt">Address</span><span class="o">]</span> <span class="k">=</span> <span class="o">...</span>
<span class="nv">stream</span><span class="o">.</span><span class="py">sinkTo</span><span class="o">(</span><span class="nv">FileSink</span><span class="o">.</span><span class="py">forBulkFormat</span><span class="o">(</span>
    <span class="n">outputBasePath</span><span class="o">,</span>
    <span class="n">factory</span><span class="o">).</span><span class="py">build</span><span class="o">());</span></code></pre></figure>

  </div>
</div>

<h4 id="orc-format">ORC Format</h4>

<p>为了使用基于批量编码的 ORC 格式，Flink提供了 <a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/api/java/org/apache/flink/formats/orc/writers/OrcBulkWriterFactory.html">OrcBulkWriterFactory</a> ，它需要用户提供一个 <a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/api/java/org/apache/flink/orc/vector/Vectorizer.html">Vectorizer</a> 的具体实现。</p>

<p>和其它基于列式存储的批量编码格式类似，Flink中的 <code class="highlighter-rouge">OrcBulkWriter</code> 将数据按批写出。它通过 ORC 的 VectorizedRowBatch 来实现这一点。</p>

<p>由于输入数据必须先缓存为一个完整的 <code class="highlighter-rouge">VectorizedRowBatch</code> ，用户需要继承 <code class="highlighter-rouge">Vectorizer</code> 抽像类并且实现其中的 <code class="highlighter-rouge">vectorize(T element, VectorizedRowBatch batch)</code> 方法。方法参数中传入的 <code class="highlighter-rouge">VectorizedRowBatch</code> 使用户只需将输入 <code class="highlighter-rouge">element</code> 转化为 <code class="highlighter-rouge">ColumnVectors</code> 并将它存储到所提供的 <code class="highlighter-rouge">VectorizedRowBatch</code> 实例中。</p>

<p>例如，如果输入元素的类型是 <code class="highlighter-rouge">Person</code> 并且它的定义如下：</p>

<div class="codetabs">
  <div data-lang="java">

    <figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="kd">class</span> <span class="nc">Person</span> <span class="o">{</span>
    <span class="kd">private</span> <span class="kd">final</span> <span class="nc">String</span> <span class="n">name</span><span class="o">;</span>
    <span class="kd">private</span> <span class="kd">final</span> <span class="kt">int</span> <span class="n">age</span><span class="o">;</span>
    <span class="o">...</span>
<span class="o">}</span></code></pre></figure>

  </div>
</div>

<p>那么用户可以采用如下方式在子类中将 <code class="highlighter-rouge">Person</code> 对象转化为 <code class="highlighter-rouge">VectorizedRowBatch</code> ：</p>

<div class="codetabs">
  <div data-lang="java">

    <figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="kn">import</span> <span class="nn">org.apache.hadoop.hive.ql.exec.vector.BytesColumnVector</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.hadoop.hive.ql.exec.vector.LongColumnVector</span><span class="o">;</span>

<span class="kn">import</span> <span class="nn">java.io.IOException</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">java.io.Serializable</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">java.nio.charset.StandardCharsets</span><span class="o">;</span>

<span class="kd">public</span> <span class="kd">class</span> <span class="nc">PersonVectorizer</span> <span class="kd">extends</span> <span class="nc">Vectorizer</span><span class="o">&lt;</span><span class="nc">Person</span><span class="o">&gt;</span> <span class="kd">implements</span> <span class="nc">Serializable</span> <span class="o">{</span>
	<span class="kd">public</span> <span class="nf">PersonVectorizer</span><span class="o">(</span><span class="nc">String</span> <span class="n">schema</span><span class="o">)</span> <span class="o">{</span>
		<span class="kd">super</span><span class="o">(</span><span class="n">schema</span><span class="o">);</span>
	<span class="o">}</span>
	<span class="nd">@Override</span>
	<span class="kd">public</span> <span class="kt">void</span> <span class="nf">vectorize</span><span class="o">(</span><span class="nc">Person</span> <span class="n">element</span><span class="o">,</span> <span class="nc">VectorizedRowBatch</span> <span class="n">batch</span><span class="o">)</span> <span class="kd">throws</span> <span class="nc">IOException</span> <span class="o">{</span>
		<span class="nc">BytesColumnVector</span> <span class="n">nameColVector</span> <span class="o">=</span> <span class="o">(</span><span class="nc">BytesColumnVector</span><span class="o">)</span> <span class="n">batch</span><span class="o">.</span><span class="na">cols</span><span class="o">[</span><span class="mi">0</span><span class="o">];</span>
		<span class="nc">LongColumnVector</span> <span class="n">ageColVector</span> <span class="o">=</span> <span class="o">(</span><span class="nc">LongColumnVector</span><span class="o">)</span> <span class="n">batch</span><span class="o">.</span><span class="na">cols</span><span class="o">[</span><span class="mi">1</span><span class="o">];</span>
		<span class="kt">int</span> <span class="n">row</span> <span class="o">=</span> <span class="n">batch</span><span class="o">.</span><span class="na">size</span><span class="o">++;</span>
		<span class="n">nameColVector</span><span class="o">.</span><span class="na">setVal</span><span class="o">(</span><span class="n">row</span><span class="o">,</span> <span class="n">element</span><span class="o">.</span><span class="na">getName</span><span class="o">().</span><span class="na">getBytes</span><span class="o">(</span><span class="nc">StandardCharsets</span><span class="o">.</span><span class="na">UTF_8</span><span class="o">));</span>
		<span class="n">ageColVector</span><span class="o">.</span><span class="na">vector</span><span class="o">[</span><span class="n">row</span><span class="o">]</span> <span class="o">=</span> <span class="n">element</span><span class="o">.</span><span class="na">getAge</span><span class="o">();</span>
	<span class="o">}</span>
<span class="o">}</span></code></pre></figure>

  </div>
  <div data-lang="scala">

    <figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">import</span> <span class="nn">java.nio.charset.StandardCharsets</span>
<span class="k">import</span> <span class="nn">org.apache.hadoop.hive.ql.exec.vector.</span><span class="o">{</span><span class="nc">BytesColumnVector</span><span class="o">,</span> <span class="nc">LongColumnVector</span><span class="o">}</span>

<span class="k">class</span> <span class="nc">PersonVectorizer</span><span class="o">(</span><span class="n">schema</span><span class="k">:</span> <span class="kt">String</span><span class="o">)</span> <span class="k">extends</span> <span class="nc">Vectorizer</span><span class="o">[</span><span class="kt">Person</span><span class="o">](</span><span class="n">schema</span><span class="o">)</span> <span class="o">{</span>

  <span class="k">override</span> <span class="k">def</span> <span class="nf">vectorize</span><span class="o">(</span><span class="n">element</span><span class="k">:</span> <span class="kt">Person</span><span class="o">,</span> <span class="n">batch</span><span class="k">:</span> <span class="kt">VectorizedRowBatch</span><span class="o">)</span><span class="k">:</span> <span class="kt">Unit</span> <span class="o">=</span> <span class="o">{</span>
    <span class="k">val</span> <span class="nv">nameColVector</span> <span class="k">=</span> <span class="nv">batch</span><span class="o">.</span><span class="py">cols</span><span class="o">(</span><span class="mi">0</span><span class="o">).</span><span class="py">asInstanceOf</span><span class="o">[</span><span class="kt">BytesColumnVector</span><span class="o">]</span>
    <span class="k">val</span> <span class="nv">ageColVector</span> <span class="k">=</span> <span class="nv">batch</span><span class="o">.</span><span class="py">cols</span><span class="o">(</span><span class="mi">1</span><span class="o">).</span><span class="py">asInstanceOf</span><span class="o">[</span><span class="kt">LongColumnVector</span><span class="o">]</span>
    <span class="nv">nameColVector</span><span class="o">.</span><span class="py">setVal</span><span class="o">(</span><span class="nv">batch</span><span class="o">.</span><span class="py">size</span> <span class="o">+</span> <span class="mi">1</span><span class="o">,</span> <span class="nv">element</span><span class="o">.</span><span class="py">getName</span><span class="o">.</span><span class="py">getBytes</span><span class="o">(</span><span class="nv">StandardCharsets</span><span class="o">.</span><span class="py">UTF_8</span><span class="o">))</span>
    <span class="nv">ageColVector</span><span class="o">.</span><span class="py">vector</span><span class="o">(</span><span class="nv">batch</span><span class="o">.</span><span class="py">size</span> <span class="o">+</span> <span class="mi">1</span><span class="o">)</span> <span class="k">=</span> <span class="nv">element</span><span class="o">.</span><span class="py">getAge</span>
  <span class="o">}</span>

<span class="o">}</span></code></pre></figure>

  </div>
</div>

<p>为了在应用中使用 ORC 批量编码，用户需要添加如下依赖：</p>

<figure class="highlight"><pre><code class="language-xml" data-lang="xml"><span class="nt">&lt;dependency&gt;</span>
  <span class="nt">&lt;groupId&gt;</span>org.apache.flink<span class="nt">&lt;/groupId&gt;</span>
  <span class="nt">&lt;artifactId&gt;</span>flink-orc_2.11<span class="nt">&lt;/artifactId&gt;</span>
  <span class="nt">&lt;version&gt;</span>1.12.0<span class="nt">&lt;/version&gt;</span>
<span class="nt">&lt;/dependency&gt;</span></code></pre></figure>

<p>然后使用 ORC 格式的 <code class="highlighter-rouge">FileSink</code> 可以通过如下方式创建：</p>

<div class="codetabs">
  <div data-lang="java">

    <figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="kn">import</span> <span class="nn">org.apache.flink.connector.file.sink.FileSink</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.flink.orc.writer.OrcBulkWriterFactory</span><span class="o">;</span>

<span class="nc">String</span> <span class="n">schema</span> <span class="o">=</span> <span class="s">"struct&lt;_col0:string,_col1:int&gt;"</span><span class="o">;</span>
<span class="nc">DataStream</span><span class="o">&lt;</span><span class="nc">Person</span><span class="o">&gt;</span> <span class="n">stream</span> <span class="o">=</span> <span class="o">...;</span>

<span class="kd">final</span> <span class="nc">OrcBulkWriterFactory</span><span class="o">&lt;</span><span class="nc">Person</span><span class="o">&gt;</span> <span class="n">writerFactory</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">OrcBulkWriterFactory</span><span class="o">&lt;&gt;(</span><span class="k">new</span> <span class="nc">PersonVectorizer</span><span class="o">(</span><span class="n">schema</span><span class="o">));</span>

<span class="kd">final</span> <span class="nc">FileSink</span><span class="o">&lt;</span><span class="nc">Person</span><span class="o">&gt;</span> <span class="n">sink</span> <span class="o">=</span> <span class="nc">FileSink</span>
	<span class="o">.</span><span class="na">forBulkFormat</span><span class="o">(</span><span class="n">outputBasePath</span><span class="o">,</span> <span class="n">writerFactory</span><span class="o">)</span>
	<span class="o">.</span><span class="na">build</span><span class="o">();</span>

<span class="n">input</span><span class="o">.</span><span class="na">sinkTo</span><span class="o">(</span><span class="n">sink</span><span class="o">);</span></code></pre></figure>

  </div>
  <div data-lang="scala">

    <figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">import</span> <span class="nn">org.apache.flink.connector.file.sink.FileSink</span><span class="o">;</span>
<span class="k">import</span> <span class="nn">org.apache.flink.orc.writer.OrcBulkWriterFactory</span>

<span class="k">val</span> <span class="nv">schema</span><span class="k">:</span> <span class="kt">String</span> <span class="o">=</span> <span class="s">"struct&lt;_col0:string,_col1:int&gt;"</span>
<span class="k">val</span> <span class="nv">input</span><span class="k">:</span> <span class="kt">DataStream</span><span class="o">[</span><span class="kt">Person</span><span class="o">]</span> <span class="k">=</span> <span class="o">...</span>
<span class="k">val</span> <span class="nv">writerFactory</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">OrcBulkWriterFactory</span><span class="o">(</span><span class="k">new</span> <span class="nc">PersonVectorizer</span><span class="o">(</span><span class="n">schema</span><span class="o">));</span>

<span class="k">val</span> <span class="nv">sink</span><span class="k">:</span> <span class="kt">FileSink</span><span class="o">[</span><span class="kt">Person</span><span class="o">]</span> <span class="k">=</span> <span class="nc">FileSink</span>
    <span class="o">.</span><span class="py">forBulkFormat</span><span class="o">(</span><span class="n">outputBasePath</span><span class="o">,</span> <span class="n">writerFactory</span><span class="o">)</span>
    <span class="o">.</span><span class="py">build</span><span class="o">()</span>

<span class="nv">input</span><span class="o">.</span><span class="py">sinkTo</span><span class="o">(</span><span class="n">sink</span><span class="o">)</span></code></pre></figure>

  </div>
</div>

<p>用户还可以通过 Hadoop <code class="highlighter-rouge">Configuration</code> 和 <code class="highlighter-rouge">Properties</code> 来设置 OrcBulkWriterFactory 中涉及的 Hadoop 属性和 ORC Writer 属性：</p>

<div class="codetabs">
  <div data-lang="java">

    <figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="nc">String</span> <span class="n">schema</span> <span class="o">=</span> <span class="o">...;</span>
<span class="nc">Configuration</span> <span class="n">conf</span> <span class="o">=</span> <span class="o">...;</span>
<span class="nc">Properties</span> <span class="n">writerProperties</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">Properties</span><span class="o">();</span>

<span class="n">writerProps</span><span class="o">.</span><span class="na">setProperty</span><span class="o">(</span><span class="s">"orc.compress"</span><span class="o">,</span> <span class="s">"LZ4"</span><span class="o">);</span>
<span class="c1">// 其它 ORC 支持的属性也可以类似设置。</span>

<span class="kd">final</span> <span class="nc">OrcBulkWriterFactory</span><span class="o">&lt;</span><span class="nc">Person</span><span class="o">&gt;</span> <span class="n">writerFactory</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">OrcBulkWriterFactory</span><span class="o">&lt;&gt;(</span>
    <span class="k">new</span> <span class="nf">PersonVectorizer</span><span class="o">(</span><span class="n">schema</span><span class="o">),</span> <span class="n">writerProperties</span><span class="o">,</span> <span class="n">conf</span><span class="o">);</span></code></pre></figure>

  </div>
  <div data-lang="scala">

    <figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="nv">schema</span><span class="k">:</span> <span class="kt">String</span> <span class="o">=</span> <span class="o">...</span>
<span class="k">val</span> <span class="nv">conf</span><span class="k">:</span> <span class="kt">Configuration</span> <span class="o">=</span> <span class="o">...</span>
<span class="k">val</span> <span class="nv">writerProperties</span><span class="k">:</span> <span class="kt">Properties</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">Properties</span><span class="o">()</span>

<span class="nv">writerProps</span><span class="o">.</span><span class="py">setProperty</span><span class="o">(</span><span class="s">"orc.compress"</span><span class="o">,</span> <span class="s">"LZ4"</span><span class="o">)</span>
<span class="c1">// 其它 ORC 支持的属性也可以类似设置。</span>

<span class="k">val</span> <span class="nv">writerFactory</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">OrcBulkWriterFactory</span><span class="o">(</span>
    <span class="k">new</span> <span class="nc">PersonVectorizer</span><span class="o">(</span><span class="n">schema</span><span class="o">),</span> <span class="n">writerProperties</span><span class="o">,</span> <span class="n">conf</span><span class="o">)</span></code></pre></figure>

  </div>
</div>

<p>完整的 ORC Writer 的属性可以参考 <a href="https://orc.apache.org/docs/hive-config.html">相关文档</a>.</p>

<p>给 ORC 文件添加自定义元数据可以通过在实现的 <code class="highlighter-rouge">vectorize(...)</code> 方法中调用 <code class="highlighter-rouge">addUserMetadata(...)</code> 实现：</p>

<div class="codetabs">
  <div data-lang="java">

    <figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="kd">public</span> <span class="kd">class</span> <span class="nc">PersonVectorizer</span> <span class="kd">extends</span> <span class="nc">Vectorizer</span><span class="o">&lt;</span><span class="nc">Person</span><span class="o">&gt;</span> <span class="kd">implements</span> <span class="nc">Serializable</span> <span class="o">{</span>
	<span class="nd">@Override</span>
	<span class="kd">public</span> <span class="kt">void</span> <span class="nf">vectorize</span><span class="o">(</span><span class="nc">Person</span> <span class="n">element</span><span class="o">,</span> <span class="nc">VectorizedRowBatch</span> <span class="n">batch</span><span class="o">)</span> <span class="kd">throws</span> <span class="nc">IOException</span> <span class="o">{</span>
		<span class="o">...</span>
		<span class="nc">String</span> <span class="n">metadataKey</span> <span class="o">=</span> <span class="o">...;</span>
		<span class="nc">ByteBuffer</span> <span class="n">metadataValue</span> <span class="o">=</span> <span class="o">...;</span>
		<span class="k">this</span><span class="o">.</span><span class="na">addUserMetadata</span><span class="o">(</span><span class="n">metadataKey</span><span class="o">,</span> <span class="n">metadataValue</span><span class="o">);</span>
	<span class="o">}</span>
<span class="o">}</span></code></pre></figure>

  </div>
  <div data-lang="scala">

    <figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">class</span> <span class="nc">PersonVectorizer</span><span class="o">(</span><span class="n">schema</span><span class="k">:</span> <span class="kt">String</span><span class="o">)</span> <span class="k">extends</span> <span class="nc">Vectorizer</span><span class="o">[</span><span class="kt">Person</span><span class="o">](</span><span class="n">schema</span><span class="o">)</span> <span class="o">{</span>

  <span class="k">override</span> <span class="k">def</span> <span class="nf">vectorize</span><span class="o">(</span><span class="n">element</span><span class="k">:</span> <span class="kt">Person</span><span class="o">,</span> <span class="n">batch</span><span class="k">:</span> <span class="kt">VectorizedRowBatch</span><span class="o">)</span><span class="k">:</span> <span class="kt">Unit</span> <span class="o">=</span> <span class="o">{</span>
    <span class="o">...</span>
    <span class="k">val</span> <span class="nv">metadataKey</span><span class="k">:</span> <span class="kt">String</span> <span class="o">=</span> <span class="o">...</span>
    <span class="k">val</span> <span class="nv">metadataValue</span><span class="k">:</span> <span class="kt">ByteBuffer</span> <span class="o">=</span> <span class="o">...</span>
    <span class="nf">addUserMetadata</span><span class="o">(</span><span class="n">metadataKey</span><span class="o">,</span> <span class="n">metadataValue</span><span class="o">)</span>
  <span class="o">}</span>

<span class="o">}</span></code></pre></figure>

  </div>
</div>

<h4 id="hadoop-sequencefile-格式">Hadoop SequenceFile 格式</h4>

<p>在应用中使用 <code class="highlighter-rouge">SequenceFile</code> 批量编码器，你需要添加以下依赖：</p>

<figure class="highlight"><pre><code class="language-xml" data-lang="xml"><span class="nt">&lt;dependency&gt;</span>
  <span class="nt">&lt;groupId&gt;</span>org.apache.flink<span class="nt">&lt;/groupId&gt;</span>
  <span class="nt">&lt;artifactId&gt;</span>flink-sequence-file<span class="nt">&lt;/artifactId&gt;</span>
  <span class="nt">&lt;version&gt;</span>1.12.0<span class="nt">&lt;/version&gt;</span>
<span class="nt">&lt;/dependency&gt;</span></code></pre></figure>

<p>简单的 <code class="highlighter-rouge">SequenceFile</code> 写入示例：</p>

<div class="codetabs">
  <div data-lang="java">

    <figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="kn">import</span> <span class="nn">org.apache.flink.connector.file.sink.FileSink</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.flink.configuration.GlobalConfiguration</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.hadoop.conf.Configuration</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.hadoop.io.LongWritable</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.hadoop.io.SequenceFile</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.hadoop.io.Text</span><span class="o">;</span>


<span class="nc">DataStream</span><span class="o">&lt;</span><span class="nc">Tuple2</span><span class="o">&lt;</span><span class="nc">LongWritable</span><span class="o">,</span> <span class="nc">Text</span><span class="o">&gt;&gt;</span> <span class="n">input</span> <span class="o">=</span> <span class="o">...;</span>
<span class="nc">Configuration</span> <span class="n">hadoopConf</span> <span class="o">=</span> <span class="nc">HadoopUtils</span><span class="o">.</span><span class="na">getHadoopConfiguration</span><span class="o">(</span><span class="nc">GlobalConfiguration</span><span class="o">.</span><span class="na">loadConfiguration</span><span class="o">());</span>
<span class="kd">final</span> <span class="nc">FileSink</span><span class="o">&lt;</span><span class="nc">Tuple2</span><span class="o">&lt;</span><span class="nc">LongWritable</span><span class="o">,</span> <span class="nc">Text</span><span class="o">&gt;&gt;</span> <span class="n">sink</span> <span class="o">=</span> <span class="nc">FileSink</span>
  <span class="o">.</span><span class="na">forBulkFormat</span><span class="o">(</span>
    <span class="n">outputBasePath</span><span class="o">,</span>
    <span class="k">new</span> <span class="nc">SequenceFileWriterFactory</span><span class="o">&lt;&gt;(</span><span class="n">hadoopConf</span><span class="o">,</span> <span class="nc">LongWritable</span><span class="o">.</span><span class="na">class</span><span class="o">,</span> <span class="nc">Text</span><span class="o">.</span><span class="na">class</span><span class="o">))</span>
	<span class="o">.</span><span class="na">build</span><span class="o">();</span>

<span class="n">input</span><span class="o">.</span><span class="na">sinkTo</span><span class="o">(</span><span class="n">sink</span><span class="o">);</span></code></pre></figure>

  </div>
  <div data-lang="scala">

    <figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">import</span> <span class="nn">org.apache.flink.connector.file.sink.FileSink</span><span class="o">;</span>
<span class="k">import</span> <span class="nn">org.apache.flink.configuration.GlobalConfiguration</span>
<span class="k">import</span> <span class="nn">org.apache.hadoop.conf.Configuration</span>
<span class="k">import</span> <span class="nn">org.apache.hadoop.io.LongWritable</span>
<span class="k">import</span> <span class="nn">org.apache.hadoop.io.SequenceFile</span>
<span class="k">import</span> <span class="nn">org.apache.hadoop.io.Text</span><span class="o">;</span>

<span class="k">val</span> <span class="nv">input</span><span class="k">:</span> <span class="kt">DataStream</span><span class="o">[(</span><span class="kt">LongWritable</span>, <span class="kt">Text</span><span class="o">)]</span> <span class="k">=</span> <span class="o">...</span>
<span class="k">val</span> <span class="nv">hadoopConf</span><span class="k">:</span> <span class="kt">Configuration</span> <span class="o">=</span> <span class="nv">HadoopUtils</span><span class="o">.</span><span class="py">getHadoopConfiguration</span><span class="o">(</span><span class="nv">GlobalConfiguration</span><span class="o">.</span><span class="py">loadConfiguration</span><span class="o">())</span>
<span class="k">val</span> <span class="nv">sink</span><span class="k">:</span> <span class="kt">FileSink</span><span class="o">[(</span><span class="kt">LongWritable</span>, <span class="kt">Text</span><span class="o">)]</span> <span class="k">=</span> <span class="nc">FileSink</span>
  <span class="o">.</span><span class="py">forBulkFormat</span><span class="o">(</span>
    <span class="n">outputBasePath</span><span class="o">,</span>
    <span class="k">new</span> <span class="nc">SequenceFileWriterFactory</span><span class="o">(</span><span class="n">hadoopConf</span><span class="o">,</span> <span class="nv">LongWritable</span><span class="o">.</span><span class="py">class</span><span class="o">,</span> <span class="nv">Text</span><span class="o">.</span><span class="py">class</span><span class="o">))</span>
	<span class="o">.</span><span class="py">build</span><span class="o">()</span>

<span class="nv">input</span><span class="o">.</span><span class="py">sinkTo</span><span class="o">(</span><span class="n">sink</span><span class="o">)</span></code></pre></figure>

  </div>
</div>

<p><code class="highlighter-rouge">SequenceFileWriterFactory</code> 支持附加构造函数参数指定压缩设置。</p>

<h2 id="桶分配">桶分配</h2>

<p>桶分配逻辑定义了如何将数据结构化为基本输出目录中的子目录</p>

<p>行格式和批量格式都使用 <a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/api/java/org/apache/flink/streaming/api/functions/sink/filesystem/bucketassigners/DateTimeBucketAssigner.html">DateTimeBucketAssigner</a> 作为默认的分配器。
默认情况下，DateTimeBucketAssigner 基于系统默认时区每小时创建一个桶，格式如下： <code class="highlighter-rouge">yyyy-MM-dd--HH</code> 。日期格式（即桶的大小）和时区都可以手动配置。</p>

<p>我们可以在格式构建器上调用 <code class="highlighter-rouge">.withBucketAssigner(assigner)</code> 来自定义 <a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/api/java/org/apache/flink/streaming/api/functions/sink/filesystem/BucketAssigner.html">BucketAssigner</a> 。</p>

<p>Flink 有两个内置的 BucketAssigners ：</p>

<ul>
  <li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/api/java/org/apache/flink/streaming/api/functions/sink/filesystem/bucketassigners/DateTimeBucketAssigner.html">DateTimeBucketAssigner</a> ：默认基于时间的分配器</li>
  <li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/api/java/org/apache/flink/streaming/api/functions/sink/filesystem/bucketassigners/BasePathBucketAssigner.html">BasePathBucketAssigner</a> ：将所有部分文件（part file）存储在基本路径中的分配器（单个全局桶）</li>
</ul>

<h2 id="滚动策略">滚动策略</h2>

<p>在流模式下，滚动策略 <a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/api/java/org/apache/flink/streaming/api/functions/sink/filesystem/RollingPolicy.html">RollingPolicy</a> 定义了指定的文件在何时关闭（closed）并将其变为 Pending 状态，随后变为 Finished 状态。处于 Pending 状态的文件会在下一次 Checkpoint 时变为 Finished 状态，通过设置 Checkpoint 间隔时间，可以控制部分文件（part file）对下游读取者可用的速度、大小和数量。在批模式下，临时文件只会在作业处理完所有输入数据后才会变成 Finished 状态，此时滚动策略可以用来控制每个文件的大小。</p>

<p>Flink 有两个内置的滚动策略：</p>

<ul>
  <li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/api/java/org/apache/flink/streaming/api/functions/sink/filesystem/rollingpolicies/DefaultRollingPolicy.html">DefaultRollingPolicy</a></li>
  <li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/api/java/org/apache/flink/streaming/api/functions/sink/filesystem/rollingpolicies/OnCheckpointRollingPolicy.html">OnCheckpointRollingPolicy</a></li>
</ul>

<h2 id="部分文件part-file-生命周期">部分文件（part file） 生命周期</h2>

<p>为了在下游系统中使用 FileSink 的输出，我们需要了解输出文件的命名规则和生命周期。</p>

<p>部分文件（part file）可以处于以下三种状态之一：</p>
<ol>
  <li><strong>In-progress</strong> ：当前文件正在写入中。</li>
  <li><strong>Pending</strong> ：当处于 In-progress 状态的文件关闭（closed）了，就变为 Pending 状态。</li>
  <li><strong>Finished</strong> ：在成功的 Checkpoint 后（流模式）或作业处理完所有输入数据后（批模式），Pending 状态将变为 Finished 状态。</li>
</ol>

<p>处于 Finished 状态的文件不会再被修改，可以被下游系统安全地读取。</p>

<div class="alert alert-info">
     <b>重要:</b> 部分文件的索引在每个 subtask 内部是严格递增的（按文件创建顺序）。但是索引并不总是连续的。当 Job 重启后，所有部分文件的索引从 `max part index + 1` 开始，
     这里的 `max part index` 是所有 subtask 中索引的最大值。
</div>

<p>对于每个活动的桶，Writer 在任何时候都只有一个处于 In-progress 状态的部分文件（part file），但是可能有几个 Penging 和 Finished 状态的部分文件（part file）。</p>

<p><strong>部分文件（part file）例子</strong></p>

<p>为了更好地理解这些文件的生命周期，让我们来看一个包含 2 个 Sink Subtask 的简单例子：</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>└── 2019-08-25--12
    ├── part-4005733d-a830-4323-8291-8866de98b582-0.inprogress.bd053eb0-5ecf-4c85-8433-9eff486ac334
    └── part-81fc4980-a6af-41c8-9937-9939408a734b-0.inprogress.ea65a428-a1d0-4a0b-bbc5-7a436a75e575
</code></pre></div></div>

<p>当部分文件 <code class="highlighter-rouge">part-81fc4980-a6af-41c8-9937-9939408a734b-0</code> 被滚动（假设它变得太大了）时，它将成为 Pending 状态，但是它还没有被重命名。然后 Sink 会创建一个新的部分文件： <code class="highlighter-rouge">part-81fc4980-a6af-41c8-9937-9939408a734b-1</code>：</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>└── 2019-08-25--12
    ├── part-4005733d-a830-4323-8291-8866de98b582-0.inprogress.bd053eb0-5ecf-4c85-8433-9eff486ac334
    ├── part-81fc4980-a6af-41c8-9937-9939408a734b-0.inprogress.ea65a428-a1d0-4a0b-bbc5-7a436a75e575
    └── part-81fc4980-a6af-41c8-9937-9939408a734b-1.inprogress.bc279efe-b16f-47d8-b828-00ef6e2fbd11
</code></pre></div></div>

<p><code class="highlighter-rouge">part-81fc4980-a6af-41c8-9937-9939408a734b-0</code> 现在处于 Pending 状态等待完成，在下一次成功的 Checkpoint 后，它会变成 Finished 状态：</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>└── 2019-08-25--12
    ├── part-4005733d-a830-4323-8291-8866de98b582-0.inprogress.bd053eb0-5ecf-4c85-8433-9eff486ac334
    ├── part-81fc4980-a6af-41c8-9937-9939408a734b-0
    └── part-81fc4980-a6af-41c8-9937-9939408a734b-1.inprogress.bc279efe-b16f-47d8-b828-00ef6e2fbd11
</code></pre></div></div>

<p>根据分桶策略创建新的桶，但是这并不会影响当前处于 In-progress 状态的文件：</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>└── 2019-08-25--12
    ├── part-4005733d-a830-4323-8291-8866de98b582-0.inprogress.bd053eb0-5ecf-4c85-8433-9eff486ac334
    ├── part-81fc4980-a6af-41c8-9937-9939408a734b-0
    └── part-81fc4980-a6af-41c8-9937-9939408a734b-1.inprogress.bc279efe-b16f-47d8-b828-00ef6e2fbd11
└── 2019-08-25--13
    └── part-4005733d-a830-4323-8291-8866de98b582-0.inprogress.2b475fec-1482-4dea-9946-eb4353b475f1
</code></pre></div></div>

<p>因为分桶策略基于每条记录进行评估，所以旧桶仍然可以接受新的记录。</p>

<h3 id="部分文件的配置项">部分文件的配置项</h3>

<p>已经完成的文件和进行中的文件仅能通过文件名格式进行区分。</p>

<p>默认情况下，文件命名格式如下所示：</p>
<ul>
  <li><strong>In-progress / Pending:</strong> <code class="highlighter-rouge">part-&lt;uid&gt;-&lt;partFileIndex&gt;.inprogress.uid</code></li>
  <li><strong>FINISHED:</strong> <code class="highlighter-rouge">part-&lt;uid&gt;-&lt;partFileIndex&gt;</code></li>
</ul>

<p>其中 uid 是在 Sink 的各个 task 在启动时随机生成的 id，这些 id 是不支持容错的，在 task 重启后 id 会重新生成。</p>

<p>Flink 允许用户通过 <code class="highlighter-rouge">OutputFileConfig</code> 指定部分文件名的前缀和后缀。
举例来说，前缀设置为 “prefix” 以及后缀设置为 “.ext” 之后，Sink 创建的文件名如下所示：</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>└── 2019-08-25--12
    ├── prefix-4005733d-a830-4323-8291-8866de98b582-0.ext
    ├── prefix-4005733d-a830-4323-8291-8866de98b582-1.ext.inprogress.bd053eb0-5ecf-4c85-8433-9eff486ac334
    ├── prefix-81fc4980-a6af-41c8-9937-9939408a734b-0.ext
    └── prefix-81fc4980-a6af-41c8-9937-9939408a734b-1.ext.inprogress.bc279efe-b16f-47d8-b828-00ef6e2fbd11
</code></pre></div></div>

<p>用户可以通过如下方式设置 <code class="highlighter-rouge">OutputFileConfig</code>:</p>

<div class="codetabs">
  <div data-lang="java">

    <figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="nc">OutputFileConfig</span> <span class="n">config</span> <span class="o">=</span> <span class="nc">OutputFileConfig</span>
 <span class="o">.</span><span class="na">builder</span><span class="o">()</span>
 <span class="o">.</span><span class="na">withPartPrefix</span><span class="o">(</span><span class="s">"prefix"</span><span class="o">)</span>
 <span class="o">.</span><span class="na">withPartSuffix</span><span class="o">(</span><span class="s">".ext"</span><span class="o">)</span>
 <span class="o">.</span><span class="na">build</span><span class="o">();</span>
            
<span class="nc">FileSink</span><span class="o">&lt;</span><span class="nc">Tuple2</span><span class="o">&lt;</span><span class="nc">Integer</span><span class="o">,</span> <span class="nc">Integer</span><span class="o">&gt;&gt;</span> <span class="n">sink</span> <span class="o">=</span> <span class="nc">FileSink</span>
 <span class="o">.</span><span class="na">forRowFormat</span><span class="o">((</span><span class="k">new</span> <span class="nc">Path</span><span class="o">(</span><span class="n">outputPath</span><span class="o">),</span> <span class="k">new</span> <span class="nc">SimpleStringEncoder</span><span class="o">&lt;&gt;(</span><span class="s">"UTF-8"</span><span class="o">))</span>
 <span class="o">.</span><span class="na">withBucketAssigner</span><span class="o">(</span><span class="k">new</span> <span class="nc">KeyBucketAssigner</span><span class="o">())</span>
 <span class="o">.</span><span class="na">withRollingPolicy</span><span class="o">(</span><span class="nc">OnCheckpointRollingPolicy</span><span class="o">.</span><span class="na">build</span><span class="o">())</span>
 <span class="o">.</span><span class="na">withOutputFileConfig</span><span class="o">(</span><span class="n">config</span><span class="o">)</span>
 <span class="o">.</span><span class="na">build</span><span class="o">();</span></code></pre></figure>

  </div>
  <div data-lang="scala">

    <figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="nv">config</span> <span class="k">=</span> <span class="nc">OutputFileConfig</span>
 <span class="o">.</span><span class="py">builder</span><span class="o">()</span>
 <span class="o">.</span><span class="py">withPartPrefix</span><span class="o">(</span><span class="s">"prefix"</span><span class="o">)</span>
 <span class="o">.</span><span class="py">withPartSuffix</span><span class="o">(</span><span class="s">".ext"</span><span class="o">)</span>
 <span class="o">.</span><span class="py">build</span><span class="o">()</span>
            
<span class="k">val</span> <span class="nv">sink</span> <span class="k">=</span> <span class="nc">FileSink</span>
 <span class="o">.</span><span class="py">forRowFormat</span><span class="o">(</span><span class="k">new</span> <span class="nc">Path</span><span class="o">(</span><span class="n">outputPath</span><span class="o">),</span> <span class="k">new</span> <span class="nc">SimpleStringEncoder</span><span class="o">[</span><span class="kt">String</span><span class="o">](</span><span class="s">"UTF-8"</span><span class="o">))</span>
 <span class="o">.</span><span class="py">withBucketAssigner</span><span class="o">(</span><span class="k">new</span> <span class="nc">KeyBucketAssigner</span><span class="o">())</span>
 <span class="o">.</span><span class="py">withRollingPolicy</span><span class="o">(</span><span class="nv">OnCheckpointRollingPolicy</span><span class="o">.</span><span class="py">build</span><span class="o">())</span>
 <span class="o">.</span><span class="py">withOutputFileConfig</span><span class="o">(</span><span class="n">config</span><span class="o">)</span>
 <span class="o">.</span><span class="py">build</span><span class="o">()</span></code></pre></figure>

  </div>
</div>

<h2 id="重要注意事项">重要注意事项</h2>

<h3 id="通用注意事项">通用注意事项</h3>

<p><span class="label label-danger">重要提示 1</span>: 使用 Hadoop &lt; 2.7 时，请使用 <code class="highlighter-rouge">OnCheckpointRollingPolicy</code> 滚动策略，该策略会在每次检查点时进行文件滚动。
这样做的原因是如果部分文件的生命周期跨多个检查点，当 <code class="highlighter-rouge">FileSink</code> 从之前的检查点进行恢复时会调用文件系统的 <code class="highlighter-rouge">truncate()</code> 方法清理 in-progress 文件中未提交的数据。
Hadoop 2.7 之前的版本不支持这个方法，因此 Flink 会报异常。</p>

<p><span class="label label-danger">重要提示 2</span>: 鉴于 Flink 的 sink 以及 UDF 通常不会区分作业的正常结束（比如有限流）和异常终止，因此正常结束作业的最后一批 in-progress 文件不会被转换到 “完成” 状态。</p>

<p><span class="label label-danger">重要提示 3</span>: Flink 以及 <code class="highlighter-rouge">FileSink</code> 不会覆盖已经提交的数据。因此如果尝试从一个包含 in-progress 文件的旧 checkpoint/savepoint 恢复，
且这些 in-progress 文件会被接下来的成功 checkpoint 提交，Flink 会因为无法找到 in-progress 文件而抛异常，从而恢复失败。</p>

<p><span class="label label-danger">重要提示 4</span>: 目前 <code class="highlighter-rouge">FileSink</code> 只支持三种文件系统: HDFS、S3和Local。如果配置了不支持的文件系统，在执行的时候 Flink 会抛出异常。</p>

<h3 id="batch-模式">Batch 模式</h3>

<p><span class="label label-danger">重要提示 1</span>: 尽管负责写出数据的 Writer 会使用用户提定的并发，负责提交文件的 Committer 将固定并发度为1。</p>

<p><span class="label label-danger">Important Note 2</span>: 批模式下只有在所有输入都被处理后 Pending 文件才会被提交，即转为 Finished 状态。</p>

<p><span class="label label-danger">Important Note 3</span>: 在高可用模式下，如果在 Committer 提交文件时发生了 JobManager 重启，已提交的数据可能会被重复产生。这一问题将在后续版本中修复。</p>

<h3 id="s3-特有的注意事项">S3 特有的注意事项</h3>

<p><span class="label label-danger">重要提示 1</span>: 对于 S3，<code class="highlighter-rouge">FileSink</code>  只支持基于 <a href="https://hadoop.apache.org/">Hadoop</a> 
的文件系统实现，不支持基于 <a href="https://prestodb.io/">Presto</a> 的实现。如果想使用 <code class="highlighter-rouge">FileSink</code> 向 S3 写入数据并且将 
checkpoint 放在基于 Presto 的文件系统，建议明确指定 <em>“s3a://”</em> （for Hadoop）作为sink的目标路径方案，并且为 checkpoint 路径明确指定 <em>“s3p://”</em> （for Presto）。
如果 Sink 和 checkpoint 都使用 <em>“s3://”</em> 路径的话，可能会导致不可预知的行为，因为双方的实现都在“监听”这个路径。</p>

<p><span class="label label-danger">重要提示 2</span>: <code class="highlighter-rouge">FileSink</code> 使用 S3 的 <a href="https://docs.aws.amazon.com/AmazonS3/latest/dev/mpuoverview.html">Multi-part Upload</a>
（后续使用MPU代替）特性可以保证精确一次的语义。这个特性支持以独立的块（因此被称为”multi-part”）模式上传文件，当 MPU 的所有部分文件
成功上传之后，可以合并成原始文件。对于失效的 MPUs，S3 提供了一个基于桶生命周期的规则，用户可以用这个规则来丢弃在指定时间内未完成的MPU。
如果在一些部分文件还未上传时触发 savepoint，并且这个规则设置的比较严格，这意味着相关的 MPU在作业重启之前可能会超时。后续的部分文件没
有写入到 savepoint, 那么在 Flink 作业从 savepoint 恢复时，会因为拿不到缺失的部分文件，导致任务失败并抛出异常。</p>

<p><a href="#top" class="top pull-right"><span class="glyphicon glyphicon-chevron-up"></span> Back to top</a></p>



<div class="footer">
  <a href="https://cwiki.apache.org/confluence/display/FLINK/Flink+Translation+Specifications" target="_blank">
    
      想参与贡献翻译？
    
  </a>
</div>


        </div>
      </div>
    </div><!-- /.container -->

    <!-- default code tab -->
    <script>var defaultCodeTab = "";</script>

    <!-- jQuery (necessary for Bootstrap's JavaScript plugins) -->
    <script src="//ci.apache.org/projects/flink/flink-docs-release-1.12/page/js/jquery.min.js"></script>
    <!-- Include all compiled plugins (below), or include individual files as needed -->
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.4/js/bootstrap.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/anchor-js/3.1.0/anchor.min.js"></script>
    <script src="//ci.apache.org/projects/flink/flink-docs-release-1.12/page/js/flink.js"></script>

    <!-- Google Analytics -->
    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-52545728-1', 'auto');
      ga('send', 'pageview');
    </script>

    <!-- Disqus -->
    
  </body>
</html>
