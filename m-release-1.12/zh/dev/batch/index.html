<!--
Licensed to the Apache Software Foundation (ASF) under one
or more contributor license agreements.  See the NOTICE file
distributed with this work for additional information
regarding copyright ownership.  The ASF licenses this file
to you under the Apache License, Version 2.0 (the
"License"); you may not use this file except in compliance
with the License.  You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing,
software distributed under the License is distributed on an
"AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
KIND, either express or implied.  See the License for the
specific language governing permissions and limitations
under the License.
-->
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->
    <title>Apache Flink 1.12 Documentation: Flink DataSet API 编程指南</title>
    <link rel="shortcut icon" href="//ci.apache.org/projects/flink/flink-docs-release-1.12/page/favicon.ico" type="image/x-icon">
    <link rel="icon" href="//ci.apache.org/projects/flink/flink-docs-release-1.12/page/favicon.ico" type="image/x-icon">
    <link rel="canonical" href="//ci.apache.org/projects/flink/flink-docs-stable/zh/dev/batch/">

    <!-- Bootstrap -->
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.4/css/bootstrap.min.css">
    <link rel="stylesheet" href="//ci.apache.org/projects/flink/flink-docs-release-1.12/page/css/flink.css">
    <link rel="stylesheet" href="//ci.apache.org/projects/flink/flink-docs-release-1.12/page/css/syntax.css">
    <link rel="stylesheet" href="//ci.apache.org/projects/flink/flink-docs-release-1.12/page/css/codetabs.css">
    <link rel="stylesheet" href="//ci.apache.org/projects/flink/flink-docs-release-1.12/page/font-awesome/css/font-awesome.min.css">
    
    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
      <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->
  </head>
  <body>
    

    <!-- Main content. -->
    <div class="container">
      
      <div class="row">
        <div class="col-lg-3" id="sidenavcol">
          <div class="sidenav-logo">
  <p><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/"><img class="bottom" alt="Apache Flink" src="//ci.apache.org/projects/flink/flink-docs-release-1.12/page/img/navbar-brand-logo.jpg"></a> v1.12</p>
</div>
<ul id="sidenav">
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/"><i class="fa fa-home title" aria-hidden="true"></i> Home</a></li><hr class="section-break"></hr>
<li><a href="#collapse-2" data-toggle="collapse"><i class="fa fa-rocket title appetizer" aria-hidden="true"></i> Try Flink<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-2"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/try-flink/local_installation.html">本地模式安装</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/try-flink/datastream_api.html">基于 DataStream API 实现欺诈检测</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/try-flink/table_api.html">基于 Table API 实现实时报表</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/try-flink/flink-operations-playground.html">Flink 操作场景</a></li>
</ul></div></li>
<li><a href="#collapse-8" data-toggle="collapse"><i class="fa fa-hand-paper-o title appetizer" aria-hidden="true"></i> 实践练习<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-8"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/learn-flink/">概览</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/learn-flink/datastream_api.html">DataStream API 简介</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/learn-flink/etl.html">数据管道 & ETL</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/learn-flink/streaming_analytics.html">流式分析</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/learn-flink/event_driven.html">事件驱动应用</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/learn-flink/fault_tolerance.html">容错处理</a></li>
</ul></div></li>
<li><a href="#collapse-15" data-toggle="collapse"><i class="fa fa-map-o title appetizer" aria-hidden="true"></i> 概念透析<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-15"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/concepts/index.html">概览</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/concepts/stateful-stream-processing.html">有状态流处理</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/concepts/timely-stream-processing.html">及时流处理</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/concepts/flink-architecture.html">Flink 架构</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/concepts/glossary.html">词汇表</a></li>
</ul></div></li><hr class="section-break"></hr>
<li><a href="#collapse-21" data-toggle="collapse"class="active"><i class="fa fa-code title maindish" aria-hidden="true"></i> 应用开发</a><div class="collapse in" id="collapse-21"><ul>
<li><a href="#collapse-22" data-toggle="collapse">DataStream API<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-22"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/datastream_api.html">概览</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/datastream_execution_mode.html">Execution Mode (Batch/Streaming)</a></li>
<li><a href="#collapse-24" data-toggle="collapse">事件时间<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-24"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/event_time.html">概览</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/event_timestamps_watermarks.html">生成 Watermark</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/event_timestamp_extractors.html">内置 Watermark 生成器</a></li>
</ul></div></li>
<li><a href="#collapse-28" data-toggle="collapse">状态与容错<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-28"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/stream/state/">概览</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/stream/state/state.html">Working with State</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/stream/state/broadcast_state.html">Broadcast State 模式</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/stream/state/checkpointing.html">Checkpointing</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/stream/state/queryable_state.html">Queryable State</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/stream/state/state_backends.html">State Backends</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/stream/state/schema_evolution.html">状态数据结构升级</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/stream/state/custom_serialization.html">自定义状态序列化</a></li>
</ul></div></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/user_defined_functions.html">用户自定义 Functions</a></li>
<li><a href="#collapse-38" data-toggle="collapse">算子<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-38"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/stream/operators/">概览</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/stream/operators/windows.html">窗口</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/stream/operators/joining.html">Joining</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/stream/operators/process_function.html">Process Function</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/stream/operators/asyncio.html">异步 I/O</a></li>
</ul></div></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/stream/sources.html">Data Sources</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/stream/side_output.html">旁路输出</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/application_parameters.html">Handling Application Parameters</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/stream/testing.html">测试</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/stream/experimental.html">实验功能</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/scala_api_extensions.html">Scala API Extensions</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/java_lambdas.html">Java Lambda 表达式</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/project-configuration.html">Project Configuration</a></li>
</ul></div></li>
<li><a href="#collapse-53" data-toggle="collapse"class="active">DataSet API</a><div class="collapse in" id="collapse-53"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/batch/"class="active">概览</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/batch/dataset_transformations.html">Transformations</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/batch/iterations.html">迭代</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/batch/zip_elements_guide.html">Zipping Elements</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/batch/hadoop_compatibility.html">Hadoop 兼容</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/local_execution.html">本地执行</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/cluster_execution.html">集群执行</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/batch/examples.html">Batch 示例</a></li>
</ul></div></li>
<li><a href="#collapse-62" data-toggle="collapse">Table API & SQL<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-62"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/table/">概览</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/table/common.html">概念与通用 API</a></li>
<li><a href="#collapse-64" data-toggle="collapse">流式概念<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-64"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/table/streaming/">概览</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/table/streaming/dynamic_tables.html">动态表 (Dynamic Table)</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/table/streaming/time_attributes.html">时间属性</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/table/streaming/joins.html">流上的 Join</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/table/streaming/temporal_tables.html">时态表（Temporal Tables）</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/table/streaming/match_recognize.html">模式检测</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/table/streaming/query_configuration.html">Query Configuration</a></li>
</ul></div></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/table/types.html">数据类型</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/table/tableApi.html">Table API</a></li>
<li><a href="#collapse-74" data-toggle="collapse">SQL<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-74"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/table/sql/">概览</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/table/sql/queries.html">查询语句</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/table/sql/create.html">CREATE 语句</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/table/sql/drop.html">DROP 语句</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/table/sql/alter.html">ALTER 语句</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/table/sql/insert.html">INSERT 语句</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/table/sql/hints.html">SQL Hints</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/table/sql/describe.html">DESCRIBE 语句</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/table/sql/explain.html">EXPLAIN 语句</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/table/sql/use.html">USE 语句</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/table/sql/show.html">SHOW 语句</a></li>
</ul></div></li>
<li><a href="#collapse-86" data-toggle="collapse">函数<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-86"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/table/functions/">概览</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/table/functions/systemFunctions.html">系统（内置）函数</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/table/functions/udfs.html">自定义函数</a></li>
</ul></div></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/table/modules.html">模块</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/table/catalogs.html">Catalogs</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/table/sqlClient.html">SQL 客户端</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/table/config.html">配置</a></li>
<li><a href="#collapse-94" data-toggle="collapse">Performance Tuning<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-94"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/table/tuning/streaming_aggregation_optimization.html">流式聚合</a></li>
</ul></div></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/table/sourceSinks.html">User-defined Sources & Sinks</a></li>
</ul></div></li>
<li><a href="#collapse-99" data-toggle="collapse">Python API<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-99"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/python/">概览</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/python/installation.html">环境安装</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/python/table_api_tutorial.html">Table API 教程</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/python/datastream_tutorial.html">DataStream API 教程</a></li>
<li><a href="#collapse-103" data-toggle="collapse">Table API用户指南<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-103"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/python/table-api-users-guide/intro_to_table_api.html">Python Table API 简介</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/python/table-api-users-guide/table_environment.html">TableEnvironment</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/python/table-api-users-guide/operations.html">Operations</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/python/table-api-users-guide/python_types.html">数据类型</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/python/table-api-users-guide/built_in_functions.html">系统（内置）函数</a></li>
<li><a href="#collapse-109" data-toggle="collapse">自定义函数<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-109"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/python/table-api-users-guide/udfs/python_udfs.html">普通自定义函数（UDF）</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/python/table-api-users-guide/udfs/vectorized_python_udfs.html">向量化自定义函数</a></li>
</ul></div></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/python/table-api-users-guide/conversion_of_pandas.html">PyFlink Table 和 Pandas DataFrame 互转</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/python/table-api-users-guide/dependency_management.html">依赖管理</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/python/table-api-users-guide/sql.html">SQL</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/python/table-api-users-guide/catalogs.html">Catalogs</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/python/table-api-users-guide/metrics.html">指标</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/python/table-api-users-guide/python_table_api_connectors.html">连接器</a></li>
</ul></div></li>
<li><a href="#collapse-120" data-toggle="collapse">DataStream API用户指南<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-120"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/python/datastream-api-users-guide/data_types.html">数据类型</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/python/datastream-api-users-guide/operators.html">算子</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/python/datastream-api-users-guide/dependency_management.html">依赖管理</a></li>
</ul></div></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/python/python_config.html">配置</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/python/environment_variables.html">环境变量</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/python/faq.html">常见问题</a></li>
</ul></div></li>
<li><a href="#collapse-129" data-toggle="collapse">数据类型以及序列化<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-129"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/types_serialization.html">概览</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/custom_serializers.html">自定义序列化器</a></li>
</ul></div></li>
<li><a href="#collapse-132" data-toggle="collapse">管理执行<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-132"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/execution_configuration.html">执行配置</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/packaging.html">程序打包</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/parallel.html">并行执行</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/execution_plans.html">执行计划</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/task_failure_recovery.html">Task 故障恢复</a></li>
</ul></div></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/migration.html">API 迁移指南</a></li>
</ul></div></li>
<li><a href="#collapse-141" data-toggle="collapse"><i class="fa fa-book title maindish" aria-hidden="true"></i> Libraries<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-141"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/libs/cep.html">事件处理 (CEP)</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/libs/state_processor_api.html">State Processor API</a></li>
<li><a href="#collapse-144" data-toggle="collapse">图计算: Gelly<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-144"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/libs/gelly/">概览</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/libs/gelly/graph_api.html">Graph API</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/libs/gelly/iterative_graph_processing.html">Iterative Graph Processing</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/libs/gelly/library_methods.html">Library Methods</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/libs/gelly/graph_algorithms.html">Graph Algorithms</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/libs/gelly/graph_generators.html">Graph Generators</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/libs/gelly/bipartite_graph.html">Bipartite Graph</a></li>
</ul></div></li>
</ul></div></li>
<li><a href="#collapse-153" data-toggle="collapse"><i class="fa fa-random title maindish" aria-hidden="true"></i> Connectors<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-153"><ul>
<li><a href="#collapse-154" data-toggle="collapse">DataStream Connectors<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-154"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/connectors/">概览</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/connectors/guarantees.html">容错保证</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/connectors/kafka.html">Kafka</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/connectors/cassandra.html">Cassandra</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/connectors/kinesis.html">Kinesis</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/connectors/elasticsearch.html">Elasticsearch</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/connectors/file_sink.html">File Sink</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/connectors/streamfile_sink.html">Streaming File Sink</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/connectors/rabbitmq.html">RabbitMQ</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/connectors/nifi.html">NiFi</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/connectors/pubsub.html">Google Cloud PubSub</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/connectors/twitter.html">Twitter</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/connectors/jdbc.html">JDBC</a></li>
</ul></div></li>
<li><a href="#collapse-168" data-toggle="collapse">Table & SQL Connectors<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-168"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/table/connectors/">概览</a></li>
<li><a href="#collapse-169" data-toggle="collapse">Formats<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-169"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/table/connectors/formats/">概览</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/table/connectors/formats/csv.html">CSV</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/table/connectors/formats/json.html">JSON</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/table/connectors/formats/avro-confluent.html">Confluent Avro</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/table/connectors/formats/avro.html">Avro</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/table/connectors/formats/debezium.html">Debezium</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/table/connectors/formats/canal.html">Canal</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/table/connectors/formats/maxwell.html">Maxwell</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/table/connectors/formats/parquet.html">Parquet</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/table/connectors/formats/orc.html">Orc</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/table/connectors/formats/raw.html">Raw</a></li>
</ul></div></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/table/connectors/kafka.html">Kafka</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/table/connectors/upsert-kafka.html">Upsert Kafka</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/table/connectors/kinesis.html">Kinesis</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/table/connectors/jdbc.html">JDBC</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/table/connectors/elasticsearch.html">Elasticsearch</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/table/connectors/filesystem.html">FileSystem</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/table/connectors/hbase.html">HBase</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/table/connectors/datagen.html">DataGen</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/table/connectors/print.html">Print</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/table/connectors/blackhole.html">BlackHole</a></li>
<li><a href="#collapse-191" data-toggle="collapse">Hive<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-191"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/table/connectors/hive/">概览</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/table/connectors/hive/hive_catalog.html">Hive Catalog</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/table/connectors/hive/hive_dialect.html">Hive 方言</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/table/connectors/hive/hive_read_write.html">Hive Read & Write</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/table/connectors/hive/hive_functions.html">Hive 函数</a></li>
</ul></div></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/table/connectors/downloads.html">下载</a></li>
</ul></div></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/batch/connectors.html">DataSet Connectors</a></li>
</ul></div></li>
<li><a href="#collapse-201" data-toggle="collapse"><i class="fa fa-sliders title maindish" aria-hidden="true"></i> Deployment<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-201"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/deployment/">概览</a></li>
<li><a href="#collapse-202" data-toggle="collapse">Resource Providers<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-202"><ul>
<li><a href="#collapse-203" data-toggle="collapse">Standalone<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-203"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/deployment/resource-providers/standalone/">概览</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/deployment/resource-providers/standalone/local.html">本地集群</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/deployment/resource-providers/standalone/docker.html">Docker</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/deployment/resource-providers/standalone/kubernetes.html">Kubernetes</a></li>
</ul></div></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/deployment/resource-providers/native_kubernetes.html">Native Kubernetes</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/deployment/resource-providers/yarn.html">YARN</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/deployment/resource-providers/mesos.html">Mesos</a></li>
</ul></div></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/deployment/config.html">配置参数</a></li>
<li><a href="#collapse-213" data-toggle="collapse">内存配置<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-213"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/deployment/memory/mem_setup.html">配置 Flink 进程的内存</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/deployment/memory/mem_setup_tm.html">配置 TaskManager 内存</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/deployment/memory/mem_setup_jobmanager.html">配置 JobManager 内存</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/deployment/memory/mem_tuning.html">调优指南</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/deployment/memory/mem_trouble.html">常见问题</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/deployment/memory/mem_migration.html">升级指南</a></li>
</ul></div></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/deployment/cli.html">Command-Line Interface</a></li>
<li><a href="#collapse-222" data-toggle="collapse">文件系统<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-222"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/deployment/filesystems/">概览</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/deployment/filesystems/common.html">通用配置</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/deployment/filesystems/s3.html">Amazon S3</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/deployment/filesystems/oss.html">阿里云 OSS</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/deployment/filesystems/azure.html">Azure Blob 存储</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/deployment/filesystems/plugins.html">Plugins</a></li>
</ul></div></li>
<li><a href="#collapse-229" data-toggle="collapse">High Availability (HA)<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-229"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/deployment/ha/">概览</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/deployment/ha/zookeeper_ha.html">ZooKeeper HA Services</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/deployment/ha/kubernetes_ha.html">Kubernetes HA Services</a></li>
</ul></div></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/deployment/metric_reporters.html">Metric Reporters</a></li>
<li><a href="#collapse-234" data-toggle="collapse">Security<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-234"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/deployment/security/security-ssl.html">SSL 设置</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/deployment/security/security-kerberos.html">Kerberos</a></li>
</ul></div></li>
<li><a href="#collapse-238" data-toggle="collapse">REPLs<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-238"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/deployment/repls/python_shell.html">Python REPL</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/deployment/repls/scala_shell.html">Scala REPL</a></li>
</ul></div></li>
<li><a href="#collapse-242" data-toggle="collapse">Advanced<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-242"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/deployment/advanced/external_resources.html">扩展资源</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/deployment/advanced/historyserver.html">History Server</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/deployment/advanced/logging.html">日志</a></li>
</ul></div></li>
</ul></div></li>
<li><a href="#collapse-248" data-toggle="collapse"><i class="fa fa-cogs title maindish" aria-hidden="true"></i> Operations<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-248"><ul>
<li><a href="#collapse-249" data-toggle="collapse">状态与容错<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-249"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/ops/state/checkpoints.html">Checkpoints</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/ops/state/savepoints.html">Savepoints</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/ops/state/state_backends.html">State Backends</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/ops/state/large_state_tuning.html">大状态与 Checkpoint 调优</a></li>
</ul></div></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/ops/metrics.html">指标</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/ops/rest_api.html">REST API</a></li>
<li><a href="#collapse-257" data-toggle="collapse">Debugging<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-257"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/ops/debugging/debugging_event_time.html">调试窗口与事件时间</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/ops/debugging/debugging_classloading.html">调试类加载</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/ops/debugging/application_profiling.html">应用程序分析</a></li>
</ul></div></li>
<li><a href="#collapse-262" data-toggle="collapse">Monitoring<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-262"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/ops/monitoring/checkpoint_monitoring.html">监控 Checkpoint</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/ops/monitoring/back_pressure.html">监控反压</a></li>
</ul></div></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/ops/upgrading.html">升级应用程序和 Flink 版本</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/ops/production_ready.html">生产就绪情况核对清单</a></li>
</ul></div></li><hr class="section-break"></hr>
<li><a href="#collapse-269" data-toggle="collapse"><i class="fa fa-cogs title dessert" aria-hidden="true"></i> Flink 开发<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-269"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/flinkDev/ide_setup.html">导入 Flink 到 IDE 中</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/flinkDev/building.html">从源码构建 Flink</a></li>
</ul></div></li>
<li><a href="#collapse-273" data-toggle="collapse"><i class="fa fa-book title dessert" aria-hidden="true"></i> 内幕<i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-273"><ul>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/internals/job_scheduling.html">作业调度</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/internals/task_lifecycle.html">Task 生命周期</a></li>
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/internals/filesystems.html">文件系统</a></li>
</ul></div></li>
  <li class="divider"></li>
  <li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/api/java"><i class="fa fa-external-link title" aria-hidden="true"></i> Javadocs</a></li>
  <li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/api/scala/index.html#org.apache.flink.api.scala.package"><i class="fa fa-external-link title" aria-hidden="true"></i> Scaladocs</a></li>
  <li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/api/python"><i class="fa fa-external-link title" aria-hidden="true"></i> Pythondocs</a></li>
  <li><a href="http://flink.apache.org"><i class="fa fa-external-link title" aria-hidden="true"></i> Project Page</a></li>
</ul>

<div class="sidenav-search-box">
  <form class="navbar-form" role="search" action="//ci.apache.org/projects/flink/flink-docs-release-1.12/search-results.html">
    <div class="form-group">
      <input type="text" class="form-control" size="16px" name="q" placeholder="Search">
    </div>
    <button type="submit" class="btn btn-default">Go</button>
  </form>
</div>

<div class="sidenav-versions">
  <div class="dropdown">
    <button class="btn btn-default dropdown-toggle" type="button" data-toggle="dropdown">选择文档版本<span class="caret"></span></button>
    <ul class="dropdown-menu">
      <li><a href="http://ci.apache.org/projects/flink/flink-docs-release-1.11">v1.11</a></li>
      <li><a href="http://ci.apache.org/projects/flink/flink-docs-release-1.10">v1.10</a></li>
      <li><a href="http://ci.apache.org/projects/flink/flink-docs-release-1.9">v1.9</a></li>
      <li><a href="http://ci.apache.org/projects/flink/flink-docs-release-1.8">v1.8</a></li>
      <li><a href="http://ci.apache.org/projects/flink/flink-docs-release-1.7">v1.7</a></li>
      <li><a href="http://ci.apache.org/projects/flink/flink-docs-release-1.6">v1.6</a></li>
      <li><a href="http://ci.apache.org/projects/flink/flink-docs-release-1.5">v1.5</a></li>
      <li><a href="http://ci.apache.org/projects/flink/flink-docs-release-1.4">v1.4</a></li>
      <li><a href="http://ci.apache.org/projects/flink/flink-docs-release-1.3">v1.3</a></li>
      <li><a href="http://ci.apache.org/projects/flink/flink-docs-release-1.2">v1.2</a></li>
      <li><a href="http://ci.apache.org/projects/flink/flink-docs-release-1.1">v1.1</a></li>
      <li><a href="http://ci.apache.org/projects/flink/flink-docs-release-1.0">v1.0</a></li>
    </ul>
  </div>
</div>

<div class="sidenav-languages"><a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/dev/batch/">
      <button type="submit" class="btn btn-default">English</button>
    </a>
</div>

        </div>
        <div class="col-lg-9 content" id="contentcol">

          

<ol class="breadcrumb">
  
    <li><i class="fa fa-code title maindish" aria-hidden="true"></i> 应用开发</li>
  
    <li class="active">DataSet API</li>
</ol>

<h1>Flink DataSet API 编程指南</h1>




<p>DataSet programs in Flink are regular programs that implement transformations on data sets
(e.g., filtering, mapping, joining, grouping). The data sets are initially created from certain
sources (e.g., by reading files, or from local collections). Results are returned via sinks, which may for
example write the data to (distributed) files, or to standard output (for example the command line
terminal). Flink programs run in a variety of contexts, standalone, or embedded in other programs.
The execution can happen in a local JVM, or on clusters of many machines.</p>

<p>Please refer to the <a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/datastream_api.html">DataStream API overview</a>
for an introduction to the basic concepts of the Flink API. That overview is
for the DataStream API but the basic concepts of the two APIs are the same.</p>

<p>In order to create your own Flink DataSet program, we encourage you to start with the
<a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/datastream_api.html#anatomy-of-a-flink-program">anatomy of a Flink Program</a>
and gradually add your own
<a href="#dataset-transformations">transformations</a>. The remaining sections act as references for additional
operations and advanced features.</p>

<ul id="markdown-toc">
  <li><a href="#example-program" id="markdown-toc-example-program">Example Program</a></li>
  <li><a href="#dataset-transformations" id="markdown-toc-dataset-transformations">DataSet Transformations</a></li>
  <li><a href="#specifying-keys" id="markdown-toc-specifying-keys">Specifying Keys</a></li>
  <li><a href="#data-sources" id="markdown-toc-data-sources">Data Sources</a>    <ul>
      <li><a href="#read-compressed-files" id="markdown-toc-read-compressed-files">Read Compressed Files</a></li>
    </ul>
  </li>
  <li><a href="#data-sinks" id="markdown-toc-data-sinks">Data Sinks</a></li>
  <li><a href="#iteration-operators" id="markdown-toc-iteration-operators">Iteration Operators</a></li>
  <li><a href="#operating-on-data-objects-in-functions" id="markdown-toc-operating-on-data-objects-in-functions">Operating on data objects in functions</a>    <ul>
      <li><a href="#object-reuse-disabled-default" id="markdown-toc-object-reuse-disabled-default">Object-Reuse Disabled (DEFAULT)</a></li>
      <li><a href="#object-reuse-enabled" id="markdown-toc-object-reuse-enabled">Object-Reuse Enabled</a></li>
    </ul>
  </li>
  <li><a href="#debugging" id="markdown-toc-debugging">Debugging</a>    <ul>
      <li><a href="#local-execution-environment" id="markdown-toc-local-execution-environment">Local Execution Environment</a></li>
      <li><a href="#collection-data-sources-and-sinks" id="markdown-toc-collection-data-sources-and-sinks">Collection Data Sources and Sinks</a></li>
    </ul>
  </li>
  <li><a href="#semantic-annotations" id="markdown-toc-semantic-annotations">Semantic Annotations</a></li>
  <li><a href="#broadcast-variables" id="markdown-toc-broadcast-variables">Broadcast Variables</a></li>
  <li><a href="#distributed-cache" id="markdown-toc-distributed-cache">Distributed Cache</a></li>
  <li><a href="#passing-parameters-to-functions" id="markdown-toc-passing-parameters-to-functions">Passing Parameters to Functions</a></li>
</ul>

<h2 id="example-program">Example Program</h2>

<p>The following program is a complete, working example of WordCount. You can copy &amp; paste the code
to run it locally. You only have to include the correct Flink’s library into your project
(see Section <a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/project-configuration.html">Linking with Flink</a>) and specify the imports. Then you are ready
to go!</p>

<div class="codetabs">
  <div data-lang="java">

    <figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="kd">public</span> <span class="kd">class</span> <span class="nc">WordCountExample</span> <span class="o">{</span>
    <span class="kd">public</span> <span class="kd">static</span> <span class="kt">void</span> <span class="nf">main</span><span class="o">(</span><span class="nc">String</span><span class="o">[]</span> <span class="n">args</span><span class="o">)</span> <span class="kd">throws</span> <span class="nc">Exception</span> <span class="o">{</span>
        <span class="kd">final</span> <span class="nc">ExecutionEnvironment</span> <span class="n">env</span> <span class="o">=</span> <span class="nc">ExecutionEnvironment</span><span class="o">.</span><span class="na">getExecutionEnvironment</span><span class="o">();</span>

        <span class="nc">DataSet</span><span class="o">&lt;</span><span class="nc">String</span><span class="o">&gt;</span> <span class="n">text</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="na">fromElements</span><span class="o">(</span>
            <span class="s">"Who's there?"</span><span class="o">,</span>
            <span class="s">"I think I hear them. Stand, ho! Who's there?"</span><span class="o">);</span>

        <span class="nc">DataSet</span><span class="o">&lt;</span><span class="nc">Tuple2</span><span class="o">&lt;</span><span class="nc">String</span><span class="o">,</span> <span class="nc">Integer</span><span class="o">&gt;&gt;</span> <span class="n">wordCounts</span> <span class="o">=</span> <span class="n">text</span>
            <span class="o">.</span><span class="na">flatMap</span><span class="o">(</span><span class="k">new</span> <span class="nc">LineSplitter</span><span class="o">())</span>
            <span class="o">.</span><span class="na">groupBy</span><span class="o">(</span><span class="mi">0</span><span class="o">)</span>
            <span class="o">.</span><span class="na">sum</span><span class="o">(</span><span class="mi">1</span><span class="o">);</span>

        <span class="n">wordCounts</span><span class="o">.</span><span class="na">print</span><span class="o">();</span>
    <span class="o">}</span>

    <span class="kd">public</span> <span class="kd">static</span> <span class="kd">class</span> <span class="nc">LineSplitter</span> <span class="kd">implements</span> <span class="nc">FlatMapFunction</span><span class="o">&lt;</span><span class="nc">String</span><span class="o">,</span> <span class="nc">Tuple2</span><span class="o">&lt;</span><span class="nc">String</span><span class="o">,</span> <span class="nc">Integer</span><span class="o">&gt;&gt;</span> <span class="o">{</span>
        <span class="nd">@Override</span>
        <span class="kd">public</span> <span class="kt">void</span> <span class="nf">flatMap</span><span class="o">(</span><span class="nc">String</span> <span class="n">line</span><span class="o">,</span> <span class="nc">Collector</span><span class="o">&lt;</span><span class="nc">Tuple2</span><span class="o">&lt;</span><span class="nc">String</span><span class="o">,</span> <span class="nc">Integer</span><span class="o">&gt;&gt;</span> <span class="n">out</span><span class="o">)</span> <span class="o">{</span>
            <span class="k">for</span> <span class="o">(</span><span class="nc">String</span> <span class="n">word</span> <span class="o">:</span> <span class="n">line</span><span class="o">.</span><span class="na">split</span><span class="o">(</span><span class="s">" "</span><span class="o">))</span> <span class="o">{</span>
                <span class="n">out</span><span class="o">.</span><span class="na">collect</span><span class="o">(</span><span class="k">new</span> <span class="nc">Tuple2</span><span class="o">&lt;</span><span class="nc">String</span><span class="o">,</span> <span class="nc">Integer</span><span class="o">&gt;(</span><span class="n">word</span><span class="o">,</span> <span class="mi">1</span><span class="o">));</span>
            <span class="o">}</span>
        <span class="o">}</span>
    <span class="o">}</span>
<span class="o">}</span></code></pre></figure>

  </div>

  <div data-lang="scala">

    <figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">import</span> <span class="nn">org.apache.flink.api.scala._</span>

<span class="k">object</span> <span class="nc">WordCount</span> <span class="o">{</span>
  <span class="k">def</span> <span class="nf">main</span><span class="o">(</span><span class="n">args</span><span class="k">:</span> <span class="kt">Array</span><span class="o">[</span><span class="kt">String</span><span class="o">])</span> <span class="o">{</span>

    <span class="k">val</span> <span class="nv">env</span> <span class="k">=</span> <span class="nv">ExecutionEnvironment</span><span class="o">.</span><span class="py">getExecutionEnvironment</span>
    <span class="k">val</span> <span class="nv">text</span> <span class="k">=</span> <span class="nv">env</span><span class="o">.</span><span class="py">fromElements</span><span class="o">(</span>
      <span class="s">"Who's there?"</span><span class="o">,</span>
      <span class="s">"I think I hear them. Stand, ho! Who's there?"</span><span class="o">)</span>

    <span class="k">val</span> <span class="nv">counts</span> <span class="k">=</span> <span class="nv">text</span><span class="o">.</span><span class="py">flatMap</span> <span class="o">{</span> <span class="nv">_</span><span class="o">.</span><span class="py">toLowerCase</span><span class="o">.</span><span class="py">split</span><span class="o">(</span><span class="s">"\\W+"</span><span class="o">)</span> <span class="n">filter</span> <span class="o">{</span> <span class="nv">_</span><span class="o">.</span><span class="py">nonEmpty</span> <span class="o">}</span> <span class="o">}</span>
      <span class="o">.</span><span class="py">map</span> <span class="o">{</span> <span class="o">(</span><span class="k">_</span><span class="o">,</span> <span class="mi">1</span><span class="o">)</span> <span class="o">}</span>
      <span class="o">.</span><span class="py">groupBy</span><span class="o">(</span><span class="mi">0</span><span class="o">)</span>
      <span class="o">.</span><span class="py">sum</span><span class="o">(</span><span class="mi">1</span><span class="o">)</span>

    <span class="nv">counts</span><span class="o">.</span><span class="py">print</span><span class="o">()</span>
  <span class="o">}</span>
<span class="o">}</span></code></pre></figure>

  </div>

</div>

<p><a href="#top" class="top pull-right"><span class="glyphicon glyphicon-chevron-up"></span> Back to top</a></p>

<h2 id="dataset-transformations">DataSet Transformations</h2>

<p>Data transformations transform one or more DataSets into a new DataSet. Programs can combine
multiple transformations into sophisticated assemblies.</p>

<p>This section gives a brief overview of the available transformations. The <a href="dataset_transformations.html">transformations
documentation</a> has a full description of all transformations with
examples.</p>

<div class="codetabs">
  <div data-lang="java">

    <p><br /></p>

    <table class="table table-bordered">
  <thead>
    <tr>
      <th class="text-left" style="width: 20%">Transformation</th>
      <th class="text-center">Description</th>
    </tr>
  </thead>

  <tbody>
    <tr>
      <td><strong>Map</strong></td>
      <td>
        <p>Takes one element and produces one element.</p>

<figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="n">data</span><span class="o">.</span><span class="na">map</span><span class="o">(</span><span class="k">new</span> <span class="nc">MapFunction</span><span class="o">&lt;</span><span class="nc">String</span><span class="o">,</span> <span class="nc">Integer</span><span class="o">&gt;()</span> <span class="o">{</span>
  <span class="kd">public</span> <span class="nc">Integer</span> <span class="nf">map</span><span class="o">(</span><span class="nc">String</span> <span class="n">value</span><span class="o">)</span> <span class="o">{</span> <span class="k">return</span> <span class="nc">Integer</span><span class="o">.</span><span class="na">parseInt</span><span class="o">(</span><span class="n">value</span><span class="o">);</span> <span class="o">}</span>
<span class="o">});</span></code></pre></figure>

      </td>
    </tr>

    <tr>
      <td><strong>FlatMap</strong></td>
      <td>
        <p>Takes one element and produces zero, one, or more elements. </p>

<figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="n">data</span><span class="o">.</span><span class="na">flatMap</span><span class="o">(</span><span class="k">new</span> <span class="nc">FlatMapFunction</span><span class="o">&lt;</span><span class="nc">String</span><span class="o">,</span> <span class="nc">String</span><span class="o">&gt;()</span> <span class="o">{</span>
  <span class="kd">public</span> <span class="kt">void</span> <span class="nf">flatMap</span><span class="o">(</span><span class="nc">String</span> <span class="n">value</span><span class="o">,</span> <span class="nc">Collector</span><span class="o">&lt;</span><span class="nc">String</span><span class="o">&gt;</span> <span class="n">out</span><span class="o">)</span> <span class="o">{</span>
    <span class="k">for</span> <span class="o">(</span><span class="nc">String</span> <span class="n">s</span> <span class="o">:</span> <span class="n">value</span><span class="o">.</span><span class="na">split</span><span class="o">(</span><span class="s">" "</span><span class="o">))</span> <span class="o">{</span>
      <span class="n">out</span><span class="o">.</span><span class="na">collect</span><span class="o">(</span><span class="n">s</span><span class="o">);</span>
    <span class="o">}</span>
  <span class="o">}</span>
<span class="o">});</span></code></pre></figure>

      </td>
    </tr>

    <tr>
      <td><strong>MapPartition</strong></td>
      <td>
        <p>Transforms a parallel partition in a single function call. The function gets the partition
        as an <code>Iterable</code> stream and can produce an arbitrary number of result values. The number of
        elements in each partition depends on the degree-of-parallelism and previous operations.</p>

<figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="n">data</span><span class="o">.</span><span class="na">mapPartition</span><span class="o">(</span><span class="k">new</span> <span class="nc">MapPartitionFunction</span><span class="o">&lt;</span><span class="nc">String</span><span class="o">,</span> <span class="nc">Long</span><span class="o">&gt;()</span> <span class="o">{</span>
  <span class="kd">public</span> <span class="kt">void</span> <span class="nf">mapPartition</span><span class="o">(</span><span class="nc">Iterable</span><span class="o">&lt;</span><span class="nc">String</span><span class="o">&gt;</span> <span class="n">values</span><span class="o">,</span> <span class="nc">Collector</span><span class="o">&lt;</span><span class="nc">Long</span><span class="o">&gt;</span> <span class="n">out</span><span class="o">)</span> <span class="o">{</span>
    <span class="kt">long</span> <span class="n">c</span> <span class="o">=</span> <span class="mi">0</span><span class="o">;</span>
    <span class="k">for</span> <span class="o">(</span><span class="nc">String</span> <span class="n">s</span> <span class="o">:</span> <span class="n">values</span><span class="o">)</span> <span class="o">{</span>
      <span class="n">c</span><span class="o">++;</span>
    <span class="o">}</span>
    <span class="n">out</span><span class="o">.</span><span class="na">collect</span><span class="o">(</span><span class="n">c</span><span class="o">);</span>
  <span class="o">}</span>
<span class="o">});</span></code></pre></figure>

      </td>
    </tr>

    <tr>
      <td><strong>Filter</strong></td>
      <td>
        <p>Evaluates a boolean function for each element and retains those for which the function
        returns true.<br />

        <strong>IMPORTANT:</strong> The system assumes that the function does not modify the elements on which the predicate is applied. Violating this assumption
        can lead to incorrect results.
        </p>

<figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="n">data</span><span class="o">.</span><span class="na">filter</span><span class="o">(</span><span class="k">new</span> <span class="nc">FilterFunction</span><span class="o">&lt;</span><span class="nc">Integer</span><span class="o">&gt;()</span> <span class="o">{</span>
  <span class="kd">public</span> <span class="kt">boolean</span> <span class="nf">filter</span><span class="o">(</span><span class="nc">Integer</span> <span class="n">value</span><span class="o">)</span> <span class="o">{</span> <span class="k">return</span> <span class="n">value</span> <span class="o">&gt;</span> <span class="mi">1000</span><span class="o">;</span> <span class="o">}</span>
<span class="o">});</span></code></pre></figure>

      </td>
    </tr>

    <tr>
      <td><strong>Reduce</strong></td>
      <td>
        <p>Combines a group of elements into a single element by repeatedly combining two elements
        into one. Reduce may be applied on a full data set or on a grouped data set.</p>

<figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="n">data</span><span class="o">.</span><span class="na">reduce</span><span class="o">(</span><span class="k">new</span> <span class="nc">ReduceFunction</span><span class="o">&lt;</span><span class="nc">Integer</span><span class="o">&gt;</span> <span class="o">{</span>
  <span class="kd">public</span> <span class="nc">Integer</span> <span class="nf">reduce</span><span class="o">(</span><span class="nc">Integer</span> <span class="n">a</span><span class="o">,</span> <span class="nc">Integer</span> <span class="n">b</span><span class="o">)</span> <span class="o">{</span> <span class="k">return</span> <span class="n">a</span> <span class="o">+</span> <span class="n">b</span><span class="o">;</span> <span class="o">}</span>
<span class="o">});</span></code></pre></figure>

        <p>If the reduce was applied to a grouped data set then you can specify the way that the
        runtime executes the combine phase of the reduce by supplying a <code>CombineHint</code> to
        <code>setCombineHint</code>. The hash-based strategy should be faster in most cases,
        especially if the number of different keys is small compared to the number of input
        elements (eg. 1/10).</p>
      </td>
    </tr>

    <tr>
      <td><strong>ReduceGroup</strong></td>
      <td>
        <p>Combines a group of elements into one or more elements. ReduceGroup may be applied on a
        full data set or on a grouped data set.</p>

<figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="n">data</span><span class="o">.</span><span class="na">reduceGroup</span><span class="o">(</span><span class="k">new</span> <span class="nc">GroupReduceFunction</span><span class="o">&lt;</span><span class="nc">Integer</span><span class="o">,</span> <span class="nc">Integer</span><span class="o">&gt;</span> <span class="o">{</span>
  <span class="kd">public</span> <span class="kt">void</span> <span class="nf">reduce</span><span class="o">(</span><span class="nc">Iterable</span><span class="o">&lt;</span><span class="nc">Integer</span><span class="o">&gt;</span> <span class="n">values</span><span class="o">,</span> <span class="nc">Collector</span><span class="o">&lt;</span><span class="nc">Integer</span><span class="o">&gt;</span> <span class="n">out</span><span class="o">)</span> <span class="o">{</span>
    <span class="kt">int</span> <span class="n">prefixSum</span> <span class="o">=</span> <span class="mi">0</span><span class="o">;</span>
    <span class="k">for</span> <span class="o">(</span><span class="nc">Integer</span> <span class="n">i</span> <span class="o">:</span> <span class="n">values</span><span class="o">)</span> <span class="o">{</span>
      <span class="n">prefixSum</span> <span class="o">+=</span> <span class="n">i</span><span class="o">;</span>
      <span class="n">out</span><span class="o">.</span><span class="na">collect</span><span class="o">(</span><span class="n">prefixSum</span><span class="o">);</span>
    <span class="o">}</span>
  <span class="o">}</span>
<span class="o">});</span></code></pre></figure>

      </td>
    </tr>

    <tr>
      <td><strong>Aggregate</strong></td>
      <td>
        <p>Aggregates a group of values into a single value. Aggregation functions can be thought of
        as built-in reduce functions. Aggregate may be applied on a full data set, or on a grouped
        data set.</p>

<figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="nc">Dataset</span><span class="o">&lt;</span><span class="nc">Tuple3</span><span class="o">&lt;</span><span class="nc">Integer</span><span class="o">,</span> <span class="nc">String</span><span class="o">,</span> <span class="nc">Double</span><span class="o">&gt;&gt;</span> <span class="n">input</span> <span class="o">=</span> <span class="c1">// [...]</span>
<span class="nc">DataSet</span><span class="o">&lt;</span><span class="nc">Tuple3</span><span class="o">&lt;</span><span class="nc">Integer</span><span class="o">,</span> <span class="nc">String</span><span class="o">,</span> <span class="nc">Double</span><span class="o">&gt;&gt;</span> <span class="n">output</span> <span class="o">=</span> <span class="n">input</span><span class="o">.</span><span class="na">aggregate</span><span class="o">(</span><span class="no">SUM</span><span class="o">,</span> <span class="mi">0</span><span class="o">).</span><span class="na">and</span><span class="o">(</span><span class="no">MIN</span><span class="o">,</span> <span class="mi">2</span><span class="o">);</span></code></pre></figure>

	<p>You can also use short-hand syntax for minimum, maximum, and sum aggregations.</p>

<figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="nc">Dataset</span><span class="o">&lt;</span><span class="nc">Tuple3</span><span class="o">&lt;</span><span class="nc">Integer</span><span class="o">,</span> <span class="nc">String</span><span class="o">,</span> <span class="nc">Double</span><span class="o">&gt;&gt;</span> <span class="n">input</span> <span class="o">=</span> <span class="c1">// [...]</span>
<span class="nc">DataSet</span><span class="o">&lt;</span><span class="nc">Tuple3</span><span class="o">&lt;</span><span class="nc">Integer</span><span class="o">,</span> <span class="nc">String</span><span class="o">,</span> <span class="nc">Double</span><span class="o">&gt;&gt;</span> <span class="n">output</span> <span class="o">=</span> <span class="n">input</span><span class="o">.</span><span class="na">sum</span><span class="o">(</span><span class="mi">0</span><span class="o">).</span><span class="na">andMin</span><span class="o">(</span><span class="mi">2</span><span class="o">);</span></code></pre></figure>

      </td>
    </tr>

    <tr>
      <td><strong>Distinct</strong></td>
      <td>
        <p>Returns the distinct elements of a data set. It removes the duplicate entries
        from the input DataSet, with respect to all fields of the elements, or a subset of fields.</p>

<figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="n">data</span><span class="o">.</span><span class="na">distinct</span><span class="o">();</span></code></pre></figure>

        <p>Distinct is implemented using a reduce function. You can specify the way that the
        runtime executes the combine phase of the reduce by supplying a <code>CombineHint</code> to
        <code>setCombineHint</code>. The hash-based strategy should be faster in most cases,
        especially if the number of different keys is small compared to the number of input
        elements (eg. 1/10).</p>
      </td>
    </tr>

    <tr>
      <td><strong>Join</strong></td>
      <td>
        Joins two data sets by creating all pairs of elements that are equal on their keys.
        Optionally uses a JoinFunction to turn the pair of elements into a single element, or a
        FlatJoinFunction to turn the pair of elements into arbitrarily many (including none)
        elements. See the <a href="#specifying-keys">keys section</a> to learn how to define join keys.

<figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="n">result</span> <span class="o">=</span> <span class="n">input1</span><span class="o">.</span><span class="na">join</span><span class="o">(</span><span class="n">input2</span><span class="o">)</span>
               <span class="o">.</span><span class="na">where</span><span class="o">(</span><span class="mi">0</span><span class="o">)</span>       <span class="c1">// key of the first input (tuple field 0)</span>
               <span class="o">.</span><span class="na">equalTo</span><span class="o">(</span><span class="mi">1</span><span class="o">);</span>    <span class="c1">// key of the second input (tuple field 1)</span></code></pre></figure>

        You can specify the way that the runtime executes the join via <i>Join Hints</i>. The hints
        describe whether the join happens through partitioning or broadcasting, and whether it uses
        a sort-based or a hash-based algorithm. Please refer to the
        <a href="dataset_transformations.html#join-algorithm-hints">Transformations Guide</a> for
        a list of possible hints and an example.<br />
        If no hint is specified, the system will try to make an estimate of the input sizes and
        pick the best strategy according to those estimates.

<figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="c1">// This executes a join by broadcasting the first data set</span>
<span class="c1">// using a hash table for the broadcast data</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">input1</span><span class="o">.</span><span class="na">join</span><span class="o">(</span><span class="n">input2</span><span class="o">,</span> <span class="nc">JoinHint</span><span class="o">.</span><span class="na">BROADCAST_HASH_FIRST</span><span class="o">)</span>
               <span class="o">.</span><span class="na">where</span><span class="o">(</span><span class="mi">0</span><span class="o">).</span><span class="na">equalTo</span><span class="o">(</span><span class="mi">1</span><span class="o">);</span></code></pre></figure>

        Note that the join transformation works only for equi-joins. Other join types need to be expressed using OuterJoin or CoGroup.
      </td>
    </tr>

    <tr>
      <td><strong>OuterJoin</strong></td>
      <td>
        Performs a left, right, or full outer join on two data sets. Outer joins are similar to regular (inner) joins and create all pairs of elements that are equal on their keys. In addition, records of the "outer" side (left, right, or both in case of full) are preserved if no matching key is found in the other side. Matching pairs of elements (or one element and a <code>null</code> value for the other input) are given to a JoinFunction to turn the pair of elements into a single element, or to a FlatJoinFunction to turn the pair of elements into arbitrarily many (including none)         elements. See the <a href="#specifying-keys">keys section</a> to learn how to define join keys.

<figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="n">input1</span><span class="o">.</span><span class="na">leftOuterJoin</span><span class="o">(</span><span class="n">input2</span><span class="o">)</span> <span class="c1">// rightOuterJoin or fullOuterJoin for right or full outer joins</span>
      <span class="o">.</span><span class="na">where</span><span class="o">(</span><span class="mi">0</span><span class="o">)</span>              <span class="c1">// key of the first input (tuple field 0)</span>
      <span class="o">.</span><span class="na">equalTo</span><span class="o">(</span><span class="mi">1</span><span class="o">)</span>            <span class="c1">// key of the second input (tuple field 1)</span>
      <span class="o">.</span><span class="na">with</span><span class="o">(</span><span class="k">new</span> <span class="nc">JoinFunction</span><span class="o">&lt;</span><span class="nc">String</span><span class="o">,</span> <span class="nc">String</span><span class="o">,</span> <span class="nc">String</span><span class="o">&gt;()</span> <span class="o">{</span>
          <span class="kd">public</span> <span class="nc">String</span> <span class="nf">join</span><span class="o">(</span><span class="nc">String</span> <span class="n">v1</span><span class="o">,</span> <span class="nc">String</span> <span class="n">v2</span><span class="o">)</span> <span class="o">{</span>
             <span class="c1">// NOTE:</span>
             <span class="c1">// - v2 might be null for leftOuterJoin</span>
             <span class="c1">// - v1 might be null for rightOuterJoin</span>
             <span class="c1">// - v1 OR v2 might be null for fullOuterJoin</span>
          <span class="o">}</span>
      <span class="o">});</span></code></pre></figure>

      </td>
    </tr>

    <tr>
      <td><strong>CoGroup</strong></td>
      <td>
        <p>The two-dimensional variant of the reduce operation. Groups each input on one or more
        fields and then joins the groups. The transformation function is called per pair of groups.
        See the <a href="#specifying-keys">keys section</a> to learn how to define coGroup keys.</p>

<figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="n">data1</span><span class="o">.</span><span class="na">coGroup</span><span class="o">(</span><span class="n">data2</span><span class="o">)</span>
     <span class="o">.</span><span class="na">where</span><span class="o">(</span><span class="mi">0</span><span class="o">)</span>
     <span class="o">.</span><span class="na">equalTo</span><span class="o">(</span><span class="mi">1</span><span class="o">)</span>
     <span class="o">.</span><span class="na">with</span><span class="o">(</span><span class="k">new</span> <span class="nc">CoGroupFunction</span><span class="o">&lt;</span><span class="nc">String</span><span class="o">,</span> <span class="nc">String</span><span class="o">,</span> <span class="nc">String</span><span class="o">&gt;()</span> <span class="o">{</span>
         <span class="kd">public</span> <span class="kt">void</span> <span class="nf">coGroup</span><span class="o">(</span><span class="nc">Iterable</span><span class="o">&lt;</span><span class="nc">String</span><span class="o">&gt;</span> <span class="n">in1</span><span class="o">,</span> <span class="nc">Iterable</span><span class="o">&lt;</span><span class="nc">String</span><span class="o">&gt;</span> <span class="n">in2</span><span class="o">,</span> <span class="nc">Collector</span><span class="o">&lt;</span><span class="nc">String</span><span class="o">&gt;</span> <span class="n">out</span><span class="o">)</span> <span class="o">{</span>
           <span class="n">out</span><span class="o">.</span><span class="na">collect</span><span class="o">(...);</span>
         <span class="o">}</span>
      <span class="o">});</span></code></pre></figure>

      </td>
    </tr>

    <tr>
      <td><strong>Cross</strong></td>
      <td>
        <p>Builds the Cartesian product (cross product) of two inputs, creating all pairs of
        elements. Optionally uses a CrossFunction to turn the pair of elements into a single
        element</p>

<figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="nc">DataSet</span><span class="o">&lt;</span><span class="nc">Integer</span><span class="o">&gt;</span> <span class="n">data1</span> <span class="o">=</span> <span class="c1">// [...]</span>
<span class="nc">DataSet</span><span class="o">&lt;</span><span class="nc">String</span><span class="o">&gt;</span> <span class="n">data2</span> <span class="o">=</span> <span class="c1">// [...]</span>
<span class="nc">DataSet</span><span class="o">&lt;</span><span class="nc">Tuple2</span><span class="o">&lt;</span><span class="nc">Integer</span><span class="o">,</span> <span class="nc">String</span><span class="o">&gt;&gt;</span> <span class="n">result</span> <span class="o">=</span> <span class="n">data1</span><span class="o">.</span><span class="na">cross</span><span class="o">(</span><span class="n">data2</span><span class="o">);</span></code></pre></figure>

      <p>Note: Cross is potentially a <b>very</b> compute-intensive operation which can challenge even large compute clusters! It is advised to hint the system with the DataSet sizes by using <i>crossWithTiny()</i> and <i>crossWithHuge()</i>.</p>
      </td>
    </tr>
    <tr>
      <td><strong>Union</strong></td>
      <td>
        <p>Produces the union of two data sets.</p>

<figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="nc">DataSet</span><span class="o">&lt;</span><span class="nc">String</span><span class="o">&gt;</span> <span class="n">data1</span> <span class="o">=</span> <span class="c1">// [...]</span>
<span class="nc">DataSet</span><span class="o">&lt;</span><span class="nc">String</span><span class="o">&gt;</span> <span class="n">data2</span> <span class="o">=</span> <span class="c1">// [...]</span>
<span class="nc">DataSet</span><span class="o">&lt;</span><span class="nc">String</span><span class="o">&gt;</span> <span class="n">result</span> <span class="o">=</span> <span class="n">data1</span><span class="o">.</span><span class="na">union</span><span class="o">(</span><span class="n">data2</span><span class="o">);</span></code></pre></figure>

      </td>
    </tr>
    <tr>
      <td><strong>Rebalance</strong></td>
      <td>
        <p>Evenly rebalances the parallel partitions of a data set to eliminate data skew. Only Map-like transformations may follow a rebalance transformation.</p>

<figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="nc">DataSet</span><span class="o">&lt;</span><span class="nc">String</span><span class="o">&gt;</span> <span class="n">in</span> <span class="o">=</span> <span class="c1">// [...]</span>
<span class="nc">DataSet</span><span class="o">&lt;</span><span class="nc">String</span><span class="o">&gt;</span> <span class="n">result</span> <span class="o">=</span> <span class="n">in</span><span class="o">.</span><span class="na">rebalance</span><span class="o">()</span>
                           <span class="o">.</span><span class="na">map</span><span class="o">(</span><span class="k">new</span> <span class="nc">Mapper</span><span class="o">());</span></code></pre></figure>

      </td>
    </tr>
    <tr>
      <td><strong>Hash-Partition</strong></td>
      <td>
        <p>Hash-partitions a data set on a given key. Keys can be specified as position keys, expression keys, and key selector functions.</p>

<figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="nc">DataSet</span><span class="o">&lt;</span><span class="nc">Tuple2</span><span class="o">&lt;</span><span class="nc">String</span><span class="o">,</span><span class="nc">Integer</span><span class="o">&gt;&gt;</span> <span class="n">in</span> <span class="o">=</span> <span class="c1">// [...]</span>
<span class="nc">DataSet</span><span class="o">&lt;</span><span class="nc">Integer</span><span class="o">&gt;</span> <span class="n">result</span> <span class="o">=</span> <span class="n">in</span><span class="o">.</span><span class="na">partitionByHash</span><span class="o">(</span><span class="mi">0</span><span class="o">)</span>
                            <span class="o">.</span><span class="na">mapPartition</span><span class="o">(</span><span class="k">new</span> <span class="nc">PartitionMapper</span><span class="o">());</span></code></pre></figure>

      </td>
    </tr>
    <tr>
      <td><strong>Range-Partition</strong></td>
      <td>
        <p>Range-partitions a data set on a given key. Keys can be specified as position keys, expression keys, and key selector functions.</p>

<figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="nc">DataSet</span><span class="o">&lt;</span><span class="nc">Tuple2</span><span class="o">&lt;</span><span class="nc">String</span><span class="o">,</span><span class="nc">Integer</span><span class="o">&gt;&gt;</span> <span class="n">in</span> <span class="o">=</span> <span class="c1">// [...]</span>
<span class="nc">DataSet</span><span class="o">&lt;</span><span class="nc">Integer</span><span class="o">&gt;</span> <span class="n">result</span> <span class="o">=</span> <span class="n">in</span><span class="o">.</span><span class="na">partitionByRange</span><span class="o">(</span><span class="mi">0</span><span class="o">)</span>
                            <span class="o">.</span><span class="na">mapPartition</span><span class="o">(</span><span class="k">new</span> <span class="nc">PartitionMapper</span><span class="o">());</span></code></pre></figure>

      </td>
    </tr>
    <tr>
      <td><strong>Custom Partitioning</strong></td>
      <td>
        <p>Assigns records based on a key to a specific partition using a custom Partitioner function.
          The key can be specified as position key, expression key, and key selector function.
          <br />
          <i>Note</i>: This method only works with a single field key.</p>

<figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="nc">DataSet</span><span class="o">&lt;</span><span class="nc">Tuple2</span><span class="o">&lt;</span><span class="nc">String</span><span class="o">,</span><span class="nc">Integer</span><span class="o">&gt;&gt;</span> <span class="n">in</span> <span class="o">=</span> <span class="c1">// [...]</span>
<span class="nc">DataSet</span><span class="o">&lt;</span><span class="nc">Integer</span><span class="o">&gt;</span> <span class="n">result</span> <span class="o">=</span> <span class="n">in</span><span class="o">.</span><span class="na">partitionCustom</span><span class="o">(</span><span class="n">partitioner</span><span class="o">,</span> <span class="n">key</span><span class="o">)</span>
                            <span class="o">.</span><span class="na">mapPartition</span><span class="o">(</span><span class="k">new</span> <span class="nc">PartitionMapper</span><span class="o">());</span></code></pre></figure>

      </td>
    </tr>
    <tr>
      <td><strong>Sort Partition</strong></td>
      <td>
        <p>Locally sorts all partitions of a data set on a specified field in a specified order.
          Fields can be specified as tuple positions or field expressions.
          Sorting on multiple fields is done by chaining sortPartition() calls.</p>

<figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="nc">DataSet</span><span class="o">&lt;</span><span class="nc">Tuple2</span><span class="o">&lt;</span><span class="nc">String</span><span class="o">,</span><span class="nc">Integer</span><span class="o">&gt;&gt;</span> <span class="n">in</span> <span class="o">=</span> <span class="c1">// [...]</span>
<span class="nc">DataSet</span><span class="o">&lt;</span><span class="nc">Integer</span><span class="o">&gt;</span> <span class="n">result</span> <span class="o">=</span> <span class="n">in</span><span class="o">.</span><span class="na">sortPartition</span><span class="o">(</span><span class="mi">1</span><span class="o">,</span> <span class="nc">Order</span><span class="o">.</span><span class="na">ASCENDING</span><span class="o">)</span>
                            <span class="o">.</span><span class="na">mapPartition</span><span class="o">(</span><span class="k">new</span> <span class="nc">PartitionMapper</span><span class="o">());</span></code></pre></figure>

      </td>
    </tr>
    <tr>
      <td><strong>First-n</strong></td>
      <td>
        <p>Returns the first n (arbitrary) elements of a data set. First-n can be applied on a regular data set, a grouped data set, or a grouped-sorted data set. Grouping keys can be specified as key-selector functions or field position keys.</p>

<figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="nc">DataSet</span><span class="o">&lt;</span><span class="nc">Tuple2</span><span class="o">&lt;</span><span class="nc">String</span><span class="o">,</span><span class="nc">Integer</span><span class="o">&gt;&gt;</span> <span class="n">in</span> <span class="o">=</span> <span class="c1">// [...]</span>
<span class="c1">// regular data set</span>
<span class="nc">DataSet</span><span class="o">&lt;</span><span class="nc">Tuple2</span><span class="o">&lt;</span><span class="nc">String</span><span class="o">,</span><span class="nc">Integer</span><span class="o">&gt;&gt;</span> <span class="n">result1</span> <span class="o">=</span> <span class="n">in</span><span class="o">.</span><span class="na">first</span><span class="o">(</span><span class="mi">3</span><span class="o">);</span>
<span class="c1">// grouped data set</span>
<span class="nc">DataSet</span><span class="o">&lt;</span><span class="nc">Tuple2</span><span class="o">&lt;</span><span class="nc">String</span><span class="o">,</span><span class="nc">Integer</span><span class="o">&gt;&gt;</span> <span class="n">result2</span> <span class="o">=</span> <span class="n">in</span><span class="o">.</span><span class="na">groupBy</span><span class="o">(</span><span class="mi">0</span><span class="o">)</span>
                                            <span class="o">.</span><span class="na">first</span><span class="o">(</span><span class="mi">3</span><span class="o">);</span>
<span class="c1">// grouped-sorted data set</span>
<span class="nc">DataSet</span><span class="o">&lt;</span><span class="nc">Tuple2</span><span class="o">&lt;</span><span class="nc">String</span><span class="o">,</span><span class="nc">Integer</span><span class="o">&gt;&gt;</span> <span class="n">result3</span> <span class="o">=</span> <span class="n">in</span><span class="o">.</span><span class="na">groupBy</span><span class="o">(</span><span class="mi">0</span><span class="o">)</span>
                                            <span class="o">.</span><span class="na">sortGroup</span><span class="o">(</span><span class="mi">1</span><span class="o">,</span> <span class="nc">Order</span><span class="o">.</span><span class="na">ASCENDING</span><span class="o">)</span>
                                            <span class="o">.</span><span class="na">first</span><span class="o">(</span><span class="mi">3</span><span class="o">);</span></code></pre></figure>

      </td>
    </tr>
  </tbody>
</table>

    <hr />

    <p>The following transformations are available on data sets of Tuples:</p>

    <table class="table table-bordered">
  <thead>
    <tr>
      <th class="text-left" style="width: 20%">Transformation</th>
      <th class="text-center">Description</th>
    </tr>
  </thead>
  <tbody>
   <tr>
      <td><strong>Project</strong></td>
      <td>
        <p>Selects a subset of fields from the tuples</p>

<figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="nc">DataSet</span><span class="o">&lt;</span><span class="nc">Tuple3</span><span class="o">&lt;</span><span class="nc">Integer</span><span class="o">,</span> <span class="nc">Double</span><span class="o">,</span> <span class="nc">String</span><span class="o">&gt;&gt;</span> <span class="n">in</span> <span class="o">=</span> <span class="c1">// [...]</span>
<span class="nc">DataSet</span><span class="o">&lt;</span><span class="nc">Tuple2</span><span class="o">&lt;</span><span class="nc">String</span><span class="o">,</span> <span class="nc">Integer</span><span class="o">&gt;&gt;</span> <span class="n">out</span> <span class="o">=</span> <span class="n">in</span><span class="o">.</span><span class="na">project</span><span class="o">(</span><span class="mi">2</span><span class="o">,</span><span class="mi">0</span><span class="o">);</span></code></pre></figure>

      </td>
    </tr>
    <tr>
      <td><strong>MinBy / MaxBy</strong></td>
      <td>
        <p>Selects a tuple from a group of tuples whose values of one or more fields are minimum (maximum). The fields which are used for comparison must be valid key fields, i.e., comparable. If multiple tuples have minimum (maximum) field values, an arbitrary tuple of these tuples is returned. MinBy (MaxBy) may be applied on a full data set or a grouped data set.</p>

<figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="nc">DataSet</span><span class="o">&lt;</span><span class="nc">Tuple3</span><span class="o">&lt;</span><span class="nc">Integer</span><span class="o">,</span> <span class="nc">Double</span><span class="o">,</span> <span class="nc">String</span><span class="o">&gt;&gt;</span> <span class="n">in</span> <span class="o">=</span> <span class="c1">// [...]</span>
<span class="c1">// a DataSet with a single tuple with minimum values for the Integer and String fields.</span>
<span class="nc">DataSet</span><span class="o">&lt;</span><span class="nc">Tuple3</span><span class="o">&lt;</span><span class="nc">Integer</span><span class="o">,</span> <span class="nc">Double</span><span class="o">,</span> <span class="nc">String</span><span class="o">&gt;&gt;</span> <span class="n">out</span> <span class="o">=</span> <span class="n">in</span><span class="o">.</span><span class="na">minBy</span><span class="o">(</span><span class="mi">0</span><span class="o">,</span> <span class="mi">2</span><span class="o">);</span>
<span class="c1">// a DataSet with one tuple for each group with the minimum value for the Double field.</span>
<span class="nc">DataSet</span><span class="o">&lt;</span><span class="nc">Tuple3</span><span class="o">&lt;</span><span class="nc">Integer</span><span class="o">,</span> <span class="nc">Double</span><span class="o">,</span> <span class="nc">String</span><span class="o">&gt;&gt;</span> <span class="n">out2</span> <span class="o">=</span> <span class="n">in</span><span class="o">.</span><span class="na">groupBy</span><span class="o">(</span><span class="mi">2</span><span class="o">)</span>
                                                  <span class="o">.</span><span class="na">minBy</span><span class="o">(</span><span class="mi">1</span><span class="o">);</span></code></pre></figure>

      </td>
    </tr>
  </tbody>
</table>

  </div>
  <div data-lang="scala">
    <p><br /></p>

    <table class="table table-bordered">
  <thead>
    <tr>
      <th class="text-left" style="width: 20%">Transformation</th>
      <th class="text-center">Description</th>
    </tr>
  </thead>

  <tbody>
    <tr>
      <td><strong>Map</strong></td>
      <td>
        <p>Takes one element and produces one element.</p>

<figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="nv">data</span><span class="o">.</span><span class="py">map</span> <span class="o">{</span> <span class="n">x</span> <span class="k">=&gt;</span> <span class="nv">x</span><span class="o">.</span><span class="py">toInt</span> <span class="o">}</span></code></pre></figure>

      </td>
    </tr>

    <tr>
      <td><strong>FlatMap</strong></td>
      <td>
        <p>Takes one element and produces zero, one, or more elements. </p>

<figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="nv">data</span><span class="o">.</span><span class="py">flatMap</span> <span class="o">{</span> <span class="n">str</span> <span class="k">=&gt;</span> <span class="nv">str</span><span class="o">.</span><span class="py">split</span><span class="o">(</span><span class="s">" "</span><span class="o">)</span> <span class="o">}</span></code></pre></figure>

      </td>
    </tr>

    <tr>
      <td><strong>MapPartition</strong></td>
      <td>
        <p>Transforms a parallel partition in a single function call. The function get the partition
        as an `Iterator` and can produce an arbitrary number of result values. The number of
        elements in each partition depends on the degree-of-parallelism and previous operations.</p>

<figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="nv">data</span><span class="o">.</span><span class="py">mapPartition</span> <span class="o">{</span> <span class="n">in</span> <span class="k">=&gt;</span> <span class="n">in</span> <span class="n">map</span> <span class="o">{</span> <span class="o">(</span><span class="k">_</span><span class="o">,</span> <span class="mi">1</span><span class="o">)</span> <span class="o">}</span> <span class="o">}</span></code></pre></figure>

      </td>
    </tr>

    <tr>
      <td><strong>Filter</strong></td>
      <td>
        <p>Evaluates a boolean function for each element and retains those for which the function
        returns true.<br />
        <strong>IMPORTANT:</strong> The system assumes that the function does not modify the element on which the predicate is applied.
        Violating this assumption can lead to incorrect results.</p>

<figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="nv">data</span><span class="o">.</span><span class="py">filter</span> <span class="o">{</span> <span class="k">_</span> <span class="o">&gt;</span> <span class="mi">1000</span> <span class="o">}</span></code></pre></figure>

      </td>
    </tr>

    <tr>
      <td><strong>Reduce</strong></td>
      <td>
        <p>Combines a group of elements into a single element by repeatedly combining two elements
        into one. Reduce may be applied on a full data set, or on a grouped data set.</p>

<figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="nv">data</span><span class="o">.</span><span class="py">reduce</span> <span class="o">{</span> <span class="k">_</span> <span class="o">+</span> <span class="k">_</span> <span class="o">}</span></code></pre></figure>

      </td>
    </tr>

    <tr>
      <td><strong>ReduceGroup</strong></td>
      <td>
        <p>Combines a group of elements into one or more elements. ReduceGroup may be applied on a
        full data set, or on a grouped data set.</p>

<figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="nv">data</span><span class="o">.</span><span class="py">reduceGroup</span> <span class="o">{</span> <span class="n">elements</span> <span class="k">=&gt;</span> <span class="nv">elements</span><span class="o">.</span><span class="py">sum</span> <span class="o">}</span></code></pre></figure>

      </td>
    </tr>

    <tr>
      <td><strong>Aggregate</strong></td>
      <td>
        <p>Aggregates a group of values into a single value. Aggregation functions can be thought of
        as built-in reduce functions. Aggregate may be applied on a full data set, or on a grouped
        data set.</p>

<figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="nv">input</span><span class="k">:</span> <span class="kt">DataSet</span><span class="o">[(</span><span class="kt">Int</span>, <span class="kt">String</span>, <span class="kt">Double</span><span class="o">)]</span> <span class="k">=</span> <span class="c1">// [...]</span>
<span class="k">val</span> <span class="nv">output</span><span class="k">:</span> <span class="kt">DataSet</span><span class="o">[(</span><span class="kt">Int</span>, <span class="kt">String</span>, <span class="kt">Double</span><span class="o">)]</span> <span class="k">=</span> <span class="nv">input</span><span class="o">.</span><span class="py">aggregate</span><span class="o">(</span><span class="nc">SUM</span><span class="o">,</span> <span class="mi">0</span><span class="o">).</span><span class="py">aggregate</span><span class="o">(</span><span class="nc">MIN</span><span class="o">,</span> <span class="mi">2</span><span class="o">)</span></code></pre></figure>

  <p>You can also use short-hand syntax for minimum, maximum, and sum aggregations.</p>

<figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="nv">input</span><span class="k">:</span> <span class="kt">DataSet</span><span class="o">[(</span><span class="kt">Int</span>, <span class="kt">String</span>, <span class="kt">Double</span><span class="o">)]</span> <span class="k">=</span> <span class="c1">// [...]</span>
<span class="k">val</span> <span class="nv">output</span><span class="k">:</span> <span class="kt">DataSet</span><span class="o">[(</span><span class="kt">Int</span>, <span class="kt">String</span>, <span class="kt">Double</span><span class="o">)]</span> <span class="k">=</span> <span class="nv">input</span><span class="o">.</span><span class="py">sum</span><span class="o">(</span><span class="mi">0</span><span class="o">).</span><span class="py">min</span><span class="o">(</span><span class="mi">2</span><span class="o">)</span></code></pre></figure>

      </td>
    </tr>

    <tr>
      <td><strong>Distinct</strong></td>
      <td>
        <p>Returns the distinct elements of a data set. It removes the duplicate entries
        from the input DataSet, with respect to all fields of the elements, or a subset of fields.</p>

<figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="nv">data</span><span class="o">.</span><span class="py">distinct</span><span class="o">()</span></code></pre></figure>

      </td>
    </tr>

    <tr>
      <td><strong>Join</strong></td>
      <td>
        Joins two data sets by creating all pairs of elements that are equal on their keys.
        Optionally uses a JoinFunction to turn the pair of elements into a single element, or a
        FlatJoinFunction to turn the pair of elements into arbitrarily many (including none)
        elements. See the <a href="#specifying-keys">keys section</a> to learn how to define join keys.

<figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="c1">// In this case tuple fields are used as keys. "0" is the join field on the first tuple</span>
<span class="c1">// "1" is the join field on the second tuple.</span>
<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">input1</span><span class="o">.</span><span class="py">join</span><span class="o">(</span><span class="n">input2</span><span class="o">).</span><span class="py">where</span><span class="o">(</span><span class="mi">0</span><span class="o">).</span><span class="py">equalTo</span><span class="o">(</span><span class="mi">1</span><span class="o">)</span></code></pre></figure>

        You can specify the way that the runtime executes the join via <i>Join Hints</i>. The hints
        describe whether the join happens through partitioning or broadcasting, and whether it uses
        a sort-based or a hash-based algorithm. Please refer to the
        <a href="dataset_transformations.html#join-algorithm-hints">Transformations Guide</a> for
        a list of possible hints and an example.<br />
        If no hint is specified, the system will try to make an estimate of the input sizes and
        pick the best strategy according to those estimates.

<figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="c1">// This executes a join by broadcasting the first data set</span>
<span class="c1">// using a hash table for the broadcast data</span>
<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">input1</span><span class="o">.</span><span class="py">join</span><span class="o">(</span><span class="n">input2</span><span class="o">,</span> <span class="nv">JoinHint</span><span class="o">.</span><span class="py">BROADCAST_HASH_FIRST</span><span class="o">)</span>
                   <span class="o">.</span><span class="py">where</span><span class="o">(</span><span class="mi">0</span><span class="o">).</span><span class="py">equalTo</span><span class="o">(</span><span class="mi">1</span><span class="o">)</span></code></pre></figure>

          Note that the join transformation works only for equi-joins. Other join types need to be expressed using OuterJoin or CoGroup.
      </td>
    </tr>

    <tr>
      <td><strong>OuterJoin</strong></td>
      <td>
        Performs a left, right, or full outer join on two data sets. Outer joins are similar to regular (inner) joins and create all pairs of elements that are equal on their keys. In addition, records of the "outer" side (left, right, or both in case of full) are preserved if no matching key is found in the other side. Matching pairs of elements (or one element and a `null` value for the other input) are given to a JoinFunction to turn the pair of elements into a single element, or to a FlatJoinFunction to turn the pair of elements into arbitrarily many (including none)         elements. See the <a href="#specifying-keys">keys section</a> to learn how to define join keys.

<figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="nv">joined</span> <span class="k">=</span> <span class="nv">left</span><span class="o">.</span><span class="py">leftOuterJoin</span><span class="o">(</span><span class="n">right</span><span class="o">).</span><span class="py">where</span><span class="o">(</span><span class="mi">0</span><span class="o">).</span><span class="py">equalTo</span><span class="o">(</span><span class="mi">1</span><span class="o">)</span> <span class="o">{</span>
   <span class="o">(</span><span class="n">left</span><span class="o">,</span> <span class="n">right</span><span class="o">)</span> <span class="k">=&gt;</span>
     <span class="k">val</span> <span class="nv">a</span> <span class="k">=</span> <span class="nf">if</span> <span class="o">(</span><span class="n">left</span> <span class="o">==</span> <span class="kc">null</span><span class="o">)</span> <span class="s">"none"</span> <span class="k">else</span> <span class="nv">left</span><span class="o">.</span><span class="py">_1</span>
     <span class="o">(</span><span class="n">a</span><span class="o">,</span> <span class="n">right</span><span class="o">)</span>
  <span class="o">}</span></code></pre></figure>

      </td>
    </tr>

    <tr>
      <td><strong>CoGroup</strong></td>
      <td>
        <p>The two-dimensional variant of the reduce operation. Groups each input on one or more
        fields and then joins the groups. The transformation function is called per pair of groups.
        See the <a href="#specifying-keys">keys section</a> to learn how to define coGroup keys.</p>

<figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="nv">data1</span><span class="o">.</span><span class="py">coGroup</span><span class="o">(</span><span class="n">data2</span><span class="o">).</span><span class="py">where</span><span class="o">(</span><span class="mi">0</span><span class="o">).</span><span class="py">equalTo</span><span class="o">(</span><span class="mi">1</span><span class="o">)</span></code></pre></figure>

      </td>
    </tr>

    <tr>
      <td><strong>Cross</strong></td>
      <td>
        <p>Builds the Cartesian product (cross product) of two inputs, creating all pairs of
        elements. Optionally uses a CrossFunction to turn the pair of elements into a single
        element</p>

<figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="nv">data1</span><span class="k">:</span> <span class="kt">DataSet</span><span class="o">[</span><span class="kt">Int</span><span class="o">]</span> <span class="k">=</span> <span class="c1">// [...]</span>
<span class="k">val</span> <span class="nv">data2</span><span class="k">:</span> <span class="kt">DataSet</span><span class="o">[</span><span class="kt">String</span><span class="o">]</span> <span class="k">=</span> <span class="c1">// [...]</span>
<span class="k">val</span> <span class="nv">result</span><span class="k">:</span> <span class="kt">DataSet</span><span class="o">[(</span><span class="kt">Int</span>, <span class="kt">String</span><span class="o">)]</span> <span class="k">=</span> <span class="nv">data1</span><span class="o">.</span><span class="py">cross</span><span class="o">(</span><span class="n">data2</span><span class="o">)</span></code></pre></figure>

        <p>Note: Cross is potentially a <b>very</b> compute-intensive operation which can challenge even large compute clusters! It is advised to hint the system with the DataSet sizes by using <i>crossWithTiny()</i> and <i>crossWithHuge()</i>.</p>
      </td>
    </tr>
    <tr>
      <td><strong>Union</strong></td>
      <td>
        <p>Produces the union of two data sets.</p>

<figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="nv">data</span><span class="o">.</span><span class="py">union</span><span class="o">(</span><span class="n">data2</span><span class="o">)</span></code></pre></figure>

      </td>
    </tr>
    <tr>
      <td><strong>Rebalance</strong></td>
      <td>
        <p>Evenly rebalances the parallel partitions of a data set to eliminate data skew. Only Map-like transformations may follow a rebalance transformation.</p>

<figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="nv">data1</span><span class="k">:</span> <span class="kt">DataSet</span><span class="o">[</span><span class="kt">Int</span><span class="o">]</span> <span class="k">=</span> <span class="c1">// [...]</span>
<span class="k">val</span> <span class="nv">result</span><span class="k">:</span> <span class="kt">DataSet</span><span class="o">[(</span><span class="kt">Int</span>, <span class="kt">String</span><span class="o">)]</span> <span class="k">=</span> <span class="nv">data1</span><span class="o">.</span><span class="py">rebalance</span><span class="o">().</span><span class="py">map</span><span class="o">(...)</span></code></pre></figure>

      </td>
    </tr>
    <tr>
      <td><strong>Hash-Partition</strong></td>
      <td>
        <p>Hash-partitions a data set on a given key. Keys can be specified as position keys, expression keys, and key selector functions.</p>

<figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="nv">in</span><span class="k">:</span> <span class="kt">DataSet</span><span class="o">[(</span><span class="kt">Int</span>, <span class="kt">String</span><span class="o">)]</span> <span class="k">=</span> <span class="c1">// [...]</span>
<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">in</span><span class="o">.</span><span class="py">partitionByHash</span><span class="o">(</span><span class="mi">0</span><span class="o">).</span><span class="py">mapPartition</span> <span class="o">{</span> <span class="o">...</span> <span class="o">}</span></code></pre></figure>

      </td>
    </tr>
    <tr>
      <td><strong>Range-Partition</strong></td>
      <td>
        <p>Range-partitions a data set on a given key. Keys can be specified as position keys, expression keys, and key selector functions.</p>

<figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="nv">in</span><span class="k">:</span> <span class="kt">DataSet</span><span class="o">[(</span><span class="kt">Int</span>, <span class="kt">String</span><span class="o">)]</span> <span class="k">=</span> <span class="c1">// [...]</span>
<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">in</span><span class="o">.</span><span class="py">partitionByRange</span><span class="o">(</span><span class="mi">0</span><span class="o">).</span><span class="py">mapPartition</span> <span class="o">{</span> <span class="o">...</span> <span class="o">}</span></code></pre></figure>

      </td>
    </tr>
    <tr>
      <td><strong>Custom Partitioning</strong></td>
      <td>
        <p>Assigns records based on a key to a specific partition using a custom Partitioner function.
          The key can be specified as position key, expression key, and key selector function.
          <br />
          <i>Note</i>: This method only works with a single field key.</p>

<figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="nv">in</span><span class="k">:</span> <span class="kt">DataSet</span><span class="o">[(</span><span class="kt">Int</span>, <span class="kt">String</span><span class="o">)]</span> <span class="k">=</span> <span class="c1">// [...]</span>
<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="n">in</span>
  <span class="o">.</span><span class="py">partitionCustom</span><span class="o">(</span><span class="n">partitioner</span><span class="o">,</span> <span class="n">key</span><span class="o">).</span><span class="py">mapPartition</span> <span class="o">{</span> <span class="o">...</span> <span class="o">}</span></code></pre></figure>

      </td>
    </tr>
    <tr>
      <td><strong>Sort Partition</strong></td>
      <td>
        <p>Locally sorts all partitions of a data set on a specified field in a specified order.
          Fields can be specified as tuple positions or field expressions.
          Sorting on multiple fields is done by chaining sortPartition() calls.</p>

<figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="nv">in</span><span class="k">:</span> <span class="kt">DataSet</span><span class="o">[(</span><span class="kt">Int</span>, <span class="kt">String</span><span class="o">)]</span> <span class="k">=</span> <span class="c1">// [...]</span>
<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">in</span><span class="o">.</span><span class="py">sortPartition</span><span class="o">(</span><span class="mi">1</span><span class="o">,</span> <span class="nv">Order</span><span class="o">.</span><span class="py">ASCENDING</span><span class="o">).</span><span class="py">mapPartition</span> <span class="o">{</span> <span class="o">...</span> <span class="o">}</span></code></pre></figure>

      </td>
    </tr>
    <tr>
      <td><strong>First-n</strong></td>
      <td>
        <p>Returns the first n (arbitrary) elements of a data set. First-n can be applied on a regular data set, a grouped data set, or a grouped-sorted data set. Grouping keys can be specified as key-selector functions,
        tuple positions or case class fields.</p>

<figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="nv">in</span><span class="k">:</span> <span class="kt">DataSet</span><span class="o">[(</span><span class="kt">Int</span>, <span class="kt">String</span><span class="o">)]</span> <span class="k">=</span> <span class="c1">// [...]</span>
<span class="c1">// regular data set</span>
<span class="k">val</span> <span class="nv">result1</span> <span class="k">=</span> <span class="nv">in</span><span class="o">.</span><span class="py">first</span><span class="o">(</span><span class="mi">3</span><span class="o">)</span>
<span class="c1">// grouped data set</span>
<span class="k">val</span> <span class="nv">result2</span> <span class="k">=</span> <span class="nv">in</span><span class="o">.</span><span class="py">groupBy</span><span class="o">(</span><span class="mi">0</span><span class="o">).</span><span class="py">first</span><span class="o">(</span><span class="mi">3</span><span class="o">)</span>
<span class="c1">// grouped-sorted data set</span>
<span class="k">val</span> <span class="nv">result3</span> <span class="k">=</span> <span class="nv">in</span><span class="o">.</span><span class="py">groupBy</span><span class="o">(</span><span class="mi">0</span><span class="o">).</span><span class="py">sortGroup</span><span class="o">(</span><span class="mi">1</span><span class="o">,</span> <span class="nv">Order</span><span class="o">.</span><span class="py">ASCENDING</span><span class="o">).</span><span class="py">first</span><span class="o">(</span><span class="mi">3</span><span class="o">)</span></code></pre></figure>

      </td>
    </tr>
  </tbody>
</table>

    <hr />

    <p>The following transformations are available on data sets of Tuples:</p>

    <table class="table table-bordered">
  <thead>
    <tr>
      <th class="text-left" style="width: 20%">Transformation</th>
      <th class="text-center">Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><strong>MinBy / MaxBy</strong></td>
      <td>
        <p>Selects a tuple from a group of tuples whose values of one or more fields are minimum (maximum). The fields which are used for comparison must be valid key fields, i.e., comparable. If multiple tuples have minimum (maximum) field values, an arbitrary tuple of these tuples is returned. MinBy (MaxBy) may be applied on a full data set or a grouped data set.</p>

<figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="n">val</span> <span class="nl">in:</span> <span class="nc">DataSet</span><span class="o">[(</span><span class="nc">Int</span><span class="o">,</span> <span class="nc">Double</span><span class="o">,</span> <span class="nc">String</span><span class="o">)]</span> <span class="o">=</span> <span class="c1">// [...]</span>
<span class="c1">// a data set with a single tuple with minimum values for the Int and String fields.</span>
<span class="n">val</span> <span class="nl">out:</span> <span class="nc">DataSet</span><span class="o">[(</span><span class="nc">Int</span><span class="o">,</span> <span class="nc">Double</span><span class="o">,</span> <span class="nc">String</span><span class="o">)]</span> <span class="o">=</span> <span class="n">in</span><span class="o">.</span><span class="na">minBy</span><span class="o">(</span><span class="mi">0</span><span class="o">,</span> <span class="mi">2</span><span class="o">)</span>
<span class="c1">// a data set with one tuple for each group with the minimum value for the Double field.</span>
<span class="n">val</span> <span class="nl">out2:</span> <span class="nc">DataSet</span><span class="o">[(</span><span class="nc">Int</span><span class="o">,</span> <span class="nc">Double</span><span class="o">,</span> <span class="nc">String</span><span class="o">)]</span> <span class="o">=</span> <span class="n">in</span><span class="o">.</span><span class="na">groupBy</span><span class="o">(</span><span class="mi">2</span><span class="o">)</span>
                                             <span class="o">.</span><span class="na">minBy</span><span class="o">(</span><span class="mi">1</span><span class="o">)</span></code></pre></figure>

      </td>
    </tr>
  </tbody>
</table>

    <p>Extraction from tuples, case classes and collections via anonymous pattern matching, like the following:</p>

    <figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="nv">data</span><span class="k">:</span> <span class="kt">DataSet</span><span class="o">[(</span><span class="kt">Int</span>, <span class="kt">String</span>, <span class="kt">Double</span><span class="o">)]</span> <span class="k">=</span> <span class="c1">// [...]</span>
<span class="nv">data</span><span class="o">.</span><span class="py">map</span> <span class="o">{</span>
  <span class="nf">case</span> <span class="o">(</span><span class="n">id</span><span class="o">,</span> <span class="n">name</span><span class="o">,</span> <span class="n">temperature</span><span class="o">)</span> <span class="k">=&gt;</span> <span class="c1">// [...]</span>
<span class="o">}</span></code></pre></figure>

    <p>is not supported by the API out-of-the-box. To use this feature, you should use a <a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/scala_api_extensions.html">Scala API extension</a>.</p>

  </div>
</div>

<p>The <a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/parallel.html">parallelism</a> of a transformation can be defined by <code class="highlighter-rouge">setParallelism(int)</code> while
<code class="highlighter-rouge">name(String)</code> assigns a custom name to a transformation which is helpful for debugging. The same is
possible for <a href="#data-sources">Data Sources</a> and <a href="#data-sinks">Data Sinks</a>.</p>

<p><code class="highlighter-rouge">withParameters(Configuration)</code> passes Configuration objects, which can be accessed from the <code class="highlighter-rouge">open()</code> method inside the user function.</p>

<p><a href="#top" class="top pull-right"><span class="glyphicon glyphicon-chevron-up"></span> Back to top</a></p>

<h2 id="specifying-keys">Specifying Keys</h2>

<p>Some transformations (join, coGroup, groupBy) require that a key be defined on
a collection of elements. Other transformations (Reduce, GroupReduce,
Aggregate) allow data being grouped on a key before they are
applied.</p>

<p>A DataSet is grouped as</p>

<figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="nc">DataSet</span><span class="o">&lt;...&gt;</span> <span class="n">input</span> <span class="o">=</span> <span class="c1">// [...]</span>
<span class="nc">DataSet</span><span class="o">&lt;...&gt;</span> <span class="n">reduced</span> <span class="o">=</span> <span class="n">input</span>
  <span class="o">.</span><span class="na">groupBy</span><span class="o">(</span><span class="cm">/*define key here*/</span><span class="o">)</span>
  <span class="o">.</span><span class="na">reduceGroup</span><span class="o">(</span><span class="cm">/*do something*/</span><span class="o">);</span></code></pre></figure>

<p>The data model of Flink is not based on key-value pairs. Therefore,
you do not need to physically pack the data set types into keys and
values. Keys are “virtual”: they are defined as functions over the
actual data to guide the grouping operator.</p>

<h3 class="no_toc" id="define-keys-for-tuples">Define keys for Tuples</h3>

<p>The simplest case is grouping Tuples on one or more
fields of the Tuple:</p>

<div class="codetabs">
  <div data-lang="java">

    <figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="nc">DataSet</span><span class="o">&lt;</span><span class="nc">Tuple3</span><span class="o">&lt;</span><span class="nc">Integer</span><span class="o">,</span><span class="nc">String</span><span class="o">,</span><span class="nc">Long</span><span class="o">&gt;&gt;</span> <span class="n">input</span> <span class="o">=</span> <span class="c1">// [...]</span>
<span class="nc">UnsortedGrouping</span><span class="o">&lt;</span><span class="nc">Tuple3</span><span class="o">&lt;</span><span class="nc">Integer</span><span class="o">,</span><span class="nc">String</span><span class="o">,</span><span class="nc">Long</span><span class="o">&gt;,</span><span class="nc">Tuple</span><span class="o">&gt;</span> <span class="n">keyed</span> <span class="o">=</span> <span class="n">input</span><span class="o">.</span><span class="na">groupBy</span><span class="o">(</span><span class="mi">0</span><span class="o">)</span></code></pre></figure>

  </div>
  <div data-lang="scala">

    <figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="nv">input</span><span class="k">:</span> <span class="kt">DataSet</span><span class="o">[(</span><span class="kt">Int</span>, <span class="kt">String</span>, <span class="kt">Long</span><span class="o">)]</span> <span class="k">=</span> <span class="c1">// [...]</span>
<span class="k">val</span> <span class="nv">keyed</span> <span class="k">=</span> <span class="nv">input</span><span class="o">.</span><span class="py">groupBy</span><span class="o">(</span><span class="mi">0</span><span class="o">)</span></code></pre></figure>

  </div>
</div>

<p>The tuples are grouped on the first field (the one of
Integer type).</p>

<div class="codetabs">
  <div data-lang="java">

    <figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="nc">DataSet</span><span class="o">&lt;</span><span class="nc">Tuple3</span><span class="o">&lt;</span><span class="nc">Integer</span><span class="o">,</span><span class="nc">String</span><span class="o">,</span><span class="nc">Long</span><span class="o">&gt;&gt;</span> <span class="n">input</span> <span class="o">=</span> <span class="c1">// [...]</span>
<span class="nc">UnsortedGrouping</span><span class="o">&lt;</span><span class="nc">Tuple3</span><span class="o">&lt;</span><span class="nc">Integer</span><span class="o">,</span><span class="nc">String</span><span class="o">,</span><span class="nc">Long</span><span class="o">&gt;,</span><span class="nc">Tuple</span><span class="o">&gt;</span> <span class="n">keyed</span> <span class="o">=</span> <span class="n">input</span><span class="o">.</span><span class="na">groupBy</span><span class="o">(</span><span class="mi">0</span><span class="o">,</span><span class="mi">1</span><span class="o">)</span></code></pre></figure>

  </div>
  <div data-lang="scala">

    <figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="nv">input</span><span class="k">:</span> <span class="kt">DataSet</span><span class="o">[(</span><span class="kt">Int</span>, <span class="kt">String</span>, <span class="kt">Long</span><span class="o">)]</span> <span class="k">=</span> <span class="c1">// [...]</span>
<span class="k">val</span> <span class="nv">grouped</span> <span class="k">=</span> <span class="nv">input</span><span class="o">.</span><span class="py">groupBy</span><span class="o">(</span><span class="mi">0</span><span class="o">,</span><span class="mi">1</span><span class="o">)</span></code></pre></figure>

  </div>
</div>

<p>Here, we group the tuples on a composite key consisting of the first and the
second field.</p>

<p>A note on nested Tuples: If you have a DataSet with a nested tuple, such as:</p>

<figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="nc">DataSet</span><span class="o">&lt;</span><span class="nc">Tuple3</span><span class="o">&lt;</span><span class="nc">Tuple2</span><span class="o">&lt;</span><span class="nc">Integer</span><span class="o">,</span> <span class="nc">Float</span><span class="o">&gt;,</span><span class="nc">String</span><span class="o">,</span><span class="nc">Long</span><span class="o">&gt;&gt;</span> <span class="n">ds</span><span class="o">;</span></code></pre></figure>

<p>Specifying <code class="highlighter-rouge">groupBy(0)</code> will cause the system to use the full <code class="highlighter-rouge">Tuple2</code> as a key (with the Integer and Float being the key). If you want to “navigate” into the nested <code class="highlighter-rouge">Tuple2</code>, you have to use field expression keys which are explained below.</p>

<h3 class="no_toc" id="define-keys-using-field-expressions">Define keys using Field Expressions</h3>

<p>You can use String-based field expressions to reference nested fields and define keys for grouping, sorting, joining, or coGrouping.</p>

<p>Field expressions make it very easy to select fields in (nested) composite types such as <a href="#tuples-and-case-classes">Tuple</a> and <a href="#pojos">POJO</a> types.</p>

<div class="codetabs">
  <div data-lang="java">

    <p>In the example below, we have a <code class="highlighter-rouge">WC</code> POJO with two fields “word” and “count”. To group by the field <code class="highlighter-rouge">word</code>, we just pass its name to the <code class="highlighter-rouge">groupBy()</code> function.</p>

    <figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="c1">// some ordinary POJO (Plain old Java Object)</span>
<span class="kd">public</span> <span class="kd">class</span> <span class="nc">WC</span> <span class="o">{</span>
  <span class="kd">public</span> <span class="nc">String</span> <span class="n">word</span><span class="o">;</span>
  <span class="kd">public</span> <span class="kt">int</span> <span class="n">count</span><span class="o">;</span>
<span class="o">}</span>
<span class="nc">DataSet</span><span class="o">&lt;</span><span class="no">WC</span><span class="o">&gt;</span> <span class="n">words</span> <span class="o">=</span> <span class="c1">// [...]</span>
<span class="nc">DataSet</span><span class="o">&lt;</span><span class="no">WC</span><span class="o">&gt;</span> <span class="n">wordCounts</span> <span class="o">=</span> <span class="n">words</span><span class="o">.</span><span class="na">groupBy</span><span class="o">(</span><span class="s">"word"</span><span class="o">)</span></code></pre></figure>

    <p><strong>Field Expression Syntax</strong>:</p>

    <ul>
      <li>
        <p>Select POJO fields by their field name. For example <code class="highlighter-rouge">"user"</code> refers to the “user” field of a POJO type.</p>
      </li>
      <li>
        <p>Select Tuple fields by their field name or 0-offset field index. For example <code class="highlighter-rouge">"f0"</code> and <code class="highlighter-rouge">"5"</code> refer to the first and sixth field of a Java Tuple type, respectively.</p>
      </li>
      <li>
        <p>You can select nested fields in POJOs and Tuples. For example <code class="highlighter-rouge">"user.zip"</code> refers to the “zip” field of a POJO which is stored in the “user” field of a POJO type. Arbitrary nesting and mixing of POJOs and Tuples is supported such as <code class="highlighter-rouge">"f1.user.zip"</code> or <code class="highlighter-rouge">"user.f3.1.zip"</code>.</p>
      </li>
      <li>
        <p>You can select the full type using the <code class="highlighter-rouge">"*"</code> wildcard expressions. This does also work for types which are not Tuple or POJO types.</p>
      </li>
    </ul>

    <p><strong>Field Expression Example</strong>:</p>

    <figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="kd">public</span> <span class="kd">static</span> <span class="kd">class</span> <span class="nc">WC</span> <span class="o">{</span>
  <span class="kd">public</span> <span class="nc">ComplexNestedClass</span> <span class="n">complex</span><span class="o">;</span> <span class="c1">//nested POJO</span>
  <span class="kd">private</span> <span class="kt">int</span> <span class="n">count</span><span class="o">;</span>
  <span class="c1">// getter / setter for private field (count)</span>
  <span class="kd">public</span> <span class="kt">int</span> <span class="nf">getCount</span><span class="o">()</span> <span class="o">{</span>
    <span class="k">return</span> <span class="n">count</span><span class="o">;</span>
  <span class="o">}</span>
  <span class="kd">public</span> <span class="kt">void</span> <span class="nf">setCount</span><span class="o">(</span><span class="kt">int</span> <span class="n">c</span><span class="o">)</span> <span class="o">{</span>
    <span class="k">this</span><span class="o">.</span><span class="na">count</span> <span class="o">=</span> <span class="n">c</span><span class="o">;</span>
  <span class="o">}</span>
<span class="o">}</span>
<span class="kd">public</span> <span class="kd">static</span> <span class="kd">class</span> <span class="nc">ComplexNestedClass</span> <span class="o">{</span>
  <span class="kd">public</span> <span class="nc">Integer</span> <span class="n">someNumber</span><span class="o">;</span>
  <span class="kd">public</span> <span class="kt">float</span> <span class="n">someFloat</span><span class="o">;</span>
  <span class="kd">public</span> <span class="nc">Tuple3</span><span class="o">&lt;</span><span class="nc">Long</span><span class="o">,</span> <span class="nc">Long</span><span class="o">,</span> <span class="nc">String</span><span class="o">&gt;</span> <span class="n">word</span><span class="o">;</span>
  <span class="kd">public</span> <span class="nc">IntWritable</span> <span class="n">hadoopCitizen</span><span class="o">;</span>
<span class="o">}</span></code></pre></figure>

    <p>These are valid field expressions for the example code above:</p>

    <ul>
      <li>
        <p><code class="highlighter-rouge">"count"</code>: The count field in the <code class="highlighter-rouge">WC</code> class.</p>
      </li>
      <li>
        <p><code class="highlighter-rouge">"complex"</code>: Recursively selects all fields of the field complex of POJO type <code class="highlighter-rouge">ComplexNestedClass</code>.</p>
      </li>
      <li>
        <p><code class="highlighter-rouge">"complex.word.f2"</code>: Selects the last field of the nested <code class="highlighter-rouge">Tuple3</code>.</p>
      </li>
      <li>
        <p><code class="highlighter-rouge">"complex.hadoopCitizen"</code>: Selects the Hadoop <code class="highlighter-rouge">IntWritable</code> type.</p>
      </li>
    </ul>

  </div>
  <div data-lang="scala">

    <p>In the example below, we have a <code class="highlighter-rouge">WC</code> POJO with two fields “word” and “count”. To group by the field <code class="highlighter-rouge">word</code>, we just pass its name to the <code class="highlighter-rouge">groupBy()</code> function.</p>

    <figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="c1">// some ordinary POJO (Plain old Java Object)</span>
<span class="k">class</span> <span class="nc">WC</span><span class="o">(</span><span class="k">var</span> <span class="n">word</span><span class="k">:</span> <span class="kt">String</span><span class="o">,</span> <span class="k">var</span> <span class="n">count</span><span class="k">:</span> <span class="kt">Int</span><span class="o">)</span> <span class="o">{</span>
  <span class="k">def</span> <span class="nf">this</span><span class="o">()</span> <span class="o">{</span> <span class="nf">this</span><span class="o">(</span><span class="s">""</span><span class="o">,</span> <span class="mi">0L</span><span class="o">)</span> <span class="o">}</span>
<span class="o">}</span>
<span class="k">val</span> <span class="nv">words</span><span class="k">:</span> <span class="kt">DataSet</span><span class="o">[</span><span class="kt">WC</span><span class="o">]</span> <span class="k">=</span> <span class="c1">// [...]</span>
<span class="k">val</span> <span class="nv">wordCounts</span> <span class="k">=</span> <span class="nv">words</span><span class="o">.</span><span class="py">groupBy</span><span class="o">(</span><span class="s">"word"</span><span class="o">)</span>

<span class="c1">// or, as a case class, which is less typing</span>
<span class="k">case</span> <span class="k">class</span> <span class="nc">WC</span><span class="o">(</span><span class="n">word</span><span class="k">:</span> <span class="kt">String</span><span class="o">,</span> <span class="n">count</span><span class="k">:</span> <span class="kt">Int</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">words</span><span class="k">:</span> <span class="kt">DataSet</span><span class="o">[</span><span class="kt">WC</span><span class="o">]</span> <span class="k">=</span> <span class="c1">// [...]</span>
<span class="k">val</span> <span class="nv">wordCounts</span> <span class="k">=</span> <span class="nv">words</span><span class="o">.</span><span class="py">groupBy</span><span class="o">(</span><span class="s">"word"</span><span class="o">)</span></code></pre></figure>

    <p><strong>Field Expression Syntax</strong>:</p>

    <ul>
      <li>
        <p>Select POJO fields by their field name. For example <code class="highlighter-rouge">"user"</code> refers to the “user” field of a POJO type.</p>
      </li>
      <li>
        <p>Select Tuple fields by their 1-offset field name or 0-offset field index. For example <code class="highlighter-rouge">"_1"</code> and <code class="highlighter-rouge">"5"</code> refer to the first and sixth field of a Scala Tuple type, respectively.</p>
      </li>
      <li>
        <p>You can select nested fields in POJOs and Tuples. For example <code class="highlighter-rouge">"user.zip"</code> refers to the “zip” field of a POJO which is stored in the “user” field of a POJO type. Arbitrary nesting and mixing of POJOs and Tuples is supported such as <code class="highlighter-rouge">"_2.user.zip"</code> or <code class="highlighter-rouge">"user._4.1.zip"</code>.</p>
      </li>
      <li>
        <p>You can select the full type using the <code class="highlighter-rouge">"_"</code> wildcard expressions. This does also work for types which are not Tuple or POJO types.</p>
      </li>
    </ul>

    <p><strong>Field Expression Example</strong>:</p>

    <figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">class</span> <span class="nc">WC</span><span class="o">(</span><span class="k">var</span> <span class="n">complex</span><span class="k">:</span> <span class="kt">ComplexNestedClass</span><span class="o">,</span> <span class="k">var</span> <span class="n">count</span><span class="k">:</span> <span class="kt">Int</span><span class="o">)</span> <span class="o">{</span>
  <span class="k">def</span> <span class="nf">this</span><span class="o">()</span> <span class="o">{</span> <span class="nf">this</span><span class="o">(</span><span class="kc">null</span><span class="o">,</span> <span class="mi">0</span><span class="o">)</span> <span class="o">}</span>
<span class="o">}</span>

<span class="k">class</span> <span class="nc">ComplexNestedClass</span><span class="o">(</span>
    <span class="k">var</span> <span class="n">someNumber</span><span class="k">:</span> <span class="kt">Int</span><span class="o">,</span>
    <span class="n">someFloat</span><span class="k">:</span> <span class="kt">Float</span><span class="o">,</span>
    <span class="n">word</span><span class="k">:</span> <span class="o">(</span><span class="kt">Long</span><span class="o">,</span> <span class="kt">Long</span><span class="o">,</span> <span class="nc">String</span><span class="o">),</span>
    <span class="n">hadoopCitizen</span><span class="k">:</span> <span class="kt">IntWritable</span><span class="o">)</span> <span class="o">{</span>
  <span class="k">def</span> <span class="nf">this</span><span class="o">()</span> <span class="o">{</span> <span class="nf">this</span><span class="o">(</span><span class="mi">0</span><span class="o">,</span> <span class="mi">0</span><span class="o">,</span> <span class="o">(</span><span class="mi">0</span><span class="o">,</span> <span class="mi">0</span><span class="o">,</span> <span class="s">""</span><span class="o">),</span> <span class="k">new</span> <span class="nc">IntWritable</span><span class="o">(</span><span class="mi">0</span><span class="o">))</span> <span class="o">}</span>
<span class="o">}</span></code></pre></figure>

    <p>These are valid field expressions for the example code above:</p>

    <ul>
      <li>
        <p><code class="highlighter-rouge">"count"</code>: The count field in the <code class="highlighter-rouge">WC</code> class.</p>
      </li>
      <li>
        <p><code class="highlighter-rouge">"complex"</code>: Recursively selects all fields of the field complex of POJO type <code class="highlighter-rouge">ComplexNestedClass</code>.</p>
      </li>
      <li>
        <p><code class="highlighter-rouge">"complex.word._3"</code>: Selects the last field of the nested <code class="highlighter-rouge">Tuple3</code>.</p>
      </li>
      <li>
        <p><code class="highlighter-rouge">"complex.hadoopCitizen"</code>: Selects the Hadoop <code class="highlighter-rouge">IntWritable</code> type.</p>
      </li>
    </ul>

  </div>
</div>

<h3 class="no_toc" id="define-keys-using-key-selector-functions">Define keys using Key Selector Functions</h3>

<p>An additional way to define keys are “key selector” functions. A key selector function
takes a single element as input and returns the key for the element. The key can be of any type and be derived from deterministic computations.</p>

<p>The following example shows a key selector function that simply returns the field of an object:</p>

<div class="codetabs">
  <div data-lang="java">

    <figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="c1">// some ordinary POJO</span>
<span class="kd">public</span> <span class="kd">class</span> <span class="nc">WC</span> <span class="o">{</span><span class="kd">public</span> <span class="nc">String</span> <span class="n">word</span><span class="o">;</span> <span class="kd">public</span> <span class="kt">int</span> <span class="n">count</span><span class="o">;}</span>
<span class="nc">DataSet</span><span class="o">&lt;</span><span class="no">WC</span><span class="o">&gt;</span> <span class="n">words</span> <span class="o">=</span> <span class="c1">// [...]</span>
<span class="nc">UnsortedGrouping</span><span class="o">&lt;</span><span class="no">WC</span><span class="o">&gt;</span> <span class="n">keyed</span> <span class="o">=</span> <span class="n">words</span>
  <span class="o">.</span><span class="na">groupBy</span><span class="o">(</span><span class="k">new</span> <span class="nc">KeySelector</span><span class="o">&lt;</span><span class="no">WC</span><span class="o">,</span> <span class="nc">String</span><span class="o">&gt;()</span> <span class="o">{</span>
     <span class="kd">public</span> <span class="nc">String</span> <span class="nf">getKey</span><span class="o">(</span><span class="no">WC</span> <span class="n">wc</span><span class="o">)</span> <span class="o">{</span> <span class="k">return</span> <span class="n">wc</span><span class="o">.</span><span class="na">word</span><span class="o">;</span> <span class="o">}</span>
   <span class="o">});</span></code></pre></figure>

  </div>
  <div data-lang="scala">

    <figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="c1">// some ordinary case class</span>
<span class="k">case</span> <span class="k">class</span> <span class="nc">WC</span><span class="o">(</span><span class="n">word</span><span class="k">:</span> <span class="kt">String</span><span class="o">,</span> <span class="n">count</span><span class="k">:</span> <span class="kt">Int</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">words</span><span class="k">:</span> <span class="kt">DataSet</span><span class="o">[</span><span class="kt">WC</span><span class="o">]</span> <span class="k">=</span> <span class="c1">// [...]</span>
<span class="k">val</span> <span class="nv">keyed</span> <span class="k">=</span> <span class="nv">words</span><span class="o">.</span><span class="py">groupBy</span><span class="o">(</span> <span class="nv">_</span><span class="o">.</span><span class="py">word</span> <span class="o">)</span></code></pre></figure>

  </div>
</div>

<p><a href="#top" class="top pull-right"><span class="glyphicon glyphicon-chevron-up"></span> Back to top</a></p>

<h2 id="data-sources">Data Sources</h2>

<div class="codetabs">
  <div data-lang="java">

    <p>Data sources create the initial data sets, such as from files or from Java collections. The general
mechanism of creating data sets is abstracted behind an
<a href="https://github.com/apache/flink/blob/master//flink-core/src/main/java/org/apache/flink/api/common/io/InputFormat.java">InputFormat</a>.
Flink comes
with several built-in formats to create data sets from common file formats. Many of them have
shortcut methods on the <em>ExecutionEnvironment</em>.</p>

    <p>File-based:</p>

    <ul>
      <li>
        <p><code class="highlighter-rouge">readTextFile(path)</code> / <code class="highlighter-rouge">TextInputFormat</code> - Reads files line wise and returns them as Strings.</p>
      </li>
      <li>
        <p><code class="highlighter-rouge">readTextFileWithValue(path)</code> / <code class="highlighter-rouge">TextValueInputFormat</code> - Reads files line wise and returns them as
StringValues. StringValues are mutable strings.</p>
      </li>
      <li>
        <p><code class="highlighter-rouge">readCsvFile(path)</code> / <code class="highlighter-rouge">CsvInputFormat</code> - Parses files of comma (or another char) delimited fields.
Returns a DataSet of tuples or POJOs. Supports the basic java types and their Value counterparts as field
types.</p>
      </li>
      <li>
        <p><code class="highlighter-rouge">readFileOfPrimitives(path, Class)</code> / <code class="highlighter-rouge">PrimitiveInputFormat</code> - Parses files of new-line (or another char sequence)
delimited primitive data types such as <code class="highlighter-rouge">String</code> or <code class="highlighter-rouge">Integer</code>.</p>
      </li>
      <li>
        <p><code class="highlighter-rouge">readFileOfPrimitives(path, delimiter, Class)</code> / <code class="highlighter-rouge">PrimitiveInputFormat</code> - Parses files of new-line (or another char sequence)
 delimited primitive data types such as <code class="highlighter-rouge">String</code> or <code class="highlighter-rouge">Integer</code> using the given delimiter.</p>
      </li>
    </ul>

    <p>Collection-based:</p>

    <ul>
      <li>
        <p><code class="highlighter-rouge">fromCollection(Collection)</code> - Creates a data set from a Java.util.Collection. All elements
in the collection must be of the same type.</p>
      </li>
      <li>
        <p><code class="highlighter-rouge">fromCollection(Iterator, Class)</code> - Creates a data set from an iterator. The class specifies the
data type of the elements returned by the iterator.</p>
      </li>
      <li>
        <p><code class="highlighter-rouge">fromElements(T ...)</code> - Creates a data set from the given sequence of objects. All objects must be
of the same type.</p>
      </li>
      <li>
        <p><code class="highlighter-rouge">fromParallelCollection(SplittableIterator, Class)</code> - Creates a data set from an iterator, in
parallel. The class specifies the data type of the elements returned by the iterator.</p>
      </li>
      <li>
        <p><code class="highlighter-rouge">generateSequence(from, to)</code> - Generates the sequence of numbers in the given interval, in
parallel.</p>
      </li>
    </ul>

    <p>Generic:</p>

    <ul>
      <li>
        <p><code class="highlighter-rouge">readFile(inputFormat, path)</code> / <code class="highlighter-rouge">FileInputFormat</code> - Accepts a file input format.</p>
      </li>
      <li>
        <p><code class="highlighter-rouge">createInput(inputFormat)</code> / <code class="highlighter-rouge">InputFormat</code> - Accepts a generic input format.</p>
      </li>
    </ul>

    <p><strong>Examples</strong></p>

    <figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="nc">ExecutionEnvironment</span> <span class="n">env</span> <span class="o">=</span> <span class="nc">ExecutionEnvironment</span><span class="o">.</span><span class="na">getExecutionEnvironment</span><span class="o">();</span>

<span class="c1">// read text file from local files system</span>
<span class="nc">DataSet</span><span class="o">&lt;</span><span class="nc">String</span><span class="o">&gt;</span> <span class="n">localLines</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="na">readTextFile</span><span class="o">(</span><span class="s">"file:///path/to/my/textfile"</span><span class="o">);</span>

<span class="c1">// read text file from an HDFS running at nnHost:nnPort</span>
<span class="nc">DataSet</span><span class="o">&lt;</span><span class="nc">String</span><span class="o">&gt;</span> <span class="n">hdfsLines</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="na">readTextFile</span><span class="o">(</span><span class="s">"hdfs://nnHost:nnPort/path/to/my/textfile"</span><span class="o">);</span>

<span class="c1">// read a CSV file with three fields</span>
<span class="nc">DataSet</span><span class="o">&lt;</span><span class="nc">Tuple3</span><span class="o">&lt;</span><span class="nc">Integer</span><span class="o">,</span> <span class="nc">String</span><span class="o">,</span> <span class="nc">Double</span><span class="o">&gt;&gt;</span> <span class="n">csvInput</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="na">readCsvFile</span><span class="o">(</span><span class="s">"hdfs:///the/CSV/file"</span><span class="o">)</span>
	                       <span class="o">.</span><span class="na">types</span><span class="o">(</span><span class="nc">Integer</span><span class="o">.</span><span class="na">class</span><span class="o">,</span> <span class="nc">String</span><span class="o">.</span><span class="na">class</span><span class="o">,</span> <span class="nc">Double</span><span class="o">.</span><span class="na">class</span><span class="o">);</span>

<span class="c1">// read a CSV file with five fields, taking only two of them</span>
<span class="nc">DataSet</span><span class="o">&lt;</span><span class="nc">Tuple2</span><span class="o">&lt;</span><span class="nc">String</span><span class="o">,</span> <span class="nc">Double</span><span class="o">&gt;&gt;</span> <span class="n">csvInput</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="na">readCsvFile</span><span class="o">(</span><span class="s">"hdfs:///the/CSV/file"</span><span class="o">)</span>
                               <span class="o">.</span><span class="na">includeFields</span><span class="o">(</span><span class="s">"10010"</span><span class="o">)</span>  <span class="c1">// take the first and the fourth field</span>
	                       <span class="o">.</span><span class="na">types</span><span class="o">(</span><span class="nc">String</span><span class="o">.</span><span class="na">class</span><span class="o">,</span> <span class="nc">Double</span><span class="o">.</span><span class="na">class</span><span class="o">);</span>

<span class="c1">// read a CSV file with three fields into a POJO (Person.class) with corresponding fields</span>
<span class="nc">DataSet</span><span class="o">&lt;</span><span class="nc">Person</span><span class="o">&gt;&gt;</span> <span class="n">csvInput</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="na">readCsvFile</span><span class="o">(</span><span class="s">"hdfs:///the/CSV/file"</span><span class="o">)</span>
                         <span class="o">.</span><span class="na">pojoType</span><span class="o">(</span><span class="nc">Person</span><span class="o">.</span><span class="na">class</span><span class="o">,</span> <span class="s">"name"</span><span class="o">,</span> <span class="s">"age"</span><span class="o">,</span> <span class="s">"zipcode"</span><span class="o">);</span>

<span class="c1">// read a file from the specified path of type SequenceFileInputFormat</span>
<span class="nc">DataSet</span><span class="o">&lt;</span><span class="nc">Tuple2</span><span class="o">&lt;</span><span class="nc">IntWritable</span><span class="o">,</span> <span class="nc">Text</span><span class="o">&gt;&gt;</span> <span class="n">tuples</span> <span class="o">=</span>
 <span class="n">env</span><span class="o">.</span><span class="na">createInput</span><span class="o">(</span><span class="nc">HadoopInputs</span><span class="o">.</span><span class="na">readSequenceFile</span><span class="o">(</span><span class="nc">IntWritable</span><span class="o">.</span><span class="na">class</span><span class="o">,</span> <span class="nc">Text</span><span class="o">.</span><span class="na">class</span><span class="o">,</span> <span class="s">"hdfs://nnHost:nnPort/path/to/file"</span><span class="o">));</span>

<span class="c1">// creates a set from some given elements</span>
<span class="nc">DataSet</span><span class="o">&lt;</span><span class="nc">String</span><span class="o">&gt;</span> <span class="n">value</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="na">fromElements</span><span class="o">(</span><span class="s">"Foo"</span><span class="o">,</span> <span class="s">"bar"</span><span class="o">,</span> <span class="s">"foobar"</span><span class="o">,</span> <span class="s">"fubar"</span><span class="o">);</span>

<span class="c1">// generate a number sequence</span>
<span class="nc">DataSet</span><span class="o">&lt;</span><span class="nc">Long</span><span class="o">&gt;</span> <span class="n">numbers</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="na">generateSequence</span><span class="o">(</span><span class="mi">1</span><span class="o">,</span> <span class="mi">10000000</span><span class="o">);</span>

<span class="c1">// Read data from a relational database using the JDBC input format</span>
<span class="nc">DataSet</span><span class="o">&lt;</span><span class="nc">Tuple2</span><span class="o">&lt;</span><span class="nc">String</span><span class="o">,</span> <span class="nc">Integer</span><span class="o">&gt;</span> <span class="n">dbData</span> <span class="o">=</span>
    <span class="n">env</span><span class="o">.</span><span class="na">createInput</span><span class="o">(</span>
      <span class="nc">JdbcInputFormat</span><span class="o">.</span><span class="na">buildJdbcInputFormat</span><span class="o">()</span>
                     <span class="o">.</span><span class="na">setDrivername</span><span class="o">(</span><span class="s">"org.apache.derby.jdbc.EmbeddedDriver"</span><span class="o">)</span>
                     <span class="o">.</span><span class="na">setDBUrl</span><span class="o">(</span><span class="s">"jdbc:derby:memory:persons"</span><span class="o">)</span>
                     <span class="o">.</span><span class="na">setQuery</span><span class="o">(</span><span class="s">"select name, age from persons"</span><span class="o">)</span>
                     <span class="o">.</span><span class="na">setRowTypeInfo</span><span class="o">(</span><span class="k">new</span> <span class="nc">RowTypeInfo</span><span class="o">(</span><span class="nc">BasicTypeInfo</span><span class="o">.</span><span class="na">STRING_TYPE_INFO</span><span class="o">,</span> <span class="nc">BasicTypeInfo</span><span class="o">.</span><span class="na">INT_TYPE_INFO</span><span class="o">))</span>
                     <span class="o">.</span><span class="na">finish</span><span class="o">()</span>
    <span class="o">);</span>

<span class="c1">// Note: Flink's program compiler needs to infer the data types of the data items which are returned</span>
<span class="c1">// by an InputFormat. If this information cannot be automatically inferred, it is necessary to</span>
<span class="c1">// manually provide the type information as shown in the examples above.</span></code></pre></figure>

    <h4 id="configuring-csv-parsing">Configuring CSV Parsing</h4>

    <p>Flink offers a number of configuration options for CSV parsing:</p>

    <ul>
      <li>
        <p><code class="highlighter-rouge">types(Class ... types)</code> specifies the types of the fields to parse. <strong>It is mandatory to configure the types of the parsed fields.</strong>
In case of the type class Boolean.class, “True” (case-insensitive), “False” (case-insensitive), “1” and “0” are treated as booleans.</p>
      </li>
      <li>
        <p><code class="highlighter-rouge">lineDelimiter(String del)</code> specifies the delimiter of individual records. The default line delimiter is the new-line character <code class="highlighter-rouge">'\n'</code>.</p>
      </li>
      <li>
        <p><code class="highlighter-rouge">fieldDelimiter(String del)</code> specifies the delimiter that separates fields of a record. The default field delimiter is the comma character <code class="highlighter-rouge">','</code>.</p>
      </li>
      <li>
        <p><code class="highlighter-rouge">includeFields(boolean ... flag)</code>, <code class="highlighter-rouge">includeFields(String mask)</code>, or <code class="highlighter-rouge">includeFields(long bitMask)</code> defines which fields to read from the input file (and which to ignore). By default the first <em>n</em> fields (as defined by the number of types in the <code class="highlighter-rouge">types()</code> call) are parsed.</p>
      </li>
      <li>
        <p><code class="highlighter-rouge">parseQuotedStrings(char quoteChar)</code> enables quoted string parsing. Strings are parsed as quoted strings if the first character of the string field is the quote character (leading or tailing whitespaces are <em>not</em> trimmed). Field delimiters within quoted strings are ignored. Quoted string parsing fails if the last character of a quoted string field is not the quote character or if the quote character appears at some point which is not the start or the end of the quoted string field (unless the quote character is escaped using ‘'). If quoted string parsing is enabled and the first character of the field is <em>not</em> the quoting string, the string is parsed as unquoted string. By default, quoted string parsing is disabled.</p>
      </li>
      <li>
        <p><code class="highlighter-rouge">ignoreComments(String commentPrefix)</code> specifies a comment prefix. All lines that start with the specified comment prefix are not parsed and ignored. By default, no lines are ignored.</p>
      </li>
      <li>
        <p><code class="highlighter-rouge">ignoreInvalidLines()</code> enables lenient parsing, i.e., lines that cannot be correctly parsed are ignored. By default, lenient parsing is disabled and invalid lines raise an exception.</p>
      </li>
      <li>
        <p><code class="highlighter-rouge">ignoreFirstLine()</code> configures the InputFormat to ignore the first line of the input file. By default no line is ignored.</p>
      </li>
    </ul>

    <h4 id="recursive-traversal-of-the-input-path-directory">Recursive Traversal of the Input Path Directory</h4>

    <p>For file-based inputs, when the input path is a directory, nested files are not enumerated by default. Instead, only the files inside the base directory are read, while nested files are ignored. Recursive enumeration of nested files can be enabled through the <code class="highlighter-rouge">recursive.file.enumeration</code> configuration parameter, like in the following example.</p>

    <figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="c1">// enable recursive enumeration of nested input files</span>
<span class="nc">ExecutionEnvironment</span> <span class="n">env</span> <span class="o">=</span> <span class="nc">ExecutionEnvironment</span><span class="o">.</span><span class="na">getExecutionEnvironment</span><span class="o">();</span>

<span class="c1">// create a configuration object</span>
<span class="nc">Configuration</span> <span class="n">parameters</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">Configuration</span><span class="o">();</span>

<span class="c1">// set the recursive enumeration parameter</span>
<span class="n">parameters</span><span class="o">.</span><span class="na">setBoolean</span><span class="o">(</span><span class="s">"recursive.file.enumeration"</span><span class="o">,</span> <span class="kc">true</span><span class="o">);</span>

<span class="c1">// pass the configuration to the data source</span>
<span class="nc">DataSet</span><span class="o">&lt;</span><span class="nc">String</span><span class="o">&gt;</span> <span class="n">logs</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="na">readTextFile</span><span class="o">(</span><span class="s">"file:///path/with.nested/files"</span><span class="o">)</span>
			  <span class="o">.</span><span class="na">withParameters</span><span class="o">(</span><span class="n">parameters</span><span class="o">);</span></code></pre></figure>

  </div>
  <div data-lang="scala">

    <p>Data sources create the initial data sets, such as from files or from Java collections. The general
mechanism of creating data sets is abstracted behind an
<a href="https://github.com/apache/flink/blob/master//flink-core/src/main/java/org/apache/flink/api/common/io/InputFormat.java">InputFormat</a>.
Flink comes
with several built-in formats to create data sets from common file formats. Many of them have
shortcut methods on the <em>ExecutionEnvironment</em>.</p>

    <p>File-based:</p>

    <ul>
      <li>
        <p><code class="highlighter-rouge">readTextFile(path)</code> / <code class="highlighter-rouge">TextInputFormat</code> - Reads files line wise and returns them as Strings.</p>
      </li>
      <li>
        <p><code class="highlighter-rouge">readTextFileWithValue(path)</code> / <code class="highlighter-rouge">TextValueInputFormat</code> - Reads files line wise and returns them as
StringValues. StringValues are mutable strings.</p>
      </li>
      <li>
        <p><code class="highlighter-rouge">readCsvFile(path)</code> / <code class="highlighter-rouge">CsvInputFormat</code> - Parses files of comma (or another char) delimited fields.
Returns a DataSet of tuples, case class objects, or POJOs. Supports the basic java types and their Value counterparts as field
types.</p>
      </li>
      <li>
        <p><code class="highlighter-rouge">readFileOfPrimitives(path, delimiter)</code> / <code class="highlighter-rouge">PrimitiveInputFormat</code> - Parses files of new-line (or another char sequence)
delimited primitive data types such as <code class="highlighter-rouge">String</code> or <code class="highlighter-rouge">Integer</code> using the given delimiter.</p>
      </li>
      <li>
        <p><code class="highlighter-rouge">readSequenceFile(Key, Value, path)</code> / <code class="highlighter-rouge">SequenceFileInputFormat</code> - Creates a JobConf and reads file from the specified path with
 type SequenceFileInputFormat, Key class and Value class and returns them as Tuple2&lt;Key, Value&gt;.</p>
      </li>
    </ul>

    <p>Collection-based:</p>

    <ul>
      <li>
        <p><code class="highlighter-rouge">fromCollection(Iterable)</code> - Creates a data set from an Iterable. All elements
returned by the Iterable must be of the same type.</p>
      </li>
      <li>
        <p><code class="highlighter-rouge">fromCollection(Iterator)</code> - Creates a data set from an Iterator. The class specifies the
data type of the elements returned by the iterator.</p>
      </li>
      <li>
        <p><code class="highlighter-rouge">fromElements(elements: _*)</code> - Creates a data set from the given sequence of objects. All objects
must be of the same type.</p>
      </li>
      <li>
        <p><code class="highlighter-rouge">fromParallelCollection(SplittableIterator)</code> - Creates a data set from an iterator, in
parallel. The class specifies the data type of the elements returned by the iterator.</p>
      </li>
      <li>
        <p><code class="highlighter-rouge">generateSequence(from, to)</code> - Generates the sequence of numbers in the given interval, in
parallel.</p>
      </li>
    </ul>

    <p>Generic:</p>

    <ul>
      <li>
        <p><code class="highlighter-rouge">readFile(inputFormat, path)</code> / <code class="highlighter-rouge">FileInputFormat</code> - Accepts a file input format.</p>
      </li>
      <li>
        <p><code class="highlighter-rouge">createInput(inputFormat)</code> / <code class="highlighter-rouge">InputFormat</code> - Accepts a generic input format.</p>
      </li>
    </ul>

    <p><strong>Examples</strong></p>

    <figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="nv">env</span>  <span class="k">=</span> <span class="nv">ExecutionEnvironment</span><span class="o">.</span><span class="py">getExecutionEnvironment</span>

<span class="c1">// read text file from local files system</span>
<span class="k">val</span> <span class="nv">localLines</span> <span class="k">=</span> <span class="nv">env</span><span class="o">.</span><span class="py">readTextFile</span><span class="o">(</span><span class="s">"file:///path/to/my/textfile"</span><span class="o">)</span>

<span class="c1">// read text file from an HDFS running at nnHost:nnPort</span>
<span class="k">val</span> <span class="nv">hdfsLines</span> <span class="k">=</span> <span class="nv">env</span><span class="o">.</span><span class="py">readTextFile</span><span class="o">(</span><span class="s">"hdfs://nnHost:nnPort/path/to/my/textfile"</span><span class="o">)</span>

<span class="c1">// read a CSV file with three fields</span>
<span class="k">val</span> <span class="nv">csvInput</span> <span class="k">=</span> <span class="nv">env</span><span class="o">.</span><span class="py">readCsvFile</span><span class="o">[(</span><span class="kt">Int</span>, <span class="kt">String</span>, <span class="kt">Double</span><span class="o">)](</span><span class="s">"hdfs:///the/CSV/file"</span><span class="o">)</span>

<span class="c1">// read a CSV file with five fields, taking only two of them</span>
<span class="k">val</span> <span class="nv">csvInput</span> <span class="k">=</span> <span class="nv">env</span><span class="o">.</span><span class="py">readCsvFile</span><span class="o">[(</span><span class="kt">String</span>, <span class="kt">Double</span><span class="o">)](</span>
  <span class="s">"hdfs:///the/CSV/file"</span><span class="o">,</span>
  <span class="n">includedFields</span> <span class="k">=</span> <span class="nc">Array</span><span class="o">(</span><span class="mi">0</span><span class="o">,</span> <span class="mi">3</span><span class="o">))</span> <span class="c1">// take the first and the fourth field</span>

<span class="c1">// CSV input can also be used with Case Classes</span>
<span class="k">case</span> <span class="k">class</span> <span class="nc">MyCaseClass</span><span class="o">(</span><span class="n">str</span><span class="k">:</span> <span class="kt">String</span><span class="o">,</span> <span class="n">dbl</span><span class="k">:</span> <span class="kt">Double</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">csvInput</span> <span class="k">=</span> <span class="nv">env</span><span class="o">.</span><span class="py">readCsvFile</span><span class="o">[</span><span class="kt">MyCaseClass</span><span class="o">](</span>
  <span class="s">"hdfs:///the/CSV/file"</span><span class="o">,</span>
  <span class="n">includedFields</span> <span class="k">=</span> <span class="nc">Array</span><span class="o">(</span><span class="mi">0</span><span class="o">,</span> <span class="mi">3</span><span class="o">))</span> <span class="c1">// take the first and the fourth field</span>

<span class="c1">// read a CSV file with three fields into a POJO (Person) with corresponding fields</span>
<span class="k">val</span> <span class="nv">csvInput</span> <span class="k">=</span> <span class="nv">env</span><span class="o">.</span><span class="py">readCsvFile</span><span class="o">[</span><span class="kt">Person</span><span class="o">](</span>
  <span class="s">"hdfs:///the/CSV/file"</span><span class="o">,</span>
  <span class="n">pojoFields</span> <span class="k">=</span> <span class="nc">Array</span><span class="o">(</span><span class="s">"name"</span><span class="o">,</span> <span class="s">"age"</span><span class="o">,</span> <span class="s">"zipcode"</span><span class="o">))</span>

<span class="c1">// create a set from some given elements</span>
<span class="k">val</span> <span class="nv">values</span> <span class="k">=</span> <span class="nv">env</span><span class="o">.</span><span class="py">fromElements</span><span class="o">(</span><span class="s">"Foo"</span><span class="o">,</span> <span class="s">"bar"</span><span class="o">,</span> <span class="s">"foobar"</span><span class="o">,</span> <span class="s">"fubar"</span><span class="o">)</span>

<span class="c1">// generate a number sequence</span>
<span class="k">val</span> <span class="nv">numbers</span> <span class="k">=</span> <span class="nv">env</span><span class="o">.</span><span class="py">generateSequence</span><span class="o">(</span><span class="mi">1</span><span class="o">,</span> <span class="mi">10000000</span><span class="o">)</span>

<span class="c1">// read a file from the specified path of type SequenceFileInputFormat</span>
<span class="k">val</span> <span class="nv">tuples</span> <span class="k">=</span> <span class="nv">env</span><span class="o">.</span><span class="py">createInput</span><span class="o">(</span><span class="nv">HadoopInputs</span><span class="o">.</span><span class="py">readSequenceFile</span><span class="o">(</span><span class="n">classOf</span><span class="o">[</span><span class="kt">IntWritable</span><span class="o">],</span> <span class="n">classOf</span><span class="o">[</span><span class="kt">Text</span><span class="o">],</span>
 <span class="s">"hdfs://nnHost:nnPort/path/to/file"</span><span class="o">))</span></code></pre></figure>

    <h4 id="configuring-csv-parsing-1">Configuring CSV Parsing</h4>

    <p>Flink offers a number of configuration options for CSV parsing:</p>

    <ul>
      <li>
        <p><code class="highlighter-rouge">lineDelimiter: String</code> specifies the delimiter of individual records. The default line delimiter is the new-line character <code class="highlighter-rouge">'\n'</code>.</p>
      </li>
      <li>
        <p><code class="highlighter-rouge">fieldDelimiter: String</code> specifies the delimiter that separates fields of a record. The default field delimiter is the comma character <code class="highlighter-rouge">','</code>.</p>
      </li>
      <li>
        <p><code class="highlighter-rouge">includeFields: Array[Int]</code> defines which fields to read from the input file (and which to ignore). By default the first <em>n</em> fields (as defined by the number of types in the <code class="highlighter-rouge">types()</code> call) are parsed.</p>
      </li>
      <li>
        <p><code class="highlighter-rouge">pojoFields: Array[String]</code> specifies the fields of a POJO that are mapped to CSV fields. Parsers for CSV fields are automatically initialized based on the type and order of the POJO fields.</p>
      </li>
      <li>
        <p><code class="highlighter-rouge">parseQuotedStrings: Character</code> enables quoted string parsing. Strings are parsed as quoted strings if the first character of the string field is the quote character (leading or tailing whitespaces are <em>not</em> trimmed). Field delimiters within quoted strings are ignored. Quoted string parsing fails if the last character of a quoted string field is not the quote character. If quoted string parsing is enabled and the first character of the field is <em>not</em> the quoting string, the string is parsed as unquoted string. By default, quoted string parsing is disabled.</p>
      </li>
      <li>
        <p><code class="highlighter-rouge">ignoreComments: String</code> specifies a comment prefix. All lines that start with the specified comment prefix are not parsed and ignored. By default, no lines are ignored.</p>
      </li>
      <li>
        <p><code class="highlighter-rouge">lenient: Boolean</code> enables lenient parsing, i.e., lines that cannot be correctly parsed are ignored. By default, lenient parsing is disabled and invalid lines raise an exception.</p>
      </li>
      <li>
        <p><code class="highlighter-rouge">ignoreFirstLine: Boolean</code> configures the InputFormat to ignore the first line of the input file. By default no line is ignored.</p>
      </li>
    </ul>

    <h4 id="recursive-traversal-of-the-input-path-directory-1">Recursive Traversal of the Input Path Directory</h4>

    <p>For file-based inputs, when the input path is a directory, nested files are not enumerated by default. Instead, only the files inside the base directory are read, while nested files are ignored. Recursive enumeration of nested files can be enabled through the <code class="highlighter-rouge">recursive.file.enumeration</code> configuration parameter, like in the following example.</p>

    <figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="c1">// enable recursive enumeration of nested input files</span>
<span class="k">val</span> <span class="nv">env</span>  <span class="k">=</span> <span class="nv">ExecutionEnvironment</span><span class="o">.</span><span class="py">getExecutionEnvironment</span>

<span class="c1">// create a configuration object</span>
<span class="k">val</span> <span class="nv">parameters</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Configuration</span>

<span class="c1">// set the recursive enumeration parameter</span>
<span class="nv">parameters</span><span class="o">.</span><span class="py">setBoolean</span><span class="o">(</span><span class="s">"recursive.file.enumeration"</span><span class="o">,</span> <span class="kc">true</span><span class="o">)</span>

<span class="c1">// pass the configuration to the data source</span>
<span class="nv">env</span><span class="o">.</span><span class="py">readTextFile</span><span class="o">(</span><span class="s">"file:///path/with.nested/files"</span><span class="o">).</span><span class="py">withParameters</span><span class="o">(</span><span class="n">parameters</span><span class="o">)</span></code></pre></figure>

  </div>
</div>

<h3 id="read-compressed-files">Read Compressed Files</h3>

<p>Flink currently supports transparent decompression of input files if these are marked with an appropriate file extension. In particular, this means that no further configuration of the input formats is necessary and any <code class="highlighter-rouge">FileInputFormat</code> support the compression, including custom input formats. Please notice that compressed files might not be read in parallel, thus impacting job scalability.</p>

<p>The following table lists the currently supported compression methods.</p>

<p><br /></p>

<table class="table table-bordered">
  <thead>
    <tr>
      <th class="text-left" style="width: 20%">Compression method</th>
      <th class="text-left">File extensions</th>
      <th class="text-left" style="width: 20%">Parallelizable</th>
    </tr>
  </thead>

  <tbody>
    <tr>
      <td><strong>DEFLATE</strong></td>
      <td><code>.deflate</code></td>
      <td>no</td>
    </tr>
    <tr>
      <td><strong>GZip</strong></td>
      <td><code>.gz</code>, <code>.gzip</code></td>
      <td>no</td>
    </tr>
    <tr>
      <td><strong>Bzip2</strong></td>
      <td><code>.bz2</code></td>
      <td>no</td>
    </tr>
    <tr>
      <td><strong>XZ</strong></td>
      <td><code>.xz</code></td>
      <td>no</td>
    </tr>
  </tbody>
</table>

<p><a href="#top" class="top pull-right"><span class="glyphicon glyphicon-chevron-up"></span> Back to top</a></p>

<h2 id="data-sinks">Data Sinks</h2>

<div class="codetabs">
  <div data-lang="java">

    <p>Data sinks consume DataSets and are used to store or return them. Data sink operations are described
using an
<a href="https://github.com/apache/flink/blob/master//flink-core/src/main/java/org/apache/flink/api/common/io/OutputFormat.java">OutputFormat</a>.
Flink comes with a variety of built-in output formats that are encapsulated behind operations on the
DataSet:</p>

    <ul>
      <li><code class="highlighter-rouge">writeAsText()</code> / <code class="highlighter-rouge">TextOutputFormat</code> - Writes elements line-wise as Strings. The Strings are
obtained by calling the <em>toString()</em> method of each element.</li>
      <li><code class="highlighter-rouge">writeAsFormattedText()</code> / <code class="highlighter-rouge">TextOutputFormat</code> - Write elements line-wise as Strings. The Strings
are obtained by calling a user-defined <em>format()</em> method for each element.</li>
      <li><code class="highlighter-rouge">writeAsCsv(...)</code> / <code class="highlighter-rouge">CsvOutputFormat</code> - Writes tuples as comma-separated value files. Row and field
delimiters are configurable. The value for each field comes from the <em>toString()</em> method of the objects.</li>
      <li><code class="highlighter-rouge">print()</code> / <code class="highlighter-rouge">printToErr()</code> / <code class="highlighter-rouge">print(String msg)</code> / <code class="highlighter-rouge">printToErr(String msg)</code> - Prints the <em>toString()</em> value
of each element on the standard out / standard error stream. Optionally, a prefix (msg) can be provided which is
prepended to the output. This can help to distinguish between different calls to <em>print</em>. If the parallelism is
greater than 1, the output will also be prepended with the identifier of the task which produced the output.</li>
      <li><code class="highlighter-rouge">write()</code> / <code class="highlighter-rouge">FileOutputFormat</code> - Method and base class for custom file outputs. Supports
custom object-to-bytes conversion.</li>
      <li><code class="highlighter-rouge">output()</code>/ <code class="highlighter-rouge">OutputFormat</code> - Most generic output method, for data sinks that are not file based
(such as storing the result in a database).</li>
    </ul>

    <p>A DataSet can be input to multiple operations. Programs can write or print a data set and at the
same time run additional transformations on them.</p>

    <p><strong>Examples</strong></p>

    <p>Standard data sink methods:</p>

    <figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="c1">// text data</span>
<span class="nc">DataSet</span><span class="o">&lt;</span><span class="nc">String</span><span class="o">&gt;</span> <span class="n">textData</span> <span class="o">=</span> <span class="c1">// [...]</span>

<span class="c1">// write DataSet to a file on the local file system</span>
<span class="n">textData</span><span class="o">.</span><span class="na">writeAsText</span><span class="o">(</span><span class="s">"file:///my/result/on/localFS"</span><span class="o">);</span>

<span class="c1">// write DataSet to a file on an HDFS with a namenode running at nnHost:nnPort</span>
<span class="n">textData</span><span class="o">.</span><span class="na">writeAsText</span><span class="o">(</span><span class="s">"hdfs://nnHost:nnPort/my/result/on/localFS"</span><span class="o">);</span>

<span class="c1">// write DataSet to a file and overwrite the file if it exists</span>
<span class="n">textData</span><span class="o">.</span><span class="na">writeAsText</span><span class="o">(</span><span class="s">"file:///my/result/on/localFS"</span><span class="o">,</span> <span class="nc">WriteMode</span><span class="o">.</span><span class="na">OVERWRITE</span><span class="o">);</span>

<span class="c1">// tuples as lines with pipe as the separator "a|b|c"</span>
<span class="nc">DataSet</span><span class="o">&lt;</span><span class="nc">Tuple3</span><span class="o">&lt;</span><span class="nc">String</span><span class="o">,</span> <span class="nc">Integer</span><span class="o">,</span> <span class="nc">Double</span><span class="o">&gt;&gt;</span> <span class="n">values</span> <span class="o">=</span> <span class="c1">// [...]</span>
<span class="n">values</span><span class="o">.</span><span class="na">writeAsCsv</span><span class="o">(</span><span class="s">"file:///path/to/the/result/file"</span><span class="o">,</span> <span class="s">"\n"</span><span class="o">,</span> <span class="s">"|"</span><span class="o">);</span>

<span class="c1">// this writes tuples in the text formatting "(a, b, c)", rather than as CSV lines</span>
<span class="n">values</span><span class="o">.</span><span class="na">writeAsText</span><span class="o">(</span><span class="s">"file:///path/to/the/result/file"</span><span class="o">);</span>

<span class="c1">// this writes values as strings using a user-defined TextFormatter object</span>
<span class="n">values</span><span class="o">.</span><span class="na">writeAsFormattedText</span><span class="o">(</span><span class="s">"file:///path/to/the/result/file"</span><span class="o">,</span>
    <span class="k">new</span> <span class="nc">TextFormatter</span><span class="o">&lt;</span><span class="nc">Tuple2</span><span class="o">&lt;</span><span class="nc">Integer</span><span class="o">,</span> <span class="nc">Integer</span><span class="o">&gt;&gt;()</span> <span class="o">{</span>
        <span class="kd">public</span> <span class="nc">String</span> <span class="nf">format</span> <span class="o">(</span><span class="nc">Tuple2</span><span class="o">&lt;</span><span class="nc">Integer</span><span class="o">,</span> <span class="nc">Integer</span><span class="o">&gt;</span> <span class="n">value</span><span class="o">)</span> <span class="o">{</span>
            <span class="k">return</span> <span class="n">value</span><span class="o">.</span><span class="na">f1</span> <span class="o">+</span> <span class="s">" - "</span> <span class="o">+</span> <span class="n">value</span><span class="o">.</span><span class="na">f0</span><span class="o">;</span>
        <span class="o">}</span>
    <span class="o">});</span></code></pre></figure>

    <p>Using a custom output format:</p>

    <figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="nc">DataSet</span><span class="o">&lt;</span><span class="nc">Tuple3</span><span class="o">&lt;</span><span class="nc">String</span><span class="o">,</span> <span class="nc">Integer</span><span class="o">,</span> <span class="nc">Double</span><span class="o">&gt;&gt;</span> <span class="n">myResult</span> <span class="o">=</span> <span class="o">[...]</span>

<span class="c1">// write Tuple DataSet to a relational database</span>
<span class="n">myResult</span><span class="o">.</span><span class="na">output</span><span class="o">(</span>
    <span class="c1">// build and configure OutputFormat</span>
    <span class="nc">JdbcOutputFormat</span><span class="o">.</span><span class="na">buildJdbcOutputFormat</span><span class="o">()</span>
                    <span class="o">.</span><span class="na">setDrivername</span><span class="o">(</span><span class="s">"org.apache.derby.jdbc.EmbeddedDriver"</span><span class="o">)</span>
                    <span class="o">.</span><span class="na">setDBUrl</span><span class="o">(</span><span class="s">"jdbc:derby:memory:persons"</span><span class="o">)</span>
                    <span class="o">.</span><span class="na">setQuery</span><span class="o">(</span><span class="s">"insert into persons (name, age, height) values (?,?,?)"</span><span class="o">)</span>
                    <span class="o">.</span><span class="na">finish</span><span class="o">()</span>
    <span class="o">);</span></code></pre></figure>

    <h4 id="locally-sorted-output">Locally Sorted Output</h4>

    <p>The output of a data sink can be locally sorted on specified fields in specified orders using <a href="#define-keys-for-tuples">tuple field positions</a> or <a href="#define-keys-using-field-expressions">field expressions</a>. This works for every output format.</p>

    <p>The following examples show how to use this feature:</p>

    <figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="nc">DataSet</span><span class="o">&lt;</span><span class="nc">Tuple3</span><span class="o">&lt;</span><span class="nc">Integer</span><span class="o">,</span> <span class="nc">String</span><span class="o">,</span> <span class="nc">Double</span><span class="o">&gt;&gt;</span> <span class="n">tData</span> <span class="o">=</span> <span class="c1">// [...]</span>
<span class="nc">DataSet</span><span class="o">&lt;</span><span class="nc">Tuple2</span><span class="o">&lt;</span><span class="nc">BookPojo</span><span class="o">,</span> <span class="nc">Double</span><span class="o">&gt;&gt;</span> <span class="n">pData</span> <span class="o">=</span> <span class="c1">// [...]</span>
<span class="nc">DataSet</span><span class="o">&lt;</span><span class="nc">String</span><span class="o">&gt;</span> <span class="n">sData</span> <span class="o">=</span> <span class="c1">// [...]</span>

<span class="c1">// sort output on String field in ascending order</span>
<span class="n">tData</span><span class="o">.</span><span class="na">sortPartition</span><span class="o">(</span><span class="mi">1</span><span class="o">,</span> <span class="nc">Order</span><span class="o">.</span><span class="na">ASCENDING</span><span class="o">).</span><span class="na">print</span><span class="o">();</span>

<span class="c1">// sort output on Double field in descending and Integer field in ascending order</span>
<span class="n">tData</span><span class="o">.</span><span class="na">sortPartition</span><span class="o">(</span><span class="mi">2</span><span class="o">,</span> <span class="nc">Order</span><span class="o">.</span><span class="na">DESCENDING</span><span class="o">).</span><span class="na">sortPartition</span><span class="o">(</span><span class="mi">0</span><span class="o">,</span> <span class="nc">Order</span><span class="o">.</span><span class="na">ASCENDING</span><span class="o">).</span><span class="na">print</span><span class="o">();</span>

<span class="c1">// sort output on the "author" field of nested BookPojo in descending order</span>
<span class="n">pData</span><span class="o">.</span><span class="na">sortPartition</span><span class="o">(</span><span class="s">"f0.author"</span><span class="o">,</span> <span class="nc">Order</span><span class="o">.</span><span class="na">DESCENDING</span><span class="o">).</span><span class="na">writeAsText</span><span class="o">(...);</span>

<span class="c1">// sort output on the full tuple in ascending order</span>
<span class="n">tData</span><span class="o">.</span><span class="na">sortPartition</span><span class="o">(</span><span class="s">"*"</span><span class="o">,</span> <span class="nc">Order</span><span class="o">.</span><span class="na">ASCENDING</span><span class="o">).</span><span class="na">writeAsCsv</span><span class="o">(...);</span>

<span class="c1">// sort atomic type (String) output in descending order</span>
<span class="n">sData</span><span class="o">.</span><span class="na">sortPartition</span><span class="o">(</span><span class="s">"*"</span><span class="o">,</span> <span class="nc">Order</span><span class="o">.</span><span class="na">DESCENDING</span><span class="o">).</span><span class="na">writeAsText</span><span class="o">(...);</span></code></pre></figure>

    <p>Globally sorted output is not supported yet.</p>

  </div>
  <div data-lang="scala">
    <p>Data sinks consume DataSets and are used to store or return them. Data sink operations are described
using an
<a href="https://github.com/apache/flink/blob/master//flink-core/src/main/java/org/apache/flink/api/common/io/OutputFormat.java">OutputFormat</a>.
Flink comes with a variety of built-in output formats that are encapsulated behind operations on the
DataSet:</p>

    <ul>
      <li><code class="highlighter-rouge">writeAsText()</code> / <code class="highlighter-rouge">TextOutputFormat</code> - Writes elements line-wise as Strings. The Strings are
obtained by calling the <em>toString()</em> method of each element.</li>
      <li><code class="highlighter-rouge">writeAsCsv(...)</code> / <code class="highlighter-rouge">CsvOutputFormat</code> - Writes tuples as comma-separated value files. Row and field
delimiters are configurable. The value for each field comes from the <em>toString()</em> method of the objects.</li>
      <li><code class="highlighter-rouge">print()</code> / <code class="highlighter-rouge">printToErr()</code> - Prints the <em>toString()</em> value of each element on the
standard out / standard error stream.</li>
      <li><code class="highlighter-rouge">write()</code> / <code class="highlighter-rouge">FileOutputFormat</code> - Method and base class for custom file outputs. Supports
custom object-to-bytes conversion.</li>
      <li><code class="highlighter-rouge">output()</code>/ <code class="highlighter-rouge">OutputFormat</code> - Most generic output method, for data sinks that are not file based
(such as storing the result in a database).</li>
    </ul>

    <p>A DataSet can be input to multiple operations. Programs can write or print a data set and at the
same time run additional transformations on them.</p>

    <p><strong>Examples</strong></p>

    <p>Standard data sink methods:</p>

    <figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="c1">// text data</span>
<span class="k">val</span> <span class="nv">textData</span><span class="k">:</span> <span class="kt">DataSet</span><span class="o">[</span><span class="kt">String</span><span class="o">]</span> <span class="k">=</span> <span class="c1">// [...]</span>

<span class="c1">// write DataSet to a file on the local file system</span>
<span class="nv">textData</span><span class="o">.</span><span class="py">writeAsText</span><span class="o">(</span><span class="s">"file:///my/result/on/localFS"</span><span class="o">)</span>

<span class="c1">// write DataSet to a file on an HDFS with a namenode running at nnHost:nnPort</span>
<span class="nv">textData</span><span class="o">.</span><span class="py">writeAsText</span><span class="o">(</span><span class="s">"hdfs://nnHost:nnPort/my/result/on/localFS"</span><span class="o">)</span>

<span class="c1">// write DataSet to a file and overwrite the file if it exists</span>
<span class="nv">textData</span><span class="o">.</span><span class="py">writeAsText</span><span class="o">(</span><span class="s">"file:///my/result/on/localFS"</span><span class="o">,</span> <span class="nv">WriteMode</span><span class="o">.</span><span class="py">OVERWRITE</span><span class="o">)</span>

<span class="c1">// tuples as lines with pipe as the separator "a|b|c"</span>
<span class="k">val</span> <span class="nv">values</span><span class="k">:</span> <span class="kt">DataSet</span><span class="o">[(</span><span class="kt">String</span>, <span class="kt">Int</span>, <span class="kt">Double</span><span class="o">)]</span> <span class="k">=</span> <span class="c1">// [...]</span>
<span class="nv">values</span><span class="o">.</span><span class="py">writeAsCsv</span><span class="o">(</span><span class="s">"file:///path/to/the/result/file"</span><span class="o">,</span> <span class="s">"\n"</span><span class="o">,</span> <span class="s">"|"</span><span class="o">)</span>

<span class="c1">// this writes tuples in the text formatting "(a, b, c)", rather than as CSV lines</span>
<span class="nv">values</span><span class="o">.</span><span class="py">writeAsText</span><span class="o">(</span><span class="s">"file:///path/to/the/result/file"</span><span class="o">)</span>

<span class="c1">// this writes values as strings using a user-defined formatting</span>
<span class="n">values</span> <span class="n">map</span> <span class="o">{</span> <span class="n">tuple</span> <span class="k">=&gt;</span> <span class="nv">tuple</span><span class="o">.</span><span class="py">_1</span> <span class="o">+</span> <span class="s">" - "</span> <span class="o">+</span> <span class="nv">tuple</span><span class="o">.</span><span class="py">_2</span> <span class="o">}</span>
  <span class="o">.</span><span class="py">writeAsText</span><span class="o">(</span><span class="s">"file:///path/to/the/result/file"</span><span class="o">)</span></code></pre></figure>

    <h4 id="locally-sorted-output-1">Locally Sorted Output</h4>

    <p>The output of a data sink can be locally sorted on specified fields in specified orders using <a href="#define-keys-for-tuples">tuple field positions</a> or <a href="#define-keys-using-field-expressions">field expressions</a>. This works for every output format.</p>

    <p>The following examples show how to use this feature:</p>

    <figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="nv">tData</span><span class="k">:</span> <span class="kt">DataSet</span><span class="o">[(</span><span class="kt">Int</span>, <span class="kt">String</span>, <span class="kt">Double</span><span class="o">)]</span> <span class="k">=</span> <span class="c1">// [...]</span>
<span class="k">val</span> <span class="nv">pData</span><span class="k">:</span> <span class="kt">DataSet</span><span class="o">[(</span><span class="kt">BookPojo</span>, <span class="kt">Double</span><span class="o">)]</span> <span class="k">=</span> <span class="c1">// [...]</span>
<span class="k">val</span> <span class="nv">sData</span><span class="k">:</span> <span class="kt">DataSet</span><span class="o">[</span><span class="kt">String</span><span class="o">]</span> <span class="k">=</span> <span class="c1">// [...]</span>

<span class="c1">// sort output on String field in ascending order</span>
<span class="nv">tData</span><span class="o">.</span><span class="py">sortPartition</span><span class="o">(</span><span class="mi">1</span><span class="o">,</span> <span class="nv">Order</span><span class="o">.</span><span class="py">ASCENDING</span><span class="o">).</span><span class="py">print</span><span class="o">()</span>

<span class="c1">// sort output on Double field in descending and Int field in ascending order</span>
<span class="nv">tData</span><span class="o">.</span><span class="py">sortPartition</span><span class="o">(</span><span class="mi">2</span><span class="o">,</span> <span class="nv">Order</span><span class="o">.</span><span class="py">DESCENDING</span><span class="o">).</span><span class="py">sortPartition</span><span class="o">(</span><span class="mi">0</span><span class="o">,</span> <span class="nv">Order</span><span class="o">.</span><span class="py">ASCENDING</span><span class="o">).</span><span class="py">print</span><span class="o">()</span>

<span class="c1">// sort output on the "author" field of nested BookPojo in descending order</span>
<span class="nv">pData</span><span class="o">.</span><span class="py">sortPartition</span><span class="o">(</span><span class="s">"_1.author"</span><span class="o">,</span> <span class="nv">Order</span><span class="o">.</span><span class="py">DESCENDING</span><span class="o">).</span><span class="py">writeAsText</span><span class="o">(...)</span>

<span class="c1">// sort output on the full tuple in ascending order</span>
<span class="nv">tData</span><span class="o">.</span><span class="py">sortPartition</span><span class="o">(</span><span class="s">"_"</span><span class="o">,</span> <span class="nv">Order</span><span class="o">.</span><span class="py">ASCENDING</span><span class="o">).</span><span class="py">writeAsCsv</span><span class="o">(...)</span>

<span class="c1">// sort atomic type (String) output in descending order</span>
<span class="nv">sData</span><span class="o">.</span><span class="py">sortPartition</span><span class="o">(</span><span class="s">"_"</span><span class="o">,</span> <span class="nv">Order</span><span class="o">.</span><span class="py">DESCENDING</span><span class="o">).</span><span class="py">writeAsText</span><span class="o">(...)</span></code></pre></figure>

    <p>Globally sorted output is not supported yet.</p>

  </div>
</div>

<p><a href="#top" class="top pull-right"><span class="glyphicon glyphicon-chevron-up"></span> Back to top</a></p>

<h2 id="iteration-operators">Iteration Operators</h2>

<p>Iterations implement loops in Flink programs. The iteration operators encapsulate a part of the
program and execute it repeatedly, feeding back the result of one iteration (the partial solution)
into the next iteration. There are two types of iterations in Flink: <strong>BulkIteration</strong> and
<strong>DeltaIteration</strong>.</p>

<p>This section provides quick examples on how to use both operators. Check out the <a href="iterations.html">Introduction to
Iterations</a> page for a more detailed introduction.</p>

<div class="codetabs">
  <div data-lang="java">

    <h4 id="bulk-iterations">Bulk Iterations</h4>

    <p>To create a BulkIteration call the <code class="highlighter-rouge">iterate(int)</code> method of the DataSet the iteration should start
at. This will return an <code class="highlighter-rouge">IterativeDataSet</code>, which can be transformed with the regular operators. The
single argument to the iterate call specifies the maximum number of iterations.</p>

    <p>To specify the end of an iteration call the <code class="highlighter-rouge">closeWith(DataSet)</code> method on the <code class="highlighter-rouge">IterativeDataSet</code> to
specify which transformation should be fed back to the next iteration. You can optionally specify a
termination criterion with <code class="highlighter-rouge">closeWith(DataSet, DataSet)</code>, which evaluates the second DataSet and
terminates the iteration, if this DataSet is empty. If no termination criterion is specified, the
iteration terminates after the given maximum number iterations.</p>

    <p>The following example iteratively estimates the number Pi. The goal is to count the number of random
points, which fall into the unit circle. In each iteration, a random point is picked. If this point
lies inside the unit circle, we increment the count. Pi is then estimated as the resulting count
divided by the number of iterations multiplied by 4.</p>

    <figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="kd">final</span> <span class="nc">ExecutionEnvironment</span> <span class="n">env</span> <span class="o">=</span> <span class="nc">ExecutionEnvironment</span><span class="o">.</span><span class="na">getExecutionEnvironment</span><span class="o">();</span>

<span class="c1">// Create initial IterativeDataSet</span>
<span class="nc">IterativeDataSet</span><span class="o">&lt;</span><span class="nc">Integer</span><span class="o">&gt;</span> <span class="n">initial</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="na">fromElements</span><span class="o">(</span><span class="mi">0</span><span class="o">).</span><span class="na">iterate</span><span class="o">(</span><span class="mi">10000</span><span class="o">);</span>

<span class="nc">DataSet</span><span class="o">&lt;</span><span class="nc">Integer</span><span class="o">&gt;</span> <span class="n">iteration</span> <span class="o">=</span> <span class="n">initial</span><span class="o">.</span><span class="na">map</span><span class="o">(</span><span class="k">new</span> <span class="nc">MapFunction</span><span class="o">&lt;</span><span class="nc">Integer</span><span class="o">,</span> <span class="nc">Integer</span><span class="o">&gt;()</span> <span class="o">{</span>
    <span class="nd">@Override</span>
    <span class="kd">public</span> <span class="nc">Integer</span> <span class="nf">map</span><span class="o">(</span><span class="nc">Integer</span> <span class="n">i</span><span class="o">)</span> <span class="kd">throws</span> <span class="nc">Exception</span> <span class="o">{</span>
        <span class="kt">double</span> <span class="n">x</span> <span class="o">=</span> <span class="nc">Math</span><span class="o">.</span><span class="na">random</span><span class="o">();</span>
        <span class="kt">double</span> <span class="n">y</span> <span class="o">=</span> <span class="nc">Math</span><span class="o">.</span><span class="na">random</span><span class="o">();</span>

        <span class="k">return</span> <span class="n">i</span> <span class="o">+</span> <span class="o">((</span><span class="n">x</span> <span class="o">*</span> <span class="n">x</span> <span class="o">+</span> <span class="n">y</span> <span class="o">*</span> <span class="n">y</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="o">)</span> <span class="o">?</span> <span class="mi">1</span> <span class="o">:</span> <span class="mi">0</span><span class="o">);</span>
    <span class="o">}</span>
<span class="o">});</span>

<span class="c1">// Iteratively transform the IterativeDataSet</span>
<span class="nc">DataSet</span><span class="o">&lt;</span><span class="nc">Integer</span><span class="o">&gt;</span> <span class="n">count</span> <span class="o">=</span> <span class="n">initial</span><span class="o">.</span><span class="na">closeWith</span><span class="o">(</span><span class="n">iteration</span><span class="o">);</span>

<span class="n">count</span><span class="o">.</span><span class="na">map</span><span class="o">(</span><span class="k">new</span> <span class="nc">MapFunction</span><span class="o">&lt;</span><span class="nc">Integer</span><span class="o">,</span> <span class="nc">Double</span><span class="o">&gt;()</span> <span class="o">{</span>
    <span class="nd">@Override</span>
    <span class="kd">public</span> <span class="nc">Double</span> <span class="nf">map</span><span class="o">(</span><span class="nc">Integer</span> <span class="n">count</span><span class="o">)</span> <span class="kd">throws</span> <span class="nc">Exception</span> <span class="o">{</span>
        <span class="k">return</span> <span class="n">count</span> <span class="o">/</span> <span class="o">(</span><span class="kt">double</span><span class="o">)</span> <span class="mi">10000</span> <span class="o">*</span> <span class="mi">4</span><span class="o">;</span>
    <span class="o">}</span>
<span class="o">}).</span><span class="na">print</span><span class="o">();</span>

<span class="n">env</span><span class="o">.</span><span class="na">execute</span><span class="o">(</span><span class="s">"Iterative Pi Example"</span><span class="o">);</span></code></pre></figure>

    <p>You can also check out the
<a href="https://github.com/apache/flink/blob/master//flink-examples/flink-examples-batch/src/main/java/org/apache/flink/examples/java/clustering/KMeans.java">K-Means example</a>,
which uses a BulkIteration to cluster a set of unlabeled points.</p>

    <h4 id="delta-iterations">Delta Iterations</h4>

    <p>Delta iterations exploit the fact that certain algorithms do not change every data point of the
solution in each iteration.</p>

    <p>In addition to the partial solution that is fed back (called workset) in every iteration, delta
iterations maintain state across iterations (called solution set), which can be updated through
deltas. The result of the iterative computation is the state after the last iteration. Please refer
to the <a href="iterations.html">Introduction to Iterations</a> for an overview of the basic principle of delta
iterations.</p>

    <p>Defining a DeltaIteration is similar to defining a BulkIteration. For delta iterations, two data
sets form the input to each iteration (workset and solution set), and two data sets are produced as
the result (new workset, solution set delta) in each iteration.</p>

    <p>To create a DeltaIteration call the <code class="highlighter-rouge">iterateDelta(DataSet, int, int)</code> (or <code class="highlighter-rouge">iterateDelta(DataSet,
int, int[])</code> respectively). This method is called on the initial solution set. The arguments are the
initial delta set, the maximum number of iterations and the key positions. The returned
<code class="highlighter-rouge">DeltaIteration</code> object gives you access to the DataSets representing the workset and solution set
via the methods <code class="highlighter-rouge">iteration.getWorkset()</code> and <code class="highlighter-rouge">iteration.getSolutionSet()</code>.</p>

    <p>Below is an example for the syntax of a delta iteration</p>

    <figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="c1">// read the initial data sets</span>
<span class="nc">DataSet</span><span class="o">&lt;</span><span class="nc">Tuple2</span><span class="o">&lt;</span><span class="nc">Long</span><span class="o">,</span> <span class="nc">Double</span><span class="o">&gt;&gt;</span> <span class="n">initialSolutionSet</span> <span class="o">=</span> <span class="c1">// [...]</span>

<span class="nc">DataSet</span><span class="o">&lt;</span><span class="nc">Tuple2</span><span class="o">&lt;</span><span class="nc">Long</span><span class="o">,</span> <span class="nc">Double</span><span class="o">&gt;&gt;</span> <span class="n">initialDeltaSet</span> <span class="o">=</span> <span class="c1">// [...]</span>

<span class="kt">int</span> <span class="n">maxIterations</span> <span class="o">=</span> <span class="mi">100</span><span class="o">;</span>
<span class="kt">int</span> <span class="n">keyPosition</span> <span class="o">=</span> <span class="mi">0</span><span class="o">;</span>

<span class="nc">DeltaIteration</span><span class="o">&lt;</span><span class="nc">Tuple2</span><span class="o">&lt;</span><span class="nc">Long</span><span class="o">,</span> <span class="nc">Double</span><span class="o">&gt;,</span> <span class="nc">Tuple2</span><span class="o">&lt;</span><span class="nc">Long</span><span class="o">,</span> <span class="nc">Double</span><span class="o">&gt;&gt;</span> <span class="n">iteration</span> <span class="o">=</span> <span class="n">initialSolutionSet</span>
    <span class="o">.</span><span class="na">iterateDelta</span><span class="o">(</span><span class="n">initialDeltaSet</span><span class="o">,</span> <span class="n">maxIterations</span><span class="o">,</span> <span class="n">keyPosition</span><span class="o">);</span>

<span class="nc">DataSet</span><span class="o">&lt;</span><span class="nc">Tuple2</span><span class="o">&lt;</span><span class="nc">Long</span><span class="o">,</span> <span class="nc">Double</span><span class="o">&gt;&gt;</span> <span class="n">candidateUpdates</span> <span class="o">=</span> <span class="n">iteration</span><span class="o">.</span><span class="na">getWorkset</span><span class="o">()</span>
    <span class="o">.</span><span class="na">groupBy</span><span class="o">(</span><span class="mi">1</span><span class="o">)</span>
    <span class="o">.</span><span class="na">reduceGroup</span><span class="o">(</span><span class="k">new</span> <span class="nc">ComputeCandidateChanges</span><span class="o">());</span>

<span class="nc">DataSet</span><span class="o">&lt;</span><span class="nc">Tuple2</span><span class="o">&lt;</span><span class="nc">Long</span><span class="o">,</span> <span class="nc">Double</span><span class="o">&gt;&gt;</span> <span class="n">deltas</span> <span class="o">=</span> <span class="n">candidateUpdates</span>
    <span class="o">.</span><span class="na">join</span><span class="o">(</span><span class="n">iteration</span><span class="o">.</span><span class="na">getSolutionSet</span><span class="o">())</span>
    <span class="o">.</span><span class="na">where</span><span class="o">(</span><span class="mi">0</span><span class="o">)</span>
    <span class="o">.</span><span class="na">equalTo</span><span class="o">(</span><span class="mi">0</span><span class="o">)</span>
    <span class="o">.</span><span class="na">with</span><span class="o">(</span><span class="k">new</span> <span class="nc">CompareChangesToCurrent</span><span class="o">());</span>

<span class="nc">DataSet</span><span class="o">&lt;</span><span class="nc">Tuple2</span><span class="o">&lt;</span><span class="nc">Long</span><span class="o">,</span> <span class="nc">Double</span><span class="o">&gt;&gt;</span> <span class="n">nextWorkset</span> <span class="o">=</span> <span class="n">deltas</span>
    <span class="o">.</span><span class="na">filter</span><span class="o">(</span><span class="k">new</span> <span class="nc">FilterByThreshold</span><span class="o">());</span>

<span class="n">iteration</span><span class="o">.</span><span class="na">closeWith</span><span class="o">(</span><span class="n">deltas</span><span class="o">,</span> <span class="n">nextWorkset</span><span class="o">)</span>
	<span class="o">.</span><span class="na">writeAsCsv</span><span class="o">(</span><span class="n">outputPath</span><span class="o">);</span></code></pre></figure>

  </div>
  <div data-lang="scala">
    <h4 id="bulk-iterations-1">Bulk Iterations</h4>

    <p>To create a BulkIteration call the <code class="highlighter-rouge">iterate(int)</code> method of the DataSet the iteration should start
at and also specify a step function. The step function gets the input DataSet for the current
iteration and must return a new DataSet. The parameter of the iterate call is the maximum number
of iterations after which to stop.</p>

    <p>There is also the <code class="highlighter-rouge">iterateWithTermination(int)</code> function that accepts a step function that
returns two DataSets: The result of the iteration step and a termination criterion. The iterations
are stopped once the termination criterion DataSet is empty.</p>

    <p>The following example iteratively estimates the number Pi. The goal is to count the number of random
points, which fall into the unit circle. In each iteration, a random point is picked. If this point
lies inside the unit circle, we increment the count. Pi is then estimated as the resulting count
divided by the number of iterations multiplied by 4.</p>

    <figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="nv">env</span> <span class="k">=</span> <span class="nv">ExecutionEnvironment</span><span class="o">.</span><span class="py">getExecutionEnvironment</span><span class="o">()</span>

<span class="c1">// Create initial DataSet</span>
<span class="k">val</span> <span class="nv">initial</span> <span class="k">=</span> <span class="nv">env</span><span class="o">.</span><span class="py">fromElements</span><span class="o">(</span><span class="mi">0</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">count</span> <span class="k">=</span> <span class="nv">initial</span><span class="o">.</span><span class="py">iterate</span><span class="o">(</span><span class="mi">10000</span><span class="o">)</span> <span class="o">{</span> <span class="n">iterationInput</span><span class="k">:</span> <span class="kt">DataSet</span><span class="o">[</span><span class="kt">Int</span><span class="o">]</span> <span class="k">=&gt;</span>
  <span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">iterationInput</span><span class="o">.</span><span class="py">map</span> <span class="o">{</span> <span class="n">i</span> <span class="k">=&gt;</span>
    <span class="k">val</span> <span class="nv">x</span> <span class="k">=</span> <span class="nv">Math</span><span class="o">.</span><span class="py">random</span><span class="o">()</span>
    <span class="k">val</span> <span class="nv">y</span> <span class="k">=</span> <span class="nv">Math</span><span class="o">.</span><span class="py">random</span><span class="o">()</span>
    <span class="n">i</span> <span class="o">+</span> <span class="o">(</span><span class="nf">if</span> <span class="o">(</span><span class="n">x</span> <span class="o">*</span> <span class="n">x</span> <span class="o">+</span> <span class="n">y</span> <span class="o">*</span> <span class="n">y</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="o">)</span> <span class="mi">1</span> <span class="k">else</span> <span class="mi">0</span><span class="o">)</span>
  <span class="o">}</span>
  <span class="n">result</span>
<span class="o">}</span>

<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="n">count</span> <span class="n">map</span> <span class="o">{</span> <span class="n">c</span> <span class="k">=&gt;</span> <span class="n">c</span> <span class="o">/</span> <span class="mf">10000.0</span> <span class="o">*</span> <span class="mi">4</span> <span class="o">}</span>

<span class="nv">result</span><span class="o">.</span><span class="py">print</span><span class="o">()</span>

<span class="nv">env</span><span class="o">.</span><span class="py">execute</span><span class="o">(</span><span class="s">"Iterative Pi Example"</span><span class="o">)</span></code></pre></figure>

    <p>You can also check out the
<a href="https://github.com/apache/flink/blob/master//flink-examples/flink-examples-batch/src/main/scala/org/apache/flink/examples/scala/clustering/KMeans.scala">K-Means example</a>,
which uses a BulkIteration to cluster a set of unlabeled points.</p>

    <h4 id="delta-iterations-1">Delta Iterations</h4>

    <p>Delta iterations exploit the fact that certain algorithms do not change every data point of the
solution in each iteration.</p>

    <p>In addition to the partial solution that is fed back (called workset) in every iteration, delta
iterations maintain state across iterations (called solution set), which can be updated through
deltas. The result of the iterative computation is the state after the last iteration. Please refer
to the <a href="iterations.html">Introduction to Iterations</a> for an overview of the basic principle of delta
iterations.</p>

    <p>Defining a DeltaIteration is similar to defining a BulkIteration. For delta iterations, two data
sets form the input to each iteration (workset and solution set), and two data sets are produced as
the result (new workset, solution set delta) in each iteration.</p>

    <p>To create a DeltaIteration call the <code class="highlighter-rouge">iterateDelta(initialWorkset, maxIterations, key)</code> on the
initial solution set. The step function takes two parameters: (solutionSet, workset), and must
return two values: (solutionSetDelta, newWorkset).</p>

    <p>Below is an example for the syntax of a delta iteration</p>

    <figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="c1">// read the initial data sets</span>
<span class="k">val</span> <span class="nv">initialSolutionSet</span><span class="k">:</span> <span class="kt">DataSet</span><span class="o">[(</span><span class="kt">Long</span>, <span class="kt">Double</span><span class="o">)]</span> <span class="k">=</span> <span class="c1">// [...]</span>

<span class="k">val</span> <span class="nv">initialWorkset</span><span class="k">:</span> <span class="kt">DataSet</span><span class="o">[(</span><span class="kt">Long</span>, <span class="kt">Double</span><span class="o">)]</span> <span class="k">=</span> <span class="c1">// [...]</span>

<span class="k">val</span> <span class="nv">maxIterations</span> <span class="k">=</span> <span class="mi">100</span>
<span class="k">val</span> <span class="nv">keyPosition</span> <span class="k">=</span> <span class="mi">0</span>

<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">initialSolutionSet</span><span class="o">.</span><span class="py">iterateDelta</span><span class="o">(</span><span class="n">initialWorkset</span><span class="o">,</span> <span class="n">maxIterations</span><span class="o">,</span> <span class="nc">Array</span><span class="o">(</span><span class="n">keyPosition</span><span class="o">))</span> <span class="o">{</span>
  <span class="o">(</span><span class="n">solution</span><span class="o">,</span> <span class="n">workset</span><span class="o">)</span> <span class="k">=&gt;</span>
    <span class="k">val</span> <span class="nv">candidateUpdates</span> <span class="k">=</span> <span class="nv">workset</span><span class="o">.</span><span class="py">groupBy</span><span class="o">(</span><span class="mi">1</span><span class="o">).</span><span class="py">reduceGroup</span><span class="o">(</span><span class="k">new</span> <span class="nc">ComputeCandidateChanges</span><span class="o">())</span>
    <span class="k">val</span> <span class="nv">deltas</span> <span class="k">=</span> <span class="nv">candidateUpdates</span><span class="o">.</span><span class="py">join</span><span class="o">(</span><span class="n">solution</span><span class="o">).</span><span class="py">where</span><span class="o">(</span><span class="mi">0</span><span class="o">).</span><span class="py">equalTo</span><span class="o">(</span><span class="mi">0</span><span class="o">)(</span><span class="k">new</span> <span class="nc">CompareChangesToCurrent</span><span class="o">())</span>

    <span class="k">val</span> <span class="nv">nextWorkset</span> <span class="k">=</span> <span class="nv">deltas</span><span class="o">.</span><span class="py">filter</span><span class="o">(</span><span class="k">new</span> <span class="nc">FilterByThreshold</span><span class="o">())</span>

    <span class="o">(</span><span class="n">deltas</span><span class="o">,</span> <span class="n">nextWorkset</span><span class="o">)</span>
<span class="o">}</span>

<span class="nv">result</span><span class="o">.</span><span class="py">writeAsCsv</span><span class="o">(</span><span class="n">outputPath</span><span class="o">)</span>

<span class="nv">env</span><span class="o">.</span><span class="py">execute</span><span class="o">()</span></code></pre></figure>

  </div>
</div>

<p><a href="#top" class="top pull-right"><span class="glyphicon glyphicon-chevron-up"></span> Back to top</a></p>

<h2 id="operating-on-data-objects-in-functions">Operating on data objects in functions</h2>

<p>Flink’s runtime exchanges data with user functions in form of Java objects. Functions receive input objects from the runtime as method parameters and return output objects as result. Because these objects are accessed by user functions and runtime code, it is very important to understand and follow the rules about how the user code may access, i.e., read and modify, these objects.</p>

<p>User functions receive objects from Flink’s runtime either as regular method parameters (like a <code class="highlighter-rouge">MapFunction</code>) or through an <code class="highlighter-rouge">Iterable</code> parameter (like a <code class="highlighter-rouge">GroupReduceFunction</code>). We refer to objects that the runtime passes to a user function as <em>input objects</em>. User functions can emit objects to the Flink runtime either as a method return value (like a <code class="highlighter-rouge">MapFunction</code>) or through a <code class="highlighter-rouge">Collector</code> (like a <code class="highlighter-rouge">FlatMapFunction</code>). We refer to objects which have been emitted by the user function to the runtime as <em>output objects</em>.</p>

<p>Flink’s DataSet API features two modes that differ in how Flink’s runtime creates or reuses input objects. This behavior affects the guarantees and constraints for how user functions may interact with input and output objects. The following sections define these rules and give coding guidelines to write safe user function code.</p>

<h3 id="object-reuse-disabled-default">Object-Reuse Disabled (DEFAULT)</h3>

<p>By default, Flink operates in object-reuse disabled mode. This mode ensures that functions always receive new input objects within a function call. The object-reuse disabled mode gives better guarantees and is safer to use. However, it comes with a certain processing overhead and might cause higher Java garbage collection activity. The following table explains how user functions may access input and output objects in object-reuse disabled mode.</p>

<table class="table table-bordered">
  <thead>
    <tr>
      <th class="text-left" style="width: 20%">Operation</th>
      <th class="text-center">Guarantees and Restrictions</th>
    </tr>
  </thead>
  <tbody>
   <tr>
      <td><strong>Reading Input Objects</strong></td>
      <td>
        Within a method call it is guaranteed that the value of an input object does not change. This includes objects served by an Iterable. For example it is safe to collect input objects served by an Iterable in a List or Map. Note that objects may be modified after the method call is left. It is <strong>not safe</strong> to remember objects across function calls.
      </td>
   </tr>
   <tr>
      <td><strong>Modifying Input Objects</strong></td>
      <td>You may modify input objects.</td>
   </tr>
   <tr>
      <td><strong>Emitting Input Objects</strong></td>
      <td>
        You may emit input objects. The value of an input object may have changed after it was emitted. It is <strong>not safe</strong> to read an input object after it was emitted.
      </td>
   </tr>
   <tr>
      <td><strong>Reading Output Objects</strong></td>
      <td>
        An object that was given to a Collector or returned as method result might have changed its value. It is <strong>not safe</strong> to read an output object.
      </td>
   </tr>
   <tr>
      <td><strong>Modifying Output Objects</strong></td>
      <td>You may modify an object after it was emitted and emit it again.</td>
   </tr>
  </tbody>
</table>

<p><strong>Coding guidelines for the object-reuse disabled (default) mode:</strong></p>

<ul>
  <li>Do not remember and read input objects across method calls.</li>
  <li>Do not read objects after you emitted them.</li>
</ul>

<h3 id="object-reuse-enabled">Object-Reuse Enabled</h3>

<p>In object-reuse enabled mode, Flink’s runtime minimizes the number of object instantiations. This can improve the performance and can reduce the Java garbage collection pressure. The object-reuse enabled mode is activated by calling <code class="highlighter-rouge">ExecutionConfig.enableObjectReuse()</code>. The following table explains how user functions may access input and output objects in object-reuse enabled mode.</p>

<table class="table table-bordered">
  <thead>
    <tr>
      <th class="text-left" style="width: 20%">Operation</th>
      <th class="text-center">Guarantees and Restrictions</th>
    </tr>
  </thead>
  <tbody>
   <tr>
      <td><strong>Reading input objects received as regular method parameters</strong></td>
      <td>
        Input objects received as regular method arguments are not modified within a function call. Objects may be modified after method call is left. It is <strong>not safe</strong> to remember objects across function calls.
      </td>
   </tr>
   <tr>
      <td><strong>Reading input objects received from an Iterable parameter</strong></td>
      <td>
        Input objects received from an Iterable are only valid until the next() method is called. An Iterable or Iterator may serve the same object instance multiple times. It is <strong>not safe</strong> to remember input objects received from an Iterable, e.g., by putting them in a List or Map.
      </td>
   </tr>
   <tr>
      <td><strong>Modifying Input Objects</strong></td>
      <td>You <strong>must not</strong> modify input objects, except for input objects of MapFunction, FlatMapFunction, MapPartitionFunction, GroupReduceFunction, GroupCombineFunction, CoGroupFunction, and InputFormat.next(reuse).</td>
   </tr>
   <tr>
      <td><strong>Emitting Input Objects</strong></td>
      <td>
        You <strong>must not</strong> emit input objects, except for input objects of MapFunction, FlatMapFunction, MapPartitionFunction, GroupReduceFunction, GroupCombineFunction, CoGroupFunction, and InputFormat.next(reuse).
      </td>
   </tr>
   <tr>
      <td><strong>Reading Output Objects</strong></td>
      <td>
        An object that was given to a Collector or returned as method result might have changed its value. It is <strong>not safe</strong> to read an output object.
      </td>
   </tr>
   <tr>
      <td><strong>Modifying Output Objects</strong></td>
      <td>You may modify an output object and emit it again.</td>
   </tr>
  </tbody>
</table>

<p><strong>Coding guidelines for object-reuse enabled:</strong></p>

<ul>
  <li>Do not remember input objects received from an <code class="highlighter-rouge">Iterable</code>.</li>
  <li>Do not remember and read input objects across method calls.</li>
  <li>Do not modify or emit input objects, except for input objects of <code class="highlighter-rouge">MapFunction</code>, <code class="highlighter-rouge">FlatMapFunction</code>, <code class="highlighter-rouge">MapPartitionFunction</code>, <code class="highlighter-rouge">GroupReduceFunction</code>, <code class="highlighter-rouge">GroupCombineFunction</code>, <code class="highlighter-rouge">CoGroupFunction</code>, and <code class="highlighter-rouge">InputFormat.next(reuse)</code>.</li>
  <li>To reduce object instantiations, you can always emit a dedicated output object which is repeatedly modified but never read.</li>
</ul>

<p><a href="#top" class="top pull-right"><span class="glyphicon glyphicon-chevron-up"></span> Back to top</a></p>

<h2 id="debugging">Debugging</h2>

<p>Before running a data analysis program on a large data set in a distributed cluster, it is a good
idea to make sure that the implemented algorithm works as desired. Hence, implementing data analysis
programs is usually an incremental process of checking results, debugging, and improving.</p>

<p>Flink provides a few nice features to significantly ease the development process of data analysis
programs by supporting local debugging from within an IDE, injection of test data, and collection of
result data. This section give some hints how to ease the development of Flink programs.</p>

<h3 id="local-execution-environment">Local Execution Environment</h3>

<p>A <code class="highlighter-rouge">LocalEnvironment</code> starts a Flink system within the same JVM process it was created in. If you
start the LocalEnvironment from an IDE, you can set breakpoints in your code and easily debug your
program.</p>

<p>A LocalEnvironment is created and used as follows:</p>

<div class="codetabs">
  <div data-lang="java">

    <figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="kd">final</span> <span class="nc">ExecutionEnvironment</span> <span class="n">env</span> <span class="o">=</span> <span class="nc">ExecutionEnvironment</span><span class="o">.</span><span class="na">createLocalEnvironment</span><span class="o">();</span>

<span class="nc">DataSet</span><span class="o">&lt;</span><span class="nc">String</span><span class="o">&gt;</span> <span class="n">lines</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="na">readTextFile</span><span class="o">(</span><span class="n">pathToTextFile</span><span class="o">);</span>
<span class="c1">// build your program</span>

<span class="n">env</span><span class="o">.</span><span class="na">execute</span><span class="o">();</span></code></pre></figure>

  </div>
  <div data-lang="scala">

    <figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="nv">env</span> <span class="k">=</span> <span class="nv">ExecutionEnvironment</span><span class="o">.</span><span class="py">createLocalEnvironment</span><span class="o">()</span>

<span class="k">val</span> <span class="nv">lines</span> <span class="k">=</span> <span class="nv">env</span><span class="o">.</span><span class="py">readTextFile</span><span class="o">(</span><span class="n">pathToTextFile</span><span class="o">)</span>
<span class="c1">// build your program</span>

<span class="nv">env</span><span class="o">.</span><span class="py">execute</span><span class="o">()</span></code></pre></figure>

  </div>
</div>

<h3 id="collection-data-sources-and-sinks">Collection Data Sources and Sinks</h3>

<p>Providing input for an analysis program and checking its output is cumbersome when done by creating
input files and reading output files. Flink features special data sources and sinks which are backed
by Java collections to ease testing. Once a program has been tested, the sources and sinks can be
easily replaced by sources and sinks that read from / write to external data stores such as HDFS.</p>

<p>Collection data sources can be used as follows:</p>

<div class="codetabs">
  <div data-lang="java">

    <figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="kd">final</span> <span class="nc">ExecutionEnvironment</span> <span class="n">env</span> <span class="o">=</span> <span class="nc">ExecutionEnvironment</span><span class="o">.</span><span class="na">createLocalEnvironment</span><span class="o">();</span>

<span class="c1">// Create a DataSet from a list of elements</span>
<span class="nc">DataSet</span><span class="o">&lt;</span><span class="nc">Integer</span><span class="o">&gt;</span> <span class="n">myInts</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="na">fromElements</span><span class="o">(</span><span class="mi">1</span><span class="o">,</span> <span class="mi">2</span><span class="o">,</span> <span class="mi">3</span><span class="o">,</span> <span class="mi">4</span><span class="o">,</span> <span class="mi">5</span><span class="o">);</span>

<span class="c1">// Create a DataSet from any Java collection</span>
<span class="nc">List</span><span class="o">&lt;</span><span class="nc">Tuple2</span><span class="o">&lt;</span><span class="nc">String</span><span class="o">,</span> <span class="nc">Integer</span><span class="o">&gt;&gt;</span> <span class="n">data</span> <span class="o">=</span> <span class="o">...</span>
<span class="nc">DataSet</span><span class="o">&lt;</span><span class="nc">Tuple2</span><span class="o">&lt;</span><span class="nc">String</span><span class="o">,</span> <span class="nc">Integer</span><span class="o">&gt;&gt;</span> <span class="n">myTuples</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="na">fromCollection</span><span class="o">(</span><span class="n">data</span><span class="o">);</span>

<span class="c1">// Create a DataSet from an Iterator</span>
<span class="nc">Iterator</span><span class="o">&lt;</span><span class="nc">Long</span><span class="o">&gt;</span> <span class="n">longIt</span> <span class="o">=</span> <span class="o">...</span>
<span class="nc">DataSet</span><span class="o">&lt;</span><span class="nc">Long</span><span class="o">&gt;</span> <span class="n">myLongs</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="na">fromCollection</span><span class="o">(</span><span class="n">longIt</span><span class="o">,</span> <span class="nc">Long</span><span class="o">.</span><span class="na">class</span><span class="o">);</span></code></pre></figure>

    <p>A collection data sink is specified as follows:</p>

    <figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="nc">DataSet</span><span class="o">&lt;</span><span class="nc">Tuple2</span><span class="o">&lt;</span><span class="nc">String</span><span class="o">,</span> <span class="nc">Integer</span><span class="o">&gt;&gt;</span> <span class="n">myResult</span> <span class="o">=</span> <span class="o">...</span>

<span class="nc">List</span><span class="o">&lt;</span><span class="nc">Tuple2</span><span class="o">&lt;</span><span class="nc">String</span><span class="o">,</span> <span class="nc">Integer</span><span class="o">&gt;&gt;</span> <span class="n">outData</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">ArrayList</span><span class="o">&lt;</span><span class="nc">Tuple2</span><span class="o">&lt;</span><span class="nc">String</span><span class="o">,</span> <span class="nc">Integer</span><span class="o">&gt;&gt;();</span>
<span class="n">myResult</span><span class="o">.</span><span class="na">output</span><span class="o">(</span><span class="k">new</span> <span class="nc">LocalCollectionOutputFormat</span><span class="o">(</span><span class="n">outData</span><span class="o">));</span></code></pre></figure>

    <p><strong>Note:</strong> Currently, the collection data sink is restricted to local execution, as a debugging tool.</p>

  </div>
  <div data-lang="scala">

    <figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="nv">env</span> <span class="k">=</span> <span class="nv">ExecutionEnvironment</span><span class="o">.</span><span class="py">createLocalEnvironment</span><span class="o">()</span>

<span class="c1">// Create a DataSet from a list of elements</span>
<span class="k">val</span> <span class="nv">myInts</span> <span class="k">=</span> <span class="nv">env</span><span class="o">.</span><span class="py">fromElements</span><span class="o">(</span><span class="mi">1</span><span class="o">,</span> <span class="mi">2</span><span class="o">,</span> <span class="mi">3</span><span class="o">,</span> <span class="mi">4</span><span class="o">,</span> <span class="mi">5</span><span class="o">)</span>

<span class="c1">// Create a DataSet from any Collection</span>
<span class="k">val</span> <span class="nv">data</span><span class="k">:</span> <span class="kt">Seq</span><span class="o">[(</span><span class="kt">String</span>, <span class="kt">Int</span><span class="o">)]</span> <span class="k">=</span> <span class="o">...</span>
<span class="k">val</span> <span class="nv">myTuples</span> <span class="k">=</span> <span class="nv">env</span><span class="o">.</span><span class="py">fromCollection</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="c1">// Create a DataSet from an Iterator</span>
<span class="k">val</span> <span class="nv">longIt</span><span class="k">:</span> <span class="kt">Iterator</span><span class="o">[</span><span class="kt">Long</span><span class="o">]</span> <span class="k">=</span> <span class="o">...</span>
<span class="k">val</span> <span class="nv">myLongs</span> <span class="k">=</span> <span class="nv">env</span><span class="o">.</span><span class="py">fromCollection</span><span class="o">(</span><span class="n">longIt</span><span class="o">)</span></code></pre></figure>

  </div>
</div>

<p><strong>Note:</strong> Currently, the collection data source requires that data types and iterators implement
<code class="highlighter-rouge">Serializable</code>. Furthermore, collection data sources can not be executed in parallel (
parallelism = 1).</p>

<p><a href="#top" class="top pull-right"><span class="glyphicon glyphicon-chevron-up"></span> Back to top</a></p>

<h2 id="semantic-annotations">Semantic Annotations</h2>

<p>Semantic annotations can be used to give Flink hints about the behavior of a function.
They tell the system which fields of a function’s input the function reads and evaluates and
which fields it unmodified forwards from its input to its output.
Semantic annotations are a powerful means to speed up execution, because they
allow the system to reason about reusing sort orders or partitions across multiple operations. Using
semantic annotations may eventually save the program from unnecessary data shuffling or unnecessary
sorts and significantly improve the performance of a program.</p>

<p><strong>Note:</strong> The use of semantic annotations is optional. However, it is absolutely crucial to
be conservative when providing semantic annotations!
Incorrect semantic annotations will cause Flink to make incorrect assumptions about your program and
might eventually lead to incorrect results.
If the behavior of an operator is not clearly predictable, no annotation should be provided.
Please read the documentation carefully.</p>

<p>The following semantic annotations are currently supported.</p>

<h4 id="forwarded-fields-annotation">Forwarded Fields Annotation</h4>

<p>Forwarded fields information declares input fields which are unmodified forwarded by a function to the same position or to another position in the output.
This information is used by the optimizer to infer whether a data property such as sorting or
partitioning is preserved by a function.
For functions that operate on groups of input elements such as <code class="highlighter-rouge">GroupReduce</code>, <code class="highlighter-rouge">GroupCombine</code>, <code class="highlighter-rouge">CoGroup</code>, and <code class="highlighter-rouge">MapPartition</code>, all fields that are defined as forwarded fields must always be jointly forwarded from the same input element. The forwarded fields of each element that is emitted by a group-wise function may originate from a different element of the function’s input group.</p>

<p>Field forward information is specified using <a href="#define-keys-using-field-expressions">field expressions</a>.
Fields that are forwarded to the same position in the output can be specified by their position.
The specified position must be valid for the input and output data type and have the same type.
For example the String <code class="highlighter-rouge">"f2"</code> declares that the third field of a Java input tuple is always equal to the third field in the output tuple.</p>

<p>Fields which are unmodified forwarded to another position in the output are declared by specifying the
source field in the input and the target field in the output as field expressions.
The String <code class="highlighter-rouge">"f0-&gt;f2"</code> denotes that the first field of the Java input tuple is
unchanged copied to the third field of the Java output tuple. The wildcard expression <code class="highlighter-rouge">*</code> can be used to refer to a whole input or output type, i.e., <code class="highlighter-rouge">"f0-&gt;*"</code> denotes that the output of a function is always equal to the first field of its Java input tuple.</p>

<p>Multiple forwarded fields can be declared in a single String by separating them with semicolons as <code class="highlighter-rouge">"f0; f2-&gt;f1; f3-&gt;f2"</code> or in separate Strings <code class="highlighter-rouge">"f0", "f2-&gt;f1", "f3-&gt;f2"</code>. When specifying forwarded fields it is not required that all forwarded fields are declared, but all declarations must be correct.</p>

<p>Forwarded field information can be declared by attaching Java annotations on function class definitions or
by passing them as operator arguments after invoking a function on a DataSet as shown below.</p>

<h5 id="function-class-annotations">Function Class Annotations</h5>

<ul>
  <li><code class="highlighter-rouge">@ForwardedFields</code> for single input functions such as Map and Reduce.</li>
  <li><code class="highlighter-rouge">@ForwardedFieldsFirst</code> for the first input of a functions with two inputs such as Join and CoGroup.</li>
  <li><code class="highlighter-rouge">@ForwardedFieldsSecond</code> for the second input of a functions with two inputs such as Join and CoGroup.</li>
</ul>

<h5 id="operator-arguments">Operator Arguments</h5>

<ul>
  <li><code class="highlighter-rouge">data.map(myMapFnc).withForwardedFields()</code> for single input function such as Map and Reduce.</li>
  <li><code class="highlighter-rouge">data1.join(data2).where().equalTo().with(myJoinFnc).withForwardFieldsFirst()</code> for the first input of a function with two inputs such as Join and CoGroup.</li>
  <li><code class="highlighter-rouge">data1.join(data2).where().equalTo().with(myJoinFnc).withForwardFieldsSecond()</code> for the second input of a function with two inputs such as Join and CoGroup.</li>
</ul>

<p>Please note that it is not possible to overwrite field forward information which was specified as a class annotation by operator arguments.</p>

<h5 id="example">Example</h5>

<p>The following example shows how to declare forwarded field information using a function class annotation:</p>

<div class="codetabs">
  <div data-lang="java">

    <figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="nd">@ForwardedFields</span><span class="o">(</span><span class="s">"f0-&gt;f2"</span><span class="o">)</span>
<span class="kd">public</span> <span class="kd">class</span> <span class="nc">MyMap</span> <span class="kd">implements</span>
              <span class="nc">MapFunction</span><span class="o">&lt;</span><span class="nc">Tuple2</span><span class="o">&lt;</span><span class="nc">Integer</span><span class="o">,</span> <span class="nc">Integer</span><span class="o">&gt;,</span> <span class="nc">Tuple3</span><span class="o">&lt;</span><span class="nc">String</span><span class="o">,</span> <span class="nc">Integer</span><span class="o">,</span> <span class="nc">Integer</span><span class="o">&gt;&gt;</span> <span class="o">{</span>
  <span class="nd">@Override</span>
  <span class="kd">public</span> <span class="nc">Tuple3</span><span class="o">&lt;</span><span class="nc">String</span><span class="o">,</span> <span class="nc">Integer</span><span class="o">,</span> <span class="nc">Integer</span><span class="o">&gt;</span> <span class="nf">map</span><span class="o">(</span><span class="nc">Tuple2</span><span class="o">&lt;</span><span class="nc">Integer</span><span class="o">,</span> <span class="nc">Integer</span><span class="o">&gt;</span> <span class="n">val</span><span class="o">)</span> <span class="o">{</span>
    <span class="k">return</span> <span class="k">new</span> <span class="nc">Tuple3</span><span class="o">&lt;</span><span class="nc">String</span><span class="o">,</span> <span class="nc">Integer</span><span class="o">,</span> <span class="nc">Integer</span><span class="o">&gt;(</span><span class="s">"foo"</span><span class="o">,</span> <span class="n">val</span><span class="o">.</span><span class="na">f1</span> <span class="o">/</span> <span class="mi">2</span><span class="o">,</span> <span class="n">val</span><span class="o">.</span><span class="na">f0</span><span class="o">);</span>
  <span class="o">}</span>
<span class="o">}</span></code></pre></figure>

  </div>
  <div data-lang="scala">

    <figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="nd">@ForwardedFields</span><span class="o">(</span><span class="s">"_1-&gt;_3"</span><span class="o">)</span>
<span class="k">class</span> <span class="nc">MyMap</span> <span class="k">extends</span> <span class="nc">MapFunction</span><span class="o">[(</span><span class="kt">Int</span>, <span class="kt">Int</span><span class="o">)</span>, <span class="o">(</span><span class="kt">String</span>, <span class="kt">Int</span>, <span class="kt">Int</span><span class="o">)]{</span>
   <span class="k">def</span> <span class="nf">map</span><span class="o">(</span><span class="n">value</span><span class="k">:</span> <span class="o">(</span><span class="kt">Int</span><span class="o">,</span> <span class="kt">Int</span><span class="o">))</span><span class="k">:</span> <span class="o">(</span><span class="kt">String</span><span class="o">,</span> <span class="kt">Int</span><span class="o">,</span> <span class="nc">Int</span><span class="o">)</span> <span class="k">=</span> <span class="o">{</span>
    <span class="nf">return</span> <span class="o">(</span><span class="s">"foo"</span><span class="o">,</span> <span class="nv">value</span><span class="o">.</span><span class="py">_2</span> <span class="o">/</span> <span class="mi">2</span><span class="o">,</span> <span class="nv">value</span><span class="o">.</span><span class="py">_1</span><span class="o">)</span>
  <span class="o">}</span>
<span class="o">}</span></code></pre></figure>

  </div>
</div>

<h4 id="non-forwarded-fields">Non-Forwarded Fields</h4>

<p>Non-forwarded fields information declares all fields which are not preserved on the same position in a function’s output.
The values of all other fields are considered to be preserved at the same position in the output.
Hence, non-forwarded fields information is inverse to forwarded fields information.
Non-forwarded field information for group-wise operators such as <code class="highlighter-rouge">GroupReduce</code>, <code class="highlighter-rouge">GroupCombine</code>, <code class="highlighter-rouge">CoGroup</code>, and <code class="highlighter-rouge">MapPartition</code> must fulfill the same requirements as for forwarded field information.</p>

<p><strong>IMPORTANT</strong>: The specification of non-forwarded fields information is optional. However if used,
<strong>ALL!</strong> non-forwarded fields must be specified, because all other fields are considered to be forwarded in place. It is safe to declare a forwarded field as non-forwarded.</p>

<p>Non-forwarded fields are specified as a list of <a href="#define-keys-using-field-expressions">field expressions</a>. The list can be either given as a single String with field expressions separated by semicolons or as multiple Strings.
For example both <code class="highlighter-rouge">"f1; f3"</code> and <code class="highlighter-rouge">"f1", "f3"</code> declare that the second and fourth field of a Java tuple
are not preserved in place and all other fields are preserved in place.
Non-forwarded field information can only be specified for functions which have identical input and output types.</p>

<p>Non-forwarded field information is specified as function class annotations using the following annotations:</p>

<ul>
  <li><code class="highlighter-rouge">@NonForwardedFields</code> for single input functions such as Map and Reduce.</li>
  <li><code class="highlighter-rouge">@NonForwardedFieldsFirst</code> for the first input of a function with two inputs such as Join and CoGroup.</li>
  <li><code class="highlighter-rouge">@NonForwardedFieldsSecond</code> for the second input of a function with two inputs such as Join and CoGroup.</li>
</ul>

<h5 id="example-1">Example</h5>

<p>The following example shows how to declare non-forwarded field information:</p>

<div class="codetabs">
  <div data-lang="java">

    <figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="nd">@NonForwardedFields</span><span class="o">(</span><span class="s">"f1"</span><span class="o">)</span> <span class="c1">// second field is not forwarded</span>
<span class="kd">public</span> <span class="kd">class</span> <span class="nc">MyMap</span> <span class="kd">implements</span>
              <span class="nc">MapFunction</span><span class="o">&lt;</span><span class="nc">Tuple2</span><span class="o">&lt;</span><span class="nc">Integer</span><span class="o">,</span> <span class="nc">Integer</span><span class="o">&gt;,</span> <span class="nc">Tuple2</span><span class="o">&lt;</span><span class="nc">Integer</span><span class="o">,</span> <span class="nc">Integer</span><span class="o">&gt;&gt;</span> <span class="o">{</span>
  <span class="nd">@Override</span>
  <span class="kd">public</span> <span class="nc">Tuple2</span><span class="o">&lt;</span><span class="nc">Integer</span><span class="o">,</span> <span class="nc">Integer</span><span class="o">&gt;</span> <span class="nf">map</span><span class="o">(</span><span class="nc">Tuple2</span><span class="o">&lt;</span><span class="nc">Integer</span><span class="o">,</span> <span class="nc">Integer</span><span class="o">&gt;</span> <span class="n">val</span><span class="o">)</span> <span class="o">{</span>
    <span class="k">return</span> <span class="k">new</span> <span class="nc">Tuple2</span><span class="o">&lt;</span><span class="nc">Integer</span><span class="o">,</span> <span class="nc">Integer</span><span class="o">&gt;(</span><span class="n">val</span><span class="o">.</span><span class="na">f0</span><span class="o">,</span> <span class="n">val</span><span class="o">.</span><span class="na">f1</span> <span class="o">/</span> <span class="mi">2</span><span class="o">);</span>
  <span class="o">}</span>
<span class="o">}</span></code></pre></figure>

  </div>
  <div data-lang="scala">

    <figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="nd">@NonForwardedFields</span><span class="o">(</span><span class="s">"_2"</span><span class="o">)</span> <span class="c1">// second field is not forwarded</span>
<span class="k">class</span> <span class="nc">MyMap</span> <span class="k">extends</span> <span class="nc">MapFunction</span><span class="o">[(</span><span class="kt">Int</span>, <span class="kt">Int</span><span class="o">)</span>, <span class="o">(</span><span class="kt">Int</span>, <span class="kt">Int</span><span class="o">)]{</span>
  <span class="k">def</span> <span class="nf">map</span><span class="o">(</span><span class="n">value</span><span class="k">:</span> <span class="o">(</span><span class="kt">Int</span><span class="o">,</span> <span class="kt">Int</span><span class="o">))</span><span class="k">:</span> <span class="o">(</span><span class="kt">Int</span><span class="o">,</span> <span class="kt">Int</span><span class="o">)</span> <span class="k">=</span> <span class="o">{</span>
    <span class="nf">return</span> <span class="o">(</span><span class="nv">value</span><span class="o">.</span><span class="py">_1</span><span class="o">,</span> <span class="nv">value</span><span class="o">.</span><span class="py">_2</span> <span class="o">/</span> <span class="mi">2</span><span class="o">)</span>
  <span class="o">}</span>
<span class="o">}</span></code></pre></figure>

  </div>
</div>

<h4 id="read-fields">Read Fields</h4>

<p>Read fields information declares all fields that are accessed and evaluated by a function, i.e.,
all fields that are used by the function to compute its result.
For example, fields which are evaluated in conditional statements or used for computations must be marked as read when specifying read fields information.
Fields which are only unmodified forwarded to the output without evaluating their values or fields which are not accessed at all are not considered to be read.</p>

<p><strong>IMPORTANT</strong>: The specification of read fields information is optional. However if used,
<strong>ALL!</strong> read fields must be specified. It is safe to declare a non-read field as read.</p>

<p>Read fields are specified as a list of <a href="#define-keys-using-field-expressions">field expressions</a>. The list can be either given as a single String with field expressions separated by semicolons or as multiple Strings.
For example both <code class="highlighter-rouge">"f1; f3"</code> and <code class="highlighter-rouge">"f1", "f3"</code> declare that the second and fourth field of a Java tuple are read and evaluated by the function.</p>

<p>Read field information is specified as function class annotations using the following annotations:</p>

<ul>
  <li><code class="highlighter-rouge">@ReadFields</code> for single input functions such as Map and Reduce.</li>
  <li><code class="highlighter-rouge">@ReadFieldsFirst</code> for the first input of a function with two inputs such as Join and CoGroup.</li>
  <li><code class="highlighter-rouge">@ReadFieldsSecond</code> for the second input of a function with two inputs such as Join and CoGroup.</li>
</ul>

<h5 id="example-2">Example</h5>

<p>The following example shows how to declare read field information:</p>

<div class="codetabs">
  <div data-lang="java">

    <figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="nd">@ReadFields</span><span class="o">(</span><span class="s">"f0; f3"</span><span class="o">)</span> <span class="c1">// f0 and f3 are read and evaluated by the function.</span>
<span class="kd">public</span> <span class="kd">class</span> <span class="nc">MyMap</span> <span class="kd">implements</span>
              <span class="nc">MapFunction</span><span class="o">&lt;</span><span class="nc">Tuple4</span><span class="o">&lt;</span><span class="nc">Integer</span><span class="o">,</span> <span class="nc">Integer</span><span class="o">,</span> <span class="nc">Integer</span><span class="o">,</span> <span class="nc">Integer</span><span class="o">&gt;,</span>
                          <span class="nc">Tuple2</span><span class="o">&lt;</span><span class="nc">Integer</span><span class="o">,</span> <span class="nc">Integer</span><span class="o">&gt;&gt;</span> <span class="o">{</span>
  <span class="nd">@Override</span>
  <span class="kd">public</span> <span class="nc">Tuple2</span><span class="o">&lt;</span><span class="nc">Integer</span><span class="o">,</span> <span class="nc">Integer</span><span class="o">&gt;</span> <span class="nf">map</span><span class="o">(</span><span class="nc">Tuple4</span><span class="o">&lt;</span><span class="nc">Integer</span><span class="o">,</span> <span class="nc">Integer</span><span class="o">,</span> <span class="nc">Integer</span><span class="o">,</span> <span class="nc">Integer</span><span class="o">&gt;</span> <span class="n">val</span><span class="o">)</span> <span class="o">{</span>
    <span class="k">if</span><span class="o">(</span><span class="n">val</span><span class="o">.</span><span class="na">f0</span> <span class="o">==</span> <span class="mi">42</span><span class="o">)</span> <span class="o">{</span>
      <span class="k">return</span> <span class="k">new</span> <span class="nc">Tuple2</span><span class="o">&lt;</span><span class="nc">Integer</span><span class="o">,</span> <span class="nc">Integer</span><span class="o">&gt;(</span><span class="n">val</span><span class="o">.</span><span class="na">f0</span><span class="o">,</span> <span class="n">val</span><span class="o">.</span><span class="na">f1</span><span class="o">);</span>
    <span class="o">}</span> <span class="k">else</span> <span class="o">{</span>
      <span class="k">return</span> <span class="k">new</span> <span class="nc">Tuple2</span><span class="o">&lt;</span><span class="nc">Integer</span><span class="o">,</span> <span class="nc">Integer</span><span class="o">&gt;(</span><span class="n">val</span><span class="o">.</span><span class="na">f3</span><span class="o">+</span><span class="mi">10</span><span class="o">,</span> <span class="n">val</span><span class="o">.</span><span class="na">f1</span><span class="o">);</span>
    <span class="o">}</span>
  <span class="o">}</span>
<span class="o">}</span></code></pre></figure>

  </div>
  <div data-lang="scala">

    <figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="nd">@ReadFields</span><span class="o">(</span><span class="s">"_1; _4"</span><span class="o">)</span> <span class="c1">// _1 and _4 are read and evaluated by the function.</span>
<span class="k">class</span> <span class="nc">MyMap</span> <span class="k">extends</span> <span class="nc">MapFunction</span><span class="o">[(</span><span class="kt">Int</span>, <span class="kt">Int</span>, <span class="kt">Int</span>, <span class="kt">Int</span><span class="o">)</span>, <span class="o">(</span><span class="kt">Int</span>, <span class="kt">Int</span><span class="o">)]{</span>
   <span class="k">def</span> <span class="nf">map</span><span class="o">(</span><span class="n">value</span><span class="k">:</span> <span class="o">(</span><span class="kt">Int</span><span class="o">,</span> <span class="kt">Int</span><span class="o">,</span> <span class="nc">Int</span><span class="o">,</span> <span class="nc">Int</span><span class="o">))</span><span class="k">:</span> <span class="o">(</span><span class="kt">Int</span><span class="o">,</span> <span class="kt">Int</span><span class="o">)</span> <span class="k">=</span> <span class="o">{</span>
    <span class="nf">if</span> <span class="o">(</span><span class="nv">value</span><span class="o">.</span><span class="py">_1</span> <span class="o">==</span> <span class="mi">42</span><span class="o">)</span> <span class="o">{</span>
      <span class="nf">return</span> <span class="o">(</span><span class="nv">value</span><span class="o">.</span><span class="py">_1</span><span class="o">,</span> <span class="nv">value</span><span class="o">.</span><span class="py">_2</span><span class="o">)</span>
    <span class="o">}</span> <span class="k">else</span> <span class="o">{</span>
      <span class="nf">return</span> <span class="o">(</span><span class="nv">value</span><span class="o">.</span><span class="py">_4</span> <span class="o">+</span> <span class="mi">10</span><span class="o">,</span> <span class="nv">value</span><span class="o">.</span><span class="py">_2</span><span class="o">)</span>
    <span class="o">}</span>
  <span class="o">}</span>
<span class="o">}</span></code></pre></figure>

  </div>
</div>

<p><a href="#top" class="top pull-right"><span class="glyphicon glyphicon-chevron-up"></span> Back to top</a></p>

<h2 id="broadcast-variables">Broadcast Variables</h2>

<p>Broadcast variables allow you to make a data set available to all parallel instances of an
operation, in addition to the regular input of the operation. This is useful for auxiliary data
sets, or data-dependent parameterization. The data set will then be accessible at the operator as a
Collection.</p>

<ul>
  <li><strong>Broadcast</strong>: broadcast sets are registered by name via <code class="highlighter-rouge">withBroadcastSet(DataSet, String)</code>, and</li>
  <li><strong>Access</strong>: accessible via <code class="highlighter-rouge">getRuntimeContext().getBroadcastVariable(String)</code> at the target operator.</li>
</ul>

<div class="codetabs">
  <div data-lang="java">

    <figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="c1">// 1. The DataSet to be broadcast</span>
<span class="nc">DataSet</span><span class="o">&lt;</span><span class="nc">Integer</span><span class="o">&gt;</span> <span class="n">toBroadcast</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="na">fromElements</span><span class="o">(</span><span class="mi">1</span><span class="o">,</span> <span class="mi">2</span><span class="o">,</span> <span class="mi">3</span><span class="o">);</span>

<span class="nc">DataSet</span><span class="o">&lt;</span><span class="nc">String</span><span class="o">&gt;</span> <span class="n">data</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="na">fromElements</span><span class="o">(</span><span class="s">"a"</span><span class="o">,</span> <span class="s">"b"</span><span class="o">);</span>

<span class="n">data</span><span class="o">.</span><span class="na">map</span><span class="o">(</span><span class="k">new</span> <span class="nc">RichMapFunction</span><span class="o">&lt;</span><span class="nc">String</span><span class="o">,</span> <span class="nc">String</span><span class="o">&gt;()</span> <span class="o">{</span>
    <span class="nd">@Override</span>
    <span class="kd">public</span> <span class="kt">void</span> <span class="nf">open</span><span class="o">(</span><span class="nc">Configuration</span> <span class="n">parameters</span><span class="o">)</span> <span class="kd">throws</span> <span class="nc">Exception</span> <span class="o">{</span>
      <span class="c1">// 3. Access the broadcast DataSet as a Collection</span>
      <span class="nc">Collection</span><span class="o">&lt;</span><span class="nc">Integer</span><span class="o">&gt;</span> <span class="n">broadcastSet</span> <span class="o">=</span> <span class="n">getRuntimeContext</span><span class="o">().</span><span class="na">getBroadcastVariable</span><span class="o">(</span><span class="s">"broadcastSetName"</span><span class="o">);</span>
    <span class="o">}</span>


    <span class="nd">@Override</span>
    <span class="kd">public</span> <span class="nc">String</span> <span class="nf">map</span><span class="o">(</span><span class="nc">String</span> <span class="n">value</span><span class="o">)</span> <span class="kd">throws</span> <span class="nc">Exception</span> <span class="o">{</span>
        <span class="o">...</span>
    <span class="o">}</span>
<span class="o">}).</span><span class="na">withBroadcastSet</span><span class="o">(</span><span class="n">toBroadcast</span><span class="o">,</span> <span class="s">"broadcastSetName"</span><span class="o">);</span> <span class="c1">// 2. Broadcast the DataSet</span></code></pre></figure>

    <p>Make sure that the names (<code class="highlighter-rouge">broadcastSetName</code> in the previous example) match when registering and
accessing broadcast data sets. For a complete example program, have a look at
<a href="https://github.com/apache/flink/blob/master//flink-examples/flink-examples-batch/src/main/java/org/apache/flink/examples/java/clustering/KMeans.java">K-Means Algorithm</a>.</p>
  </div>
  <div data-lang="scala">

    <figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="c1">// 1. The DataSet to be broadcast</span>
<span class="k">val</span> <span class="nv">toBroadcast</span> <span class="k">=</span> <span class="nv">env</span><span class="o">.</span><span class="py">fromElements</span><span class="o">(</span><span class="mi">1</span><span class="o">,</span> <span class="mi">2</span><span class="o">,</span> <span class="mi">3</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nv">env</span><span class="o">.</span><span class="py">fromElements</span><span class="o">(</span><span class="s">"a"</span><span class="o">,</span> <span class="s">"b"</span><span class="o">)</span>

<span class="nv">data</span><span class="o">.</span><span class="py">map</span><span class="o">(</span><span class="k">new</span> <span class="nc">RichMapFunction</span><span class="o">[</span><span class="kt">String</span>, <span class="kt">String</span><span class="o">]()</span> <span class="o">{</span>
    <span class="k">var</span> <span class="n">broadcastSet</span><span class="k">:</span> <span class="kt">Traversable</span><span class="o">[</span><span class="kt">String</span><span class="o">]</span> <span class="k">=</span> <span class="kc">null</span>

    <span class="k">override</span> <span class="k">def</span> <span class="nf">open</span><span class="o">(</span><span class="n">config</span><span class="k">:</span> <span class="kt">Configuration</span><span class="o">)</span><span class="k">:</span> <span class="kt">Unit</span> <span class="o">=</span> <span class="o">{</span>
      <span class="c1">// 3. Access the broadcast DataSet as a Collection</span>
      <span class="n">broadcastSet</span> <span class="k">=</span> <span class="nf">getRuntimeContext</span><span class="o">().</span><span class="py">getBroadcastVariable</span><span class="o">[</span><span class="kt">String</span><span class="o">](</span><span class="s">"broadcastSetName"</span><span class="o">).</span><span class="py">asScala</span>
    <span class="o">}</span>

    <span class="k">def</span> <span class="nf">map</span><span class="o">(</span><span class="n">in</span><span class="k">:</span> <span class="kt">String</span><span class="o">)</span><span class="k">:</span> <span class="kt">String</span> <span class="o">=</span> <span class="o">{</span>
        <span class="o">...</span>
    <span class="o">}</span>
<span class="o">}).</span><span class="py">withBroadcastSet</span><span class="o">(</span><span class="n">toBroadcast</span><span class="o">,</span> <span class="s">"broadcastSetName"</span><span class="o">)</span> <span class="c1">// 2. Broadcast the DataSet</span></code></pre></figure>

    <p>Make sure that the names (<code class="highlighter-rouge">broadcastSetName</code> in the previous example) match when registering and
accessing broadcast data sets. For a complete example program, have a look at
<a href="https://github.com/apache/flink/blob/master//flink-examples/flink-examples-batch/src/main/scala/org/apache/flink/examples/scala/clustering/KMeans.scala">KMeans Algorithm</a>.</p>
  </div>
</div>

<p><strong>Note</strong>: As the content of broadcast variables is kept in-memory on each node, it should not become
too large. For simpler things like scalar values you can simply make parameters part of the closure
of a function, or use the <code class="highlighter-rouge">withParameters(...)</code> method to pass in a configuration.</p>

<p><a href="#top" class="top pull-right"><span class="glyphicon glyphicon-chevron-up"></span> Back to top</a></p>

<h2 id="distributed-cache">Distributed Cache</h2>

<p>Flink offers a distributed cache, similar to Apache Hadoop, to make files locally accessible to parallel instances of user functions. This functionality can be used to share files that contain static external data such as dictionaries or machine-learned regression models.</p>

<p>The cache works as follows. A program registers a file or directory of a <a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/batch/connectors.html#reading-from-file-systems">local or remote filesystem such as HDFS or S3</a> under a specific name in its <code class="highlighter-rouge">ExecutionEnvironment</code> as a cached file. When the program is executed, Flink automatically copies the file or directory to the local filesystem of all workers. A user function can look up the file or directory under the specified name and access it from the worker’s local filesystem.</p>

<p>The distributed cache is used as follows:</p>

<div class="codetabs">
  <div data-lang="java">

    <p>Register the file or directory in the <code class="highlighter-rouge">ExecutionEnvironment</code>.</p>

    <figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="nc">ExecutionEnvironment</span> <span class="n">env</span> <span class="o">=</span> <span class="nc">ExecutionEnvironment</span><span class="o">.</span><span class="na">getExecutionEnvironment</span><span class="o">();</span>

<span class="c1">// register a file from HDFS</span>
<span class="n">env</span><span class="o">.</span><span class="na">registerCachedFile</span><span class="o">(</span><span class="s">"hdfs:///path/to/your/file"</span><span class="o">,</span> <span class="s">"hdfsFile"</span><span class="o">)</span>

<span class="c1">// register a local executable file (script, executable, ...)</span>
<span class="n">env</span><span class="o">.</span><span class="na">registerCachedFile</span><span class="o">(</span><span class="s">"file:///path/to/exec/file"</span><span class="o">,</span> <span class="s">"localExecFile"</span><span class="o">,</span> <span class="kc">true</span><span class="o">)</span>

<span class="c1">// define your program and execute</span>
<span class="o">...</span>
<span class="nc">DataSet</span><span class="o">&lt;</span><span class="nc">String</span><span class="o">&gt;</span> <span class="n">input</span> <span class="o">=</span> <span class="o">...</span>
<span class="nc">DataSet</span><span class="o">&lt;</span><span class="nc">Integer</span><span class="o">&gt;</span> <span class="n">result</span> <span class="o">=</span> <span class="n">input</span><span class="o">.</span><span class="na">map</span><span class="o">(</span><span class="k">new</span> <span class="nc">MyMapper</span><span class="o">());</span>
<span class="o">...</span>
<span class="n">env</span><span class="o">.</span><span class="na">execute</span><span class="o">();</span></code></pre></figure>

    <p>Access the cached file or directory in a user function (here a <code class="highlighter-rouge">MapFunction</code>). The function must extend a <a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/user_defined_functions.html#rich-functions">RichFunction</a> class because it needs access to the <code class="highlighter-rouge">RuntimeContext</code>.</p>

    <figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="c1">// extend a RichFunction to have access to the RuntimeContext</span>
<span class="kd">public</span> <span class="kd">final</span> <span class="kd">class</span> <span class="nc">MyMapper</span> <span class="kd">extends</span> <span class="nc">RichMapFunction</span><span class="o">&lt;</span><span class="nc">String</span><span class="o">,</span> <span class="nc">Integer</span><span class="o">&gt;</span> <span class="o">{</span>

    <span class="nd">@Override</span>
    <span class="kd">public</span> <span class="kt">void</span> <span class="nf">open</span><span class="o">(</span><span class="nc">Configuration</span> <span class="n">config</span><span class="o">)</span> <span class="o">{</span>

      <span class="c1">// access cached file via RuntimeContext and DistributedCache</span>
      <span class="nc">File</span> <span class="n">myFile</span> <span class="o">=</span> <span class="n">getRuntimeContext</span><span class="o">().</span><span class="na">getDistributedCache</span><span class="o">().</span><span class="na">getFile</span><span class="o">(</span><span class="s">"hdfsFile"</span><span class="o">);</span>
      <span class="c1">// read the file (or navigate the directory)</span>
      <span class="o">...</span>
    <span class="o">}</span>

    <span class="nd">@Override</span>
    <span class="kd">public</span> <span class="nc">Integer</span> <span class="nf">map</span><span class="o">(</span><span class="nc">String</span> <span class="n">value</span><span class="o">)</span> <span class="kd">throws</span> <span class="nc">Exception</span> <span class="o">{</span>
      <span class="c1">// use content of cached file</span>
      <span class="o">...</span>
    <span class="o">}</span>
<span class="o">}</span></code></pre></figure>

  </div>
  <div data-lang="scala">

    <p>Register the file or directory in the <code class="highlighter-rouge">ExecutionEnvironment</code>.</p>

    <figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="nv">env</span> <span class="k">=</span> <span class="nv">ExecutionEnvironment</span><span class="o">.</span><span class="py">getExecutionEnvironment</span>

<span class="c1">// register a file from HDFS</span>
<span class="nv">env</span><span class="o">.</span><span class="py">registerCachedFile</span><span class="o">(</span><span class="s">"hdfs:///path/to/your/file"</span><span class="o">,</span> <span class="s">"hdfsFile"</span><span class="o">)</span>

<span class="c1">// register a local executable file (script, executable, ...)</span>
<span class="nv">env</span><span class="o">.</span><span class="py">registerCachedFile</span><span class="o">(</span><span class="s">"file:///path/to/exec/file"</span><span class="o">,</span> <span class="s">"localExecFile"</span><span class="o">,</span> <span class="kc">true</span><span class="o">)</span>

<span class="c1">// define your program and execute</span>
<span class="o">...</span>
<span class="k">val</span> <span class="nv">input</span><span class="k">:</span> <span class="kt">DataSet</span><span class="o">[</span><span class="kt">String</span><span class="o">]</span> <span class="k">=</span> <span class="o">...</span>
<span class="k">val</span> <span class="nv">result</span><span class="k">:</span> <span class="kt">DataSet</span><span class="o">[</span><span class="kt">Integer</span><span class="o">]</span> <span class="k">=</span> <span class="nv">input</span><span class="o">.</span><span class="py">map</span><span class="o">(</span><span class="k">new</span> <span class="nc">MyMapper</span><span class="o">())</span>
<span class="o">...</span>
<span class="nv">env</span><span class="o">.</span><span class="py">execute</span><span class="o">()</span></code></pre></figure>

    <p>Access the cached file in a user function (here a <code class="highlighter-rouge">MapFunction</code>). The function must extend a <a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/user_defined_functions.html#rich-functions">RichFunction</a> class because it needs access to the <code class="highlighter-rouge">RuntimeContext</code>.</p>

    <figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="c1">// extend a RichFunction to have access to the RuntimeContext</span>
<span class="k">class</span> <span class="nc">MyMapper</span> <span class="k">extends</span> <span class="nc">RichMapFunction</span><span class="o">[</span><span class="kt">String</span>, <span class="kt">Int</span><span class="o">]</span> <span class="o">{</span>

  <span class="k">override</span> <span class="k">def</span> <span class="nf">open</span><span class="o">(</span><span class="n">config</span><span class="k">:</span> <span class="kt">Configuration</span><span class="o">)</span><span class="k">:</span> <span class="kt">Unit</span> <span class="o">=</span> <span class="o">{</span>

    <span class="c1">// access cached file via RuntimeContext and DistributedCache</span>
    <span class="k">val</span> <span class="nv">myFile</span><span class="k">:</span> <span class="kt">File</span> <span class="o">=</span> <span class="nv">getRuntimeContext</span><span class="o">.</span><span class="py">getDistributedCache</span><span class="o">.</span><span class="py">getFile</span><span class="o">(</span><span class="s">"hdfsFile"</span><span class="o">)</span>
    <span class="c1">// read the file (or navigate the directory)</span>
    <span class="o">...</span>
  <span class="o">}</span>

  <span class="k">override</span> <span class="k">def</span> <span class="nf">map</span><span class="o">(</span><span class="n">value</span><span class="k">:</span> <span class="kt">String</span><span class="o">)</span><span class="k">:</span> <span class="kt">Int</span> <span class="o">=</span> <span class="o">{</span>
    <span class="c1">// use content of cached file</span>
    <span class="o">...</span>
  <span class="o">}</span>
<span class="o">}</span></code></pre></figure>

  </div>
</div>

<p><a href="#top" class="top pull-right"><span class="glyphicon glyphicon-chevron-up"></span> Back to top</a></p>

<h2 id="passing-parameters-to-functions">Passing Parameters to Functions</h2>

<p>Parameters can be passed to functions using either the constructor or the <code class="highlighter-rouge">withParameters(Configuration)</code> method. The parameters are serialized as part of the function object and shipped to all parallel task instances.</p>

<h4 id="via-constructor">Via Constructor</h4>

<div class="codetabs">
  <div data-lang="java">

    <figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="nc">DataSet</span><span class="o">&lt;</span><span class="nc">Integer</span><span class="o">&gt;</span> <span class="n">toFilter</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="na">fromElements</span><span class="o">(</span><span class="mi">1</span><span class="o">,</span> <span class="mi">2</span><span class="o">,</span> <span class="mi">3</span><span class="o">);</span>

<span class="n">toFilter</span><span class="o">.</span><span class="na">filter</span><span class="o">(</span><span class="k">new</span> <span class="nc">MyFilter</span><span class="o">(</span><span class="mi">2</span><span class="o">));</span>

<span class="kd">private</span> <span class="kd">static</span> <span class="kd">class</span> <span class="nc">MyFilter</span> <span class="kd">implements</span> <span class="nc">FilterFunction</span><span class="o">&lt;</span><span class="nc">Integer</span><span class="o">&gt;</span> <span class="o">{</span>

  <span class="kd">private</span> <span class="kd">final</span> <span class="kt">int</span> <span class="n">limit</span><span class="o">;</span>

  <span class="kd">public</span> <span class="nf">MyFilter</span><span class="o">(</span><span class="kt">int</span> <span class="n">limit</span><span class="o">)</span> <span class="o">{</span>
    <span class="k">this</span><span class="o">.</span><span class="na">limit</span> <span class="o">=</span> <span class="n">limit</span><span class="o">;</span>
  <span class="o">}</span>

  <span class="nd">@Override</span>
  <span class="kd">public</span> <span class="kt">boolean</span> <span class="nf">filter</span><span class="o">(</span><span class="nc">Integer</span> <span class="n">value</span><span class="o">)</span> <span class="kd">throws</span> <span class="nc">Exception</span> <span class="o">{</span>
    <span class="k">return</span> <span class="n">value</span> <span class="o">&gt;</span> <span class="n">limit</span><span class="o">;</span>
  <span class="o">}</span>
<span class="o">}</span></code></pre></figure>

  </div>
  <div data-lang="scala">

    <figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="nv">toFilter</span> <span class="k">=</span> <span class="nv">env</span><span class="o">.</span><span class="py">fromElements</span><span class="o">(</span><span class="mi">1</span><span class="o">,</span> <span class="mi">2</span><span class="o">,</span> <span class="mi">3</span><span class="o">)</span>

<span class="nv">toFilter</span><span class="o">.</span><span class="py">filter</span><span class="o">(</span><span class="k">new</span> <span class="nc">MyFilter</span><span class="o">(</span><span class="mi">2</span><span class="o">))</span>

<span class="k">class</span> <span class="nc">MyFilter</span><span class="o">(</span><span class="n">limit</span><span class="k">:</span> <span class="kt">Int</span><span class="o">)</span> <span class="k">extends</span> <span class="nc">FilterFunction</span><span class="o">[</span><span class="kt">Int</span><span class="o">]</span> <span class="o">{</span>
  <span class="k">override</span> <span class="k">def</span> <span class="nf">filter</span><span class="o">(</span><span class="n">value</span><span class="k">:</span> <span class="kt">Int</span><span class="o">)</span><span class="k">:</span> <span class="kt">Boolean</span> <span class="o">=</span> <span class="o">{</span>
    <span class="n">value</span> <span class="o">&gt;</span> <span class="n">limit</span>
  <span class="o">}</span>
<span class="o">}</span></code></pre></figure>

  </div>
</div>

<h4 id="via-withparametersconfiguration">Via <code class="highlighter-rouge">withParameters(Configuration)</code></h4>

<p>This method takes a Configuration object as an argument, which will be passed to the <a href="//ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/user_defined_functions.html#rich-functions">rich function</a>’s <code class="highlighter-rouge">open()</code>
method. The Configuration object is a Map from String keys to different value types.</p>

<div class="codetabs">
  <div data-lang="java">

    <figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="nc">DataSet</span><span class="o">&lt;</span><span class="nc">Integer</span><span class="o">&gt;</span> <span class="n">toFilter</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="na">fromElements</span><span class="o">(</span><span class="mi">1</span><span class="o">,</span> <span class="mi">2</span><span class="o">,</span> <span class="mi">3</span><span class="o">);</span>

<span class="nc">Configuration</span> <span class="n">config</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">Configuration</span><span class="o">();</span>
<span class="n">config</span><span class="o">.</span><span class="na">setInteger</span><span class="o">(</span><span class="s">"limit"</span><span class="o">,</span> <span class="mi">2</span><span class="o">);</span>

<span class="n">toFilter</span><span class="o">.</span><span class="na">filter</span><span class="o">(</span><span class="k">new</span> <span class="nc">RichFilterFunction</span><span class="o">&lt;</span><span class="nc">Integer</span><span class="o">&gt;()</span> <span class="o">{</span>
    <span class="kd">private</span> <span class="kt">int</span> <span class="n">limit</span><span class="o">;</span>

    <span class="nd">@Override</span>
    <span class="kd">public</span> <span class="kt">void</span> <span class="nf">open</span><span class="o">(</span><span class="nc">Configuration</span> <span class="n">parameters</span><span class="o">)</span> <span class="kd">throws</span> <span class="nc">Exception</span> <span class="o">{</span>
      <span class="n">limit</span> <span class="o">=</span> <span class="n">parameters</span><span class="o">.</span><span class="na">getInteger</span><span class="o">(</span><span class="s">"limit"</span><span class="o">,</span> <span class="mi">0</span><span class="o">);</span>
    <span class="o">}</span>

    <span class="nd">@Override</span>
    <span class="kd">public</span> <span class="kt">boolean</span> <span class="nf">filter</span><span class="o">(</span><span class="nc">Integer</span> <span class="n">value</span><span class="o">)</span> <span class="kd">throws</span> <span class="nc">Exception</span> <span class="o">{</span>
      <span class="k">return</span> <span class="n">value</span> <span class="o">&gt;</span> <span class="n">limit</span><span class="o">;</span>
    <span class="o">}</span>
<span class="o">}).</span><span class="na">withParameters</span><span class="o">(</span><span class="n">config</span><span class="o">);</span></code></pre></figure>

  </div>
  <div data-lang="scala">

    <figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="nv">toFilter</span> <span class="k">=</span> <span class="nv">env</span><span class="o">.</span><span class="py">fromElements</span><span class="o">(</span><span class="mi">1</span><span class="o">,</span> <span class="mi">2</span><span class="o">,</span> <span class="mi">3</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">c</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Configuration</span><span class="o">()</span>
<span class="nv">c</span><span class="o">.</span><span class="py">setInteger</span><span class="o">(</span><span class="s">"limit"</span><span class="o">,</span> <span class="mi">2</span><span class="o">)</span>

<span class="nv">toFilter</span><span class="o">.</span><span class="py">filter</span><span class="o">(</span><span class="k">new</span> <span class="nc">RichFilterFunction</span><span class="o">[</span><span class="kt">Int</span><span class="o">]()</span> <span class="o">{</span>
    <span class="k">var</span> <span class="n">limit</span> <span class="k">=</span> <span class="mi">0</span>

    <span class="k">override</span> <span class="k">def</span> <span class="nf">open</span><span class="o">(</span><span class="n">config</span><span class="k">:</span> <span class="kt">Configuration</span><span class="o">)</span><span class="k">:</span> <span class="kt">Unit</span> <span class="o">=</span> <span class="o">{</span>
      <span class="n">limit</span> <span class="k">=</span> <span class="nv">config</span><span class="o">.</span><span class="py">getInteger</span><span class="o">(</span><span class="s">"limit"</span><span class="o">,</span> <span class="mi">0</span><span class="o">)</span>
    <span class="o">}</span>

    <span class="k">def</span> <span class="nf">filter</span><span class="o">(</span><span class="n">in</span><span class="k">:</span> <span class="kt">Int</span><span class="o">)</span><span class="k">:</span> <span class="kt">Boolean</span> <span class="o">=</span> <span class="o">{</span>
        <span class="n">in</span> <span class="o">&gt;</span> <span class="n">limit</span>
    <span class="o">}</span>
<span class="o">}).</span><span class="py">withParameters</span><span class="o">(</span><span class="n">c</span><span class="o">)</span></code></pre></figure>

  </div>
</div>

<h4 id="globally-via-the-executionconfig">Globally via the <code class="highlighter-rouge">ExecutionConfig</code></h4>

<p>Flink also allows to pass custom configuration values to the <code class="highlighter-rouge">ExecutionConfig</code> interface of the environment. Since the execution config is accessible in all (rich) user functions, the custom configuration will be available globally in all functions.</p>

<p><strong>Setting a custom global configuration</strong></p>

<div class="codetabs">
  <div data-lang="java">

    <figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="nc">Configuration</span> <span class="n">conf</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">Configuration</span><span class="o">();</span>
<span class="n">conf</span><span class="o">.</span><span class="na">setString</span><span class="o">(</span><span class="s">"mykey"</span><span class="o">,</span><span class="s">"myvalue"</span><span class="o">);</span>
<span class="kd">final</span> <span class="nc">ExecutionEnvironment</span> <span class="n">env</span> <span class="o">=</span> <span class="nc">ExecutionEnvironment</span><span class="o">.</span><span class="na">getExecutionEnvironment</span><span class="o">();</span>
<span class="n">env</span><span class="o">.</span><span class="na">getConfig</span><span class="o">().</span><span class="na">setGlobalJobParameters</span><span class="o">(</span><span class="n">conf</span><span class="o">);</span></code></pre></figure>

  </div>
  <div data-lang="scala">

    <figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="nv">env</span> <span class="k">=</span> <span class="nv">ExecutionEnvironment</span><span class="o">.</span><span class="py">getExecutionEnvironment</span>
<span class="k">val</span> <span class="nv">conf</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Configuration</span><span class="o">()</span>
<span class="nv">conf</span><span class="o">.</span><span class="py">setString</span><span class="o">(</span><span class="s">"mykey"</span><span class="o">,</span> <span class="s">"myvalue"</span><span class="o">)</span>
<span class="nv">env</span><span class="o">.</span><span class="py">getConfig</span><span class="o">.</span><span class="py">setGlobalJobParameters</span><span class="o">(</span><span class="n">conf</span><span class="o">)</span></code></pre></figure>

  </div>
</div>

<p>Please note that you can also pass a custom class extending the <code class="highlighter-rouge">ExecutionConfig.GlobalJobParameters</code> class as the global job parameters to the execution config. The interface allows to implement the <code class="highlighter-rouge">Map&lt;String, String&gt; toMap()</code> method which will in turn show the values from the configuration in the web frontend.</p>

<p><strong>Accessing values from the global configuration</strong></p>

<p>Objects in the global job parameters are accessible in many places in the system. All user functions implementing a <code class="highlighter-rouge">RichFunction</code> interface have access through the runtime context.</p>

<figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="kd">public</span> <span class="kd">static</span> <span class="kd">final</span> <span class="kd">class</span> <span class="nc">Tokenizer</span> <span class="kd">extends</span> <span class="nc">RichFlatMapFunction</span><span class="o">&lt;</span><span class="nc">String</span><span class="o">,</span> <span class="nc">Tuple2</span><span class="o">&lt;</span><span class="nc">String</span><span class="o">,</span> <span class="nc">Integer</span><span class="o">&gt;&gt;</span> <span class="o">{</span>

    <span class="kd">private</span> <span class="nc">String</span> <span class="n">mykey</span><span class="o">;</span>
    <span class="nd">@Override</span>
    <span class="kd">public</span> <span class="kt">void</span> <span class="nf">open</span><span class="o">(</span><span class="nc">Configuration</span> <span class="n">parameters</span><span class="o">)</span> <span class="kd">throws</span> <span class="nc">Exception</span> <span class="o">{</span>
      <span class="kd">super</span><span class="o">.</span><span class="na">open</span><span class="o">(</span><span class="n">parameters</span><span class="o">);</span>
      <span class="nc">ExecutionConfig</span><span class="o">.</span><span class="na">GlobalJobParameters</span> <span class="n">globalParams</span> <span class="o">=</span> <span class="n">getRuntimeContext</span><span class="o">().</span><span class="na">getExecutionConfig</span><span class="o">().</span><span class="na">getGlobalJobParameters</span><span class="o">();</span>
      <span class="nc">Configuration</span> <span class="n">globConf</span> <span class="o">=</span> <span class="o">(</span><span class="nc">Configuration</span><span class="o">)</span> <span class="n">globalParams</span><span class="o">;</span>
      <span class="n">mykey</span> <span class="o">=</span> <span class="n">globConf</span><span class="o">.</span><span class="na">getString</span><span class="o">(</span><span class="s">"mykey"</span><span class="o">,</span> <span class="kc">null</span><span class="o">);</span>
    <span class="o">}</span>
    <span class="c1">// ... more here ...</span></code></pre></figure>

<p><a href="#top" class="top pull-right"><span class="glyphicon glyphicon-chevron-up"></span> Back to top</a></p>



<div class="footer">
  <a href="https://cwiki.apache.org/confluence/display/FLINK/Flink+Translation+Specifications" target="_blank">
    
      想参与贡献翻译？
    
  </a>
</div>


        </div>
      </div>
    </div><!-- /.container -->

    <!-- default code tab -->
    <script>var defaultCodeTab = "";</script>

    <!-- jQuery (necessary for Bootstrap's JavaScript plugins) -->
    <script src="//ci.apache.org/projects/flink/flink-docs-release-1.12/page/js/jquery.min.js"></script>
    <!-- Include all compiled plugins (below), or include individual files as needed -->
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.4/js/bootstrap.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/anchor-js/3.1.0/anchor.min.js"></script>
    <script src="//ci.apache.org/projects/flink/flink-docs-release-1.12/page/js/flink.js"></script>

    <!-- Google Analytics -->
    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-52545728-1', 'auto');
      ga('send', 'pageview');
    </script>

    <!-- Disqus -->
    
  </body>
</html>
